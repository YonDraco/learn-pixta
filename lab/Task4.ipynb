{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4hsNFkRJMlB",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### git clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1Egnt-gE_Kt",
    "outputId": "1d697ca2-89a9-44b4-bb82-391da4e1c788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch-retinanet'...\n",
      "remote: Enumerating objects: 232, done.\u001b[K\n",
      "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 232 (delta 1), reused 1 (delta 0), pack-reused 226\u001b[K\n",
      "Receiving objects: 100% (232/232), 1.02 MiB | 15.54 MiB/s, done.\n",
      "Resolving deltas: 100% (116/116), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/yhenon/pytorch-retinanet.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "995gxddVJPNl",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "fzCwxaV3FbSd",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2288f80d-49c9-4f2c-c69e-6a080d391266",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "tk-dev is already the newest version (8.6.0+9).\n",
      "python-tk is already the newest version (2.7.17-1~18.04).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install tk-dev python-tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "0Y8HmcwIF1Ii",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e55be06d-4137-4563-f459-3b3055d59c45",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (2.0.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pycocotools) (1.21.5)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools) (3.2.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.0.7)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools) (3.10.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.15.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install pycocotools\n",
    "!pip install opencv-python\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bD3AYPc9JS4m",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### get datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "puZynpTxPyZT",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "d362469a-9d1a-4c98-c956-88b021d6d8a7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mKết quả truyền trực tuyến bị cắt bớt đến 5000 dòng cuối.\u001b[0m\n",
      " extracting: unlabeled2017/000000547603.jpg  \n",
      " extracting: unlabeled2017/000000194333.jpg  \n",
      " extracting: unlabeled2017/000000147084.jpg  \n",
      " extracting: unlabeled2017/000000254246.jpg  \n",
      " extracting: unlabeled2017/000000510188.jpg  \n",
      " extracting: unlabeled2017/000000057034.jpg  \n",
      " extracting: unlabeled2017/000000503265.jpg  \n",
      " extracting: unlabeled2017/000000288929.jpg  \n",
      " extracting: unlabeled2017/000000073443.jpg  \n",
      " extracting: unlabeled2017/000000199987.jpg  \n",
      " extracting: unlabeled2017/000000151326.jpg  \n",
      " extracting: unlabeled2017/000000244263.jpg  \n",
      " extracting: unlabeled2017/000000433094.jpg  \n",
      " extracting: unlabeled2017/000000124527.jpg  \n",
      " extracting: unlabeled2017/000000541104.jpg  \n",
      " extracting: unlabeled2017/000000184231.jpg  \n",
      " extracting: unlabeled2017/000000041539.jpg  \n",
      " extracting: unlabeled2017/000000533397.jpg  \n",
      " extracting: unlabeled2017/000000570383.jpg  \n",
      " extracting: unlabeled2017/000000205951.jpg  \n",
      " extracting: unlabeled2017/000000351219.jpg  \n",
      " extracting: unlabeled2017/000000203012.jpg  \n",
      " extracting: unlabeled2017/000000089235.jpg  \n",
      " extracting: unlabeled2017/000000490614.jpg  \n",
      " extracting: unlabeled2017/000000323323.jpg  \n",
      " extracting: unlabeled2017/000000577741.jpg  \n",
      " extracting: unlabeled2017/000000211315.jpg  \n",
      " extracting: unlabeled2017/000000357409.jpg  \n",
      " extracting: unlabeled2017/000000179096.jpg  \n",
      " extracting: unlabeled2017/000000428318.jpg  \n",
      " extracting: unlabeled2017/000000109170.jpg  \n",
      " extracting: unlabeled2017/000000293699.jpg  \n",
      " extracting: unlabeled2017/000000175349.jpg  \n",
      " extracting: unlabeled2017/000000115083.jpg  \n",
      " extracting: unlabeled2017/000000428388.jpg  \n",
      " extracting: unlabeled2017/000000189385.jpg  \n",
      " extracting: unlabeled2017/000000112185.jpg  \n",
      " extracting: unlabeled2017/000000364347.jpg  \n",
      " extracting: unlabeled2017/000000416505.jpg  \n",
      " extracting: unlabeled2017/000000531802.jpg  \n",
      " extracting: unlabeled2017/000000278233.jpg  \n",
      " extracting: unlabeled2017/000000121650.jpg  \n",
      " extracting: unlabeled2017/000000158523.jpg  \n",
      " extracting: unlabeled2017/000000066310.jpg  \n",
      " extracting: unlabeled2017/000000160425.jpg  \n",
      " extracting: unlabeled2017/000000323730.jpg  \n",
      " extracting: unlabeled2017/000000238830.jpg  \n",
      " extracting: unlabeled2017/000000137308.jpg  \n",
      " extracting: unlabeled2017/000000301112.jpg  \n",
      " extracting: unlabeled2017/000000381897.jpg  \n",
      " extracting: unlabeled2017/000000319550.jpg  \n",
      " extracting: unlabeled2017/000000276640.jpg  \n",
      " extracting: unlabeled2017/000000292129.jpg  \n",
      " extracting: unlabeled2017/000000020914.jpg  \n",
      " extracting: unlabeled2017/000000057307.jpg  \n",
      " extracting: unlabeled2017/000000308794.jpg  \n",
      " extracting: unlabeled2017/000000218396.jpg  \n",
      " extracting: unlabeled2017/000000124833.jpg  \n",
      " extracting: unlabeled2017/000000400665.jpg  \n",
      " extracting: unlabeled2017/000000353777.jpg  \n",
      " extracting: unlabeled2017/000000219052.jpg  \n",
      " extracting: unlabeled2017/000000344681.jpg  \n",
      " extracting: unlabeled2017/000000424031.jpg  \n",
      " extracting: unlabeled2017/000000283676.jpg  \n",
      " extracting: unlabeled2017/000000075642.jpg  \n",
      " extracting: unlabeled2017/000000276103.jpg  \n",
      " extracting: unlabeled2017/000000304032.jpg  \n",
      " extracting: unlabeled2017/000000274938.jpg  \n",
      " extracting: unlabeled2017/000000251536.jpg  \n",
      " extracting: unlabeled2017/000000084140.jpg  \n",
      " extracting: unlabeled2017/000000103085.jpg  \n",
      " extracting: unlabeled2017/000000143906.jpg  \n",
      " extracting: unlabeled2017/000000122042.jpg  \n",
      " extracting: unlabeled2017/000000529865.jpg  \n",
      " extracting: unlabeled2017/000000563463.jpg  \n",
      " extracting: unlabeled2017/000000366612.jpg  \n",
      " extracting: unlabeled2017/000000488770.jpg  \n",
      " extracting: unlabeled2017/000000488096.jpg  \n",
      " extracting: unlabeled2017/000000076272.jpg  \n",
      " extracting: unlabeled2017/000000448443.jpg  \n",
      " extracting: unlabeled2017/000000213014.jpg  \n",
      " extracting: unlabeled2017/000000502122.jpg  \n",
      " extracting: unlabeled2017/000000561041.jpg  \n",
      " extracting: unlabeled2017/000000157810.jpg  \n",
      " extracting: unlabeled2017/000000228202.jpg  \n",
      " extracting: unlabeled2017/000000144376.jpg  \n",
      " extracting: unlabeled2017/000000293984.jpg  \n",
      " extracting: unlabeled2017/000000206711.jpg  \n",
      " extracting: unlabeled2017/000000191222.jpg  \n",
      " extracting: unlabeled2017/000000580899.jpg  \n",
      " extracting: unlabeled2017/000000064734.jpg  \n",
      " extracting: unlabeled2017/000000146020.jpg  \n",
      " extracting: unlabeled2017/000000281269.jpg  \n",
      " extracting: unlabeled2017/000000474641.jpg  \n",
      " extracting: unlabeled2017/000000580422.jpg  \n",
      " extracting: unlabeled2017/000000513521.jpg  \n",
      " extracting: unlabeled2017/000000398670.jpg  \n",
      " extracting: unlabeled2017/000000101075.jpg  \n",
      " extracting: unlabeled2017/000000395474.jpg  \n",
      " extracting: unlabeled2017/000000574663.jpg  \n",
      " extracting: unlabeled2017/000000124987.jpg  \n",
      " extracting: unlabeled2017/000000357922.jpg  \n",
      " extracting: unlabeled2017/000000081376.jpg  \n",
      " extracting: unlabeled2017/000000024470.jpg  \n",
      " extracting: unlabeled2017/000000234156.jpg  \n",
      " extracting: unlabeled2017/000000543277.jpg  \n",
      " extracting: unlabeled2017/000000470405.jpg  \n",
      " extracting: unlabeled2017/000000162821.jpg  \n",
      " extracting: unlabeled2017/000000337485.jpg  \n",
      " extracting: unlabeled2017/000000458824.jpg  \n",
      " extracting: unlabeled2017/000000161995.jpg  \n",
      " extracting: unlabeled2017/000000457329.jpg  \n",
      " extracting: unlabeled2017/000000054061.jpg  \n",
      " extracting: unlabeled2017/000000290621.jpg  \n",
      " extracting: unlabeled2017/000000172656.jpg  \n",
      " extracting: unlabeled2017/000000529937.jpg  \n",
      " extracting: unlabeled2017/000000085995.jpg  \n",
      " extracting: unlabeled2017/000000348530.jpg  \n",
      " extracting: unlabeled2017/000000134719.jpg  \n",
      " extracting: unlabeled2017/000000222121.jpg  \n",
      " extracting: unlabeled2017/000000189914.jpg  \n",
      " extracting: unlabeled2017/000000002695.jpg  \n",
      " extracting: unlabeled2017/000000305579.jpg  \n",
      " extracting: unlabeled2017/000000134274.jpg  \n",
      " extracting: unlabeled2017/000000241864.jpg  \n",
      " extracting: unlabeled2017/000000337291.jpg  \n",
      " extracting: unlabeled2017/000000562159.jpg  \n",
      " extracting: unlabeled2017/000000106450.jpg  \n",
      " extracting: unlabeled2017/000000570127.jpg  \n",
      " extracting: unlabeled2017/000000388689.jpg  \n",
      " extracting: unlabeled2017/000000374315.jpg  \n",
      " extracting: unlabeled2017/000000451029.jpg  \n",
      " extracting: unlabeled2017/000000382858.jpg  \n",
      " extracting: unlabeled2017/000000387099.jpg  \n",
      " extracting: unlabeled2017/000000207552.jpg  \n",
      " extracting: unlabeled2017/000000103762.jpg  \n",
      " extracting: unlabeled2017/000000116513.jpg  \n",
      " extracting: unlabeled2017/000000159574.jpg  \n",
      " extracting: unlabeled2017/000000529113.jpg  \n",
      " extracting: unlabeled2017/000000030835.jpg  \n",
      " extracting: unlabeled2017/000000251992.jpg  \n",
      " extracting: unlabeled2017/000000217845.jpg  \n",
      " extracting: unlabeled2017/000000076832.jpg  \n",
      " extracting: unlabeled2017/000000407183.jpg  \n",
      " extracting: unlabeled2017/000000008410.jpg  \n",
      " extracting: unlabeled2017/000000290699.jpg  \n",
      " extracting: unlabeled2017/000000301237.jpg  \n",
      " extracting: unlabeled2017/000000070892.jpg  \n",
      " extracting: unlabeled2017/000000380114.jpg  \n",
      " extracting: unlabeled2017/000000345523.jpg  \n",
      " extracting: unlabeled2017/000000151634.jpg  \n",
      " extracting: unlabeled2017/000000278068.jpg  \n",
      " extracting: unlabeled2017/000000190309.jpg  \n",
      " extracting: unlabeled2017/000000401535.jpg  \n",
      " extracting: unlabeled2017/000000374358.jpg  \n",
      " extracting: unlabeled2017/000000513431.jpg  \n",
      " extracting: unlabeled2017/000000340112.jpg  \n",
      " extracting: unlabeled2017/000000067475.jpg  \n",
      " extracting: unlabeled2017/000000418022.jpg  \n",
      " extracting: unlabeled2017/000000430471.jpg  \n",
      " extracting: unlabeled2017/000000392135.jpg  \n",
      " extracting: unlabeled2017/000000270095.jpg  \n",
      " extracting: unlabeled2017/000000544208.jpg  \n",
      " extracting: unlabeled2017/000000266428.jpg  \n",
      " extracting: unlabeled2017/000000341654.jpg  \n",
      " extracting: unlabeled2017/000000167828.jpg  \n",
      " extracting: unlabeled2017/000000333853.jpg  \n",
      " extracting: unlabeled2017/000000047114.jpg  \n",
      " extracting: unlabeled2017/000000405774.jpg  \n",
      " extracting: unlabeled2017/000000237519.jpg  \n",
      " extracting: unlabeled2017/000000334072.jpg  \n",
      " extracting: unlabeled2017/000000494907.jpg  \n",
      " extracting: unlabeled2017/000000105081.jpg  \n",
      " extracting: unlabeled2017/000000290746.jpg  \n",
      " extracting: unlabeled2017/000000022379.jpg  \n",
      " extracting: unlabeled2017/000000165871.jpg  \n",
      " extracting: unlabeled2017/000000528146.jpg  \n",
      " extracting: unlabeled2017/000000023711.jpg  \n",
      " extracting: unlabeled2017/000000114102.jpg  \n",
      " extracting: unlabeled2017/000000039069.jpg  \n",
      " extracting: unlabeled2017/000000446775.jpg  \n",
      " extracting: unlabeled2017/000000416519.jpg  \n",
      " extracting: unlabeled2017/000000187445.jpg  \n",
      " extracting: unlabeled2017/000000528500.jpg  \n",
      " extracting: unlabeled2017/000000026455.jpg  \n",
      " extracting: unlabeled2017/000000003522.jpg  \n",
      " extracting: unlabeled2017/000000322782.jpg  \n",
      " extracting: unlabeled2017/000000049498.jpg  \n",
      " extracting: unlabeled2017/000000057724.jpg  \n",
      " extracting: unlabeled2017/000000505431.jpg  \n",
      " extracting: unlabeled2017/000000406365.jpg  \n",
      " extracting: unlabeled2017/000000519034.jpg  \n",
      " extracting: unlabeled2017/000000353045.jpg  \n",
      " extracting: unlabeled2017/000000064135.jpg  \n",
      " extracting: unlabeled2017/000000052058.jpg  \n",
      " extracting: unlabeled2017/000000441558.jpg  \n",
      " extracting: unlabeled2017/000000077977.jpg  \n",
      " extracting: unlabeled2017/000000395770.jpg  \n",
      " extracting: unlabeled2017/000000041631.jpg  \n",
      " extracting: unlabeled2017/000000170274.jpg  \n",
      " extracting: unlabeled2017/000000480775.jpg  \n",
      " extracting: unlabeled2017/000000271291.jpg  \n",
      " extracting: unlabeled2017/000000533679.jpg  \n",
      " extracting: unlabeled2017/000000297761.jpg  \n",
      " extracting: unlabeled2017/000000276665.jpg  \n",
      " extracting: unlabeled2017/000000176888.jpg  \n",
      " extracting: unlabeled2017/000000324323.jpg  \n",
      " extracting: unlabeled2017/000000106821.jpg  \n",
      " extracting: unlabeled2017/000000499981.jpg  \n",
      " extracting: unlabeled2017/000000306841.jpg  \n",
      " extracting: unlabeled2017/000000010947.jpg  \n",
      " extracting: unlabeled2017/000000315266.jpg  \n",
      " extracting: unlabeled2017/000000305232.jpg  \n",
      " extracting: unlabeled2017/000000237236.jpg  \n",
      " extracting: unlabeled2017/000000023394.jpg  \n",
      " extracting: unlabeled2017/000000208662.jpg  \n",
      " extracting: unlabeled2017/000000234496.jpg  \n",
      " extracting: unlabeled2017/000000081910.jpg  \n",
      " extracting: unlabeled2017/000000519284.jpg  \n",
      " extracting: unlabeled2017/000000089015.jpg  \n",
      " extracting: unlabeled2017/000000266090.jpg  \n",
      " extracting: unlabeled2017/000000549144.jpg  \n",
      " extracting: unlabeled2017/000000097424.jpg  \n",
      " extracting: unlabeled2017/000000353703.jpg  \n",
      " extracting: unlabeled2017/000000393878.jpg  \n",
      " extracting: unlabeled2017/000000220098.jpg  \n",
      " extracting: unlabeled2017/000000195823.jpg  \n",
      " extracting: unlabeled2017/000000253574.jpg  \n",
      " extracting: unlabeled2017/000000107029.jpg  \n",
      " extracting: unlabeled2017/000000049558.jpg  \n",
      " extracting: unlabeled2017/000000429950.jpg  \n",
      " extracting: unlabeled2017/000000161149.jpg  \n",
      " extracting: unlabeled2017/000000390639.jpg  \n",
      " extracting: unlabeled2017/000000574502.jpg  \n",
      " extracting: unlabeled2017/000000079877.jpg  \n",
      " extracting: unlabeled2017/000000418083.jpg  \n",
      " extracting: unlabeled2017/000000351611.jpg  \n",
      " extracting: unlabeled2017/000000219511.jpg  \n",
      " extracting: unlabeled2017/000000418118.jpg  \n",
      " extracting: unlabeled2017/000000196599.jpg  \n",
      " extracting: unlabeled2017/000000494362.jpg  \n",
      " extracting: unlabeled2017/000000025626.jpg  \n",
      " extracting: unlabeled2017/000000326996.jpg  \n",
      " extracting: unlabeled2017/000000024513.jpg  \n",
      " extracting: unlabeled2017/000000359850.jpg  \n",
      " extracting: unlabeled2017/000000186898.jpg  \n",
      " extracting: unlabeled2017/000000540197.jpg  \n",
      " extracting: unlabeled2017/000000018707.jpg  \n",
      " extracting: unlabeled2017/000000145478.jpg  \n",
      " extracting: unlabeled2017/000000526969.jpg  \n",
      " extracting: unlabeled2017/000000111345.jpg  \n",
      " extracting: unlabeled2017/000000011378.jpg  \n",
      " extracting: unlabeled2017/000000095530.jpg  \n",
      " extracting: unlabeled2017/000000520052.jpg  \n",
      " extracting: unlabeled2017/000000231913.jpg  \n",
      " extracting: unlabeled2017/000000131381.jpg  \n",
      " extracting: unlabeled2017/000000322033.jpg  \n",
      " extracting: unlabeled2017/000000208802.jpg  \n",
      " extracting: unlabeled2017/000000478012.jpg  \n",
      " extracting: unlabeled2017/000000545104.jpg  \n",
      " extracting: unlabeled2017/000000373799.jpg  \n",
      " extracting: unlabeled2017/000000112643.jpg  \n",
      " extracting: unlabeled2017/000000421257.jpg  \n",
      " extracting: unlabeled2017/000000206022.jpg  \n",
      " extracting: unlabeled2017/000000140806.jpg  \n",
      " extracting: unlabeled2017/000000080677.jpg  \n",
      " extracting: unlabeled2017/000000544359.jpg  \n",
      " extracting: unlabeled2017/000000404991.jpg  \n",
      " extracting: unlabeled2017/000000520949.jpg  \n",
      " extracting: unlabeled2017/000000423707.jpg  \n",
      " extracting: unlabeled2017/000000002790.jpg  \n",
      " extracting: unlabeled2017/000000449226.jpg  \n",
      " extracting: unlabeled2017/000000217392.jpg  \n",
      " extracting: unlabeled2017/000000452999.jpg  \n",
      " extracting: unlabeled2017/000000502355.jpg  \n",
      " extracting: unlabeled2017/000000203953.jpg  \n",
      " extracting: unlabeled2017/000000260568.jpg  \n",
      " extracting: unlabeled2017/000000352460.jpg  \n",
      " extracting: unlabeled2017/000000550210.jpg  \n",
      " extracting: unlabeled2017/000000458737.jpg  \n",
      " extracting: unlabeled2017/000000222485.jpg  \n",
      " extracting: unlabeled2017/000000058031.jpg  \n",
      " extracting: unlabeled2017/000000385197.jpg  \n",
      " extracting: unlabeled2017/000000291006.jpg  \n",
      " extracting: unlabeled2017/000000032503.jpg  \n",
      " extracting: unlabeled2017/000000139005.jpg  \n",
      " extracting: unlabeled2017/000000298774.jpg  \n",
      " extracting: unlabeled2017/000000384469.jpg  \n",
      " extracting: unlabeled2017/000000045044.jpg  \n",
      " extracting: unlabeled2017/000000055159.jpg  \n",
      " extracting: unlabeled2017/000000020346.jpg  \n",
      " extracting: unlabeled2017/000000542710.jpg  \n",
      " extracting: unlabeled2017/000000101993.jpg  \n",
      " extracting: unlabeled2017/000000486646.jpg  \n",
      " extracting: unlabeled2017/000000166238.jpg  \n",
      " extracting: unlabeled2017/000000128913.jpg  \n",
      " extracting: unlabeled2017/000000226548.jpg  \n",
      " extracting: unlabeled2017/000000557786.jpg  \n",
      " extracting: unlabeled2017/000000385357.jpg  \n",
      " extracting: unlabeled2017/000000426786.jpg  \n",
      " extracting: unlabeled2017/000000332491.jpg  \n",
      " extracting: unlabeled2017/000000471702.jpg  \n",
      " extracting: unlabeled2017/000000414467.jpg  \n",
      " extracting: unlabeled2017/000000314742.jpg  \n",
      " extracting: unlabeled2017/000000437042.jpg  \n",
      " extracting: unlabeled2017/000000110823.jpg  \n",
      " extracting: unlabeled2017/000000329031.jpg  \n",
      " extracting: unlabeled2017/000000324840.jpg  \n",
      " extracting: unlabeled2017/000000456055.jpg  \n",
      " extracting: unlabeled2017/000000052707.jpg  \n",
      " extracting: unlabeled2017/000000558620.jpg  \n",
      " extracting: unlabeled2017/000000086490.jpg  \n",
      " extracting: unlabeled2017/000000078759.jpg  \n",
      " extracting: unlabeled2017/000000236200.jpg  \n",
      " extracting: unlabeled2017/000000045161.jpg  \n",
      " extracting: unlabeled2017/000000538812.jpg  \n",
      " extracting: unlabeled2017/000000541501.jpg  \n",
      " extracting: unlabeled2017/000000155898.jpg  \n",
      " extracting: unlabeled2017/000000504360.jpg  \n",
      " extracting: unlabeled2017/000000378042.jpg  \n",
      " extracting: unlabeled2017/000000073032.jpg  \n",
      " extracting: unlabeled2017/000000493367.jpg  \n",
      " extracting: unlabeled2017/000000165450.jpg  \n",
      " extracting: unlabeled2017/000000456749.jpg  \n",
      " extracting: unlabeled2017/000000123740.jpg  \n",
      " extracting: unlabeled2017/000000137421.jpg  \n",
      " extracting: unlabeled2017/000000216660.jpg  \n",
      " extracting: unlabeled2017/000000474754.jpg  \n",
      " extracting: unlabeled2017/000000243065.jpg  \n",
      " extracting: unlabeled2017/000000095421.jpg  \n",
      " extracting: unlabeled2017/000000380028.jpg  \n",
      " extracting: unlabeled2017/000000427243.jpg  \n",
      " extracting: unlabeled2017/000000256007.jpg  \n",
      " extracting: unlabeled2017/000000355224.jpg  \n",
      " extracting: unlabeled2017/000000161558.jpg  \n",
      " extracting: unlabeled2017/000000117623.jpg  \n",
      " extracting: unlabeled2017/000000525411.jpg  \n",
      " extracting: unlabeled2017/000000548047.jpg  \n",
      " extracting: unlabeled2017/000000392691.jpg  \n",
      " extracting: unlabeled2017/000000369327.jpg  \n",
      " extracting: unlabeled2017/000000289601.jpg  \n",
      " extracting: unlabeled2017/000000339178.jpg  \n",
      " extracting: unlabeled2017/000000427106.jpg  \n",
      " extracting: unlabeled2017/000000444228.jpg  \n",
      " extracting: unlabeled2017/000000343731.jpg  \n",
      " extracting: unlabeled2017/000000260406.jpg  \n",
      " extracting: unlabeled2017/000000495045.jpg  \n",
      " extracting: unlabeled2017/000000049253.jpg  \n",
      " extracting: unlabeled2017/000000003408.jpg  \n",
      " extracting: unlabeled2017/000000573217.jpg  \n",
      " extracting: unlabeled2017/000000400287.jpg  \n",
      " extracting: unlabeled2017/000000526162.jpg  \n",
      " extracting: unlabeled2017/000000259876.jpg  \n",
      " extracting: unlabeled2017/000000327140.jpg  \n",
      " extracting: unlabeled2017/000000051118.jpg  \n",
      " extracting: unlabeled2017/000000527894.jpg  \n",
      " extracting: unlabeled2017/000000065709.jpg  \n",
      " extracting: unlabeled2017/000000266456.jpg  \n",
      " extracting: unlabeled2017/000000176566.jpg  \n",
      " extracting: unlabeled2017/000000551151.jpg  \n",
      " extracting: unlabeled2017/000000402725.jpg  \n",
      " extracting: unlabeled2017/000000134933.jpg  \n",
      " extracting: unlabeled2017/000000024665.jpg  \n",
      " extracting: unlabeled2017/000000434000.jpg  \n",
      " extracting: unlabeled2017/000000371852.jpg  \n",
      " extracting: unlabeled2017/000000274274.jpg  \n",
      " extracting: unlabeled2017/000000254264.jpg  \n",
      " extracting: unlabeled2017/000000092653.jpg  \n",
      " extracting: unlabeled2017/000000278429.jpg  \n",
      " extracting: unlabeled2017/000000167440.jpg  \n",
      " extracting: unlabeled2017/000000199316.jpg  \n",
      " extracting: unlabeled2017/000000477457.jpg  \n",
      " extracting: unlabeled2017/000000461381.jpg  \n",
      " extracting: unlabeled2017/000000315385.jpg  \n",
      " extracting: unlabeled2017/000000053880.jpg  \n",
      " extracting: unlabeled2017/000000129292.jpg  \n",
      " extracting: unlabeled2017/000000387380.jpg  \n",
      " extracting: unlabeled2017/000000370381.jpg  \n",
      " extracting: unlabeled2017/000000513235.jpg  \n",
      " extracting: unlabeled2017/000000354790.jpg  \n",
      " extracting: unlabeled2017/000000396353.jpg  \n",
      " extracting: unlabeled2017/000000344919.jpg  \n",
      " extracting: unlabeled2017/000000140212.jpg  \n",
      " extracting: unlabeled2017/000000152939.jpg  \n",
      " extracting: unlabeled2017/000000504759.jpg  \n",
      " extracting: unlabeled2017/000000164483.jpg  \n",
      " extracting: unlabeled2017/000000058974.jpg  \n",
      " extracting: unlabeled2017/000000564278.jpg  \n",
      " extracting: unlabeled2017/000000509667.jpg  \n",
      " extracting: unlabeled2017/000000351625.jpg  \n",
      " extracting: unlabeled2017/000000192374.jpg  \n",
      " extracting: unlabeled2017/000000472193.jpg  \n",
      " extracting: unlabeled2017/000000267949.jpg  \n",
      " extracting: unlabeled2017/000000239945.jpg  \n",
      " extracting: unlabeled2017/000000418411.jpg  \n",
      " extracting: unlabeled2017/000000321498.jpg  \n",
      " extracting: unlabeled2017/000000190050.jpg  \n",
      " extracting: unlabeled2017/000000329861.jpg  \n",
      " extracting: unlabeled2017/000000512888.jpg  \n",
      " extracting: unlabeled2017/000000043880.jpg  \n",
      " extracting: unlabeled2017/000000371721.jpg  \n",
      " extracting: unlabeled2017/000000301617.jpg  \n",
      " extracting: unlabeled2017/000000061135.jpg  \n",
      " extracting: unlabeled2017/000000044528.jpg  \n",
      " extracting: unlabeled2017/000000439231.jpg  \n",
      " extracting: unlabeled2017/000000210941.jpg  \n",
      " extracting: unlabeled2017/000000357657.jpg  \n",
      " extracting: unlabeled2017/000000276446.jpg  \n",
      " extracting: unlabeled2017/000000435980.jpg  \n",
      " extracting: unlabeled2017/000000156995.jpg  \n",
      " extracting: unlabeled2017/000000214611.jpg  \n",
      " extracting: unlabeled2017/000000129309.jpg  \n",
      " extracting: unlabeled2017/000000072488.jpg  \n",
      " extracting: unlabeled2017/000000135850.jpg  \n",
      " extracting: unlabeled2017/000000244696.jpg  \n",
      " extracting: unlabeled2017/000000533289.jpg  \n",
      " extracting: unlabeled2017/000000282119.jpg  \n",
      " extracting: unlabeled2017/000000274950.jpg  \n",
      " extracting: unlabeled2017/000000299919.jpg  \n",
      " extracting: unlabeled2017/000000165250.jpg  \n",
      " extracting: unlabeled2017/000000311727.jpg  \n",
      " extracting: unlabeled2017/000000321555.jpg  \n",
      " extracting: unlabeled2017/000000090269.jpg  \n",
      " extracting: unlabeled2017/000000336970.jpg  \n",
      " extracting: unlabeled2017/000000511697.jpg  \n",
      " extracting: unlabeled2017/000000216574.jpg  \n",
      " extracting: unlabeled2017/000000554242.jpg  \n",
      " extracting: unlabeled2017/000000521474.jpg  \n",
      " extracting: unlabeled2017/000000314811.jpg  \n",
      " extracting: unlabeled2017/000000054807.jpg  \n",
      " extracting: unlabeled2017/000000570357.jpg  \n",
      " extracting: unlabeled2017/000000384090.jpg  \n",
      " extracting: unlabeled2017/000000573592.jpg  \n",
      " extracting: unlabeled2017/000000277546.jpg  \n",
      " extracting: unlabeled2017/000000434443.jpg  \n",
      " extracting: unlabeled2017/000000302120.jpg  \n",
      " extracting: unlabeled2017/000000078094.jpg  \n",
      " extracting: unlabeled2017/000000101994.jpg  \n",
      " extracting: unlabeled2017/000000346756.jpg  \n",
      " extracting: unlabeled2017/000000435982.jpg  \n",
      " extracting: unlabeled2017/000000297553.jpg  \n",
      " extracting: unlabeled2017/000000479024.jpg  \n",
      " extracting: unlabeled2017/000000551765.jpg  \n",
      " extracting: unlabeled2017/000000230782.jpg  \n",
      " extracting: unlabeled2017/000000019701.jpg  \n",
      " extracting: unlabeled2017/000000147632.jpg  \n",
      " extracting: unlabeled2017/000000527614.jpg  \n",
      " extracting: unlabeled2017/000000235055.jpg  \n",
      " extracting: unlabeled2017/000000335431.jpg  \n",
      " extracting: unlabeled2017/000000531182.jpg  \n",
      " extracting: unlabeled2017/000000006526.jpg  \n",
      " extracting: unlabeled2017/000000460323.jpg  \n",
      " extracting: unlabeled2017/000000183282.jpg  \n",
      " extracting: unlabeled2017/000000177507.jpg  \n",
      " extracting: unlabeled2017/000000088373.jpg  \n",
      " extracting: unlabeled2017/000000464008.jpg  \n",
      " extracting: unlabeled2017/000000189252.jpg  \n",
      " extracting: unlabeled2017/000000372681.jpg  \n",
      " extracting: unlabeled2017/000000175508.jpg  \n",
      " extracting: unlabeled2017/000000153798.jpg  \n",
      " extracting: unlabeled2017/000000082639.jpg  \n",
      " extracting: unlabeled2017/000000070980.jpg  \n",
      " extracting: unlabeled2017/000000093450.jpg  \n",
      " extracting: unlabeled2017/000000235894.jpg  \n",
      " extracting: unlabeled2017/000000496863.jpg  \n",
      " extracting: unlabeled2017/000000473893.jpg  \n",
      " extracting: unlabeled2017/000000051406.jpg  \n",
      " extracting: unlabeled2017/000000336678.jpg  \n",
      " extracting: unlabeled2017/000000193999.jpg  \n",
      " extracting: unlabeled2017/000000172791.jpg  \n",
      " extracting: unlabeled2017/000000462919.jpg  \n",
      " extracting: unlabeled2017/000000376943.jpg  \n",
      " extracting: unlabeled2017/000000525324.jpg  \n",
      " extracting: unlabeled2017/000000142647.jpg  \n",
      " extracting: unlabeled2017/000000383476.jpg  \n",
      " extracting: unlabeled2017/000000327247.jpg  \n",
      " extracting: unlabeled2017/000000551911.jpg  \n",
      " extracting: unlabeled2017/000000121373.jpg  \n",
      " extracting: unlabeled2017/000000145579.jpg  \n",
      " extracting: unlabeled2017/000000496002.jpg  \n",
      " extracting: unlabeled2017/000000349452.jpg  \n",
      " extracting: unlabeled2017/000000082733.jpg  \n",
      " extracting: unlabeled2017/000000216380.jpg  \n",
      " extracting: unlabeled2017/000000403487.jpg  \n",
      " extracting: unlabeled2017/000000494397.jpg  \n",
      " extracting: unlabeled2017/000000158037.jpg  \n",
      " extracting: unlabeled2017/000000272244.jpg  \n",
      " extracting: unlabeled2017/000000258852.jpg  \n",
      " extracting: unlabeled2017/000000125046.jpg  \n",
      " extracting: unlabeled2017/000000318286.jpg  \n",
      " extracting: unlabeled2017/000000162785.jpg  \n",
      " extracting: unlabeled2017/000000384500.jpg  \n",
      " extracting: unlabeled2017/000000006434.jpg  \n",
      " extracting: unlabeled2017/000000244541.jpg  \n",
      " extracting: unlabeled2017/000000099541.jpg  \n",
      " extracting: unlabeled2017/000000253571.jpg  \n",
      " extracting: unlabeled2017/000000098386.jpg  \n",
      " extracting: unlabeled2017/000000265499.jpg  \n",
      " extracting: unlabeled2017/000000414291.jpg  \n",
      " extracting: unlabeled2017/000000035821.jpg  \n",
      " extracting: unlabeled2017/000000142003.jpg  \n",
      " extracting: unlabeled2017/000000481948.jpg  \n",
      " extracting: unlabeled2017/000000295301.jpg  \n",
      " extracting: unlabeled2017/000000155668.jpg  \n",
      " extracting: unlabeled2017/000000239897.jpg  \n",
      " extracting: unlabeled2017/000000397589.jpg  \n",
      " extracting: unlabeled2017/000000251570.jpg  \n",
      " extracting: unlabeled2017/000000340006.jpg  \n",
      " extracting: unlabeled2017/000000574129.jpg  \n",
      " extracting: unlabeled2017/000000026268.jpg  \n",
      " extracting: unlabeled2017/000000372867.jpg  \n",
      " extracting: unlabeled2017/000000188368.jpg  \n",
      " extracting: unlabeled2017/000000283245.jpg  \n",
      " extracting: unlabeled2017/000000383896.jpg  \n",
      " extracting: unlabeled2017/000000292965.jpg  \n",
      " extracting: unlabeled2017/000000415576.jpg  \n",
      " extracting: unlabeled2017/000000429596.jpg  \n",
      " extracting: unlabeled2017/000000222103.jpg  \n",
      " extracting: unlabeled2017/000000392979.jpg  \n",
      " extracting: unlabeled2017/000000167809.jpg  \n",
      " extracting: unlabeled2017/000000172321.jpg  \n",
      " extracting: unlabeled2017/000000128574.jpg  \n",
      " extracting: unlabeled2017/000000228502.jpg  \n",
      " extracting: unlabeled2017/000000228726.jpg  \n",
      " extracting: unlabeled2017/000000041695.jpg  \n",
      " extracting: unlabeled2017/000000155634.jpg  \n",
      " extracting: unlabeled2017/000000312570.jpg  \n",
      " extracting: unlabeled2017/000000499669.jpg  \n",
      " extracting: unlabeled2017/000000089218.jpg  \n",
      " extracting: unlabeled2017/000000082882.jpg  \n",
      " extracting: unlabeled2017/000000089455.jpg  \n",
      " extracting: unlabeled2017/000000152476.jpg  \n",
      " extracting: unlabeled2017/000000021539.jpg  \n",
      " extracting: unlabeled2017/000000298792.jpg  \n",
      " extracting: unlabeled2017/000000409357.jpg  \n",
      " extracting: unlabeled2017/000000273310.jpg  \n",
      " extracting: unlabeled2017/000000411553.jpg  \n",
      " extracting: unlabeled2017/000000384923.jpg  \n",
      " extracting: unlabeled2017/000000171247.jpg  \n",
      " extracting: unlabeled2017/000000531436.jpg  \n",
      " extracting: unlabeled2017/000000068443.jpg  \n",
      " extracting: unlabeled2017/000000299462.jpg  \n",
      " extracting: unlabeled2017/000000354676.jpg  \n",
      " extracting: unlabeled2017/000000325866.jpg  \n",
      " extracting: unlabeled2017/000000162572.jpg  \n",
      " extracting: unlabeled2017/000000173207.jpg  \n",
      " extracting: unlabeled2017/000000076105.jpg  \n",
      " extracting: unlabeled2017/000000185612.jpg  \n",
      " extracting: unlabeled2017/000000478104.jpg  \n",
      " extracting: unlabeled2017/000000402116.jpg  \n",
      " extracting: unlabeled2017/000000388150.jpg  \n",
      " extracting: unlabeled2017/000000158381.jpg  \n",
      " extracting: unlabeled2017/000000242038.jpg  \n",
      " extracting: unlabeled2017/000000368941.jpg  \n",
      " extracting: unlabeled2017/000000395566.jpg  \n",
      " extracting: unlabeled2017/000000494807.jpg  \n",
      " extracting: unlabeled2017/000000040155.jpg  \n",
      " extracting: unlabeled2017/000000509981.jpg  \n",
      " extracting: unlabeled2017/000000211292.jpg  \n",
      " extracting: unlabeled2017/000000569778.jpg  \n",
      " extracting: unlabeled2017/000000453368.jpg  \n",
      " extracting: unlabeled2017/000000130259.jpg  \n",
      " extracting: unlabeled2017/000000255081.jpg  \n",
      " extracting: unlabeled2017/000000190804.jpg  \n",
      " extracting: unlabeled2017/000000203181.jpg  \n",
      " extracting: unlabeled2017/000000296332.jpg  \n",
      " extracting: unlabeled2017/000000129797.jpg  \n",
      " extracting: unlabeled2017/000000108788.jpg  \n",
      " extracting: unlabeled2017/000000258387.jpg  \n",
      " extracting: unlabeled2017/000000081314.jpg  \n",
      " extracting: unlabeled2017/000000512333.jpg  \n",
      " extracting: unlabeled2017/000000558359.jpg  \n",
      " extracting: unlabeled2017/000000180882.jpg  \n",
      " extracting: unlabeled2017/000000415255.jpg  \n",
      " extracting: unlabeled2017/000000541068.jpg  \n",
      " extracting: unlabeled2017/000000224856.jpg  \n",
      " extracting: unlabeled2017/000000203316.jpg  \n",
      " extracting: unlabeled2017/000000280704.jpg  \n",
      " extracting: unlabeled2017/000000329984.jpg  \n",
      " extracting: unlabeled2017/000000065164.jpg  \n",
      " extracting: unlabeled2017/000000124625.jpg  \n",
      " extracting: unlabeled2017/000000248451.jpg  \n",
      " extracting: unlabeled2017/000000120134.jpg  \n",
      " extracting: unlabeled2017/000000370536.jpg  \n",
      " extracting: unlabeled2017/000000446017.jpg  \n",
      " extracting: unlabeled2017/000000180115.jpg  \n",
      " extracting: unlabeled2017/000000199045.jpg  \n",
      " extracting: unlabeled2017/000000367304.jpg  \n",
      " extracting: unlabeled2017/000000514621.jpg  \n",
      " extracting: unlabeled2017/000000484804.jpg  \n",
      " extracting: unlabeled2017/000000432747.jpg  \n",
      " extracting: unlabeled2017/000000348195.jpg  \n",
      " extracting: unlabeled2017/000000302502.jpg  \n",
      " extracting: unlabeled2017/000000383969.jpg  \n",
      " extracting: unlabeled2017/000000549343.jpg  \n",
      " extracting: unlabeled2017/000000425663.jpg  \n",
      " extracting: unlabeled2017/000000037224.jpg  \n",
      " extracting: unlabeled2017/000000267110.jpg  \n",
      " extracting: unlabeled2017/000000017001.jpg  \n",
      " extracting: unlabeled2017/000000014601.jpg  \n",
      " extracting: unlabeled2017/000000037691.jpg  \n",
      " extracting: unlabeled2017/000000433638.jpg  \n",
      " extracting: unlabeled2017/000000014482.jpg  \n",
      " extracting: unlabeled2017/000000415357.jpg  \n",
      " extracting: unlabeled2017/000000296379.jpg  \n",
      " extracting: unlabeled2017/000000334595.jpg  \n",
      " extracting: unlabeled2017/000000544990.jpg  \n",
      " extracting: unlabeled2017/000000165506.jpg  \n",
      " extracting: unlabeled2017/000000104135.jpg  \n",
      " extracting: unlabeled2017/000000267304.jpg  \n",
      " extracting: unlabeled2017/000000557202.jpg  \n",
      " extracting: unlabeled2017/000000409507.jpg  \n",
      " extracting: unlabeled2017/000000519947.jpg  \n",
      " extracting: unlabeled2017/000000254552.jpg  \n",
      " extracting: unlabeled2017/000000155228.jpg  \n",
      " extracting: unlabeled2017/000000477346.jpg  \n",
      " extracting: unlabeled2017/000000311875.jpg  \n",
      " extracting: unlabeled2017/000000496601.jpg  \n",
      " extracting: unlabeled2017/000000392449.jpg  \n",
      " extracting: unlabeled2017/000000261153.jpg  \n",
      " extracting: unlabeled2017/000000196604.jpg  \n",
      " extracting: unlabeled2017/000000210561.jpg  \n",
      " extracting: unlabeled2017/000000433599.jpg  \n",
      " extracting: unlabeled2017/000000087852.jpg  \n",
      " extracting: unlabeled2017/000000276790.jpg  \n",
      " extracting: unlabeled2017/000000425466.jpg  \n",
      " extracting: unlabeled2017/000000568539.jpg  \n",
      " extracting: unlabeled2017/000000070550.jpg  \n",
      " extracting: unlabeled2017/000000116835.jpg  \n",
      " extracting: unlabeled2017/000000055384.jpg  \n",
      " extracting: unlabeled2017/000000170889.jpg  \n",
      " extracting: unlabeled2017/000000037883.jpg  \n",
      " extracting: unlabeled2017/000000090530.jpg  \n",
      " extracting: unlabeled2017/000000043865.jpg  \n",
      " extracting: unlabeled2017/000000076620.jpg  \n",
      " extracting: unlabeled2017/000000086813.jpg  \n",
      " extracting: unlabeled2017/000000190761.jpg  \n",
      " extracting: unlabeled2017/000000181308.jpg  \n",
      " extracting: unlabeled2017/000000554758.jpg  \n",
      " extracting: unlabeled2017/000000240683.jpg  \n",
      " extracting: unlabeled2017/000000254453.jpg  \n",
      " extracting: unlabeled2017/000000489888.jpg  \n",
      " extracting: unlabeled2017/000000362047.jpg  \n",
      " extracting: unlabeled2017/000000419398.jpg  \n",
      " extracting: unlabeled2017/000000156358.jpg  \n",
      " extracting: unlabeled2017/000000177773.jpg  \n",
      " extracting: unlabeled2017/000000053810.jpg  \n",
      " extracting: unlabeled2017/000000413365.jpg  \n",
      " extracting: unlabeled2017/000000113359.jpg  \n",
      " extracting: unlabeled2017/000000515559.jpg  \n",
      " extracting: unlabeled2017/000000558856.jpg  \n",
      " extracting: unlabeled2017/000000230337.jpg  \n",
      " extracting: unlabeled2017/000000327082.jpg  \n",
      " extracting: unlabeled2017/000000158045.jpg  \n",
      " extracting: unlabeled2017/000000296757.jpg  \n",
      " extracting: unlabeled2017/000000106966.jpg  \n",
      " extracting: unlabeled2017/000000339093.jpg  \n",
      " extracting: unlabeled2017/000000452426.jpg  \n",
      " extracting: unlabeled2017/000000567594.jpg  \n",
      " extracting: unlabeled2017/000000350890.jpg  \n",
      " extracting: unlabeled2017/000000238710.jpg  \n",
      " extracting: unlabeled2017/000000260529.jpg  \n",
      " extracting: unlabeled2017/000000241936.jpg  \n",
      " extracting: unlabeled2017/000000070806.jpg  \n",
      " extracting: unlabeled2017/000000031291.jpg  \n",
      " extracting: unlabeled2017/000000076061.jpg  \n",
      " extracting: unlabeled2017/000000162335.jpg  \n",
      " extracting: unlabeled2017/000000438343.jpg  \n",
      " extracting: unlabeled2017/000000249015.jpg  \n",
      " extracting: unlabeled2017/000000425197.jpg  \n",
      " extracting: unlabeled2017/000000244009.jpg  \n",
      " extracting: unlabeled2017/000000167424.jpg  \n",
      " extracting: unlabeled2017/000000200819.jpg  \n",
      " extracting: unlabeled2017/000000211037.jpg  \n",
      " extracting: unlabeled2017/000000362325.jpg  \n",
      " extracting: unlabeled2017/000000360257.jpg  \n",
      " extracting: unlabeled2017/000000433553.jpg  \n",
      " extracting: unlabeled2017/000000180697.jpg  \n",
      " extracting: unlabeled2017/000000566131.jpg  \n",
      " extracting: unlabeled2017/000000555821.jpg  \n",
      " extracting: unlabeled2017/000000353118.jpg  \n",
      " extracting: unlabeled2017/000000125864.jpg  \n",
      " extracting: unlabeled2017/000000498750.jpg  \n",
      " extracting: unlabeled2017/000000136393.jpg  \n",
      " extracting: unlabeled2017/000000481414.jpg  \n",
      " extracting: unlabeled2017/000000580519.jpg  \n",
      " extracting: unlabeled2017/000000418758.jpg  \n",
      " extracting: unlabeled2017/000000533361.jpg  \n",
      " extracting: unlabeled2017/000000389764.jpg  \n",
      " extracting: unlabeled2017/000000072227.jpg  \n",
      " extracting: unlabeled2017/000000439503.jpg  \n",
      " extracting: unlabeled2017/000000102884.jpg  \n",
      " extracting: unlabeled2017/000000445905.jpg  \n",
      " extracting: unlabeled2017/000000259679.jpg  \n",
      " extracting: unlabeled2017/000000564919.jpg  \n",
      " extracting: unlabeled2017/000000006934.jpg  \n",
      " extracting: unlabeled2017/000000053007.jpg  \n",
      " extracting: unlabeled2017/000000334933.jpg  \n",
      " extracting: unlabeled2017/000000543794.jpg  \n",
      " extracting: unlabeled2017/000000214343.jpg  \n",
      " extracting: unlabeled2017/000000079519.jpg  \n",
      " extracting: unlabeled2017/000000113881.jpg  \n",
      " extracting: unlabeled2017/000000286743.jpg  \n",
      " extracting: unlabeled2017/000000223539.jpg  \n",
      " extracting: unlabeled2017/000000240630.jpg  \n",
      " extracting: unlabeled2017/000000340533.jpg  \n",
      " extracting: unlabeled2017/000000165728.jpg  \n",
      " extracting: unlabeled2017/000000284635.jpg  \n",
      " extracting: unlabeled2017/000000466258.jpg  \n",
      " extracting: unlabeled2017/000000181994.jpg  \n",
      " extracting: unlabeled2017/000000138647.jpg  \n",
      " extracting: unlabeled2017/000000450602.jpg  \n",
      " extracting: unlabeled2017/000000181521.jpg  \n",
      " extracting: unlabeled2017/000000035659.jpg  \n",
      " extracting: unlabeled2017/000000024979.jpg  \n",
      " extracting: unlabeled2017/000000002183.jpg  \n",
      " extracting: unlabeled2017/000000236334.jpg  \n",
      " extracting: unlabeled2017/000000350846.jpg  \n",
      " extracting: unlabeled2017/000000565770.jpg  \n",
      " extracting: unlabeled2017/000000348777.jpg  \n",
      " extracting: unlabeled2017/000000137951.jpg  \n",
      " extracting: unlabeled2017/000000564039.jpg  \n",
      " extracting: unlabeled2017/000000409505.jpg  \n",
      " extracting: unlabeled2017/000000401941.jpg  \n",
      " extracting: unlabeled2017/000000378792.jpg  \n",
      " extracting: unlabeled2017/000000055662.jpg  \n",
      " extracting: unlabeled2017/000000576437.jpg  \n",
      " extracting: unlabeled2017/000000354730.jpg  \n",
      " extracting: unlabeled2017/000000170707.jpg  \n",
      " extracting: unlabeled2017/000000010668.jpg  \n",
      " extracting: unlabeled2017/000000110686.jpg  \n",
      " extracting: unlabeled2017/000000107856.jpg  \n",
      " extracting: unlabeled2017/000000158803.jpg  \n",
      " extracting: unlabeled2017/000000053398.jpg  \n",
      " extracting: unlabeled2017/000000377325.jpg  \n",
      " extracting: unlabeled2017/000000507883.jpg  \n",
      " extracting: unlabeled2017/000000434120.jpg  \n",
      " extracting: unlabeled2017/000000198926.jpg  \n",
      " extracting: unlabeled2017/000000049634.jpg  \n",
      " extracting: unlabeled2017/000000372815.jpg  \n",
      " extracting: unlabeled2017/000000555149.jpg  \n",
      " extracting: unlabeled2017/000000300364.jpg  \n",
      " extracting: unlabeled2017/000000559007.jpg  \n",
      " extracting: unlabeled2017/000000171509.jpg  \n",
      " extracting: unlabeled2017/000000396955.jpg  \n",
      " extracting: unlabeled2017/000000165321.jpg  \n",
      " extracting: unlabeled2017/000000225802.jpg  \n",
      " extracting: unlabeled2017/000000350698.jpg  \n",
      " extracting: unlabeled2017/000000040566.jpg  \n",
      " extracting: unlabeled2017/000000317497.jpg  \n",
      " extracting: unlabeled2017/000000058215.jpg  \n",
      " extracting: unlabeled2017/000000552920.jpg  \n",
      " extracting: unlabeled2017/000000526516.jpg  \n",
      " extracting: unlabeled2017/000000164546.jpg  \n",
      " extracting: unlabeled2017/000000255528.jpg  \n",
      " extracting: unlabeled2017/000000313708.jpg  \n",
      " extracting: unlabeled2017/000000314231.jpg  \n",
      " extracting: unlabeled2017/000000222373.jpg  \n",
      " extracting: unlabeled2017/000000112520.jpg  \n",
      " extracting: unlabeled2017/000000299037.jpg  \n",
      " extracting: unlabeled2017/000000209298.jpg  \n",
      " extracting: unlabeled2017/000000160758.jpg  \n",
      " extracting: unlabeled2017/000000545723.jpg  \n",
      " extracting: unlabeled2017/000000115366.jpg  \n",
      " extracting: unlabeled2017/000000370807.jpg  \n",
      " extracting: unlabeled2017/000000114417.jpg  \n",
      " extracting: unlabeled2017/000000313392.jpg  \n",
      " extracting: unlabeled2017/000000124730.jpg  \n",
      " extracting: unlabeled2017/000000557485.jpg  \n",
      " extracting: unlabeled2017/000000339519.jpg  \n",
      " extracting: unlabeled2017/000000323009.jpg  \n",
      " extracting: unlabeled2017/000000106135.jpg  \n",
      " extracting: unlabeled2017/000000368914.jpg  \n",
      " extracting: unlabeled2017/000000103410.jpg  \n",
      " extracting: unlabeled2017/000000083064.jpg  \n",
      " extracting: unlabeled2017/000000307277.jpg  \n",
      " extracting: unlabeled2017/000000015820.jpg  \n",
      " extracting: unlabeled2017/000000507640.jpg  \n",
      " extracting: unlabeled2017/000000342687.jpg  \n",
      " extracting: unlabeled2017/000000388379.jpg  \n",
      " extracting: unlabeled2017/000000522289.jpg  \n",
      " extracting: unlabeled2017/000000456018.jpg  \n",
      " extracting: unlabeled2017/000000201803.jpg  \n",
      " extracting: unlabeled2017/000000543997.jpg  \n",
      " extracting: unlabeled2017/000000283663.jpg  \n",
      " extracting: unlabeled2017/000000107300.jpg  \n",
      " extracting: unlabeled2017/000000190459.jpg  \n",
      " extracting: unlabeled2017/000000514040.jpg  \n",
      " extracting: unlabeled2017/000000166393.jpg  \n",
      " extracting: unlabeled2017/000000071762.jpg  \n",
      " extracting: unlabeled2017/000000269155.jpg  \n",
      " extracting: unlabeled2017/000000042605.jpg  \n",
      " extracting: unlabeled2017/000000414044.jpg  \n",
      " extracting: unlabeled2017/000000278471.jpg  \n",
      " extracting: unlabeled2017/000000162440.jpg  \n",
      " extracting: unlabeled2017/000000404609.jpg  \n",
      " extracting: unlabeled2017/000000221741.jpg  \n",
      " extracting: unlabeled2017/000000079504.jpg  \n",
      " extracting: unlabeled2017/000000099190.jpg  \n",
      " extracting: unlabeled2017/000000369448.jpg  \n",
      " extracting: unlabeled2017/000000561768.jpg  \n",
      " extracting: unlabeled2017/000000115532.jpg  \n",
      " extracting: unlabeled2017/000000360918.jpg  \n",
      " extracting: unlabeled2017/000000085414.jpg  \n",
      " extracting: unlabeled2017/000000359739.jpg  \n",
      " extracting: unlabeled2017/000000298202.jpg  \n",
      " extracting: unlabeled2017/000000317273.jpg  \n",
      " extracting: unlabeled2017/000000015832.jpg  \n",
      " extracting: unlabeled2017/000000215802.jpg  \n",
      " extracting: unlabeled2017/000000198824.jpg  \n",
      " extracting: unlabeled2017/000000182216.jpg  \n",
      " extracting: unlabeled2017/000000473192.jpg  \n",
      " extracting: unlabeled2017/000000302023.jpg  \n",
      " extracting: unlabeled2017/000000434153.jpg  \n",
      " extracting: unlabeled2017/000000323452.jpg  \n",
      " extracting: unlabeled2017/000000176636.jpg  \n",
      " extracting: unlabeled2017/000000161564.jpg  \n",
      " extracting: unlabeled2017/000000431360.jpg  \n",
      " extracting: unlabeled2017/000000556663.jpg  \n",
      " extracting: unlabeled2017/000000303437.jpg  \n",
      " extracting: unlabeled2017/000000534704.jpg  \n",
      " extracting: unlabeled2017/000000472661.jpg  \n",
      " extracting: unlabeled2017/000000333577.jpg  \n",
      " extracting: unlabeled2017/000000049510.jpg  \n",
      " extracting: unlabeled2017/000000095531.jpg  \n",
      " extracting: unlabeled2017/000000237637.jpg  \n",
      " extracting: unlabeled2017/000000230950.jpg  \n",
      " extracting: unlabeled2017/000000001133.jpg  \n",
      " extracting: unlabeled2017/000000185659.jpg  \n",
      " extracting: unlabeled2017/000000402138.jpg  \n",
      " extracting: unlabeled2017/000000451480.jpg  \n",
      " extracting: unlabeled2017/000000548295.jpg  \n",
      " extracting: unlabeled2017/000000298497.jpg  \n",
      " extracting: unlabeled2017/000000375834.jpg  \n",
      " extracting: unlabeled2017/000000306438.jpg  \n",
      " extracting: unlabeled2017/000000524122.jpg  \n",
      " extracting: unlabeled2017/000000193558.jpg  \n",
      " extracting: unlabeled2017/000000555930.jpg  \n",
      " extracting: unlabeled2017/000000244449.jpg  \n",
      " extracting: unlabeled2017/000000327968.jpg  \n",
      " extracting: unlabeled2017/000000417486.jpg  \n",
      " extracting: unlabeled2017/000000503995.jpg  \n",
      " extracting: unlabeled2017/000000506477.jpg  \n",
      " extracting: unlabeled2017/000000051886.jpg  \n",
      " extracting: unlabeled2017/000000327107.jpg  \n",
      " extracting: unlabeled2017/000000005329.jpg  \n",
      " extracting: unlabeled2017/000000228668.jpg  \n",
      " extracting: unlabeled2017/000000451992.jpg  \n",
      " extracting: unlabeled2017/000000151923.jpg  \n",
      " extracting: unlabeled2017/000000174120.jpg  \n",
      " extracting: unlabeled2017/000000415467.jpg  \n",
      " extracting: unlabeled2017/000000110910.jpg  \n",
      " extracting: unlabeled2017/000000412494.jpg  \n",
      " extracting: unlabeled2017/000000011232.jpg  \n",
      " extracting: unlabeled2017/000000023410.jpg  \n",
      " extracting: unlabeled2017/000000456034.jpg  \n",
      " extracting: unlabeled2017/000000530418.jpg  \n",
      " extracting: unlabeled2017/000000194915.jpg  \n",
      " extracting: unlabeled2017/000000474636.jpg  \n",
      " extracting: unlabeled2017/000000051679.jpg  \n",
      " extracting: unlabeled2017/000000313333.jpg  \n",
      " extracting: unlabeled2017/000000577156.jpg  \n",
      " extracting: unlabeled2017/000000107038.jpg  \n",
      " extracting: unlabeled2017/000000133618.jpg  \n",
      " extracting: unlabeled2017/000000024004.jpg  \n",
      " extracting: unlabeled2017/000000397928.jpg  \n",
      " extracting: unlabeled2017/000000076395.jpg  \n",
      " extracting: unlabeled2017/000000510932.jpg  \n",
      " extracting: unlabeled2017/000000423716.jpg  \n",
      " extracting: unlabeled2017/000000314312.jpg  \n",
      " extracting: unlabeled2017/000000020474.jpg  \n",
      " extracting: unlabeled2017/000000010406.jpg  \n",
      " extracting: unlabeled2017/000000024992.jpg  \n",
      " extracting: unlabeled2017/000000523844.jpg  \n",
      " extracting: unlabeled2017/000000327593.jpg  \n",
      " extracting: unlabeled2017/000000501265.jpg  \n",
      " extracting: unlabeled2017/000000119912.jpg  \n",
      " extracting: unlabeled2017/000000015608.jpg  \n",
      " extracting: unlabeled2017/000000138665.jpg  \n",
      " extracting: unlabeled2017/000000560556.jpg  \n",
      " extracting: unlabeled2017/000000081849.jpg  \n",
      " extracting: unlabeled2017/000000463121.jpg  \n",
      " extracting: unlabeled2017/000000227148.jpg  \n",
      " extracting: unlabeled2017/000000435407.jpg  \n",
      " extracting: unlabeled2017/000000381411.jpg  \n",
      " extracting: unlabeled2017/000000265683.jpg  \n",
      " extracting: unlabeled2017/000000234392.jpg  \n",
      " extracting: unlabeled2017/000000572863.jpg  \n",
      " extracting: unlabeled2017/000000096409.jpg  \n",
      " extracting: unlabeled2017/000000534398.jpg  \n",
      " extracting: unlabeled2017/000000118136.jpg  \n",
      " extracting: unlabeled2017/000000218400.jpg  \n",
      " extracting: unlabeled2017/000000217256.jpg  \n",
      " extracting: unlabeled2017/000000421114.jpg  \n",
      " extracting: unlabeled2017/000000029232.jpg  \n",
      " extracting: unlabeled2017/000000207399.jpg  \n",
      " extracting: unlabeled2017/000000533776.jpg  \n",
      " extracting: unlabeled2017/000000359044.jpg  \n",
      " extracting: unlabeled2017/000000271798.jpg  \n",
      " extracting: unlabeled2017/000000077040.jpg  \n",
      " extracting: unlabeled2017/000000412122.jpg  \n",
      " extracting: unlabeled2017/000000362630.jpg  \n",
      " extracting: unlabeled2017/000000180461.jpg  \n",
      " extracting: unlabeled2017/000000402374.jpg  \n",
      " extracting: unlabeled2017/000000149998.jpg  \n",
      " extracting: unlabeled2017/000000208273.jpg  \n",
      " extracting: unlabeled2017/000000223843.jpg  \n",
      " extracting: unlabeled2017/000000500835.jpg  \n",
      " extracting: unlabeled2017/000000477063.jpg  \n",
      " extracting: unlabeled2017/000000054353.jpg  \n",
      " extracting: unlabeled2017/000000569210.jpg  \n",
      " extracting: unlabeled2017/000000088747.jpg  \n",
      " extracting: unlabeled2017/000000197062.jpg  \n",
      " extracting: unlabeled2017/000000067460.jpg  \n",
      " extracting: unlabeled2017/000000259070.jpg  \n",
      " extracting: unlabeled2017/000000383086.jpg  \n",
      " extracting: unlabeled2017/000000177885.jpg  \n",
      " extracting: unlabeled2017/000000354137.jpg  \n",
      " extracting: unlabeled2017/000000250015.jpg  \n",
      " extracting: unlabeled2017/000000197332.jpg  \n",
      " extracting: unlabeled2017/000000274553.jpg  \n",
      " extracting: unlabeled2017/000000375511.jpg  \n",
      " extracting: unlabeled2017/000000524807.jpg  \n",
      " extracting: unlabeled2017/000000505634.jpg  \n",
      " extracting: unlabeled2017/000000443105.jpg  \n",
      " extracting: unlabeled2017/000000219530.jpg  \n",
      " extracting: unlabeled2017/000000457014.jpg  \n",
      " extracting: unlabeled2017/000000475684.jpg  \n",
      " extracting: unlabeled2017/000000335583.jpg  \n",
      " extracting: unlabeled2017/000000167138.jpg  \n",
      " extracting: unlabeled2017/000000133992.jpg  \n",
      " extracting: unlabeled2017/000000131791.jpg  \n",
      " extracting: unlabeled2017/000000044223.jpg  \n",
      " extracting: unlabeled2017/000000193184.jpg  \n",
      " extracting: unlabeled2017/000000396571.jpg  \n",
      " extracting: unlabeled2017/000000048766.jpg  \n",
      " extracting: unlabeled2017/000000309839.jpg  \n",
      " extracting: unlabeled2017/000000001823.jpg  \n",
      " extracting: unlabeled2017/000000263206.jpg  \n",
      " extracting: unlabeled2017/000000162368.jpg  \n",
      " extracting: unlabeled2017/000000078731.jpg  \n",
      " extracting: unlabeled2017/000000233086.jpg  \n",
      " extracting: unlabeled2017/000000346224.jpg  \n",
      " extracting: unlabeled2017/000000333499.jpg  \n",
      " extracting: unlabeled2017/000000438207.jpg  \n",
      " extracting: unlabeled2017/000000214738.jpg  \n",
      " extracting: unlabeled2017/000000400136.jpg  \n",
      " extracting: unlabeled2017/000000295930.jpg  \n",
      " extracting: unlabeled2017/000000361532.jpg  \n",
      " extracting: unlabeled2017/000000043317.jpg  \n",
      " extracting: unlabeled2017/000000409902.jpg  \n",
      " extracting: unlabeled2017/000000142424.jpg  \n",
      " extracting: unlabeled2017/000000333620.jpg  \n",
      " extracting: unlabeled2017/000000483063.jpg  \n",
      " extracting: unlabeled2017/000000271885.jpg  \n",
      " extracting: unlabeled2017/000000235766.jpg  \n",
      " extracting: unlabeled2017/000000061544.jpg  \n",
      " extracting: unlabeled2017/000000043315.jpg  \n",
      " extracting: unlabeled2017/000000013871.jpg  \n",
      " extracting: unlabeled2017/000000550163.jpg  \n",
      " extracting: unlabeled2017/000000310100.jpg  \n",
      " extracting: unlabeled2017/000000526869.jpg  \n",
      " extracting: unlabeled2017/000000303364.jpg  \n",
      " extracting: unlabeled2017/000000130509.jpg  \n",
      " extracting: unlabeled2017/000000423466.jpg  \n",
      " extracting: unlabeled2017/000000132396.jpg  \n",
      " extracting: unlabeled2017/000000387346.jpg  \n",
      " extracting: unlabeled2017/000000567217.jpg  \n",
      " extracting: unlabeled2017/000000476794.jpg  \n",
      " extracting: unlabeled2017/000000269762.jpg  \n",
      " extracting: unlabeled2017/000000486806.jpg  \n",
      " extracting: unlabeled2017/000000032878.jpg  \n",
      " extracting: unlabeled2017/000000534435.jpg  \n",
      " extracting: unlabeled2017/000000064917.jpg  \n",
      " extracting: unlabeled2017/000000448307.jpg  \n",
      " extracting: unlabeled2017/000000547812.jpg  \n",
      " extracting: unlabeled2017/000000134762.jpg  \n",
      " extracting: unlabeled2017/000000156584.jpg  \n",
      " extracting: unlabeled2017/000000407697.jpg  \n",
      " extracting: unlabeled2017/000000576670.jpg  \n",
      " extracting: unlabeled2017/000000074768.jpg  \n",
      " extracting: unlabeled2017/000000500550.jpg  \n",
      " extracting: unlabeled2017/000000506970.jpg  \n",
      " extracting: unlabeled2017/000000471826.jpg  \n",
      " extracting: unlabeled2017/000000474365.jpg  \n",
      " extracting: unlabeled2017/000000189185.jpg  \n",
      " extracting: unlabeled2017/000000069610.jpg  \n",
      " extracting: unlabeled2017/000000042390.jpg  \n",
      " extracting: unlabeled2017/000000475747.jpg  \n",
      " extracting: unlabeled2017/000000318487.jpg  \n",
      " extracting: unlabeled2017/000000392451.jpg  \n",
      " extracting: unlabeled2017/000000209447.jpg  \n",
      " extracting: unlabeled2017/000000253443.jpg  \n",
      " extracting: unlabeled2017/000000111614.jpg  \n",
      " extracting: unlabeled2017/000000222249.jpg  \n",
      " extracting: unlabeled2017/000000080403.jpg  \n",
      " extracting: unlabeled2017/000000548213.jpg  \n",
      " extracting: unlabeled2017/000000197991.jpg  \n",
      " extracting: unlabeled2017/000000514530.jpg  \n",
      " extracting: unlabeled2017/000000508188.jpg  \n",
      " extracting: unlabeled2017/000000390256.jpg  \n",
      " extracting: unlabeled2017/000000106141.jpg  \n",
      " extracting: unlabeled2017/000000376633.jpg  \n",
      " extracting: unlabeled2017/000000147852.jpg  \n",
      " extracting: unlabeled2017/000000228849.jpg  \n",
      " extracting: unlabeled2017/000000576424.jpg  \n",
      " extracting: unlabeled2017/000000299219.jpg  \n",
      " extracting: unlabeled2017/000000415312.jpg  \n",
      " extracting: unlabeled2017/000000484188.jpg  \n",
      " extracting: unlabeled2017/000000001971.jpg  \n",
      " extracting: unlabeled2017/000000050235.jpg  \n",
      " extracting: unlabeled2017/000000348893.jpg  \n",
      " extracting: unlabeled2017/000000217217.jpg  \n",
      " extracting: unlabeled2017/000000519561.jpg  \n",
      " extracting: unlabeled2017/000000316682.jpg  \n",
      " extracting: unlabeled2017/000000525628.jpg  \n",
      " extracting: unlabeled2017/000000046421.jpg  \n",
      " extracting: unlabeled2017/000000308887.jpg  \n",
      " extracting: unlabeled2017/000000219497.jpg  \n",
      " extracting: unlabeled2017/000000552341.jpg  \n",
      " extracting: unlabeled2017/000000498226.jpg  \n",
      " extracting: unlabeled2017/000000173771.jpg  \n",
      " extracting: unlabeled2017/000000438747.jpg  \n",
      " extracting: unlabeled2017/000000138679.jpg  \n",
      " extracting: unlabeled2017/000000194287.jpg  \n",
      " extracting: unlabeled2017/000000007223.jpg  \n",
      " extracting: unlabeled2017/000000063940.jpg  \n",
      " extracting: unlabeled2017/000000359478.jpg  \n",
      " extracting: unlabeled2017/000000547541.jpg  \n",
      " extracting: unlabeled2017/000000325765.jpg  \n",
      " extracting: unlabeled2017/000000285578.jpg  \n",
      " extracting: unlabeled2017/000000264759.jpg  \n",
      " extracting: unlabeled2017/000000424811.jpg  \n",
      " extracting: unlabeled2017/000000562378.jpg  \n",
      " extracting: unlabeled2017/000000558489.jpg  \n",
      " extracting: unlabeled2017/000000235457.jpg  \n",
      " extracting: unlabeled2017/000000321892.jpg  \n",
      " extracting: unlabeled2017/000000410313.jpg  \n",
      " extracting: unlabeled2017/000000439332.jpg  \n",
      " extracting: unlabeled2017/000000341935.jpg  \n",
      " extracting: unlabeled2017/000000521564.jpg  \n",
      " extracting: unlabeled2017/000000242087.jpg  \n",
      " extracting: unlabeled2017/000000402280.jpg  \n",
      " extracting: unlabeled2017/000000031422.jpg  \n",
      " extracting: unlabeled2017/000000125802.jpg  \n",
      " extracting: unlabeled2017/000000174225.jpg  \n",
      " extracting: unlabeled2017/000000534142.jpg  \n",
      " extracting: unlabeled2017/000000057184.jpg  \n",
      " extracting: unlabeled2017/000000044893.jpg  \n",
      " extracting: unlabeled2017/000000276732.jpg  \n",
      " extracting: unlabeled2017/000000442843.jpg  \n",
      " extracting: unlabeled2017/000000309343.jpg  \n",
      " extracting: unlabeled2017/000000318163.jpg  \n",
      " extracting: unlabeled2017/000000435660.jpg  \n",
      " extracting: unlabeled2017/000000149565.jpg  \n",
      " extracting: unlabeled2017/000000359196.jpg  \n",
      " extracting: unlabeled2017/000000173648.jpg  \n",
      " extracting: unlabeled2017/000000007091.jpg  \n",
      " extracting: unlabeled2017/000000167772.jpg  \n",
      " extracting: unlabeled2017/000000182707.jpg  \n",
      " extracting: unlabeled2017/000000137521.jpg  \n",
      " extracting: unlabeled2017/000000475222.jpg  \n",
      " extracting: unlabeled2017/000000512807.jpg  \n",
      " extracting: unlabeled2017/000000529731.jpg  \n",
      " extracting: unlabeled2017/000000058719.jpg  \n",
      " extracting: unlabeled2017/000000362780.jpg  \n",
      " extracting: unlabeled2017/000000160737.jpg  \n",
      " extracting: unlabeled2017/000000212958.jpg  \n",
      " extracting: unlabeled2017/000000065077.jpg  \n",
      " extracting: unlabeled2017/000000112419.jpg  \n",
      " extracting: unlabeled2017/000000576091.jpg  \n",
      " extracting: unlabeled2017/000000217457.jpg  \n",
      " extracting: unlabeled2017/000000456304.jpg  \n",
      " extracting: unlabeled2017/000000044343.jpg  \n",
      " extracting: unlabeled2017/000000544353.jpg  \n",
      " extracting: unlabeled2017/000000100487.jpg  \n",
      " extracting: unlabeled2017/000000194623.jpg  \n",
      " extracting: unlabeled2017/000000214302.jpg  \n",
      " extracting: unlabeled2017/000000098828.jpg  \n",
      " extracting: unlabeled2017/000000573634.jpg  \n",
      " extracting: unlabeled2017/000000091838.jpg  \n",
      " extracting: unlabeled2017/000000321029.jpg  \n",
      " extracting: unlabeled2017/000000355400.jpg  \n",
      " extracting: unlabeled2017/000000089175.jpg  \n",
      " extracting: unlabeled2017/000000171015.jpg  \n",
      " extracting: unlabeled2017/000000082747.jpg  \n",
      " extracting: unlabeled2017/000000071817.jpg  \n",
      " extracting: unlabeled2017/000000049200.jpg  \n",
      " extracting: unlabeled2017/000000124129.jpg  \n",
      " extracting: unlabeled2017/000000320980.jpg  \n",
      " extracting: unlabeled2017/000000132324.jpg  \n",
      " extracting: unlabeled2017/000000011218.jpg  \n",
      " extracting: unlabeled2017/000000388007.jpg  \n",
      " extracting: unlabeled2017/000000425730.jpg  \n",
      " extracting: unlabeled2017/000000064261.jpg  \n",
      " extracting: unlabeled2017/000000184060.jpg  \n",
      " extracting: unlabeled2017/000000227754.jpg  \n",
      " extracting: unlabeled2017/000000046095.jpg  \n",
      " extracting: unlabeled2017/000000555135.jpg  \n",
      " extracting: unlabeled2017/000000279480.jpg  \n",
      " extracting: unlabeled2017/000000252164.jpg  \n",
      " extracting: unlabeled2017/000000147937.jpg  \n",
      " extracting: unlabeled2017/000000313831.jpg  \n",
      " extracting: unlabeled2017/000000443983.jpg  \n",
      " extracting: unlabeled2017/000000308230.jpg  \n",
      " extracting: unlabeled2017/000000534245.jpg  \n",
      " extracting: unlabeled2017/000000231268.jpg  \n",
      " extracting: unlabeled2017/000000137048.jpg  \n",
      " extracting: unlabeled2017/000000493182.jpg  \n",
      " extracting: unlabeled2017/000000483430.jpg  \n",
      " extracting: unlabeled2017/000000440492.jpg  \n",
      " extracting: unlabeled2017/000000205452.jpg  \n",
      " extracting: unlabeled2017/000000133246.jpg  \n",
      " extracting: unlabeled2017/000000242219.jpg  \n",
      " extracting: unlabeled2017/000000054720.jpg  \n",
      " extracting: unlabeled2017/000000365058.jpg  \n",
      " extracting: unlabeled2017/000000400693.jpg  \n",
      " extracting: unlabeled2017/000000187539.jpg  \n",
      " extracting: unlabeled2017/000000444213.jpg  \n",
      " extracting: unlabeled2017/000000052199.jpg  \n",
      " extracting: unlabeled2017/000000519458.jpg  \n",
      " extracting: unlabeled2017/000000535240.jpg  \n",
      " extracting: unlabeled2017/000000528519.jpg  \n",
      " extracting: unlabeled2017/000000445293.jpg  \n",
      " extracting: unlabeled2017/000000349223.jpg  \n",
      " extracting: unlabeled2017/000000245678.jpg  \n",
      " extracting: unlabeled2017/000000172926.jpg  \n",
      " extracting: unlabeled2017/000000107602.jpg  \n",
      " extracting: unlabeled2017/000000170663.jpg  \n",
      " extracting: unlabeled2017/000000199595.jpg  \n",
      " extracting: unlabeled2017/000000479614.jpg  \n",
      " extracting: unlabeled2017/000000266595.jpg  \n",
      " extracting: unlabeled2017/000000326979.jpg  \n",
      " extracting: unlabeled2017/000000433015.jpg  \n",
      " extracting: unlabeled2017/000000542227.jpg  \n",
      " extracting: unlabeled2017/000000089808.jpg  \n",
      " extracting: unlabeled2017/000000365272.jpg  \n",
      " extracting: unlabeled2017/000000170252.jpg  \n",
      " extracting: unlabeled2017/000000242402.jpg  \n",
      " extracting: unlabeled2017/000000466246.jpg  \n",
      " extracting: unlabeled2017/000000218245.jpg  \n",
      " extracting: unlabeled2017/000000490207.jpg  \n",
      " extracting: unlabeled2017/000000060571.jpg  \n",
      " extracting: unlabeled2017/000000394437.jpg  \n",
      " extracting: unlabeled2017/000000046933.jpg  \n",
      " extracting: unlabeled2017/000000348007.jpg  \n",
      " extracting: unlabeled2017/000000114983.jpg  \n",
      " extracting: unlabeled2017/000000385223.jpg  \n",
      " extracting: unlabeled2017/000000493344.jpg  \n",
      " extracting: unlabeled2017/000000464363.jpg  \n",
      " extracting: unlabeled2017/000000456765.jpg  \n",
      " extracting: unlabeled2017/000000322176.jpg  \n",
      " extracting: unlabeled2017/000000065879.jpg  \n",
      " extracting: unlabeled2017/000000413591.jpg  \n",
      " extracting: unlabeled2017/000000371918.jpg  \n",
      " extracting: unlabeled2017/000000097089.jpg  \n",
      " extracting: unlabeled2017/000000507701.jpg  \n",
      " extracting: unlabeled2017/000000200300.jpg  \n",
      " extracting: unlabeled2017/000000157294.jpg  \n",
      " extracting: unlabeled2017/000000564988.jpg  \n",
      " extracting: unlabeled2017/000000448327.jpg  \n",
      " extracting: unlabeled2017/000000079342.jpg  \n",
      " extracting: unlabeled2017/000000166410.jpg  \n",
      " extracting: unlabeled2017/000000515554.jpg  \n",
      " extracting: unlabeled2017/000000425586.jpg  \n",
      " extracting: unlabeled2017/000000576934.jpg  \n",
      " extracting: unlabeled2017/000000076388.jpg  \n",
      " extracting: unlabeled2017/000000190154.jpg  \n",
      " extracting: unlabeled2017/000000448895.jpg  \n",
      " extracting: unlabeled2017/000000306655.jpg  \n",
      " extracting: unlabeled2017/000000106457.jpg  \n",
      " extracting: unlabeled2017/000000463146.jpg  \n",
      " extracting: unlabeled2017/000000152363.jpg  \n",
      " extracting: unlabeled2017/000000199289.jpg  \n",
      " extracting: unlabeled2017/000000441136.jpg  \n",
      " extracting: unlabeled2017/000000112973.jpg  \n",
      " extracting: unlabeled2017/000000501563.jpg  \n",
      " extracting: unlabeled2017/000000113289.jpg  \n",
      " extracting: unlabeled2017/000000352029.jpg  \n",
      " extracting: unlabeled2017/000000289549.jpg  \n",
      " extracting: unlabeled2017/000000046022.jpg  \n",
      " extracting: unlabeled2017/000000032182.jpg  \n",
      " extracting: unlabeled2017/000000267424.jpg  \n",
      " extracting: unlabeled2017/000000556736.jpg  \n",
      " extracting: unlabeled2017/000000277627.jpg  \n",
      " extracting: unlabeled2017/000000346127.jpg  \n",
      " extracting: unlabeled2017/000000144448.jpg  \n",
      " extracting: unlabeled2017/000000086730.jpg  \n",
      " extracting: unlabeled2017/000000131768.jpg  \n",
      " extracting: unlabeled2017/000000410591.jpg  \n",
      " extracting: unlabeled2017/000000037630.jpg  \n",
      " extracting: unlabeled2017/000000195289.jpg  \n",
      " extracting: unlabeled2017/000000184823.jpg  \n",
      " extracting: unlabeled2017/000000095844.jpg  \n",
      " extracting: unlabeled2017/000000098486.jpg  \n",
      " extracting: unlabeled2017/000000144710.jpg  \n",
      " extracting: unlabeled2017/000000234336.jpg  \n",
      " extracting: unlabeled2017/000000191844.jpg  \n",
      " extracting: unlabeled2017/000000255521.jpg  \n",
      " extracting: unlabeled2017/000000060260.jpg  \n",
      " extracting: unlabeled2017/000000533083.jpg  \n",
      " extracting: unlabeled2017/000000040888.jpg  \n",
      " extracting: unlabeled2017/000000300327.jpg  \n",
      " extracting: unlabeled2017/000000166607.jpg  \n",
      " extracting: unlabeled2017/000000487993.jpg  \n",
      " extracting: unlabeled2017/000000038104.jpg  \n",
      " extracting: unlabeled2017/000000512566.jpg  \n",
      " extracting: unlabeled2017/000000149877.jpg  \n",
      " extracting: unlabeled2017/000000385799.jpg  \n",
      " extracting: unlabeled2017/000000164536.jpg  \n",
      " extracting: unlabeled2017/000000127000.jpg  \n",
      " extracting: unlabeled2017/000000431747.jpg  \n",
      " extracting: unlabeled2017/000000223509.jpg  \n",
      " extracting: unlabeled2017/000000412981.jpg  \n",
      " extracting: unlabeled2017/000000534930.jpg  \n",
      " extracting: unlabeled2017/000000054408.jpg  \n",
      " extracting: unlabeled2017/000000353520.jpg  \n",
      " extracting: unlabeled2017/000000083287.jpg  \n",
      " extracting: unlabeled2017/000000250709.jpg  \n",
      " extracting: unlabeled2017/000000453379.jpg  \n",
      " extracting: unlabeled2017/000000134080.jpg  \n",
      " extracting: unlabeled2017/000000570638.jpg  \n",
      " extracting: unlabeled2017/000000567894.jpg  \n",
      " extracting: unlabeled2017/000000355515.jpg  \n",
      " extracting: unlabeled2017/000000032412.jpg  \n",
      " extracting: unlabeled2017/000000429914.jpg  \n",
      " extracting: unlabeled2017/000000334207.jpg  \n",
      " extracting: unlabeled2017/000000394971.jpg  \n",
      " extracting: unlabeled2017/000000577773.jpg  \n",
      " extracting: unlabeled2017/000000547273.jpg  \n",
      " extracting: unlabeled2017/000000196866.jpg  \n",
      " extracting: unlabeled2017/000000433933.jpg  \n",
      " extracting: unlabeled2017/000000523452.jpg  \n",
      " extracting: unlabeled2017/000000531809.jpg  \n",
      " extracting: unlabeled2017/000000208873.jpg  \n",
      " extracting: unlabeled2017/000000372903.jpg  \n",
      " extracting: unlabeled2017/000000117449.jpg  \n",
      " extracting: unlabeled2017/000000379258.jpg  \n",
      " extracting: unlabeled2017/000000512642.jpg  \n",
      " extracting: unlabeled2017/000000338182.jpg  \n",
      " extracting: unlabeled2017/000000343672.jpg  \n",
      " extracting: unlabeled2017/000000330482.jpg  \n",
      " extracting: unlabeled2017/000000287433.jpg  \n",
      " extracting: unlabeled2017/000000239408.jpg  \n",
      " extracting: unlabeled2017/000000438177.jpg  \n",
      " extracting: unlabeled2017/000000093388.jpg  \n",
      " extracting: unlabeled2017/000000454321.jpg  \n",
      " extracting: unlabeled2017/000000077878.jpg  \n",
      " extracting: unlabeled2017/000000427426.jpg  \n",
      " extracting: unlabeled2017/000000142505.jpg  \n",
      " extracting: unlabeled2017/000000179212.jpg  \n",
      " extracting: unlabeled2017/000000451565.jpg  \n",
      " extracting: unlabeled2017/000000057024.jpg  \n",
      " extracting: unlabeled2017/000000184785.jpg  \n",
      " extracting: unlabeled2017/000000010254.jpg  \n",
      " extracting: unlabeled2017/000000352526.jpg  \n",
      " extracting: unlabeled2017/000000206896.jpg  \n",
      " extracting: unlabeled2017/000000190584.jpg  \n",
      " extracting: unlabeled2017/000000208264.jpg  \n",
      " extracting: unlabeled2017/000000405573.jpg  \n",
      " extracting: unlabeled2017/000000339069.jpg  \n",
      " extracting: unlabeled2017/000000211023.jpg  \n",
      " extracting: unlabeled2017/000000329805.jpg  \n",
      " extracting: unlabeled2017/000000263175.jpg  \n",
      " extracting: unlabeled2017/000000244075.jpg  \n",
      " extracting: unlabeled2017/000000008155.jpg  \n",
      " extracting: unlabeled2017/000000057701.jpg  \n",
      " extracting: unlabeled2017/000000022175.jpg  \n",
      " extracting: unlabeled2017/000000525577.jpg  \n",
      " extracting: unlabeled2017/000000564839.jpg  \n",
      " extracting: unlabeled2017/000000562184.jpg  \n",
      " extracting: unlabeled2017/000000471821.jpg  \n",
      " extracting: unlabeled2017/000000003508.jpg  \n",
      " extracting: unlabeled2017/000000132135.jpg  \n",
      " extracting: unlabeled2017/000000484207.jpg  \n",
      " extracting: unlabeled2017/000000478381.jpg  \n",
      " extracting: unlabeled2017/000000150815.jpg  \n",
      " extracting: unlabeled2017/000000104577.jpg  \n",
      " extracting: unlabeled2017/000000577431.jpg  \n",
      " extracting: unlabeled2017/000000254148.jpg  \n",
      " extracting: unlabeled2017/000000360201.jpg  \n",
      " extracting: unlabeled2017/000000068454.jpg  \n",
      " extracting: unlabeled2017/000000439440.jpg  \n",
      " extracting: unlabeled2017/000000090711.jpg  \n",
      " extracting: unlabeled2017/000000562486.jpg  \n",
      " extracting: unlabeled2017/000000479342.jpg  \n",
      " extracting: unlabeled2017/000000103210.jpg  \n",
      " extracting: unlabeled2017/000000003787.jpg  \n",
      " extracting: unlabeled2017/000000576276.jpg  \n",
      " extracting: unlabeled2017/000000317572.jpg  \n",
      " extracting: unlabeled2017/000000013864.jpg  \n",
      " extracting: unlabeled2017/000000407475.jpg  \n",
      " extracting: unlabeled2017/000000323962.jpg  \n",
      " extracting: unlabeled2017/000000217694.jpg  \n",
      " extracting: unlabeled2017/000000057272.jpg  \n",
      " extracting: unlabeled2017/000000524264.jpg  \n",
      " extracting: unlabeled2017/000000459711.jpg  \n",
      " extracting: unlabeled2017/000000038839.jpg  \n",
      " extracting: unlabeled2017/000000448650.jpg  \n",
      " extracting: unlabeled2017/000000024488.jpg  \n",
      " extracting: unlabeled2017/000000183464.jpg  \n",
      " extracting: unlabeled2017/000000467942.jpg  \n",
      " extracting: unlabeled2017/000000140771.jpg  \n",
      " extracting: unlabeled2017/000000251902.jpg  \n",
      " extracting: unlabeled2017/000000112709.jpg  \n",
      " extracting: unlabeled2017/000000013968.jpg  \n",
      " extracting: unlabeled2017/000000026519.jpg  \n",
      " extracting: unlabeled2017/000000226769.jpg  \n",
      " extracting: unlabeled2017/000000558588.jpg  \n",
      " extracting: unlabeled2017/000000389689.jpg  \n",
      " extracting: unlabeled2017/000000294109.jpg  \n",
      " extracting: unlabeled2017/000000548473.jpg  \n",
      " extracting: unlabeled2017/000000566527.jpg  \n",
      " extracting: unlabeled2017/000000238572.jpg  \n",
      " extracting: unlabeled2017/000000017142.jpg  \n",
      " extracting: unlabeled2017/000000094226.jpg  \n",
      " extracting: unlabeled2017/000000046790.jpg  \n",
      " extracting: unlabeled2017/000000254835.jpg  \n",
      " extracting: unlabeled2017/000000137812.jpg  \n",
      " extracting: unlabeled2017/000000414979.jpg  \n",
      " extracting: unlabeled2017/000000255803.jpg  \n",
      " extracting: unlabeled2017/000000311662.jpg  \n",
      " extracting: unlabeled2017/000000367988.jpg  \n",
      " extracting: unlabeled2017/000000440163.jpg  \n",
      " extracting: unlabeled2017/000000140153.jpg  \n",
      " extracting: unlabeled2017/000000434715.jpg  \n",
      " extracting: unlabeled2017/000000404611.jpg  \n",
      " extracting: unlabeled2017/000000275326.jpg  \n",
      " extracting: unlabeled2017/000000231507.jpg  \n",
      " extracting: unlabeled2017/000000112788.jpg  \n",
      " extracting: unlabeled2017/000000523667.jpg  \n",
      " extracting: unlabeled2017/000000304338.jpg  \n",
      " extracting: unlabeled2017/000000351946.jpg  \n",
      " extracting: unlabeled2017/000000074800.jpg  \n",
      " extracting: unlabeled2017/000000305316.jpg  \n",
      " extracting: unlabeled2017/000000396640.jpg  \n",
      " extracting: unlabeled2017/000000065508.jpg  \n",
      " extracting: unlabeled2017/000000216311.jpg  \n",
      " extracting: unlabeled2017/000000122772.jpg  \n",
      " extracting: unlabeled2017/000000339167.jpg  \n",
      " extracting: unlabeled2017/000000301805.jpg  \n",
      " extracting: unlabeled2017/000000232637.jpg  \n",
      " extracting: unlabeled2017/000000479873.jpg  \n",
      " extracting: unlabeled2017/000000168348.jpg  \n",
      " extracting: unlabeled2017/000000396813.jpg  \n",
      " extracting: unlabeled2017/000000541154.jpg  \n",
      " extracting: unlabeled2017/000000432463.jpg  \n",
      " extracting: unlabeled2017/000000516845.jpg  \n",
      " extracting: unlabeled2017/000000065310.jpg  \n",
      " extracting: unlabeled2017/000000539524.jpg  \n",
      " extracting: unlabeled2017/000000411992.jpg  \n",
      " extracting: unlabeled2017/000000367417.jpg  \n",
      " extracting: unlabeled2017/000000063001.jpg  \n",
      " extracting: unlabeled2017/000000545270.jpg  \n",
      " extracting: unlabeled2017/000000026106.jpg  \n",
      " extracting: unlabeled2017/000000370909.jpg  \n",
      " extracting: unlabeled2017/000000252478.jpg  \n",
      " extracting: unlabeled2017/000000580809.jpg  \n",
      " extracting: unlabeled2017/000000570979.jpg  \n",
      " extracting: unlabeled2017/000000459479.jpg  \n",
      " extracting: unlabeled2017/000000062352.jpg  \n",
      " extracting: unlabeled2017/000000274661.jpg  \n",
      " extracting: unlabeled2017/000000064990.jpg  \n",
      " extracting: unlabeled2017/000000033176.jpg  \n",
      " extracting: unlabeled2017/000000032790.jpg  \n",
      " extracting: unlabeled2017/000000306093.jpg  \n",
      " extracting: unlabeled2017/000000525505.jpg  \n",
      " extracting: unlabeled2017/000000352172.jpg  \n",
      " extracting: unlabeled2017/000000183047.jpg  \n",
      " extracting: unlabeled2017/000000296148.jpg  \n",
      " extracting: unlabeled2017/000000510324.jpg  \n",
      " extracting: unlabeled2017/000000425002.jpg  \n",
      " extracting: unlabeled2017/000000019796.jpg  \n",
      " extracting: unlabeled2017/000000267340.jpg  \n",
      " extracting: unlabeled2017/000000021236.jpg  \n",
      " extracting: unlabeled2017/000000526984.jpg  \n",
      " extracting: unlabeled2017/000000526821.jpg  \n",
      " extracting: unlabeled2017/000000519592.jpg  \n",
      " extracting: unlabeled2017/000000187703.jpg  \n",
      " extracting: unlabeled2017/000000510999.jpg  \n",
      " extracting: unlabeled2017/000000069499.jpg  \n",
      " extracting: unlabeled2017/000000450254.jpg  \n",
      " extracting: unlabeled2017/000000533571.jpg  \n",
      " extracting: unlabeled2017/000000312938.jpg  \n",
      " extracting: unlabeled2017/000000362933.jpg  \n",
      " extracting: unlabeled2017/000000321165.jpg  \n",
      " extracting: unlabeled2017/000000260570.jpg  \n",
      " extracting: unlabeled2017/000000426361.jpg  \n",
      " extracting: unlabeled2017/000000509661.jpg  \n",
      " extracting: unlabeled2017/000000166802.jpg  \n",
      " extracting: unlabeled2017/000000507692.jpg  \n",
      " extracting: unlabeled2017/000000271071.jpg  \n",
      " extracting: unlabeled2017/000000216730.jpg  \n",
      " extracting: unlabeled2017/000000020918.jpg  \n",
      " extracting: unlabeled2017/000000278719.jpg  \n",
      " extracting: unlabeled2017/000000389688.jpg  \n",
      " extracting: unlabeled2017/000000550048.jpg  \n",
      " extracting: unlabeled2017/000000062033.jpg  \n",
      " extracting: unlabeled2017/000000311976.jpg  \n",
      " extracting: unlabeled2017/000000413856.jpg  \n",
      " extracting: unlabeled2017/000000153275.jpg  \n",
      " extracting: unlabeled2017/000000194836.jpg  \n",
      " extracting: unlabeled2017/000000578014.jpg  \n",
      " extracting: unlabeled2017/000000531152.jpg  \n",
      " extracting: unlabeled2017/000000133390.jpg  \n",
      " extracting: unlabeled2017/000000259866.jpg  \n",
      " extracting: unlabeled2017/000000410842.jpg  \n",
      " extracting: unlabeled2017/000000067411.jpg  \n",
      " extracting: unlabeled2017/000000149934.jpg  \n",
      " extracting: unlabeled2017/000000178907.jpg  \n",
      " extracting: unlabeled2017/000000302625.jpg  \n",
      " extracting: unlabeled2017/000000049015.jpg  \n",
      " extracting: unlabeled2017/000000112979.jpg  \n",
      " extracting: unlabeled2017/000000016999.jpg  \n",
      " extracting: unlabeled2017/000000534507.jpg  \n",
      " extracting: unlabeled2017/000000438507.jpg  \n",
      " extracting: unlabeled2017/000000166218.jpg  \n",
      " extracting: unlabeled2017/000000128386.jpg  \n",
      " extracting: unlabeled2017/000000377950.jpg  \n",
      " extracting: unlabeled2017/000000486144.jpg  \n",
      " extracting: unlabeled2017/000000506648.jpg  \n",
      " extracting: unlabeled2017/000000205732.jpg  \n",
      " extracting: unlabeled2017/000000088569.jpg  \n",
      " extracting: unlabeled2017/000000104874.jpg  \n",
      " extracting: unlabeled2017/000000459389.jpg  \n",
      " extracting: unlabeled2017/000000416595.jpg  \n",
      " extracting: unlabeled2017/000000037307.jpg  \n",
      " extracting: unlabeled2017/000000444313.jpg  \n",
      " extracting: unlabeled2017/000000029202.jpg  \n",
      " extracting: unlabeled2017/000000401923.jpg  \n",
      " extracting: unlabeled2017/000000577534.jpg  \n",
      " extracting: unlabeled2017/000000255288.jpg  \n",
      " extracting: unlabeled2017/000000553426.jpg  \n",
      " extracting: unlabeled2017/000000005012.jpg  \n",
      " extracting: unlabeled2017/000000156732.jpg  \n",
      " extracting: unlabeled2017/000000244699.jpg  \n",
      " extracting: unlabeled2017/000000550959.jpg  \n",
      " extracting: unlabeled2017/000000440363.jpg  \n",
      " extracting: unlabeled2017/000000241524.jpg  \n",
      " extracting: unlabeled2017/000000153519.jpg  \n",
      " extracting: unlabeled2017/000000455838.jpg  \n",
      " extracting: unlabeled2017/000000252182.jpg  \n",
      " extracting: unlabeled2017/000000022318.jpg  \n",
      " extracting: unlabeled2017/000000005406.jpg  \n",
      " extracting: unlabeled2017/000000457912.jpg  \n",
      " extracting: unlabeled2017/000000314146.jpg  \n",
      " extracting: unlabeled2017/000000486735.jpg  \n",
      " extracting: unlabeled2017/000000028667.jpg  \n",
      " extracting: unlabeled2017/000000348410.jpg  \n",
      " extracting: unlabeled2017/000000077453.jpg  \n",
      " extracting: unlabeled2017/000000426692.jpg  \n",
      " extracting: unlabeled2017/000000478301.jpg  \n",
      " extracting: unlabeled2017/000000341819.jpg  \n",
      " extracting: unlabeled2017/000000088765.jpg  \n",
      " extracting: unlabeled2017/000000323575.jpg  \n",
      " extracting: unlabeled2017/000000456488.jpg  \n",
      " extracting: unlabeled2017/000000187528.jpg  \n",
      " extracting: unlabeled2017/000000059978.jpg  \n",
      " extracting: unlabeled2017/000000216162.jpg  \n",
      " extracting: unlabeled2017/000000542852.jpg  \n",
      " extracting: unlabeled2017/000000333423.jpg  \n",
      " extracting: unlabeled2017/000000291418.jpg  \n",
      " extracting: unlabeled2017/000000087645.jpg  \n",
      " extracting: unlabeled2017/000000064416.jpg  \n",
      " extracting: unlabeled2017/000000367062.jpg  \n",
      " extracting: unlabeled2017/000000032980.jpg  \n",
      " extracting: unlabeled2017/000000116930.jpg  \n",
      " extracting: unlabeled2017/000000349429.jpg  \n",
      " extracting: unlabeled2017/000000033510.jpg  \n",
      " extracting: unlabeled2017/000000312011.jpg  \n",
      " extracting: unlabeled2017/000000375176.jpg  \n",
      " extracting: unlabeled2017/000000121325.jpg  \n",
      " extracting: unlabeled2017/000000536324.jpg  \n",
      " extracting: unlabeled2017/000000191499.jpg  \n",
      " extracting: unlabeled2017/000000060646.jpg  \n",
      " extracting: unlabeled2017/000000417012.jpg  \n",
      " extracting: unlabeled2017/000000500600.jpg  \n",
      " extracting: unlabeled2017/000000139264.jpg  \n",
      " extracting: unlabeled2017/000000404104.jpg  \n",
      " extracting: unlabeled2017/000000022188.jpg  \n",
      " extracting: unlabeled2017/000000116230.jpg  \n",
      " extracting: unlabeled2017/000000219366.jpg  \n",
      " extracting: unlabeled2017/000000398728.jpg  \n",
      " extracting: unlabeled2017/000000074210.jpg  \n",
      " extracting: unlabeled2017/000000256071.jpg  \n",
      " extracting: unlabeled2017/000000250602.jpg  \n",
      " extracting: unlabeled2017/000000525610.jpg  \n",
      " extracting: unlabeled2017/000000263219.jpg  \n",
      " extracting: unlabeled2017/000000499938.jpg  \n",
      " extracting: unlabeled2017/000000458562.jpg  \n",
      " extracting: unlabeled2017/000000064246.jpg  \n",
      " extracting: unlabeled2017/000000177591.jpg  \n",
      " extracting: unlabeled2017/000000031659.jpg  \n",
      " extracting: unlabeled2017/000000204160.jpg  \n",
      " extracting: unlabeled2017/000000404206.jpg  \n",
      " extracting: unlabeled2017/000000281402.jpg  \n",
      " extracting: unlabeled2017/000000161037.jpg  \n",
      " extracting: unlabeled2017/000000472194.jpg  \n",
      " extracting: unlabeled2017/000000223205.jpg  \n",
      " extracting: unlabeled2017/000000174323.jpg  \n",
      " extracting: unlabeled2017/000000302917.jpg  \n",
      " extracting: unlabeled2017/000000119177.jpg  \n",
      " extracting: unlabeled2017/000000296361.jpg  \n",
      " extracting: unlabeled2017/000000397866.jpg  \n",
      " extracting: unlabeled2017/000000291893.jpg  \n",
      " extracting: unlabeled2017/000000535727.jpg  \n",
      " extracting: unlabeled2017/000000106197.jpg  \n",
      " extracting: unlabeled2017/000000261986.jpg  \n",
      " extracting: unlabeled2017/000000297484.jpg  \n",
      " extracting: unlabeled2017/000000497995.jpg  \n",
      " extracting: unlabeled2017/000000550800.jpg  \n",
      " extracting: unlabeled2017/000000565852.jpg  \n",
      " extracting: unlabeled2017/000000572483.jpg  \n",
      " extracting: unlabeled2017/000000349317.jpg  \n",
      " extracting: unlabeled2017/000000399691.jpg  \n",
      " extracting: unlabeled2017/000000440523.jpg  \n",
      " extracting: unlabeled2017/000000117236.jpg  \n",
      " extracting: unlabeled2017/000000575443.jpg  \n",
      " extracting: unlabeled2017/000000483774.jpg  \n",
      " extracting: unlabeled2017/000000504463.jpg  \n",
      " extracting: unlabeled2017/000000300258.jpg  \n",
      " extracting: unlabeled2017/000000325030.jpg  \n",
      " extracting: unlabeled2017/000000512831.jpg  \n",
      " extracting: unlabeled2017/000000524660.jpg  \n",
      " extracting: unlabeled2017/000000141050.jpg  \n",
      " extracting: unlabeled2017/000000454487.jpg  \n",
      " extracting: unlabeled2017/000000447110.jpg  \n",
      " extracting: unlabeled2017/000000301278.jpg  \n",
      " extracting: unlabeled2017/000000575087.jpg  \n",
      " extracting: unlabeled2017/000000278459.jpg  \n",
      " extracting: unlabeled2017/000000429419.jpg  \n",
      " extracting: unlabeled2017/000000421909.jpg  \n",
      " extracting: unlabeled2017/000000529392.jpg  \n",
      " extracting: unlabeled2017/000000554053.jpg  \n",
      " extracting: unlabeled2017/000000211342.jpg  \n",
      " extracting: unlabeled2017/000000129880.jpg  \n",
      " extracting: unlabeled2017/000000311140.jpg  \n",
      " extracting: unlabeled2017/000000576451.jpg  \n",
      " extracting: unlabeled2017/000000323533.jpg  \n",
      " extracting: unlabeled2017/000000422526.jpg  \n",
      " extracting: unlabeled2017/000000429562.jpg  \n",
      " extracting: unlabeled2017/000000015589.jpg  \n",
      " extracting: unlabeled2017/000000527988.jpg  \n",
      " extracting: unlabeled2017/000000399027.jpg  \n",
      " extracting: unlabeled2017/000000142520.jpg  \n",
      " extracting: unlabeled2017/000000061731.jpg  \n",
      " extracting: unlabeled2017/000000327037.jpg  \n",
      " extracting: unlabeled2017/000000162437.jpg  \n",
      " extracting: unlabeled2017/000000222744.jpg  \n",
      " extracting: unlabeled2017/000000267272.jpg  \n",
      " extracting: unlabeled2017/000000372388.jpg  \n",
      " extracting: unlabeled2017/000000488482.jpg  \n",
      " extracting: unlabeled2017/000000566147.jpg  \n",
      " extracting: unlabeled2017/000000053557.jpg  \n",
      " extracting: unlabeled2017/000000425157.jpg  \n",
      " extracting: unlabeled2017/000000350482.jpg  \n",
      " extracting: unlabeled2017/000000225822.jpg  \n",
      " extracting: unlabeled2017/000000480441.jpg  \n",
      " extracting: unlabeled2017/000000394281.jpg  \n",
      " extracting: unlabeled2017/000000249885.jpg  \n",
      " extracting: unlabeled2017/000000376086.jpg  \n",
      " extracting: unlabeled2017/000000501712.jpg  \n",
      " extracting: unlabeled2017/000000389482.jpg  \n",
      " extracting: unlabeled2017/000000279218.jpg  \n",
      " extracting: unlabeled2017/000000220975.jpg  \n",
      " extracting: unlabeled2017/000000505276.jpg  \n",
      " extracting: unlabeled2017/000000425766.jpg  \n",
      " extracting: unlabeled2017/000000447188.jpg  \n",
      " extracting: unlabeled2017/000000401253.jpg  \n",
      " extracting: unlabeled2017/000000251059.jpg  \n",
      " extracting: unlabeled2017/000000495267.jpg  \n",
      " extracting: unlabeled2017/000000415374.jpg  \n",
      " extracting: unlabeled2017/000000037188.jpg  \n",
      " extracting: unlabeled2017/000000197572.jpg  \n",
      " extracting: unlabeled2017/000000120781.jpg  \n",
      " extracting: unlabeled2017/000000424719.jpg  \n",
      " extracting: unlabeled2017/000000521733.jpg  \n",
      " extracting: unlabeled2017/000000508692.jpg  \n",
      " extracting: unlabeled2017/000000320866.jpg  \n",
      " extracting: unlabeled2017/000000462334.jpg  \n",
      " extracting: unlabeled2017/000000120332.jpg  \n",
      " extracting: unlabeled2017/000000017116.jpg  \n",
      " extracting: unlabeled2017/000000570402.jpg  \n",
      " extracting: unlabeled2017/000000123981.jpg  \n",
      " extracting: unlabeled2017/000000064037.jpg  \n",
      " extracting: unlabeled2017/000000182493.jpg  \n",
      " extracting: unlabeled2017/000000359952.jpg  \n",
      " extracting: unlabeled2017/000000237446.jpg  \n",
      " extracting: unlabeled2017/000000064995.jpg  \n",
      " extracting: unlabeled2017/000000340319.jpg  \n",
      " extracting: unlabeled2017/000000119921.jpg  \n",
      " extracting: unlabeled2017/000000280312.jpg  \n",
      " extracting: unlabeled2017/000000211899.jpg  \n",
      " extracting: unlabeled2017/000000418707.jpg  \n",
      " extracting: unlabeled2017/000000222069.jpg  \n",
      " extracting: unlabeled2017/000000203491.jpg  \n",
      " extracting: unlabeled2017/000000375312.jpg  \n",
      " extracting: unlabeled2017/000000564016.jpg  \n",
      " extracting: unlabeled2017/000000572810.jpg  \n",
      " extracting: unlabeled2017/000000525231.jpg  \n",
      " extracting: unlabeled2017/000000473567.jpg  \n",
      " extracting: unlabeled2017/000000549227.jpg  \n",
      " extracting: unlabeled2017/000000331469.jpg  \n",
      " extracting: unlabeled2017/000000400641.jpg  \n",
      " extracting: unlabeled2017/000000070163.jpg  \n",
      " extracting: unlabeled2017/000000480700.jpg  \n",
      " extracting: unlabeled2017/000000041490.jpg  \n",
      " extracting: unlabeled2017/000000289868.jpg  \n",
      " extracting: unlabeled2017/000000331531.jpg  \n",
      " extracting: unlabeled2017/000000153640.jpg  \n",
      " extracting: unlabeled2017/000000109150.jpg  \n",
      " extracting: unlabeled2017/000000357908.jpg  \n",
      " extracting: unlabeled2017/000000039400.jpg  \n",
      " extracting: unlabeled2017/000000148467.jpg  \n",
      " extracting: unlabeled2017/000000576350.jpg  \n",
      " extracting: unlabeled2017/000000247583.jpg  \n",
      " extracting: unlabeled2017/000000167637.jpg  \n",
      " extracting: unlabeled2017/000000152396.jpg  \n",
      " extracting: unlabeled2017/000000295167.jpg  \n",
      " extracting: unlabeled2017/000000175559.jpg  \n",
      " extracting: unlabeled2017/000000089935.jpg  \n",
      " extracting: unlabeled2017/000000197538.jpg  \n",
      " extracting: unlabeled2017/000000570146.jpg  \n",
      " extracting: unlabeled2017/000000371550.jpg  \n",
      " extracting: unlabeled2017/000000191723.jpg  \n",
      " extracting: unlabeled2017/000000537121.jpg  \n",
      " extracting: unlabeled2017/000000551835.jpg  \n",
      " extracting: unlabeled2017/000000295424.jpg  \n",
      " extracting: unlabeled2017/000000530172.jpg  \n",
      " extracting: unlabeled2017/000000162879.jpg  \n",
      " extracting: unlabeled2017/000000334264.jpg  \n",
      " extracting: unlabeled2017/000000018803.jpg  \n",
      " extracting: unlabeled2017/000000474849.jpg  \n",
      " extracting: unlabeled2017/000000466275.jpg  \n",
      " extracting: unlabeled2017/000000546289.jpg  \n",
      " extracting: unlabeled2017/000000509898.jpg  \n",
      " extracting: unlabeled2017/000000512262.jpg  \n",
      " extracting: unlabeled2017/000000310609.jpg  \n",
      " extracting: unlabeled2017/000000501847.jpg  \n",
      " extracting: unlabeled2017/000000158589.jpg  \n",
      " extracting: unlabeled2017/000000245120.jpg  \n",
      " extracting: unlabeled2017/000000065897.jpg  \n",
      " extracting: unlabeled2017/000000131931.jpg  \n",
      " extracting: unlabeled2017/000000416475.jpg  \n",
      " extracting: unlabeled2017/000000051407.jpg  \n",
      " extracting: unlabeled2017/000000261267.jpg  \n",
      " extracting: unlabeled2017/000000390467.jpg  \n",
      " extracting: unlabeled2017/000000146314.jpg  \n",
      " extracting: unlabeled2017/000000440433.jpg  \n",
      " extracting: unlabeled2017/000000194585.jpg  \n",
      " extracting: unlabeled2017/000000149685.jpg  \n",
      " extracting: unlabeled2017/000000138311.jpg  \n",
      " extracting: unlabeled2017/000000314208.jpg  \n",
      " extracting: unlabeled2017/000000088816.jpg  \n",
      " extracting: unlabeled2017/000000017969.jpg  \n",
      " extracting: unlabeled2017/000000446789.jpg  \n",
      " extracting: unlabeled2017/000000464579.jpg  \n",
      " extracting: unlabeled2017/000000136824.jpg  \n",
      " extracting: unlabeled2017/000000249469.jpg  \n",
      " extracting: unlabeled2017/000000185967.jpg  \n",
      " extracting: unlabeled2017/000000306310.jpg  \n",
      " extracting: unlabeled2017/000000529587.jpg  \n",
      " extracting: unlabeled2017/000000168941.jpg  \n",
      " extracting: unlabeled2017/000000280016.jpg  \n",
      " extracting: unlabeled2017/000000049303.jpg  \n",
      " extracting: unlabeled2017/000000105889.jpg  \n",
      " extracting: unlabeled2017/000000381497.jpg  \n",
      " extracting: unlabeled2017/000000495389.jpg  \n",
      " extracting: unlabeled2017/000000326045.jpg  \n",
      " extracting: unlabeled2017/000000028467.jpg  \n",
      " extracting: unlabeled2017/000000229338.jpg  \n",
      " extracting: unlabeled2017/000000517640.jpg  \n",
      " extracting: unlabeled2017/000000170182.jpg  \n",
      " extracting: unlabeled2017/000000123522.jpg  \n",
      " extracting: unlabeled2017/000000119106.jpg  \n",
      " extracting: unlabeled2017/000000101704.jpg  \n",
      " extracting: unlabeled2017/000000252372.jpg  \n",
      " extracting: unlabeled2017/000000272249.jpg  \n",
      " extracting: unlabeled2017/000000193638.jpg  \n",
      " extracting: unlabeled2017/000000545498.jpg  \n",
      " extracting: unlabeled2017/000000406238.jpg  \n",
      " extracting: unlabeled2017/000000468449.jpg  \n",
      " extracting: unlabeled2017/000000126753.jpg  \n",
      " extracting: unlabeled2017/000000468514.jpg  \n",
      " extracting: unlabeled2017/000000257147.jpg  \n",
      " extracting: unlabeled2017/000000101927.jpg  \n",
      " extracting: unlabeled2017/000000164573.jpg  \n",
      " extracting: unlabeled2017/000000021636.jpg  \n",
      " extracting: unlabeled2017/000000352868.jpg  \n",
      " extracting: unlabeled2017/000000543145.jpg  \n",
      " extracting: unlabeled2017/000000016236.jpg  \n",
      " extracting: unlabeled2017/000000539963.jpg  \n",
      " extracting: unlabeled2017/000000229210.jpg  \n",
      " extracting: unlabeled2017/000000364329.jpg  \n",
      " extracting: unlabeled2017/000000538952.jpg  \n",
      " extracting: unlabeled2017/000000562130.jpg  \n",
      " extracting: unlabeled2017/000000515861.jpg  \n",
      " extracting: unlabeled2017/000000272788.jpg  \n",
      " extracting: unlabeled2017/000000304497.jpg  \n",
      " extracting: unlabeled2017/000000514145.jpg  \n",
      " extracting: unlabeled2017/000000000579.jpg  \n",
      " extracting: unlabeled2017/000000234137.jpg  \n",
      " extracting: unlabeled2017/000000434418.jpg  \n",
      " extracting: unlabeled2017/000000470591.jpg  \n",
      " extracting: unlabeled2017/000000319734.jpg  \n",
      " extracting: unlabeled2017/000000375679.jpg  \n",
      " extracting: unlabeled2017/000000127465.jpg  \n",
      " extracting: unlabeled2017/000000043050.jpg  \n",
      " extracting: unlabeled2017/000000279406.jpg  \n",
      " extracting: unlabeled2017/000000423751.jpg  \n",
      " extracting: unlabeled2017/000000511975.jpg  \n",
      " extracting: unlabeled2017/000000299810.jpg  \n",
      " extracting: unlabeled2017/000000262934.jpg  \n",
      " extracting: unlabeled2017/000000075683.jpg  \n",
      " extracting: unlabeled2017/000000425853.jpg  \n",
      " extracting: unlabeled2017/000000267937.jpg  \n",
      " extracting: unlabeled2017/000000370100.jpg  \n",
      " extracting: unlabeled2017/000000175056.jpg  \n",
      " extracting: unlabeled2017/000000336785.jpg  \n",
      " extracting: unlabeled2017/000000360513.jpg  \n",
      " extracting: unlabeled2017/000000295482.jpg  \n",
      " extracting: unlabeled2017/000000169339.jpg  \n",
      " extracting: unlabeled2017/000000416035.jpg  \n",
      " extracting: unlabeled2017/000000465128.jpg  \n",
      " extracting: unlabeled2017/000000427406.jpg  \n",
      " extracting: unlabeled2017/000000018511.jpg  \n",
      " extracting: unlabeled2017/000000420477.jpg  \n",
      " extracting: unlabeled2017/000000009936.jpg  \n",
      " extracting: unlabeled2017/000000016750.jpg  \n",
      " extracting: unlabeled2017/000000211210.jpg  \n",
      " extracting: unlabeled2017/000000247757.jpg  \n",
      " extracting: unlabeled2017/000000060310.jpg  \n",
      " extracting: unlabeled2017/000000126267.jpg  \n",
      " extracting: unlabeled2017/000000580281.jpg  \n",
      " extracting: unlabeled2017/000000521890.jpg  \n",
      " extracting: unlabeled2017/000000345704.jpg  \n",
      " extracting: unlabeled2017/000000341798.jpg  \n",
      " extracting: unlabeled2017/000000512343.jpg  \n",
      " extracting: unlabeled2017/000000356499.jpg  \n",
      " extracting: unlabeled2017/000000569837.jpg  \n",
      " extracting: unlabeled2017/000000400890.jpg  \n",
      " extracting: unlabeled2017/000000566719.jpg  \n",
      " extracting: unlabeled2017/000000067284.jpg  \n",
      " extracting: unlabeled2017/000000378485.jpg  \n",
      " extracting: unlabeled2017/000000498167.jpg  \n",
      " extracting: unlabeled2017/000000248684.jpg  \n",
      " extracting: unlabeled2017/000000473278.jpg  \n",
      " extracting: unlabeled2017/000000173755.jpg  \n",
      " extracting: unlabeled2017/000000119231.jpg  \n",
      " extracting: unlabeled2017/000000109607.jpg  \n",
      " extracting: unlabeled2017/000000200435.jpg  \n",
      " extracting: unlabeled2017/000000214598.jpg  \n",
      " extracting: unlabeled2017/000000055609.jpg  \n",
      " extracting: unlabeled2017/000000199324.jpg  \n",
      " extracting: unlabeled2017/000000230466.jpg  \n",
      " extracting: unlabeled2017/000000460758.jpg  \n",
      " extracting: unlabeled2017/000000118321.jpg  \n",
      " extracting: unlabeled2017/000000153969.jpg  \n",
      " extracting: unlabeled2017/000000515257.jpg  \n",
      " extracting: unlabeled2017/000000297405.jpg  \n",
      " extracting: unlabeled2017/000000189822.jpg  \n",
      " extracting: unlabeled2017/000000057675.jpg  \n",
      " extracting: unlabeled2017/000000322314.jpg  \n",
      " extracting: unlabeled2017/000000455740.jpg  \n",
      " extracting: unlabeled2017/000000102304.jpg  \n",
      " extracting: unlabeled2017/000000393681.jpg  \n",
      " extracting: unlabeled2017/000000580897.jpg  \n",
      " extracting: unlabeled2017/000000207588.jpg  \n",
      " extracting: unlabeled2017/000000004650.jpg  \n",
      " extracting: unlabeled2017/000000136762.jpg  \n",
      " extracting: unlabeled2017/000000361292.jpg  \n",
      " extracting: unlabeled2017/000000537033.jpg  \n",
      " extracting: unlabeled2017/000000305488.jpg  \n",
      " extracting: unlabeled2017/000000524126.jpg  \n",
      " extracting: unlabeled2017/000000280154.jpg  \n",
      " extracting: unlabeled2017/000000346919.jpg  \n",
      " extracting: unlabeled2017/000000306588.jpg  \n",
      " extracting: unlabeled2017/000000527692.jpg  \n",
      " extracting: unlabeled2017/000000050171.jpg  \n",
      " extracting: unlabeled2017/000000226937.jpg  \n",
      " extracting: unlabeled2017/000000236960.jpg  \n",
      " extracting: unlabeled2017/000000207856.jpg  \n",
      " extracting: unlabeled2017/000000148089.jpg  \n",
      " extracting: unlabeled2017/000000185746.jpg  \n",
      " extracting: unlabeled2017/000000387095.jpg  \n",
      " extracting: unlabeled2017/000000123245.jpg  \n",
      " extracting: unlabeled2017/000000446430.jpg  \n",
      " extracting: unlabeled2017/000000581046.jpg  \n",
      " extracting: unlabeled2017/000000504757.jpg  \n",
      " extracting: unlabeled2017/000000071529.jpg  \n",
      " extracting: unlabeled2017/000000547640.jpg  \n",
      " extracting: unlabeled2017/000000422598.jpg  \n",
      " extracting: unlabeled2017/000000151905.jpg  \n",
      " extracting: unlabeled2017/000000172848.jpg  \n",
      " extracting: unlabeled2017/000000031423.jpg  \n",
      " extracting: unlabeled2017/000000321686.jpg  \n",
      " extracting: unlabeled2017/000000556362.jpg  \n",
      " extracting: unlabeled2017/000000563107.jpg  \n",
      " extracting: unlabeled2017/000000051815.jpg  \n",
      " extracting: unlabeled2017/000000131297.jpg  \n",
      " extracting: unlabeled2017/000000337009.jpg  \n",
      " extracting: unlabeled2017/000000542390.jpg  \n",
      " extracting: unlabeled2017/000000287693.jpg  \n",
      " extracting: unlabeled2017/000000459688.jpg  \n",
      " extracting: unlabeled2017/000000495315.jpg  \n",
      " extracting: unlabeled2017/000000238397.jpg  \n",
      " extracting: unlabeled2017/000000454871.jpg  \n",
      " extracting: unlabeled2017/000000220219.jpg  \n",
      " extracting: unlabeled2017/000000061432.jpg  \n",
      " extracting: unlabeled2017/000000459902.jpg  \n",
      " extracting: unlabeled2017/000000545878.jpg  \n",
      " extracting: unlabeled2017/000000161803.jpg  \n",
      " extracting: unlabeled2017/000000343502.jpg  \n",
      " extracting: unlabeled2017/000000236680.jpg  \n",
      " extracting: unlabeled2017/000000520666.jpg  \n",
      " extracting: unlabeled2017/000000184273.jpg  \n",
      " extracting: unlabeled2017/000000299430.jpg  \n",
      " extracting: unlabeled2017/000000001328.jpg  \n",
      " extracting: unlabeled2017/000000341020.jpg  \n",
      " extracting: unlabeled2017/000000536193.jpg  \n",
      " extracting: unlabeled2017/000000559013.jpg  \n",
      " extracting: unlabeled2017/000000514660.jpg  \n",
      " extracting: unlabeled2017/000000401824.jpg  \n",
      " extracting: unlabeled2017/000000304227.jpg  \n",
      " extracting: unlabeled2017/000000351602.jpg  \n",
      " extracting: unlabeled2017/000000202974.jpg  \n",
      " extracting: unlabeled2017/000000255377.jpg  \n",
      " extracting: unlabeled2017/000000024860.jpg  \n",
      " extracting: unlabeled2017/000000106410.jpg  \n",
      " extracting: unlabeled2017/000000097470.jpg  \n",
      " extracting: unlabeled2017/000000409997.jpg  \n",
      " extracting: unlabeled2017/000000281838.jpg  \n",
      " extracting: unlabeled2017/000000436748.jpg  \n",
      " extracting: unlabeled2017/000000274080.jpg  \n",
      " extracting: unlabeled2017/000000276827.jpg  \n",
      " extracting: unlabeled2017/000000571604.jpg  \n",
      " extracting: unlabeled2017/000000286777.jpg  \n",
      " extracting: unlabeled2017/000000031231.jpg  \n",
      " extracting: unlabeled2017/000000418705.jpg  \n",
      " extracting: unlabeled2017/000000499100.jpg  \n",
      " extracting: unlabeled2017/000000285374.jpg  \n",
      " extracting: unlabeled2017/000000184732.jpg  \n",
      " extracting: unlabeled2017/000000155161.jpg  \n",
      " extracting: unlabeled2017/000000571304.jpg  \n",
      " extracting: unlabeled2017/000000256797.jpg  \n",
      " extracting: unlabeled2017/000000053714.jpg  \n",
      " extracting: unlabeled2017/000000009585.jpg  \n",
      " extracting: unlabeled2017/000000538765.jpg  \n",
      " extracting: unlabeled2017/000000083193.jpg  \n",
      " extracting: unlabeled2017/000000246771.jpg  \n",
      " extracting: unlabeled2017/000000071500.jpg  \n",
      " extracting: unlabeled2017/000000055741.jpg  \n",
      " extracting: unlabeled2017/000000296411.jpg  \n",
      " extracting: unlabeled2017/000000364849.jpg  \n",
      " extracting: unlabeled2017/000000110193.jpg  \n",
      " extracting: unlabeled2017/000000423326.jpg  \n",
      " extracting: unlabeled2017/000000022189.jpg  \n",
      " extracting: unlabeled2017/000000172456.jpg  \n",
      " extracting: unlabeled2017/000000188851.jpg  \n",
      " extracting: unlabeled2017/000000403641.jpg  \n",
      " extracting: unlabeled2017/000000528118.jpg  \n",
      " extracting: unlabeled2017/000000530465.jpg  \n",
      " extracting: unlabeled2017/000000225538.jpg  \n",
      " extracting: unlabeled2017/000000574832.jpg  \n",
      " extracting: unlabeled2017/000000444410.jpg  \n",
      " extracting: unlabeled2017/000000435834.jpg  \n",
      " extracting: unlabeled2017/000000239556.jpg  \n",
      " extracting: unlabeled2017/000000157553.jpg  \n",
      " extracting: unlabeled2017/000000550220.jpg  \n",
      " extracting: unlabeled2017/000000365787.jpg  \n",
      " extracting: unlabeled2017/000000075602.jpg  \n",
      " extracting: unlabeled2017/000000421512.jpg  \n",
      " extracting: unlabeled2017/000000477995.jpg  \n",
      " extracting: unlabeled2017/000000129606.jpg  \n",
      " extracting: unlabeled2017/000000082819.jpg  \n",
      " extracting: unlabeled2017/000000091709.jpg  \n",
      " extracting: unlabeled2017/000000398026.jpg  \n",
      " extracting: unlabeled2017/000000228911.jpg  \n",
      " extracting: unlabeled2017/000000034036.jpg  \n",
      " extracting: unlabeled2017/000000194524.jpg  \n",
      " extracting: unlabeled2017/000000461881.jpg  \n",
      " extracting: unlabeled2017/000000474385.jpg  \n",
      " extracting: unlabeled2017/000000546614.jpg  \n",
      " extracting: unlabeled2017/000000522837.jpg  \n",
      " extracting: unlabeled2017/000000336358.jpg  \n",
      " extracting: unlabeled2017/000000027369.jpg  \n",
      " extracting: unlabeled2017/000000048362.jpg  \n",
      " extracting: unlabeled2017/000000015855.jpg  \n",
      " extracting: unlabeled2017/000000148380.jpg  \n",
      " extracting: unlabeled2017/000000569735.jpg  \n",
      " extracting: unlabeled2017/000000243450.jpg  \n",
      " extracting: unlabeled2017/000000379133.jpg  \n",
      " extracting: unlabeled2017/000000427693.jpg  \n",
      " extracting: unlabeled2017/000000185143.jpg  \n",
      " extracting: unlabeled2017/000000231695.jpg  \n",
      " extracting: unlabeled2017/000000260816.jpg  \n",
      " extracting: unlabeled2017/000000154422.jpg  \n",
      " extracting: unlabeled2017/000000265056.jpg  \n",
      " extracting: unlabeled2017/000000107039.jpg  \n",
      " extracting: unlabeled2017/000000516075.jpg  \n",
      " extracting: unlabeled2017/000000120239.jpg  \n",
      " extracting: unlabeled2017/000000453803.jpg  \n",
      " extracting: unlabeled2017/000000183773.jpg  \n",
      " extracting: unlabeled2017/000000447636.jpg  \n",
      " extracting: unlabeled2017/000000208675.jpg  \n",
      " extracting: unlabeled2017/000000176992.jpg  \n",
      " extracting: unlabeled2017/000000533341.jpg  \n",
      " extracting: unlabeled2017/000000177408.jpg  \n",
      " extracting: unlabeled2017/000000138855.jpg  \n",
      " extracting: unlabeled2017/000000499192.jpg  \n",
      " extracting: unlabeled2017/000000278635.jpg  \n",
      " extracting: unlabeled2017/000000422627.jpg  \n",
      " extracting: unlabeled2017/000000000024.jpg  \n",
      " extracting: unlabeled2017/000000002086.jpg  \n",
      " extracting: unlabeled2017/000000114534.jpg  \n",
      " extracting: unlabeled2017/000000372434.jpg  \n",
      " extracting: unlabeled2017/000000562913.jpg  \n",
      " extracting: unlabeled2017/000000467876.jpg  \n",
      " extracting: unlabeled2017/000000021040.jpg  \n",
      " extracting: unlabeled2017/000000433206.jpg  \n",
      " extracting: unlabeled2017/000000566708.jpg  \n",
      " extracting: unlabeled2017/000000147458.jpg  \n",
      " extracting: unlabeled2017/000000466972.jpg  \n",
      " extracting: unlabeled2017/000000485611.jpg  \n",
      " extracting: unlabeled2017/000000557141.jpg  \n",
      " extracting: unlabeled2017/000000311496.jpg  \n",
      " extracting: unlabeled2017/000000190340.jpg  \n",
      " extracting: unlabeled2017/000000372820.jpg  \n",
      " extracting: unlabeled2017/000000112713.jpg  \n",
      " extracting: unlabeled2017/000000543156.jpg  \n",
      " extracting: unlabeled2017/000000122718.jpg  \n",
      " extracting: unlabeled2017/000000007513.jpg  \n",
      " extracting: unlabeled2017/000000067295.jpg  \n",
      " extracting: unlabeled2017/000000407169.jpg  \n",
      " extracting: unlabeled2017/000000484267.jpg  \n",
      " extracting: unlabeled2017/000000445152.jpg  \n",
      " extracting: unlabeled2017/000000446333.jpg  \n",
      " extracting: unlabeled2017/000000111246.jpg  \n",
      " extracting: unlabeled2017/000000407950.jpg  \n",
      " extracting: unlabeled2017/000000351743.jpg  \n",
      " extracting: unlabeled2017/000000539443.jpg  \n",
      " extracting: unlabeled2017/000000267592.jpg  \n",
      " extracting: unlabeled2017/000000048203.jpg  \n",
      " extracting: unlabeled2017/000000499831.jpg  \n",
      " extracting: unlabeled2017/000000502627.jpg  \n",
      " extracting: unlabeled2017/000000003334.jpg  \n",
      " extracting: unlabeled2017/000000363688.jpg  \n",
      " extracting: unlabeled2017/000000413162.jpg  \n",
      " extracting: unlabeled2017/000000351448.jpg  \n",
      " extracting: unlabeled2017/000000412624.jpg  \n",
      " extracting: unlabeled2017/000000070464.jpg  \n",
      " extracting: unlabeled2017/000000457996.jpg  \n",
      " extracting: unlabeled2017/000000040381.jpg  \n",
      " extracting: unlabeled2017/000000295601.jpg  \n",
      " extracting: unlabeled2017/000000550200.jpg  \n",
      " extracting: unlabeled2017/000000218092.jpg  \n",
      " extracting: unlabeled2017/000000053889.jpg  \n",
      " extracting: unlabeled2017/000000238326.jpg  \n",
      " extracting: unlabeled2017/000000481947.jpg  \n",
      " extracting: unlabeled2017/000000156442.jpg  \n",
      " extracting: unlabeled2017/000000284963.jpg  \n",
      " extracting: unlabeled2017/000000261484.jpg  \n",
      " extracting: unlabeled2017/000000086866.jpg  \n",
      " extracting: unlabeled2017/000000298861.jpg  \n",
      " extracting: unlabeled2017/000000532186.jpg  \n",
      " extracting: unlabeled2017/000000305009.jpg  \n",
      " extracting: unlabeled2017/000000562276.jpg  \n",
      " extracting: unlabeled2017/000000278377.jpg  \n",
      " extracting: unlabeled2017/000000116062.jpg  \n",
      " extracting: unlabeled2017/000000512893.jpg  \n",
      " extracting: unlabeled2017/000000549916.jpg  \n",
      " extracting: unlabeled2017/000000324941.jpg  \n",
      " extracting: unlabeled2017/000000252501.jpg  \n",
      " extracting: unlabeled2017/000000576345.jpg  \n",
      " extracting: unlabeled2017/000000287493.jpg  \n",
      " extracting: unlabeled2017/000000292344.jpg  \n",
      " extracting: unlabeled2017/000000323879.jpg  \n",
      " extracting: unlabeled2017/000000485379.jpg  \n",
      " extracting: unlabeled2017/000000095643.jpg  \n",
      " extracting: unlabeled2017/000000565400.jpg  \n",
      " extracting: unlabeled2017/000000329646.jpg  \n",
      " extracting: unlabeled2017/000000176035.jpg  \n",
      " extracting: unlabeled2017/000000071525.jpg  \n",
      " extracting: unlabeled2017/000000184247.jpg  \n",
      " extracting: unlabeled2017/000000454063.jpg  \n",
      " extracting: unlabeled2017/000000184108.jpg  \n",
      " extracting: unlabeled2017/000000018488.jpg  \n",
      " extracting: unlabeled2017/000000529423.jpg  \n",
      " extracting: unlabeled2017/000000026237.jpg  \n",
      " extracting: unlabeled2017/000000246047.jpg  \n",
      " extracting: unlabeled2017/000000059781.jpg  \n",
      " extracting: unlabeled2017/000000218989.jpg  \n",
      " extracting: unlabeled2017/000000008506.jpg  \n",
      " extracting: unlabeled2017/000000080373.jpg  \n",
      " extracting: unlabeled2017/000000428870.jpg  \n",
      " extracting: unlabeled2017/000000040196.jpg  \n",
      " extracting: unlabeled2017/000000248717.jpg  \n",
      " extracting: unlabeled2017/000000172933.jpg  \n",
      " extracting: unlabeled2017/000000040972.jpg  \n",
      " extracting: unlabeled2017/000000139957.jpg  \n",
      " extracting: unlabeled2017/000000332984.jpg  \n",
      " extracting: unlabeled2017/000000521247.jpg  \n",
      " extracting: unlabeled2017/000000083406.jpg  \n",
      " extracting: unlabeled2017/000000420471.jpg  \n",
      " extracting: unlabeled2017/000000371734.jpg  \n",
      " extracting: unlabeled2017/000000274200.jpg  \n",
      " extracting: unlabeled2017/000000055396.jpg  \n",
      " extracting: unlabeled2017/000000323875.jpg  \n",
      " extracting: unlabeled2017/000000311660.jpg  \n",
      " extracting: unlabeled2017/000000575453.jpg  \n",
      " extracting: unlabeled2017/000000382170.jpg  \n",
      " extracting: unlabeled2017/000000076336.jpg  \n",
      " extracting: unlabeled2017/000000210313.jpg  \n",
      " extracting: unlabeled2017/000000401385.jpg  \n",
      " extracting: unlabeled2017/000000395329.jpg  \n",
      " extracting: unlabeled2017/000000503372.jpg  \n",
      " extracting: unlabeled2017/000000111887.jpg  \n",
      " extracting: unlabeled2017/000000381086.jpg  \n",
      " extracting: unlabeled2017/000000258863.jpg  \n",
      " extracting: unlabeled2017/000000133241.jpg  \n",
      " extracting: unlabeled2017/000000006501.jpg  \n",
      " extracting: unlabeled2017/000000319697.jpg  \n",
      " extracting: unlabeled2017/000000381070.jpg  \n",
      " extracting: unlabeled2017/000000003996.jpg  \n",
      " extracting: unlabeled2017/000000533857.jpg  \n",
      " extracting: unlabeled2017/000000149638.jpg  \n",
      " extracting: unlabeled2017/000000501319.jpg  \n",
      " extracting: unlabeled2017/000000456022.jpg  \n",
      " extracting: unlabeled2017/000000525862.jpg  \n",
      " extracting: unlabeled2017/000000053614.jpg  \n",
      " extracting: unlabeled2017/000000408633.jpg  \n",
      " extracting: unlabeled2017/000000035906.jpg  \n",
      " extracting: unlabeled2017/000000104228.jpg  \n",
      " extracting: unlabeled2017/000000295669.jpg  \n",
      " extracting: unlabeled2017/000000541563.jpg  \n",
      " extracting: unlabeled2017/000000297988.jpg  \n",
      " extracting: unlabeled2017/000000286546.jpg  \n",
      " extracting: unlabeled2017/000000032505.jpg  \n",
      " extracting: unlabeled2017/000000280197.jpg  \n",
      " extracting: unlabeled2017/000000248939.jpg  \n",
      " extracting: unlabeled2017/000000057066.jpg  \n",
      " extracting: unlabeled2017/000000255475.jpg  \n",
      " extracting: unlabeled2017/000000370172.jpg  \n",
      " extracting: unlabeled2017/000000319294.jpg  \n",
      " extracting: unlabeled2017/000000383745.jpg  \n",
      " extracting: unlabeled2017/000000411850.jpg  \n",
      " extracting: unlabeled2017/000000178039.jpg  \n",
      " extracting: unlabeled2017/000000374305.jpg  \n",
      " extracting: unlabeled2017/000000300799.jpg  \n",
      " extracting: unlabeled2017/000000068495.jpg  \n",
      " extracting: unlabeled2017/000000295229.jpg  \n",
      " extracting: unlabeled2017/000000147813.jpg  \n",
      " extracting: unlabeled2017/000000176836.jpg  \n",
      " extracting: unlabeled2017/000000109628.jpg  \n",
      " extracting: unlabeled2017/000000331434.jpg  \n",
      " extracting: unlabeled2017/000000348818.jpg  \n",
      " extracting: unlabeled2017/000000538027.jpg  \n",
      " extracting: unlabeled2017/000000101311.jpg  \n",
      " extracting: unlabeled2017/000000392424.jpg  \n",
      " extracting: unlabeled2017/000000425048.jpg  \n",
      " extracting: unlabeled2017/000000302709.jpg  \n",
      " extracting: unlabeled2017/000000302337.jpg  \n",
      " extracting: unlabeled2017/000000562505.jpg  \n",
      " extracting: unlabeled2017/000000296966.jpg  \n",
      " extracting: unlabeled2017/000000003114.jpg  \n",
      " extracting: unlabeled2017/000000562583.jpg  \n",
      " extracting: unlabeled2017/000000377442.jpg  \n",
      " extracting: unlabeled2017/000000079875.jpg  \n",
      " extracting: unlabeled2017/000000545465.jpg  \n",
      " extracting: unlabeled2017/000000391683.jpg  \n",
      " extracting: unlabeled2017/000000021789.jpg  \n",
      " extracting: unlabeled2017/000000481794.jpg  \n",
      " extracting: unlabeled2017/000000197346.jpg  \n",
      " extracting: unlabeled2017/000000383331.jpg  \n",
      " extracting: unlabeled2017/000000367238.jpg  \n",
      " extracting: unlabeled2017/000000484785.jpg  \n",
      " extracting: unlabeled2017/000000272437.jpg  \n",
      " extracting: unlabeled2017/000000320994.jpg  \n",
      " extracting: unlabeled2017/000000338302.jpg  \n",
      " extracting: unlabeled2017/000000302501.jpg  \n",
      " extracting: unlabeled2017/000000388703.jpg  \n",
      " extracting: unlabeled2017/000000529868.jpg  \n",
      " extracting: unlabeled2017/000000318715.jpg  \n",
      " extracting: unlabeled2017/000000025026.jpg  \n",
      " extracting: unlabeled2017/000000552763.jpg  \n",
      " extracting: unlabeled2017/000000561079.jpg  \n",
      " extracting: unlabeled2017/000000420786.jpg  \n",
      " extracting: unlabeled2017/000000332314.jpg  \n",
      " extracting: unlabeled2017/000000130128.jpg  \n",
      " extracting: unlabeled2017/000000570571.jpg  \n",
      " extracting: unlabeled2017/000000489603.jpg  \n",
      " extracting: unlabeled2017/000000278585.jpg  \n",
      " extracting: unlabeled2017/000000027038.jpg  \n",
      " extracting: unlabeled2017/000000231917.jpg  \n",
      " extracting: unlabeled2017/000000274125.jpg  \n",
      " extracting: unlabeled2017/000000386663.jpg  \n",
      " extracting: unlabeled2017/000000578074.jpg  \n",
      " extracting: unlabeled2017/000000346277.jpg  \n",
      " extracting: unlabeled2017/000000478493.jpg  \n",
      " extracting: unlabeled2017/000000516356.jpg  \n",
      " extracting: unlabeled2017/000000068665.jpg  \n",
      " extracting: unlabeled2017/000000580584.jpg  \n",
      " extracting: unlabeled2017/000000274948.jpg  \n",
      " extracting: unlabeled2017/000000095638.jpg  \n",
      " extracting: unlabeled2017/000000232606.jpg  \n",
      " extracting: unlabeled2017/000000210660.jpg  \n",
      " extracting: unlabeled2017/000000297381.jpg  \n",
      " extracting: unlabeled2017/000000502869.jpg  \n",
      " extracting: unlabeled2017/000000333202.jpg  \n",
      " extracting: unlabeled2017/000000354156.jpg  \n",
      " extracting: unlabeled2017/000000012237.jpg  \n",
      " extracting: unlabeled2017/000000558226.jpg  \n",
      " extracting: unlabeled2017/000000012554.jpg  \n",
      " extracting: unlabeled2017/000000465455.jpg  \n",
      " extracting: unlabeled2017/000000532872.jpg  \n",
      " extracting: unlabeled2017/000000136912.jpg  \n",
      " extracting: unlabeled2017/000000346861.jpg  \n",
      " extracting: unlabeled2017/000000576590.jpg  \n",
      " extracting: unlabeled2017/000000157414.jpg  \n",
      " extracting: unlabeled2017/000000136564.jpg  \n",
      " extracting: unlabeled2017/000000106439.jpg  \n",
      " extracting: unlabeled2017/000000220634.jpg  \n",
      " extracting: unlabeled2017/000000578507.jpg  \n",
      " extracting: unlabeled2017/000000400237.jpg  \n",
      " extracting: unlabeled2017/000000568594.jpg  \n",
      " extracting: unlabeled2017/000000478150.jpg  \n",
      " extracting: unlabeled2017/000000001839.jpg  \n",
      " extracting: unlabeled2017/000000313393.jpg  \n",
      " extracting: unlabeled2017/000000190735.jpg  \n",
      " extracting: unlabeled2017/000000112273.jpg  \n",
      " extracting: unlabeled2017/000000138874.jpg  \n",
      " extracting: unlabeled2017/000000264366.jpg  \n",
      " extracting: unlabeled2017/000000552437.jpg  \n",
      " extracting: unlabeled2017/000000140401.jpg  \n",
      " extracting: unlabeled2017/000000472179.jpg  \n",
      " extracting: unlabeled2017/000000010298.jpg  \n",
      " extracting: unlabeled2017/000000296443.jpg  \n",
      " extracting: unlabeled2017/000000353714.jpg  \n",
      " extracting: unlabeled2017/000000424323.jpg  \n",
      " extracting: unlabeled2017/000000212357.jpg  \n",
      " extracting: unlabeled2017/000000426476.jpg  \n",
      " extracting: unlabeled2017/000000296396.jpg  \n",
      " extracting: unlabeled2017/000000163301.jpg  \n",
      " extracting: unlabeled2017/000000354696.jpg  \n",
      " extracting: unlabeled2017/000000304662.jpg  \n",
      " extracting: unlabeled2017/000000163291.jpg  \n",
      " extracting: unlabeled2017/000000480349.jpg  \n",
      " extracting: unlabeled2017/000000121549.jpg  \n",
      " extracting: unlabeled2017/000000539712.jpg  \n",
      " extracting: unlabeled2017/000000135643.jpg  \n",
      " extracting: unlabeled2017/000000216629.jpg  \n",
      " extracting: unlabeled2017/000000281588.jpg  \n",
      " extracting: unlabeled2017/000000381452.jpg  \n",
      " extracting: unlabeled2017/000000542700.jpg  \n",
      " extracting: unlabeled2017/000000334828.jpg  \n",
      " extracting: unlabeled2017/000000158175.jpg  \n",
      " extracting: unlabeled2017/000000438866.jpg  \n",
      " extracting: unlabeled2017/000000398418.jpg  \n",
      " extracting: unlabeled2017/000000189727.jpg  \n",
      " extracting: unlabeled2017/000000333813.jpg  \n",
      " extracting: unlabeled2017/000000022594.jpg  \n",
      " extracting: unlabeled2017/000000446412.jpg  \n",
      " extracting: unlabeled2017/000000239431.jpg  \n",
      " extracting: unlabeled2017/000000012091.jpg  \n",
      " extracting: unlabeled2017/000000010692.jpg  \n",
      " extracting: unlabeled2017/000000397474.jpg  \n",
      " extracting: unlabeled2017/000000350728.jpg  \n",
      " extracting: unlabeled2017/000000383593.jpg  \n",
      " extracting: unlabeled2017/000000200885.jpg  \n",
      " extracting: unlabeled2017/000000357907.jpg  \n",
      " extracting: unlabeled2017/000000504844.jpg  \n",
      " extracting: unlabeled2017/000000524727.jpg  \n",
      " extracting: unlabeled2017/000000155411.jpg  \n",
      " extracting: unlabeled2017/000000415715.jpg  \n",
      " extracting: unlabeled2017/000000272084.jpg  \n",
      " extracting: unlabeled2017/000000036035.jpg  \n",
      " extracting: unlabeled2017/000000180159.jpg  \n",
      " extracting: unlabeled2017/000000040791.jpg  \n",
      " extracting: unlabeled2017/000000148961.jpg  \n",
      " extracting: unlabeled2017/000000104175.jpg  \n",
      " extracting: unlabeled2017/000000029425.jpg  \n",
      " extracting: unlabeled2017/000000449744.jpg  \n",
      " extracting: unlabeled2017/000000043910.jpg  \n",
      " extracting: unlabeled2017/000000417207.jpg  \n",
      " extracting: unlabeled2017/000000259432.jpg  \n",
      " extracting: unlabeled2017/000000380679.jpg  \n",
      " extracting: unlabeled2017/000000127361.jpg  \n",
      " extracting: unlabeled2017/000000086508.jpg  \n",
      " extracting: unlabeled2017/000000173210.jpg  \n",
      " extracting: unlabeled2017/000000568631.jpg  \n",
      " extracting: unlabeled2017/000000231011.jpg  \n",
      " extracting: unlabeled2017/000000527943.jpg  \n",
      " extracting: unlabeled2017/000000019481.jpg  \n",
      " extracting: unlabeled2017/000000190600.jpg  \n",
      " extracting: unlabeled2017/000000575113.jpg  \n",
      " extracting: unlabeled2017/000000366100.jpg  \n",
      " extracting: unlabeled2017/000000262803.jpg  \n",
      " extracting: unlabeled2017/000000182761.jpg  \n",
      " extracting: unlabeled2017/000000367765.jpg  \n",
      " extracting: unlabeled2017/000000043157.jpg  \n",
      " extracting: unlabeled2017/000000308890.jpg  \n",
      " extracting: unlabeled2017/000000025074.jpg  \n",
      " extracting: unlabeled2017/000000285721.jpg  \n",
      " extracting: unlabeled2017/000000063718.jpg  \n",
      " extracting: unlabeled2017/000000194919.jpg  \n",
      " extracting: unlabeled2017/000000410639.jpg  \n",
      " extracting: unlabeled2017/000000196237.jpg  \n",
      " extracting: unlabeled2017/000000443501.jpg  \n",
      " extracting: unlabeled2017/000000202720.jpg  \n",
      " extracting: unlabeled2017/000000537586.jpg  \n",
      " extracting: unlabeled2017/000000203755.jpg  \n",
      " extracting: unlabeled2017/000000072144.jpg  \n",
      " extracting: unlabeled2017/000000346029.jpg  \n",
      " extracting: unlabeled2017/000000506679.jpg  \n",
      " extracting: unlabeled2017/000000455171.jpg  \n",
      " extracting: unlabeled2017/000000193575.jpg  \n",
      " extracting: unlabeled2017/000000077299.jpg  \n",
      " extracting: unlabeled2017/000000372446.jpg  \n",
      " extracting: unlabeled2017/000000289521.jpg  \n",
      " extracting: unlabeled2017/000000554042.jpg  \n",
      " extracting: unlabeled2017/000000044443.jpg  \n",
      " extracting: unlabeled2017/000000314399.jpg  \n",
      " extracting: unlabeled2017/000000371809.jpg  \n",
      " extracting: unlabeled2017/000000579878.jpg  \n",
      " extracting: unlabeled2017/000000198906.jpg  \n",
      " extracting: unlabeled2017/000000276534.jpg  \n",
      " extracting: unlabeled2017/000000339265.jpg  \n",
      " extracting: unlabeled2017/000000075667.jpg  \n",
      " extracting: unlabeled2017/000000243553.jpg  \n",
      " extracting: unlabeled2017/000000089272.jpg  \n",
      " extracting: unlabeled2017/000000381830.jpg  \n",
      " extracting: unlabeled2017/000000461797.jpg  \n",
      " extracting: unlabeled2017/000000163094.jpg  \n",
      " extracting: unlabeled2017/000000033148.jpg  \n",
      " extracting: unlabeled2017/000000515279.jpg  \n",
      " extracting: unlabeled2017/000000388554.jpg  \n",
      " extracting: unlabeled2017/000000106690.jpg  \n",
      " extracting: unlabeled2017/000000437152.jpg  \n",
      " extracting: unlabeled2017/000000167233.jpg  \n",
      " extracting: unlabeled2017/000000516154.jpg  \n",
      " extracting: unlabeled2017/000000026595.jpg  \n",
      " extracting: unlabeled2017/000000002134.jpg  \n",
      " extracting: unlabeled2017/000000328517.jpg  \n",
      " extracting: unlabeled2017/000000472184.jpg  \n",
      " extracting: unlabeled2017/000000265486.jpg  \n",
      " extracting: unlabeled2017/000000061785.jpg  \n",
      " extracting: unlabeled2017/000000335122.jpg  \n",
      " extracting: unlabeled2017/000000316465.jpg  \n",
      " extracting: unlabeled2017/000000054915.jpg  \n",
      " extracting: unlabeled2017/000000403244.jpg  \n",
      " extracting: unlabeled2017/000000245601.jpg  \n",
      " extracting: unlabeled2017/000000249490.jpg  \n",
      " extracting: unlabeled2017/000000510576.jpg  \n",
      " extracting: unlabeled2017/000000555895.jpg  \n",
      " extracting: unlabeled2017/000000413158.jpg  \n",
      " extracting: unlabeled2017/000000341166.jpg  \n",
      " extracting: unlabeled2017/000000187201.jpg  \n",
      " extracting: unlabeled2017/000000320002.jpg  \n",
      " extracting: unlabeled2017/000000522458.jpg  \n",
      " extracting: unlabeled2017/000000438616.jpg  \n",
      " extracting: unlabeled2017/000000328566.jpg  \n",
      " extracting: unlabeled2017/000000279601.jpg  \n",
      " extracting: unlabeled2017/000000255514.jpg  \n",
      " extracting: unlabeled2017/000000322732.jpg  \n",
      " extracting: unlabeled2017/000000367265.jpg  \n",
      " extracting: unlabeled2017/000000560383.jpg  \n",
      " extracting: unlabeled2017/000000216669.jpg  \n",
      " extracting: unlabeled2017/000000065778.jpg  \n",
      " extracting: unlabeled2017/000000144571.jpg  \n",
      " extracting: unlabeled2017/000000218217.jpg  \n",
      " extracting: unlabeled2017/000000226724.jpg  \n",
      " extracting: unlabeled2017/000000229503.jpg  \n",
      " extracting: unlabeled2017/000000404588.jpg  \n",
      " extracting: unlabeled2017/000000265293.jpg  \n",
      " extracting: unlabeled2017/000000072125.jpg  \n",
      " extracting: unlabeled2017/000000499744.jpg  \n",
      " extracting: unlabeled2017/000000350312.jpg  \n",
      " extracting: unlabeled2017/000000452561.jpg  \n",
      " extracting: unlabeled2017/000000104483.jpg  \n",
      " extracting: unlabeled2017/000000524942.jpg  \n",
      " extracting: unlabeled2017/000000249908.jpg  \n",
      " extracting: unlabeled2017/000000204814.jpg  \n",
      " extracting: unlabeled2017/000000331286.jpg  \n",
      " extracting: unlabeled2017/000000199343.jpg  \n",
      " extracting: unlabeled2017/000000062972.jpg  \n",
      " extracting: unlabeled2017/000000198221.jpg  \n",
      " extracting: unlabeled2017/000000376741.jpg  \n",
      " extracting: unlabeled2017/000000145108.jpg  \n",
      " extracting: unlabeled2017/000000399898.jpg  \n",
      " extracting: unlabeled2017/000000330693.jpg  \n",
      " extracting: unlabeled2017/000000368753.jpg  \n",
      " extracting: unlabeled2017/000000420694.jpg  \n",
      " extracting: unlabeled2017/000000178880.jpg  \n",
      " extracting: unlabeled2017/000000307357.jpg  \n",
      " extracting: unlabeled2017/000000257739.jpg  \n",
      " extracting: unlabeled2017/000000550330.jpg  \n",
      " extracting: unlabeled2017/000000034245.jpg  \n",
      " extracting: unlabeled2017/000000267430.jpg  \n",
      " extracting: unlabeled2017/000000266509.jpg  \n",
      " extracting: unlabeled2017/000000519379.jpg  \n",
      " extracting: unlabeled2017/000000429176.jpg  \n",
      " extracting: unlabeled2017/000000196689.jpg  \n",
      " extracting: unlabeled2017/000000031628.jpg  \n",
      " extracting: unlabeled2017/000000296694.jpg  \n",
      " extracting: unlabeled2017/000000108410.jpg  \n",
      " extracting: unlabeled2017/000000355226.jpg  \n",
      " extracting: unlabeled2017/000000447067.jpg  \n",
      " extracting: unlabeled2017/000000113864.jpg  \n",
      " extracting: unlabeled2017/000000129624.jpg  \n",
      " extracting: unlabeled2017/000000337592.jpg  \n",
      " extracting: unlabeled2017/000000253360.jpg  \n",
      " extracting: unlabeled2017/000000208444.jpg  \n",
      " extracting: unlabeled2017/000000197724.jpg  \n",
      " extracting: unlabeled2017/000000179493.jpg  \n",
      " extracting: unlabeled2017/000000015637.jpg  \n",
      " extracting: unlabeled2017/000000116847.jpg  \n",
      " extracting: unlabeled2017/000000027240.jpg  \n",
      " extracting: unlabeled2017/000000538150.jpg  \n",
      " extracting: unlabeled2017/000000095605.jpg  \n",
      " extracting: unlabeled2017/000000532110.jpg  \n",
      " extracting: unlabeled2017/000000484890.jpg  \n",
      " extracting: unlabeled2017/000000054271.jpg  \n",
      " extracting: unlabeled2017/000000048487.jpg  \n",
      " extracting: unlabeled2017/000000502917.jpg  \n",
      " extracting: unlabeled2017/000000285854.jpg  \n",
      " extracting: unlabeled2017/000000217049.jpg  \n",
      " extracting: unlabeled2017/000000332840.jpg  \n",
      " extracting: unlabeled2017/000000564347.jpg  \n",
      " extracting: unlabeled2017/000000374402.jpg  \n",
      " extracting: unlabeled2017/000000037915.jpg  \n",
      " extracting: unlabeled2017/000000533920.jpg  \n",
      " extracting: unlabeled2017/000000514420.jpg  \n",
      " extracting: unlabeled2017/000000448129.jpg  \n",
      " extracting: unlabeled2017/000000445364.jpg  \n",
      " extracting: unlabeled2017/000000341591.jpg  \n",
      " extracting: unlabeled2017/000000407832.jpg  \n",
      " extracting: unlabeled2017/000000537340.jpg  \n",
      " extracting: unlabeled2017/000000110039.jpg  \n",
      " extracting: unlabeled2017/000000362806.jpg  \n",
      " extracting: unlabeled2017/000000504575.jpg  \n",
      " extracting: unlabeled2017/000000479569.jpg  \n",
      " extracting: unlabeled2017/000000295217.jpg  \n",
      " extracting: unlabeled2017/000000295094.jpg  \n",
      " extracting: unlabeled2017/000000091230.jpg  \n",
      " extracting: unlabeled2017/000000347181.jpg  \n",
      " extracting: unlabeled2017/000000173205.jpg  \n",
      " extracting: unlabeled2017/000000511284.jpg  \n",
      " extracting: unlabeled2017/000000447544.jpg  \n",
      " extracting: unlabeled2017/000000245838.jpg  \n",
      " extracting: unlabeled2017/000000221957.jpg  \n",
      " extracting: unlabeled2017/000000457886.jpg  \n",
      " extracting: unlabeled2017/000000150207.jpg  \n",
      " extracting: unlabeled2017/000000102193.jpg  \n",
      " extracting: unlabeled2017/000000140381.jpg  \n",
      " extracting: unlabeled2017/000000133713.jpg  \n",
      " extracting: unlabeled2017/000000433260.jpg  \n",
      " extracting: unlabeled2017/000000399525.jpg  \n",
      " extracting: unlabeled2017/000000523756.jpg  \n",
      " extracting: unlabeled2017/000000083493.jpg  \n",
      " extracting: unlabeled2017/000000580075.jpg  \n",
      " extracting: unlabeled2017/000000399761.jpg  \n",
      " extracting: unlabeled2017/000000197460.jpg  \n",
      " extracting: unlabeled2017/000000478246.jpg  \n",
      " extracting: unlabeled2017/000000247347.jpg  \n",
      " extracting: unlabeled2017/000000547552.jpg  \n",
      " extracting: unlabeled2017/000000411848.jpg  \n",
      " extracting: unlabeled2017/000000273040.jpg  \n",
      " extracting: unlabeled2017/000000274503.jpg  \n",
      " extracting: unlabeled2017/000000165952.jpg  \n",
      " extracting: unlabeled2017/000000538395.jpg  \n",
      " extracting: unlabeled2017/000000302106.jpg  \n",
      " extracting: unlabeled2017/000000253160.jpg  \n",
      " extracting: unlabeled2017/000000572621.jpg  \n",
      " extracting: unlabeled2017/000000410813.jpg  \n",
      " extracting: unlabeled2017/000000026285.jpg  \n",
      " extracting: unlabeled2017/000000157407.jpg  \n",
      " extracting: unlabeled2017/000000061891.jpg  \n",
      " extracting: unlabeled2017/000000534445.jpg  \n",
      " extracting: unlabeled2017/000000417883.jpg  \n",
      " extracting: unlabeled2017/000000419498.jpg  \n",
      " extracting: unlabeled2017/000000017466.jpg  \n",
      " extracting: unlabeled2017/000000021977.jpg  \n",
      " extracting: unlabeled2017/000000254324.jpg  \n",
      " extracting: unlabeled2017/000000560013.jpg  \n",
      " extracting: unlabeled2017/000000021828.jpg  \n",
      " extracting: unlabeled2017/000000356395.jpg  \n",
      " extracting: unlabeled2017/000000045326.jpg  \n",
      " extracting: unlabeled2017/000000514431.jpg  \n",
      " extracting: unlabeled2017/000000443961.jpg  \n",
      " extracting: unlabeled2017/000000215683.jpg  \n",
      " extracting: unlabeled2017/000000161874.jpg  \n",
      " extracting: unlabeled2017/000000009535.jpg  \n",
      " extracting: unlabeled2017/000000576731.jpg  \n",
      " extracting: unlabeled2017/000000016984.jpg  \n",
      " extracting: unlabeled2017/000000278373.jpg  \n",
      " extracting: unlabeled2017/000000254034.jpg  \n",
      " extracting: unlabeled2017/000000312393.jpg  \n",
      " extracting: unlabeled2017/000000018616.jpg  \n",
      " extracting: unlabeled2017/000000315842.jpg  \n",
      " extracting: unlabeled2017/000000226480.jpg  \n",
      " extracting: unlabeled2017/000000057121.jpg  \n",
      " extracting: unlabeled2017/000000105140.jpg  \n",
      " extracting: unlabeled2017/000000060864.jpg  \n",
      " extracting: unlabeled2017/000000548085.jpg  \n",
      " extracting: unlabeled2017/000000333148.jpg  \n",
      " extracting: unlabeled2017/000000100250.jpg  \n",
      " extracting: unlabeled2017/000000544879.jpg  \n",
      " extracting: unlabeled2017/000000083577.jpg  \n",
      " extracting: unlabeled2017/000000475860.jpg  \n",
      " extracting: unlabeled2017/000000492073.jpg  \n",
      " extracting: unlabeled2017/000000317548.jpg  \n",
      " extracting: unlabeled2017/000000412168.jpg  \n",
      " extracting: unlabeled2017/000000452243.jpg  \n",
      " extracting: unlabeled2017/000000174843.jpg  \n",
      " extracting: unlabeled2017/000000489306.jpg  \n",
      " extracting: unlabeled2017/000000474412.jpg  \n",
      " extracting: unlabeled2017/000000242978.jpg  \n",
      " extracting: unlabeled2017/000000517849.jpg  \n",
      " extracting: unlabeled2017/000000418258.jpg  \n",
      " extracting: unlabeled2017/000000039338.jpg  \n",
      " extracting: unlabeled2017/000000038533.jpg  \n",
      " extracting: unlabeled2017/000000450120.jpg  \n",
      " extracting: unlabeled2017/000000513479.jpg  \n",
      " extracting: unlabeled2017/000000457983.jpg  \n",
      " extracting: unlabeled2017/000000093573.jpg  \n",
      " extracting: unlabeled2017/000000298018.jpg  \n",
      " extracting: unlabeled2017/000000427758.jpg  \n",
      " extracting: unlabeled2017/000000562024.jpg  \n",
      " extracting: unlabeled2017/000000366223.jpg  \n",
      " extracting: unlabeled2017/000000546580.jpg  \n",
      " extracting: unlabeled2017/000000170299.jpg  \n",
      " extracting: unlabeled2017/000000431101.jpg  \n",
      " extracting: unlabeled2017/000000349937.jpg  \n",
      " extracting: unlabeled2017/000000177574.jpg  \n",
      " extracting: unlabeled2017/000000370496.jpg  \n",
      " extracting: unlabeled2017/000000102164.jpg  \n",
      " extracting: unlabeled2017/000000119001.jpg  \n",
      " extracting: unlabeled2017/000000025349.jpg  \n",
      " extracting: unlabeled2017/000000534344.jpg  \n",
      " extracting: unlabeled2017/000000436053.jpg  \n",
      " extracting: unlabeled2017/000000036257.jpg  \n",
      " extracting: unlabeled2017/000000345946.jpg  \n",
      " extracting: unlabeled2017/000000228805.jpg  \n",
      " extracting: unlabeled2017/000000426154.jpg  \n",
      " extracting: unlabeled2017/000000410240.jpg  \n",
      " extracting: unlabeled2017/000000340661.jpg  \n",
      " extracting: unlabeled2017/000000443300.jpg  \n",
      " extracting: unlabeled2017/000000009019.jpg  \n",
      " extracting: unlabeled2017/000000566036.jpg  \n",
      " extracting: unlabeled2017/000000156464.jpg  \n",
      " extracting: unlabeled2017/000000397797.jpg  \n",
      " extracting: unlabeled2017/000000434490.jpg  \n",
      " extracting: unlabeled2017/000000310900.jpg  \n",
      " extracting: unlabeled2017/000000038239.jpg  \n",
      " extracting: unlabeled2017/000000118193.jpg  \n",
      " extracting: unlabeled2017/000000293451.jpg  \n",
      " extracting: unlabeled2017/000000188980.jpg  \n",
      " extracting: unlabeled2017/000000167502.jpg  \n",
      " extracting: unlabeled2017/000000117561.jpg  \n",
      " extracting: unlabeled2017/000000276393.jpg  \n",
      " extracting: unlabeled2017/000000165988.jpg  \n",
      " extracting: unlabeled2017/000000260593.jpg  \n",
      " extracting: unlabeled2017/000000281898.jpg  \n",
      " extracting: unlabeled2017/000000254188.jpg  \n",
      " extracting: unlabeled2017/000000065341.jpg  \n",
      " extracting: unlabeled2017/000000196942.jpg  \n",
      " extracting: unlabeled2017/000000114783.jpg  \n",
      " extracting: unlabeled2017/000000109685.jpg  \n",
      " extracting: unlabeled2017/000000077525.jpg  \n",
      " extracting: unlabeled2017/000000075769.jpg  \n",
      " extracting: unlabeled2017/000000061579.jpg  \n",
      " extracting: unlabeled2017/000000412381.jpg  \n",
      " extracting: unlabeled2017/000000030324.jpg  \n",
      " extracting: unlabeled2017/000000429694.jpg  \n",
      " extracting: unlabeled2017/000000330735.jpg  \n",
      " extracting: unlabeled2017/000000165149.jpg  \n",
      " extracting: unlabeled2017/000000258247.jpg  \n",
      " extracting: unlabeled2017/000000124634.jpg  \n",
      " extracting: unlabeled2017/000000054251.jpg  \n",
      " extracting: unlabeled2017/000000439152.jpg  \n",
      " extracting: unlabeled2017/000000219581.jpg  \n",
      " extracting: unlabeled2017/000000249745.jpg  \n",
      " extracting: unlabeled2017/000000458605.jpg  \n",
      " extracting: unlabeled2017/000000138532.jpg  \n",
      " extracting: unlabeled2017/000000021057.jpg  \n",
      " extracting: unlabeled2017/000000442704.jpg  \n",
      " extracting: unlabeled2017/000000328468.jpg  \n",
      " extracting: unlabeled2017/000000519274.jpg  \n",
      " extracting: unlabeled2017/000000219990.jpg  \n",
      " extracting: unlabeled2017/000000428314.jpg  \n",
      " extracting: unlabeled2017/000000202446.jpg  \n",
      " extracting: unlabeled2017/000000283590.jpg  \n",
      " extracting: unlabeled2017/000000004943.jpg  \n",
      " extracting: unlabeled2017/000000194808.jpg  \n",
      " extracting: unlabeled2017/000000509046.jpg  \n",
      " extracting: unlabeled2017/000000252404.jpg  \n",
      " extracting: unlabeled2017/000000336345.jpg  \n",
      " extracting: unlabeled2017/000000032568.jpg  \n",
      " extracting: unlabeled2017/000000028035.jpg  \n",
      " extracting: unlabeled2017/000000527794.jpg  \n",
      " extracting: unlabeled2017/000000421508.jpg  \n",
      " extracting: unlabeled2017/000000218543.jpg  \n",
      " extracting: unlabeled2017/000000483263.jpg  \n",
      " extracting: unlabeled2017/000000234926.jpg  \n",
      " extracting: unlabeled2017/000000202071.jpg  \n",
      " extracting: unlabeled2017/000000086766.jpg  \n",
      " extracting: unlabeled2017/000000117870.jpg  \n",
      " extracting: unlabeled2017/000000516860.jpg  \n",
      " extracting: unlabeled2017/000000461269.jpg  \n",
      " extracting: unlabeled2017/000000021841.jpg  \n",
      " extracting: unlabeled2017/000000538880.jpg  \n",
      " extracting: unlabeled2017/000000069547.jpg  \n",
      " extracting: unlabeled2017/000000410799.jpg  \n",
      " extracting: unlabeled2017/000000227824.jpg  \n",
      " extracting: unlabeled2017/000000391517.jpg  \n",
      " extracting: unlabeled2017/000000501836.jpg  \n",
      " extracting: unlabeled2017/000000263295.jpg  \n",
      " extracting: unlabeled2017/000000250283.jpg  \n",
      " extracting: unlabeled2017/000000460232.jpg  \n",
      " extracting: unlabeled2017/000000432034.jpg  \n",
      " extracting: unlabeled2017/000000098623.jpg  \n",
      " extracting: unlabeled2017/000000053772.jpg  \n",
      " extracting: unlabeled2017/000000432039.jpg  \n",
      " extracting: unlabeled2017/000000422204.jpg  \n",
      " extracting: unlabeled2017/000000141287.jpg  \n",
      " extracting: unlabeled2017/000000103289.jpg  \n",
      " extracting: unlabeled2017/000000007580.jpg  \n",
      " extracting: unlabeled2017/000000329645.jpg  \n",
      " extracting: unlabeled2017/000000295351.jpg  \n",
      " extracting: unlabeled2017/000000039388.jpg  \n",
      " extracting: unlabeled2017/000000468911.jpg  \n",
      " extracting: unlabeled2017/000000541986.jpg  \n",
      " extracting: unlabeled2017/000000543091.jpg  \n",
      " extracting: unlabeled2017/000000243555.jpg  \n",
      " extracting: unlabeled2017/000000038412.jpg  \n",
      " extracting: unlabeled2017/000000565510.jpg  \n",
      " extracting: unlabeled2017/000000477928.jpg  \n",
      " extracting: unlabeled2017/000000162881.jpg  \n",
      " extracting: unlabeled2017/000000304460.jpg  \n",
      " extracting: unlabeled2017/000000155492.jpg  \n",
      " extracting: unlabeled2017/000000357879.jpg  \n",
      " extracting: unlabeled2017/000000273541.jpg  \n",
      " extracting: unlabeled2017/000000196519.jpg  \n",
      " extracting: unlabeled2017/000000002162.jpg  \n",
      " extracting: unlabeled2017/000000250419.jpg  \n",
      " extracting: unlabeled2017/000000158596.jpg  \n",
      " extracting: unlabeled2017/000000580871.jpg  \n",
      " extracting: unlabeled2017/000000340818.jpg  \n",
      " extracting: unlabeled2017/000000161541.jpg  \n",
      " extracting: unlabeled2017/000000573353.jpg  \n",
      " extracting: unlabeled2017/000000484900.jpg  \n",
      " extracting: unlabeled2017/000000560663.jpg  \n",
      " extracting: unlabeled2017/000000302754.jpg  \n",
      " extracting: unlabeled2017/000000431916.jpg  \n",
      " extracting: unlabeled2017/000000070643.jpg  \n",
      " extracting: unlabeled2017/000000394181.jpg  \n",
      " extracting: unlabeled2017/000000168787.jpg  \n",
      " extracting: unlabeled2017/000000470457.jpg  \n",
      " extracting: unlabeled2017/000000440731.jpg  \n",
      " extracting: unlabeled2017/000000541200.jpg  \n",
      " extracting: unlabeled2017/000000258079.jpg  \n",
      " extracting: unlabeled2017/000000427906.jpg  \n",
      " extracting: unlabeled2017/000000442751.jpg  \n",
      " extracting: unlabeled2017/000000286635.jpg  \n",
      " extracting: unlabeled2017/000000176890.jpg  \n",
      " extracting: unlabeled2017/000000031940.jpg  \n",
      " extracting: unlabeled2017/000000364379.jpg  \n",
      " extracting: unlabeled2017/000000459371.jpg  \n",
      " extracting: unlabeled2017/000000190835.jpg  \n",
      " extracting: unlabeled2017/000000195029.jpg  \n",
      " extracting: unlabeled2017/000000142152.jpg  \n",
      " extracting: unlabeled2017/000000367800.jpg  \n",
      " extracting: unlabeled2017/000000099973.jpg  \n",
      " extracting: unlabeled2017/000000070524.jpg  \n",
      " extracting: unlabeled2017/000000130940.jpg  \n",
      " extracting: unlabeled2017/000000125777.jpg  \n",
      " extracting: unlabeled2017/000000114105.jpg  \n",
      " extracting: unlabeled2017/000000568965.jpg  \n",
      " extracting: unlabeled2017/000000106903.jpg  \n",
      " extracting: unlabeled2017/000000456430.jpg  \n",
      " extracting: unlabeled2017/000000383957.jpg  \n",
      " extracting: unlabeled2017/000000550425.jpg  \n",
      " extracting: unlabeled2017/000000573160.jpg  \n",
      " extracting: unlabeled2017/000000567029.jpg  \n",
      " extracting: unlabeled2017/000000262050.jpg  \n",
      " extracting: unlabeled2017/000000379818.jpg  \n",
      " extracting: unlabeled2017/000000152313.jpg  \n",
      " extracting: unlabeled2017/000000459178.jpg  \n",
      " extracting: unlabeled2017/000000341543.jpg  \n",
      " extracting: unlabeled2017/000000433610.jpg  \n",
      " extracting: unlabeled2017/000000538983.jpg  \n",
      " extracting: unlabeled2017/000000273267.jpg  \n",
      " extracting: unlabeled2017/000000030710.jpg  \n",
      " extracting: unlabeled2017/000000230789.jpg  \n",
      " extracting: unlabeled2017/000000437307.jpg  \n",
      " extracting: unlabeled2017/000000542393.jpg  \n",
      " extracting: unlabeled2017/000000404884.jpg  \n",
      " extracting: unlabeled2017/000000273096.jpg  \n",
      " extracting: unlabeled2017/000000576988.jpg  \n",
      " extracting: unlabeled2017/000000312609.jpg  \n",
      " extracting: unlabeled2017/000000201996.jpg  \n",
      " extracting: unlabeled2017/000000449034.jpg  \n",
      " extracting: unlabeled2017/000000056574.jpg  \n",
      " extracting: unlabeled2017/000000131639.jpg  \n",
      " extracting: unlabeled2017/000000419121.jpg  \n",
      " extracting: unlabeled2017/000000363803.jpg  \n",
      " extracting: unlabeled2017/000000261768.jpg  \n",
      " extracting: unlabeled2017/000000071243.jpg  \n",
      " extracting: unlabeled2017/000000484328.jpg  \n",
      " extracting: unlabeled2017/000000220831.jpg  \n",
      " extracting: unlabeled2017/000000004864.jpg  \n",
      " extracting: unlabeled2017/000000405100.jpg  \n",
      " extracting: unlabeled2017/000000187697.jpg  \n",
      " extracting: unlabeled2017/000000082581.jpg  \n",
      " extracting: unlabeled2017/000000438092.jpg  \n",
      " extracting: unlabeled2017/000000489124.jpg  \n",
      " extracting: unlabeled2017/000000290295.jpg  \n",
      " extracting: unlabeled2017/000000358532.jpg  \n",
      " extracting: unlabeled2017/000000503709.jpg  \n",
      " extracting: unlabeled2017/000000398868.jpg  \n",
      " extracting: unlabeled2017/000000105012.jpg  \n",
      " extracting: unlabeled2017/000000164923.jpg  \n",
      " extracting: unlabeled2017/000000357629.jpg  \n",
      " extracting: unlabeled2017/000000252117.jpg  \n",
      " extracting: unlabeled2017/000000442511.jpg  \n",
      " extracting: unlabeled2017/000000560289.jpg  \n",
      " extracting: unlabeled2017/000000067503.jpg  \n",
      " extracting: unlabeled2017/000000547289.jpg  \n",
      " extracting: unlabeled2017/000000008835.jpg  \n",
      " extracting: unlabeled2017/000000296538.jpg  \n",
      " extracting: unlabeled2017/000000393405.jpg  \n",
      " extracting: unlabeled2017/000000186139.jpg  \n",
      " extracting: unlabeled2017/000000442054.jpg  \n",
      " extracting: unlabeled2017/000000487449.jpg  \n",
      " extracting: unlabeled2017/000000029673.jpg  \n",
      " extracting: unlabeled2017/000000210211.jpg  \n",
      " extracting: unlabeled2017/000000492482.jpg  \n",
      " extracting: unlabeled2017/000000376226.jpg  \n",
      " extracting: unlabeled2017/000000001566.jpg  \n",
      " extracting: unlabeled2017/000000561404.jpg  \n",
      " extracting: unlabeled2017/000000021760.jpg  \n",
      " extracting: unlabeled2017/000000445886.jpg  \n",
      " extracting: unlabeled2017/000000137009.jpg  \n",
      " extracting: unlabeled2017/000000465221.jpg  \n",
      " extracting: unlabeled2017/000000416863.jpg  \n",
      " extracting: unlabeled2017/000000446361.jpg  \n",
      " extracting: unlabeled2017/000000066900.jpg  \n",
      " extracting: unlabeled2017/000000032320.jpg  \n",
      " extracting: unlabeled2017/000000443150.jpg  \n",
      " extracting: unlabeled2017/000000457761.jpg  \n",
      " extracting: unlabeled2017/000000327424.jpg  \n",
      " extracting: unlabeled2017/000000066623.jpg  \n",
      " extracting: unlabeled2017/000000147396.jpg  \n",
      " extracting: unlabeled2017/000000222306.jpg  \n",
      " extracting: unlabeled2017/000000057908.jpg  \n",
      " extracting: unlabeled2017/000000393951.jpg  \n",
      " extracting: unlabeled2017/000000384639.jpg  \n",
      " extracting: unlabeled2017/000000219147.jpg  \n",
      " extracting: unlabeled2017/000000581335.jpg  \n",
      " extracting: unlabeled2017/000000413179.jpg  \n",
      " extracting: unlabeled2017/000000372889.jpg  \n",
      " extracting: unlabeled2017/000000271289.jpg  \n",
      " extracting: unlabeled2017/000000508850.jpg  \n",
      " extracting: unlabeled2017/000000164728.jpg  \n",
      " extracting: unlabeled2017/000000517218.jpg  \n",
      " extracting: unlabeled2017/000000231552.jpg  \n",
      " extracting: unlabeled2017/000000064553.jpg  \n",
      " extracting: unlabeled2017/000000050963.jpg  \n",
      " extracting: unlabeled2017/000000378489.jpg  \n",
      " extracting: unlabeled2017/000000486810.jpg  \n",
      " extracting: unlabeled2017/000000217230.jpg  \n",
      " extracting: unlabeled2017/000000092390.jpg  \n",
      " extracting: unlabeled2017/000000090206.jpg  \n",
      " extracting: unlabeled2017/000000188153.jpg  \n",
      " extracting: unlabeled2017/000000401599.jpg  \n",
      " extracting: unlabeled2017/000000033170.jpg  \n",
      " extracting: unlabeled2017/000000443951.jpg  \n",
      " extracting: unlabeled2017/000000526233.jpg  \n",
      " extracting: unlabeled2017/000000188206.jpg  \n",
      " extracting: unlabeled2017/000000399035.jpg  \n",
      " extracting: unlabeled2017/000000022642.jpg  \n",
      " extracting: unlabeled2017/000000500908.jpg  \n",
      " extracting: unlabeled2017/000000317226.jpg  \n",
      " extracting: unlabeled2017/000000298188.jpg  \n",
      " extracting: unlabeled2017/000000101488.jpg  \n",
      " extracting: unlabeled2017/000000459817.jpg  \n",
      " extracting: unlabeled2017/000000491059.jpg  \n",
      " extracting: unlabeled2017/000000066326.jpg  \n",
      " extracting: unlabeled2017/000000315000.jpg  \n",
      " extracting: unlabeled2017/000000511019.jpg  \n",
      " extracting: unlabeled2017/000000491227.jpg  \n",
      " extracting: unlabeled2017/000000148755.jpg  \n",
      " extracting: unlabeled2017/000000307955.jpg  \n",
      " extracting: unlabeled2017/000000536674.jpg  \n",
      " extracting: unlabeled2017/000000384962.jpg  \n",
      " extracting: unlabeled2017/000000026228.jpg  \n",
      " extracting: unlabeled2017/000000572280.jpg  \n",
      " extracting: unlabeled2017/000000483313.jpg  \n",
      " extracting: unlabeled2017/000000159780.jpg  \n",
      " extracting: unlabeled2017/000000052326.jpg  \n",
      " extracting: unlabeled2017/000000134973.jpg  \n",
      " extracting: unlabeled2017/000000409598.jpg  \n",
      " extracting: unlabeled2017/000000546153.jpg  \n",
      " extracting: unlabeled2017/000000164268.jpg  \n",
      " extracting: unlabeled2017/000000200934.jpg  \n",
      " extracting: unlabeled2017/000000288871.jpg  \n",
      " extracting: unlabeled2017/000000452556.jpg  \n",
      " extracting: unlabeled2017/000000232014.jpg  \n",
      " extracting: unlabeled2017/000000228838.jpg  \n",
      " extracting: unlabeled2017/000000420299.jpg  \n",
      " extracting: unlabeled2017/000000166440.jpg  \n",
      " extracting: unlabeled2017/000000394503.jpg  \n",
      " extracting: unlabeled2017/000000458535.jpg  \n",
      " extracting: unlabeled2017/000000321909.jpg  \n",
      " extracting: unlabeled2017/000000111827.jpg  \n",
      " extracting: unlabeled2017/000000403932.jpg  \n",
      " extracting: unlabeled2017/000000248611.jpg  \n",
      " extracting: unlabeled2017/000000384134.jpg  \n",
      " extracting: unlabeled2017/000000078414.jpg  \n",
      " extracting: unlabeled2017/000000295712.jpg  \n",
      " extracting: unlabeled2017/000000421079.jpg  \n",
      " extracting: unlabeled2017/000000197825.jpg  \n",
      " extracting: unlabeled2017/000000323084.jpg  \n",
      " extracting: unlabeled2017/000000124568.jpg  \n",
      " extracting: unlabeled2017/000000048237.jpg  \n",
      " extracting: unlabeled2017/000000551838.jpg  \n",
      " extracting: unlabeled2017/000000426716.jpg  \n",
      " extracting: unlabeled2017/000000181597.jpg  \n",
      " extracting: unlabeled2017/000000144075.jpg  \n",
      " extracting: unlabeled2017/000000308643.jpg  \n",
      " extracting: unlabeled2017/000000034556.jpg  \n",
      " extracting: unlabeled2017/000000252677.jpg  \n",
      " extracting: unlabeled2017/000000318905.jpg  \n",
      " extracting: unlabeled2017/000000004894.jpg  \n",
      " extracting: unlabeled2017/000000117859.jpg  \n",
      " extracting: unlabeled2017/000000466214.jpg  \n",
      " extracting: unlabeled2017/000000113243.jpg  \n",
      " extracting: unlabeled2017/000000400148.jpg  \n",
      " extracting: unlabeled2017/000000573259.jpg  \n",
      " extracting: unlabeled2017/000000471165.jpg  \n",
      " extracting: unlabeled2017/000000263950.jpg  \n",
      " extracting: unlabeled2017/000000153583.jpg  \n",
      " extracting: unlabeled2017/000000146080.jpg  \n",
      " extracting: unlabeled2017/000000185321.jpg  \n",
      " extracting: unlabeled2017/000000489081.jpg  \n",
      " extracting: unlabeled2017/000000080800.jpg  \n",
      " extracting: unlabeled2017/000000494210.jpg  \n",
      " extracting: unlabeled2017/000000144895.jpg  \n",
      " extracting: unlabeled2017/000000552375.jpg  \n",
      " extracting: unlabeled2017/000000505167.jpg  \n",
      " extracting: unlabeled2017/000000538818.jpg  \n",
      " extracting: unlabeled2017/000000443762.jpg  \n",
      " extracting: unlabeled2017/000000026707.jpg  \n",
      " extracting: unlabeled2017/000000417713.jpg  \n",
      " extracting: unlabeled2017/000000232354.jpg  \n",
      " extracting: unlabeled2017/000000581115.jpg  \n",
      " extracting: unlabeled2017/000000418688.jpg  \n",
      " extracting: unlabeled2017/000000067024.jpg  \n",
      " extracting: unlabeled2017/000000433949.jpg  \n",
      " extracting: unlabeled2017/000000461345.jpg  \n",
      " extracting: unlabeled2017/000000245113.jpg  \n",
      " extracting: unlabeled2017/000000008398.jpg  \n",
      " extracting: unlabeled2017/000000313230.jpg  \n",
      " extracting: unlabeled2017/000000333770.jpg  \n",
      " extracting: unlabeled2017/000000243966.jpg  \n",
      " extracting: unlabeled2017/000000304089.jpg  \n",
      " extracting: unlabeled2017/000000334202.jpg  \n",
      " extracting: unlabeled2017/000000444835.jpg  \n",
      " extracting: unlabeled2017/000000309747.jpg  \n",
      " extracting: unlabeled2017/000000376927.jpg  \n",
      " extracting: unlabeled2017/000000124743.jpg  \n",
      " extracting: unlabeled2017/000000061386.jpg  \n",
      " extracting: unlabeled2017/000000246455.jpg  \n",
      " extracting: unlabeled2017/000000335948.jpg  \n",
      " extracting: unlabeled2017/000000096390.jpg  \n",
      " extracting: unlabeled2017/000000181602.jpg  \n",
      " extracting: unlabeled2017/000000052558.jpg  \n",
      " extracting: unlabeled2017/000000490797.jpg  \n",
      " extracting: unlabeled2017/000000117797.jpg  \n",
      " extracting: unlabeled2017/000000539901.jpg  \n",
      " extracting: unlabeled2017/000000099878.jpg  \n",
      " extracting: unlabeled2017/000000336547.jpg  \n",
      " extracting: unlabeled2017/000000130354.jpg  \n",
      " extracting: unlabeled2017/000000454062.jpg  \n",
      " extracting: unlabeled2017/000000332281.jpg  \n",
      " extracting: unlabeled2017/000000038369.jpg  \n",
      " extracting: unlabeled2017/000000260832.jpg  \n",
      " extracting: unlabeled2017/000000162597.jpg  \n",
      " extracting: unlabeled2017/000000009998.jpg  \n",
      " extracting: unlabeled2017/000000269231.jpg  \n",
      " extracting: unlabeled2017/000000215676.jpg  \n",
      " extracting: unlabeled2017/000000421828.jpg  \n",
      " extracting: unlabeled2017/000000447897.jpg  \n",
      " extracting: unlabeled2017/000000536704.jpg  \n",
      " extracting: unlabeled2017/000000492574.jpg  \n",
      " extracting: unlabeled2017/000000329842.jpg  \n",
      " extracting: unlabeled2017/000000230231.jpg  \n",
      " extracting: unlabeled2017/000000292641.jpg  \n",
      " extracting: unlabeled2017/000000087352.jpg  \n",
      " extracting: unlabeled2017/000000064958.jpg  \n",
      " extracting: unlabeled2017/000000258374.jpg  \n",
      " extracting: unlabeled2017/000000027184.jpg  \n",
      " extracting: unlabeled2017/000000234919.jpg  \n",
      " extracting: unlabeled2017/000000247103.jpg  \n",
      " extracting: unlabeled2017/000000003864.jpg  \n",
      " extracting: unlabeled2017/000000413659.jpg  \n",
      " extracting: unlabeled2017/000000042480.jpg  \n",
      " extracting: unlabeled2017/000000303904.jpg  \n",
      " extracting: unlabeled2017/000000179010.jpg  \n",
      " extracting: unlabeled2017/000000397480.jpg  \n",
      " extracting: unlabeled2017/000000415962.jpg  \n",
      " extracting: unlabeled2017/000000305808.jpg  \n",
      " extracting: unlabeled2017/000000062909.jpg  \n",
      " extracting: unlabeled2017/000000232019.jpg  \n",
      " extracting: unlabeled2017/000000313853.jpg  \n",
      " extracting: unlabeled2017/000000040225.jpg  \n",
      " extracting: unlabeled2017/000000084408.jpg  \n",
      " extracting: unlabeled2017/000000025263.jpg  \n",
      " extracting: unlabeled2017/000000183570.jpg  \n",
      " extracting: unlabeled2017/000000310959.jpg  \n",
      " extracting: unlabeled2017/000000392755.jpg  \n",
      " extracting: unlabeled2017/000000328336.jpg  \n",
      " extracting: unlabeled2017/000000484121.jpg  \n",
      " extracting: unlabeled2017/000000520474.jpg  \n",
      " extracting: unlabeled2017/000000350856.jpg  \n",
      " extracting: unlabeled2017/000000444731.jpg  \n",
      " extracting: unlabeled2017/000000021986.jpg  \n",
      " extracting: unlabeled2017/000000256102.jpg  \n",
      " extracting: unlabeled2017/000000456866.jpg  \n",
      " extracting: unlabeled2017/000000143249.jpg  \n",
      " extracting: unlabeled2017/000000319539.jpg  \n",
      " extracting: unlabeled2017/000000431762.jpg  \n",
      " extracting: unlabeled2017/000000021596.jpg  \n",
      " extracting: unlabeled2017/000000441115.jpg  \n",
      " extracting: unlabeled2017/000000112753.jpg  \n",
      " extracting: unlabeled2017/000000142888.jpg  \n",
      " extracting: unlabeled2017/000000363042.jpg  \n",
      " extracting: unlabeled2017/000000323731.jpg  \n",
      " extracting: unlabeled2017/000000227583.jpg  \n",
      " extracting: unlabeled2017/000000023304.jpg  \n",
      " extracting: unlabeled2017/000000237456.jpg  \n",
      " extracting: unlabeled2017/000000339831.jpg  \n",
      " extracting: unlabeled2017/000000224638.jpg  \n",
      " extracting: unlabeled2017/000000517529.jpg  \n",
      " extracting: unlabeled2017/000000434475.jpg  \n",
      " extracting: unlabeled2017/000000259324.jpg  \n",
      " extracting: unlabeled2017/000000008059.jpg  \n",
      " extracting: unlabeled2017/000000433284.jpg  \n",
      " extracting: unlabeled2017/000000461856.jpg  \n",
      " extracting: unlabeled2017/000000201960.jpg  \n",
      " extracting: unlabeled2017/000000078943.jpg  \n",
      " extracting: unlabeled2017/000000216684.jpg  \n",
      " extracting: unlabeled2017/000000208194.jpg  \n",
      " extracting: unlabeled2017/000000442870.jpg  \n",
      " extracting: unlabeled2017/000000335949.jpg  \n",
      " extracting: unlabeled2017/000000436395.jpg  \n",
      " extracting: unlabeled2017/000000142685.jpg  \n",
      " extracting: unlabeled2017/000000288608.jpg  \n",
      " extracting: unlabeled2017/000000322041.jpg  \n",
      " extracting: unlabeled2017/000000385412.jpg  \n",
      " extracting: unlabeled2017/000000378060.jpg  \n",
      " extracting: unlabeled2017/000000379702.jpg  \n",
      " extracting: unlabeled2017/000000357593.jpg  \n",
      " extracting: unlabeled2017/000000291157.jpg  \n",
      " extracting: unlabeled2017/000000572846.jpg  \n",
      " extracting: unlabeled2017/000000037950.jpg  \n",
      " extracting: unlabeled2017/000000466292.jpg  \n",
      " extracting: unlabeled2017/000000176724.jpg  \n",
      " extracting: unlabeled2017/000000164293.jpg  \n",
      " extracting: unlabeled2017/000000457130.jpg  \n",
      " extracting: unlabeled2017/000000415873.jpg  \n",
      " extracting: unlabeled2017/000000048639.jpg  \n",
      " extracting: unlabeled2017/000000315545.jpg  \n",
      " extracting: unlabeled2017/000000388516.jpg  \n",
      " extracting: unlabeled2017/000000188687.jpg  \n",
      " extracting: unlabeled2017/000000445100.jpg  \n",
      " extracting: unlabeled2017/000000079473.jpg  \n",
      " extracting: unlabeled2017/000000002332.jpg  \n",
      " extracting: unlabeled2017/000000478382.jpg  \n",
      " extracting: unlabeled2017/000000408019.jpg  \n",
      " extracting: unlabeled2017/000000271667.jpg  \n",
      " extracting: unlabeled2017/000000395045.jpg  \n",
      " extracting: unlabeled2017/000000050728.jpg  \n",
      " extracting: unlabeled2017/000000165708.jpg  \n",
      " extracting: unlabeled2017/000000471845.jpg  \n",
      " extracting: unlabeled2017/000000254245.jpg  \n",
      " extracting: unlabeled2017/000000488302.jpg  \n",
      " extracting: unlabeled2017/000000413246.jpg  \n",
      " extracting: unlabeled2017/000000294765.jpg  \n",
      " extracting: unlabeled2017/000000544772.jpg  \n",
      " extracting: unlabeled2017/000000231137.jpg  \n",
      " extracting: unlabeled2017/000000545838.jpg  \n",
      " extracting: unlabeled2017/000000501738.jpg  \n",
      " extracting: unlabeled2017/000000408025.jpg  \n",
      " extracting: unlabeled2017/000000149714.jpg  \n",
      " extracting: unlabeled2017/000000384799.jpg  \n",
      " extracting: unlabeled2017/000000083004.jpg  \n",
      " extracting: unlabeled2017/000000226557.jpg  \n",
      " extracting: unlabeled2017/000000101935.jpg  \n",
      " extracting: unlabeled2017/000000192475.jpg  \n",
      " extracting: unlabeled2017/000000271150.jpg  \n",
      " extracting: unlabeled2017/000000376182.jpg  \n",
      " extracting: unlabeled2017/000000069072.jpg  \n",
      " extracting: unlabeled2017/000000314891.jpg  \n",
      " extracting: unlabeled2017/000000401781.jpg  \n",
      " extracting: unlabeled2017/000000038643.jpg  \n",
      " extracting: unlabeled2017/000000054232.jpg  \n",
      " extracting: unlabeled2017/000000235013.jpg  \n",
      " extracting: unlabeled2017/000000148130.jpg  \n",
      " extracting: unlabeled2017/000000101798.jpg  \n",
      " extracting: unlabeled2017/000000195268.jpg  \n",
      " extracting: unlabeled2017/000000431276.jpg  \n",
      " extracting: unlabeled2017/000000277416.jpg  \n",
      " extracting: unlabeled2017/000000056598.jpg  \n",
      " extracting: unlabeled2017/000000125918.jpg  \n",
      " extracting: unlabeled2017/000000091515.jpg  \n",
      " extracting: unlabeled2017/000000541784.jpg  \n",
      " extracting: unlabeled2017/000000529815.jpg  \n",
      " extracting: unlabeled2017/000000225780.jpg  \n",
      " extracting: unlabeled2017/000000138560.jpg  \n",
      " extracting: unlabeled2017/000000137411.jpg  \n",
      " extracting: unlabeled2017/000000536736.jpg  \n",
      " extracting: unlabeled2017/000000107366.jpg  \n",
      " extracting: unlabeled2017/000000419512.jpg  \n",
      " extracting: unlabeled2017/000000298654.jpg  \n",
      " extracting: unlabeled2017/000000023524.jpg  \n",
      " extracting: unlabeled2017/000000078624.jpg  \n",
      " extracting: unlabeled2017/000000498600.jpg  \n",
      " extracting: unlabeled2017/000000402466.jpg  \n",
      " extracting: unlabeled2017/000000154875.jpg  \n",
      " extracting: unlabeled2017/000000429862.jpg  \n",
      " extracting: unlabeled2017/000000535194.jpg  \n",
      " extracting: unlabeled2017/000000384221.jpg  \n",
      " extracting: unlabeled2017/000000003825.jpg  \n",
      " extracting: unlabeled2017/000000228991.jpg  \n",
      " extracting: unlabeled2017/000000027375.jpg  \n",
      " extracting: unlabeled2017/000000309738.jpg  \n",
      " extracting: unlabeled2017/000000178338.jpg  \n",
      " extracting: unlabeled2017/000000510014.jpg  \n",
      " extracting: unlabeled2017/000000139829.jpg  \n",
      " extracting: unlabeled2017/000000200104.jpg  \n",
      " extracting: unlabeled2017/000000118864.jpg  \n",
      " extracting: unlabeled2017/000000091179.jpg  \n",
      " extracting: unlabeled2017/000000123374.jpg  \n",
      " extracting: unlabeled2017/000000296827.jpg  \n",
      " extracting: unlabeled2017/000000176451.jpg  \n",
      " extracting: unlabeled2017/000000075755.jpg  \n",
      " extracting: unlabeled2017/000000579685.jpg  \n",
      " extracting: unlabeled2017/000000378221.jpg  \n",
      " extracting: unlabeled2017/000000040647.jpg  \n",
      " extracting: unlabeled2017/000000572457.jpg  \n",
      " extracting: unlabeled2017/000000029123.jpg  \n",
      " extracting: unlabeled2017/000000468671.jpg  \n",
      " extracting: unlabeled2017/000000418657.jpg  \n",
      " extracting: unlabeled2017/000000450851.jpg  \n",
      " extracting: unlabeled2017/000000464614.jpg  \n",
      " extracting: unlabeled2017/000000335283.jpg  \n",
      " extracting: unlabeled2017/000000312732.jpg  \n",
      " extracting: unlabeled2017/000000212509.jpg  \n",
      " extracting: unlabeled2017/000000390694.jpg  \n",
      " extracting: unlabeled2017/000000553557.jpg  \n",
      " extracting: unlabeled2017/000000198388.jpg  \n",
      " extracting: unlabeled2017/000000529526.jpg  \n",
      " extracting: unlabeled2017/000000169681.jpg  \n",
      " extracting: unlabeled2017/000000178646.jpg  \n",
      " extracting: unlabeled2017/000000130672.jpg  \n",
      " extracting: unlabeled2017/000000410417.jpg  \n",
      " extracting: unlabeled2017/000000130837.jpg  \n",
      " extracting: unlabeled2017/000000155467.jpg  \n",
      " extracting: unlabeled2017/000000090668.jpg  \n",
      " extracting: unlabeled2017/000000471616.jpg  \n",
      " extracting: unlabeled2017/000000178561.jpg  \n",
      " extracting: unlabeled2017/000000270437.jpg  \n",
      " extracting: unlabeled2017/000000183984.jpg  \n",
      " extracting: unlabeled2017/000000418421.jpg  \n",
      " extracting: unlabeled2017/000000333696.jpg  \n",
      " extracting: unlabeled2017/000000041026.jpg  \n",
      " extracting: unlabeled2017/000000257856.jpg  \n",
      " extracting: unlabeled2017/000000567778.jpg  \n",
      " extracting: unlabeled2017/000000116139.jpg  \n",
      " extracting: unlabeled2017/000000143159.jpg  \n",
      " extracting: unlabeled2017/000000275462.jpg  \n",
      " extracting: unlabeled2017/000000375821.jpg  \n",
      " extracting: unlabeled2017/000000019512.jpg  \n",
      " extracting: unlabeled2017/000000298480.jpg  \n",
      " extracting: unlabeled2017/000000284330.jpg  \n",
      " extracting: unlabeled2017/000000457032.jpg  \n",
      " extracting: unlabeled2017/000000031910.jpg  \n",
      " extracting: unlabeled2017/000000076273.jpg  \n",
      " extracting: unlabeled2017/000000561107.jpg  \n",
      " extracting: unlabeled2017/000000273700.jpg  \n",
      " extracting: unlabeled2017/000000546820.jpg  \n",
      " extracting: unlabeled2017/000000295723.jpg  \n",
      " extracting: unlabeled2017/000000580463.jpg  \n",
      " extracting: unlabeled2017/000000496014.jpg  \n",
      " extracting: unlabeled2017/000000111850.jpg  \n",
      " extracting: unlabeled2017/000000577618.jpg  \n",
      " extracting: unlabeled2017/000000331887.jpg  \n",
      " extracting: unlabeled2017/000000113000.jpg  \n",
      " extracting: unlabeled2017/000000460329.jpg  \n",
      " extracting: unlabeled2017/000000430836.jpg  \n",
      " extracting: unlabeled2017/000000111382.jpg  \n",
      " extracting: unlabeled2017/000000336258.jpg  \n",
      " extracting: unlabeled2017/000000551337.jpg  \n",
      " extracting: unlabeled2017/000000167281.jpg  \n",
      " extracting: unlabeled2017/000000139801.jpg  \n",
      " extracting: unlabeled2017/000000478952.jpg  \n",
      " extracting: unlabeled2017/000000459520.jpg  \n",
      " extracting: unlabeled2017/000000227605.jpg  \n",
      " extracting: unlabeled2017/000000471308.jpg  \n",
      " extracting: unlabeled2017/000000423791.jpg  \n",
      " extracting: unlabeled2017/000000398860.jpg  \n",
      " extracting: unlabeled2017/000000251158.jpg  \n",
      " extracting: unlabeled2017/000000406842.jpg  \n",
      " extracting: unlabeled2017/000000457783.jpg  \n",
      " extracting: unlabeled2017/000000375562.jpg  \n",
      " extracting: unlabeled2017/000000022227.jpg  \n",
      " extracting: unlabeled2017/000000191963.jpg  \n",
      " extracting: unlabeled2017/000000143100.jpg  \n",
      " extracting: unlabeled2017/000000430426.jpg  \n",
      " extracting: unlabeled2017/000000286938.jpg  \n",
      " extracting: unlabeled2017/000000254214.jpg  \n",
      " extracting: unlabeled2017/000000416161.jpg  \n",
      " extracting: unlabeled2017/000000578851.jpg  \n",
      " extracting: unlabeled2017/000000140404.jpg  \n",
      " extracting: unlabeled2017/000000077083.jpg  \n",
      " extracting: unlabeled2017/000000338460.jpg  \n",
      " extracting: unlabeled2017/000000535203.jpg  \n",
      " extracting: unlabeled2017/000000521640.jpg  \n",
      " extracting: unlabeled2017/000000251222.jpg  \n",
      " extracting: unlabeled2017/000000495453.jpg  \n",
      " extracting: unlabeled2017/000000117652.jpg  \n",
      " extracting: unlabeled2017/000000473193.jpg  \n",
      " extracting: unlabeled2017/000000045168.jpg  \n",
      " extracting: unlabeled2017/000000457327.jpg  \n",
      " extracting: unlabeled2017/000000211296.jpg  \n",
      " extracting: unlabeled2017/000000290651.jpg  \n",
      " extracting: unlabeled2017/000000372406.jpg  \n",
      " extracting: unlabeled2017/000000491944.jpg  \n",
      " extracting: unlabeled2017/000000351512.jpg  \n",
      " extracting: unlabeled2017/000000254960.jpg  \n",
      " extracting: unlabeled2017/000000513326.jpg  \n",
      " extracting: unlabeled2017/000000424013.jpg  \n",
      " extracting: unlabeled2017/000000358714.jpg  \n",
      " extracting: unlabeled2017/000000057089.jpg  \n",
      " extracting: unlabeled2017/000000011565.jpg  \n",
      " extracting: unlabeled2017/000000358092.jpg  \n",
      " extracting: unlabeled2017/000000298528.jpg  \n",
      " extracting: unlabeled2017/000000106015.jpg  \n",
      " extracting: unlabeled2017/000000173694.jpg  \n",
      " extracting: unlabeled2017/000000450161.jpg  \n",
      " extracting: unlabeled2017/000000497432.jpg  \n",
      " extracting: unlabeled2017/000000339417.jpg  \n",
      " extracting: unlabeled2017/000000296925.jpg  \n",
      " extracting: unlabeled2017/000000493135.jpg  \n",
      " extracting: unlabeled2017/000000033668.jpg  \n",
      " extracting: unlabeled2017/000000231026.jpg  \n",
      " extracting: unlabeled2017/000000443973.jpg  \n",
      " extracting: unlabeled2017/000000155476.jpg  \n",
      " extracting: unlabeled2017/000000391299.jpg  \n",
      " extracting: unlabeled2017/000000297383.jpg  \n",
      " extracting: unlabeled2017/000000062208.jpg  \n",
      " extracting: unlabeled2017/000000343906.jpg  \n",
      " extracting: unlabeled2017/000000271836.jpg  \n",
      " extracting: unlabeled2017/000000312021.jpg  \n",
      " extracting: unlabeled2017/000000238731.jpg  \n",
      " extracting: unlabeled2017/000000488199.jpg  \n",
      " extracting: unlabeled2017/000000376412.jpg  \n",
      " extracting: unlabeled2017/000000433989.jpg  \n",
      " extracting: unlabeled2017/000000303338.jpg  \n",
      " extracting: unlabeled2017/000000136792.jpg  \n",
      " extracting: unlabeled2017/000000382626.jpg  \n",
      " extracting: unlabeled2017/000000404405.jpg  \n",
      " extracting: unlabeled2017/000000276414.jpg  \n",
      " extracting: unlabeled2017/000000452435.jpg  \n",
      " extracting: unlabeled2017/000000226416.jpg  \n",
      " extracting: unlabeled2017/000000031083.jpg  \n",
      " extracting: unlabeled2017/000000335491.jpg  \n",
      " extracting: unlabeled2017/000000563710.jpg  \n",
      " extracting: unlabeled2017/000000031173.jpg  \n",
      " extracting: unlabeled2017/000000110669.jpg  \n",
      " extracting: unlabeled2017/000000328509.jpg  \n",
      " extracting: unlabeled2017/000000251828.jpg  \n",
      " extracting: unlabeled2017/000000540373.jpg  \n",
      " extracting: unlabeled2017/000000185332.jpg  \n",
      " extracting: unlabeled2017/000000078182.jpg  \n",
      " extracting: unlabeled2017/000000020773.jpg  \n",
      " extracting: unlabeled2017/000000459171.jpg  \n",
      " extracting: unlabeled2017/000000216450.jpg  \n",
      " extracting: unlabeled2017/000000506293.jpg  \n",
      " extracting: unlabeled2017/000000243990.jpg  \n",
      " extracting: unlabeled2017/000000329744.jpg  \n",
      " extracting: unlabeled2017/000000447078.jpg  \n",
      " extracting: unlabeled2017/000000303489.jpg  \n",
      " extracting: unlabeled2017/000000579389.jpg  \n",
      " extracting: unlabeled2017/000000395392.jpg  \n",
      " extracting: unlabeled2017/000000196149.jpg  \n",
      " extracting: unlabeled2017/000000464739.jpg  \n",
      " extracting: unlabeled2017/000000489947.jpg  \n",
      " extracting: unlabeled2017/000000298406.jpg  \n",
      " extracting: unlabeled2017/000000536577.jpg  \n",
      " extracting: unlabeled2017/000000311316.jpg  \n",
      " extracting: unlabeled2017/000000334706.jpg  \n",
      " extracting: unlabeled2017/000000504605.jpg  \n",
      " extracting: unlabeled2017/000000570245.jpg  \n",
      " extracting: unlabeled2017/000000158893.jpg  \n",
      " extracting: unlabeled2017/000000566232.jpg  \n",
      " extracting: unlabeled2017/000000033876.jpg  \n",
      " extracting: unlabeled2017/000000248534.jpg  \n",
      " extracting: unlabeled2017/000000149016.jpg  \n",
      " extracting: unlabeled2017/000000271221.jpg  \n",
      " extracting: unlabeled2017/000000006255.jpg  \n",
      " extracting: unlabeled2017/000000135750.jpg  \n",
      " extracting: unlabeled2017/000000547549.jpg  \n",
      " extracting: unlabeled2017/000000269810.jpg  \n",
      " extracting: unlabeled2017/000000007948.jpg  \n",
      " extracting: unlabeled2017/000000549582.jpg  \n",
      " extracting: unlabeled2017/000000422001.jpg  \n",
      " extracting: unlabeled2017/000000158376.jpg  \n",
      " extracting: unlabeled2017/000000536936.jpg  \n",
      " extracting: unlabeled2017/000000479735.jpg  \n",
      " extracting: unlabeled2017/000000064975.jpg  \n",
      " extracting: unlabeled2017/000000304131.jpg  \n",
      " extracting: unlabeled2017/000000130965.jpg  \n",
      " extracting: unlabeled2017/000000092774.jpg  \n",
      " extracting: unlabeled2017/000000325396.jpg  \n",
      " extracting: unlabeled2017/000000066784.jpg  \n",
      " extracting: unlabeled2017/000000131362.jpg  \n",
      " extracting: unlabeled2017/000000139603.jpg  \n",
      " extracting: unlabeled2017/000000195240.jpg  \n",
      " extracting: unlabeled2017/000000340195.jpg  \n",
      " extracting: unlabeled2017/000000337310.jpg  \n",
      " extracting: unlabeled2017/000000007082.jpg  \n",
      " extracting: unlabeled2017/000000174710.jpg  \n",
      " extracting: unlabeled2017/000000091475.jpg  \n",
      " extracting: unlabeled2017/000000233714.jpg  \n",
      " extracting: unlabeled2017/000000444716.jpg  \n",
      " extracting: unlabeled2017/000000474811.jpg  \n",
      " extracting: unlabeled2017/000000113429.jpg  \n",
      " extracting: unlabeled2017/000000140889.jpg  \n",
      " extracting: unlabeled2017/000000026608.jpg  \n",
      " extracting: unlabeled2017/000000536434.jpg  \n",
      " extracting: unlabeled2017/000000056241.jpg  \n",
      " extracting: unlabeled2017/000000498146.jpg  \n",
      " extracting: unlabeled2017/000000520410.jpg  \n",
      " extracting: unlabeled2017/000000524900.jpg  \n",
      " extracting: unlabeled2017/000000139126.jpg  \n",
      " extracting: unlabeled2017/000000170756.jpg  \n",
      " extracting: unlabeled2017/000000100411.jpg  \n",
      " extracting: unlabeled2017/000000455905.jpg  \n",
      " extracting: unlabeled2017/000000099774.jpg  \n",
      " extracting: unlabeled2017/000000216563.jpg  \n",
      " extracting: unlabeled2017/000000045798.jpg  \n",
      " extracting: unlabeled2017/000000309230.jpg  \n",
      " extracting: unlabeled2017/000000247805.jpg  \n",
      " extracting: unlabeled2017/000000423057.jpg  \n",
      " extracting: unlabeled2017/000000497730.jpg  \n",
      " extracting: unlabeled2017/000000201988.jpg  \n",
      " extracting: unlabeled2017/000000580658.jpg  \n",
      " extracting: unlabeled2017/000000164995.jpg  \n",
      " extracting: unlabeled2017/000000539063.jpg  \n",
      " extracting: unlabeled2017/000000187981.jpg  \n",
      " extracting: unlabeled2017/000000479643.jpg  \n",
      " extracting: unlabeled2017/000000149986.jpg  \n",
      " extracting: unlabeled2017/000000099773.jpg  \n",
      " extracting: unlabeled2017/000000473161.jpg  \n",
      " extracting: unlabeled2017/000000577917.jpg  \n",
      " extracting: unlabeled2017/000000150659.jpg  \n",
      " extracting: unlabeled2017/000000090466.jpg  \n",
      " extracting: unlabeled2017/000000102740.jpg  \n",
      " extracting: unlabeled2017/000000294331.jpg  \n",
      " extracting: unlabeled2017/000000090143.jpg  \n",
      " extracting: unlabeled2017/000000294848.jpg  \n",
      " extracting: unlabeled2017/000000581671.jpg  \n",
      " extracting: unlabeled2017/000000344556.jpg  \n",
      " extracting: unlabeled2017/000000034084.jpg  \n",
      " extracting: unlabeled2017/000000431895.jpg  \n",
      " extracting: unlabeled2017/000000134129.jpg  \n",
      " extracting: unlabeled2017/000000242730.jpg  \n",
      " extracting: unlabeled2017/000000395917.jpg  \n",
      " extracting: unlabeled2017/000000178149.jpg  \n",
      " extracting: unlabeled2017/000000170509.jpg  \n",
      " extracting: unlabeled2017/000000319274.jpg  \n",
      " extracting: unlabeled2017/000000184229.jpg  \n",
      " extracting: unlabeled2017/000000534309.jpg  \n",
      " extracting: unlabeled2017/000000107445.jpg  \n",
      " extracting: unlabeled2017/000000155387.jpg  \n",
      " extracting: unlabeled2017/000000355219.jpg  \n",
      " extracting: unlabeled2017/000000057931.jpg  \n",
      " extracting: unlabeled2017/000000224229.jpg  \n",
      " extracting: unlabeled2017/000000553543.jpg  \n",
      " extracting: unlabeled2017/000000346052.jpg  \n",
      " extracting: unlabeled2017/000000318397.jpg  \n",
      " extracting: unlabeled2017/000000495399.jpg  \n",
      " extracting: unlabeled2017/000000497882.jpg  \n",
      " extracting: unlabeled2017/000000571528.jpg  \n",
      " extracting: unlabeled2017/000000329453.jpg  \n",
      " extracting: unlabeled2017/000000196452.jpg  \n",
      " extracting: unlabeled2017/000000172131.jpg  \n",
      " extracting: unlabeled2017/000000506473.jpg  \n",
      " extracting: unlabeled2017/000000427287.jpg  \n",
      " extracting: unlabeled2017/000000258543.jpg  \n",
      " extracting: unlabeled2017/000000317704.jpg  \n",
      " extracting: unlabeled2017/000000383743.jpg  \n",
      " extracting: unlabeled2017/000000208382.jpg  \n",
      " extracting: unlabeled2017/000000178327.jpg  \n",
      " extracting: unlabeled2017/000000443078.jpg  \n",
      " extracting: unlabeled2017/000000561247.jpg  \n",
      " extracting: unlabeled2017/000000529561.jpg  \n",
      " extracting: unlabeled2017/000000578677.jpg  \n",
      " extracting: unlabeled2017/000000285595.jpg  \n",
      " extracting: unlabeled2017/000000477720.jpg  \n",
      " extracting: unlabeled2017/000000084921.jpg  \n",
      " extracting: unlabeled2017/000000238594.jpg  \n",
      " extracting: unlabeled2017/000000447238.jpg  \n",
      " extracting: unlabeled2017/000000155295.jpg  \n",
      " extracting: unlabeled2017/000000538036.jpg  \n",
      " extracting: unlabeled2017/000000279186.jpg  \n",
      " extracting: unlabeled2017/000000224110.jpg  \n",
      " extracting: unlabeled2017/000000076850.jpg  \n",
      " extracting: unlabeled2017/000000142727.jpg  \n",
      " extracting: unlabeled2017/000000550475.jpg  \n",
      " extracting: unlabeled2017/000000308398.jpg  \n",
      " extracting: unlabeled2017/000000056672.jpg  \n",
      " extracting: unlabeled2017/000000454876.jpg  \n",
      " extracting: unlabeled2017/000000158571.jpg  \n",
      " extracting: unlabeled2017/000000022512.jpg  \n",
      " extracting: unlabeled2017/000000217688.jpg  \n",
      " extracting: unlabeled2017/000000312177.jpg  \n",
      " extracting: unlabeled2017/000000240657.jpg  \n",
      " extracting: unlabeled2017/000000452717.jpg  \n",
      " extracting: unlabeled2017/000000003998.jpg  \n",
      " extracting: unlabeled2017/000000305774.jpg  \n",
      " extracting: unlabeled2017/000000261112.jpg  \n",
      " extracting: unlabeled2017/000000350095.jpg  \n",
      " extracting: unlabeled2017/000000024987.jpg  \n",
      " extracting: unlabeled2017/000000112200.jpg  \n",
      " extracting: unlabeled2017/000000544177.jpg  \n",
      " extracting: unlabeled2017/000000064371.jpg  \n",
      " extracting: unlabeled2017/000000434664.jpg  \n",
      " extracting: unlabeled2017/000000329103.jpg  \n",
      " extracting: unlabeled2017/000000503915.jpg  \n",
      " extracting: unlabeled2017/000000404001.jpg  \n",
      " extracting: unlabeled2017/000000043590.jpg  \n",
      " extracting: unlabeled2017/000000180874.jpg  \n",
      " extracting: unlabeled2017/000000565586.jpg  \n",
      " extracting: unlabeled2017/000000480796.jpg  \n",
      " extracting: unlabeled2017/000000296899.jpg  \n",
      " extracting: unlabeled2017/000000134355.jpg  \n",
      " extracting: unlabeled2017/000000370434.jpg  \n",
      " extracting: unlabeled2017/000000115094.jpg  \n",
      " extracting: unlabeled2017/000000416824.jpg  \n",
      " extracting: unlabeled2017/000000328483.jpg  \n",
      " extracting: unlabeled2017/000000228325.jpg  \n",
      " extracting: unlabeled2017/000000180352.jpg  \n",
      " extracting: unlabeled2017/000000263749.jpg  \n",
      " extracting: unlabeled2017/000000146925.jpg  \n",
      " extracting: unlabeled2017/000000291424.jpg  \n",
      " extracting: unlabeled2017/000000214583.jpg  \n",
      " extracting: unlabeled2017/000000213959.jpg  \n",
      " extracting: unlabeled2017/000000476906.jpg  \n",
      " extracting: unlabeled2017/000000261936.jpg  \n",
      " extracting: unlabeled2017/000000350992.jpg  \n",
      " extracting: unlabeled2017/000000428128.jpg  \n",
      " extracting: unlabeled2017/000000287654.jpg  \n",
      " extracting: unlabeled2017/000000553597.jpg  \n",
      " extracting: unlabeled2017/000000499853.jpg  \n",
      " extracting: unlabeled2017/000000125610.jpg  \n",
      " extracting: unlabeled2017/000000275692.jpg  \n",
      " extracting: unlabeled2017/000000174725.jpg  \n",
      " extracting: unlabeled2017/000000237588.jpg  \n",
      " extracting: unlabeled2017/000000186499.jpg  \n",
      " extracting: unlabeled2017/000000426809.jpg  \n",
      " extracting: unlabeled2017/000000067851.jpg  \n",
      " extracting: unlabeled2017/000000196474.jpg  \n",
      " extracting: unlabeled2017/000000391148.jpg  \n",
      " extracting: unlabeled2017/000000338259.jpg  \n",
      " extracting: unlabeled2017/000000536880.jpg  \n",
      " extracting: unlabeled2017/000000381248.jpg  \n",
      " extracting: unlabeled2017/000000075853.jpg  \n",
      " extracting: unlabeled2017/000000380149.jpg  \n",
      " extracting: unlabeled2017/000000298781.jpg  \n",
      " extracting: unlabeled2017/000000556733.jpg  \n",
      " extracting: unlabeled2017/000000025769.jpg  \n",
      " extracting: unlabeled2017/000000577633.jpg  \n",
      " extracting: unlabeled2017/000000442012.jpg  \n",
      " extracting: unlabeled2017/000000244991.jpg  \n",
      " extracting: unlabeled2017/000000515380.jpg  \n",
      " extracting: unlabeled2017/000000174951.jpg  \n",
      " extracting: unlabeled2017/000000118517.jpg  \n",
      " extracting: unlabeled2017/000000307111.jpg  \n",
      " extracting: unlabeled2017/000000574649.jpg  \n",
      " extracting: unlabeled2017/000000227102.jpg  \n",
      " extracting: unlabeled2017/000000140405.jpg  \n",
      " extracting: unlabeled2017/000000115655.jpg  \n",
      " extracting: unlabeled2017/000000425841.jpg  \n",
      " extracting: unlabeled2017/000000115239.jpg  \n",
      " extracting: unlabeled2017/000000480579.jpg  \n",
      " extracting: unlabeled2017/000000174639.jpg  \n",
      " extracting: unlabeled2017/000000153712.jpg  \n",
      " extracting: unlabeled2017/000000216288.jpg  \n",
      " extracting: unlabeled2017/000000463826.jpg  \n",
      " extracting: unlabeled2017/000000050207.jpg  \n",
      " extracting: unlabeled2017/000000020214.jpg  \n",
      " extracting: unlabeled2017/000000250900.jpg  \n",
      " extracting: unlabeled2017/000000019882.jpg  \n",
      " extracting: unlabeled2017/000000219563.jpg  \n",
      " extracting: unlabeled2017/000000344537.jpg  \n",
      " extracting: unlabeled2017/000000009008.jpg  \n",
      " extracting: unlabeled2017/000000271425.jpg  \n",
      " extracting: unlabeled2017/000000267023.jpg  \n",
      " extracting: unlabeled2017/000000001872.jpg  \n",
      " extracting: unlabeled2017/000000058348.jpg  \n",
      " extracting: unlabeled2017/000000009269.jpg  \n",
      " extracting: unlabeled2017/000000577345.jpg  \n",
      " extracting: unlabeled2017/000000440320.jpg  \n",
      " extracting: unlabeled2017/000000215263.jpg  \n",
      " extracting: unlabeled2017/000000545010.jpg  \n",
      " extracting: unlabeled2017/000000356026.jpg  \n",
      " extracting: unlabeled2017/000000572883.jpg  \n",
      " extracting: unlabeled2017/000000229845.jpg  \n",
      " extracting: unlabeled2017/000000564891.jpg  \n",
      " extracting: unlabeled2017/000000542236.jpg  \n",
      " extracting: unlabeled2017/000000309154.jpg  \n",
      " extracting: unlabeled2017/000000197170.jpg  \n",
      " extracting: unlabeled2017/000000050437.jpg  \n",
      " extracting: unlabeled2017/000000392680.jpg  \n",
      " extracting: unlabeled2017/000000118146.jpg  \n",
      " extracting: unlabeled2017/000000471195.jpg  \n",
      " extracting: unlabeled2017/000000359938.jpg  \n",
      " extracting: unlabeled2017/000000182662.jpg  \n",
      " extracting: unlabeled2017/000000186546.jpg  \n",
      " extracting: unlabeled2017/000000436275.jpg  \n",
      " extracting: unlabeled2017/000000133875.jpg  \n",
      " extracting: unlabeled2017/000000412162.jpg  \n",
      " extracting: unlabeled2017/000000009824.jpg  \n",
      " extracting: unlabeled2017/000000269480.jpg  \n",
      " extracting: unlabeled2017/000000439898.jpg  \n",
      " extracting: unlabeled2017/000000133215.jpg  \n",
      " extracting: unlabeled2017/000000345034.jpg  \n",
      " extracting: unlabeled2017/000000390624.jpg  \n",
      " extracting: unlabeled2017/000000352583.jpg  \n",
      " extracting: unlabeled2017/000000012924.jpg  \n",
      " extracting: unlabeled2017/000000498181.jpg  \n",
      " extracting: unlabeled2017/000000549028.jpg  \n",
      " extracting: unlabeled2017/000000494146.jpg  \n",
      " extracting: unlabeled2017/000000395014.jpg  \n",
      " extracting: unlabeled2017/000000400086.jpg  \n",
      " extracting: unlabeled2017/000000551810.jpg  \n",
      " extracting: unlabeled2017/000000035141.jpg  \n",
      " extracting: unlabeled2017/000000288154.jpg  \n",
      " extracting: unlabeled2017/000000164021.jpg  \n",
      " extracting: unlabeled2017/000000220561.jpg  \n",
      " extracting: unlabeled2017/000000269301.jpg  \n",
      " extracting: unlabeled2017/000000553398.jpg  \n",
      " extracting: unlabeled2017/000000565099.jpg  \n",
      " extracting: unlabeled2017/000000052074.jpg  \n",
      " extracting: unlabeled2017/000000318947.jpg  \n",
      " extracting: unlabeled2017/000000109689.jpg  \n",
      " extracting: unlabeled2017/000000321462.jpg  \n",
      " extracting: unlabeled2017/000000359621.jpg  \n",
      " extracting: unlabeled2017/000000183121.jpg  \n",
      " extracting: unlabeled2017/000000355246.jpg  \n",
      " extracting: unlabeled2017/000000390509.jpg  \n",
      " extracting: unlabeled2017/000000072072.jpg  \n",
      " extracting: unlabeled2017/000000276873.jpg  \n",
      " extracting: unlabeled2017/000000242028.jpg  \n",
      " extracting: unlabeled2017/000000102259.jpg  \n",
      " extracting: unlabeled2017/000000364721.jpg  \n",
      " extracting: unlabeled2017/000000216554.jpg  \n",
      " extracting: unlabeled2017/000000109735.jpg  \n",
      " extracting: unlabeled2017/000000284497.jpg  \n",
      " extracting: unlabeled2017/000000035432.jpg  \n",
      " extracting: unlabeled2017/000000139398.jpg  \n",
      " extracting: unlabeled2017/000000011880.jpg  \n",
      " extracting: unlabeled2017/000000202749.jpg  \n",
      " extracting: unlabeled2017/000000116920.jpg  \n",
      " extracting: unlabeled2017/000000159632.jpg  \n",
      " extracting: unlabeled2017/000000012857.jpg  \n",
      " extracting: unlabeled2017/000000051274.jpg  \n",
      " extracting: unlabeled2017/000000297106.jpg  \n",
      " extracting: unlabeled2017/000000252170.jpg  \n",
      " extracting: unlabeled2017/000000234242.jpg  \n",
      " extracting: unlabeled2017/000000510021.jpg  \n",
      " extracting: unlabeled2017/000000525028.jpg  \n",
      " extracting: unlabeled2017/000000406107.jpg  \n",
      " extracting: unlabeled2017/000000166289.jpg  \n",
      " extracting: unlabeled2017/000000040074.jpg  \n",
      " extracting: unlabeled2017/000000492768.jpg  \n",
      " extracting: unlabeled2017/000000567030.jpg  \n",
      " extracting: unlabeled2017/000000276178.jpg  \n",
      " extracting: unlabeled2017/000000306748.jpg  \n",
      " extracting: unlabeled2017/000000098687.jpg  \n",
      " extracting: unlabeled2017/000000459160.jpg  \n",
      " extracting: unlabeled2017/000000329897.jpg  \n",
      " extracting: unlabeled2017/000000326269.jpg  \n",
      " extracting: unlabeled2017/000000495823.jpg  \n",
      " extracting: unlabeled2017/000000068695.jpg  \n",
      " extracting: unlabeled2017/000000564810.jpg  \n",
      " extracting: unlabeled2017/000000333425.jpg  \n",
      " extracting: unlabeled2017/000000423160.jpg  \n",
      " extracting: unlabeled2017/000000080565.jpg  \n",
      " extracting: unlabeled2017/000000179423.jpg  \n",
      " extracting: unlabeled2017/000000212760.jpg  \n",
      " extracting: unlabeled2017/000000001735.jpg  \n",
      " extracting: unlabeled2017/000000496642.jpg  \n",
      " extracting: unlabeled2017/000000245985.jpg  \n",
      " extracting: unlabeled2017/000000186313.jpg  \n",
      " extracting: unlabeled2017/000000031011.jpg  \n",
      " extracting: unlabeled2017/000000503405.jpg  \n",
      " extracting: unlabeled2017/000000261422.jpg  \n",
      " extracting: unlabeled2017/000000060367.jpg  \n",
      " extracting: unlabeled2017/000000296963.jpg  \n",
      " extracting: unlabeled2017/000000361903.jpg  \n",
      " extracting: unlabeled2017/000000098675.jpg  \n",
      " extracting: unlabeled2017/000000418334.jpg  \n",
      " extracting: unlabeled2017/000000479676.jpg  \n",
      " extracting: unlabeled2017/000000559059.jpg  \n",
      " extracting: unlabeled2017/000000102564.jpg  \n",
      " extracting: unlabeled2017/000000325395.jpg  \n",
      " extracting: unlabeled2017/000000495262.jpg  \n",
      " extracting: unlabeled2017/000000290691.jpg  \n",
      " extracting: unlabeled2017/000000139527.jpg  \n",
      " extracting: unlabeled2017/000000346280.jpg  \n",
      " extracting: unlabeled2017/000000443014.jpg  \n",
      " extracting: unlabeled2017/000000430333.jpg  \n",
      " extracting: unlabeled2017/000000339846.jpg  \n",
      " extracting: unlabeled2017/000000555264.jpg  \n",
      " extracting: unlabeled2017/000000108480.jpg  \n",
      " extracting: unlabeled2017/000000363649.jpg  \n",
      " extracting: unlabeled2017/000000383707.jpg  \n",
      " extracting: unlabeled2017/000000000648.jpg  \n",
      " extracting: unlabeled2017/000000022805.jpg  \n",
      " extracting: unlabeled2017/000000377043.jpg  \n",
      " extracting: unlabeled2017/000000325906.jpg  \n",
      " extracting: unlabeled2017/000000468582.jpg  \n",
      " extracting: unlabeled2017/000000256740.jpg  \n",
      " extracting: unlabeled2017/000000448422.jpg  \n",
      " extracting: unlabeled2017/000000030929.jpg  \n",
      " extracting: unlabeled2017/000000428733.jpg  \n",
      " extracting: unlabeled2017/000000180060.jpg  \n",
      " extracting: unlabeled2017/000000280276.jpg  \n",
      " extracting: unlabeled2017/000000575061.jpg  \n",
      " extracting: unlabeled2017/000000073133.jpg  \n",
      " extracting: unlabeled2017/000000577497.jpg  \n",
      " extracting: unlabeled2017/000000187802.jpg  \n",
      " extracting: unlabeled2017/000000430301.jpg  \n",
      " extracting: unlabeled2017/000000378689.jpg  \n",
      " extracting: unlabeled2017/000000128359.jpg  \n",
      " extracting: unlabeled2017/000000140796.jpg  \n",
      " extracting: unlabeled2017/000000538292.jpg  \n",
      " extracting: unlabeled2017/000000500404.jpg  \n",
      " extracting: unlabeled2017/000000423930.jpg  \n",
      " extracting: unlabeled2017/000000492956.jpg  \n",
      " extracting: unlabeled2017/000000541752.jpg  \n",
      " extracting: unlabeled2017/000000472824.jpg  \n",
      " extracting: unlabeled2017/000000089042.jpg  \n",
      " extracting: unlabeled2017/000000386270.jpg  \n",
      " extracting: unlabeled2017/000000578421.jpg  \n",
      " extracting: unlabeled2017/000000014649.jpg  \n",
      " extracting: unlabeled2017/000000269956.jpg  \n",
      " extracting: unlabeled2017/000000081091.jpg  \n",
      " extracting: unlabeled2017/000000402492.jpg  \n",
      " extracting: unlabeled2017/000000155970.jpg  \n",
      " extracting: unlabeled2017/000000422652.jpg  \n",
      " extracting: unlabeled2017/000000516501.jpg  \n",
      " extracting: unlabeled2017/000000396956.jpg  \n",
      " extracting: unlabeled2017/000000485420.jpg  \n",
      " extracting: unlabeled2017/000000172895.jpg  \n",
      " extracting: unlabeled2017/000000031433.jpg  \n",
      " extracting: unlabeled2017/000000527910.jpg  \n",
      " extracting: unlabeled2017/000000551817.jpg  \n",
      " extracting: unlabeled2017/000000097605.jpg  \n",
      " extracting: unlabeled2017/000000433729.jpg  \n",
      " extracting: unlabeled2017/000000246169.jpg  \n",
      " extracting: unlabeled2017/000000055734.jpg  \n",
      " extracting: unlabeled2017/000000240984.jpg  \n",
      " extracting: unlabeled2017/000000373250.jpg  \n",
      " extracting: unlabeled2017/000000543248.jpg  \n",
      " extracting: unlabeled2017/000000183955.jpg  \n",
      " extracting: unlabeled2017/000000069062.jpg  \n",
      " extracting: unlabeled2017/000000288167.jpg  \n",
      " extracting: unlabeled2017/000000033125.jpg  \n",
      " extracting: unlabeled2017/000000075511.jpg  \n",
      " extracting: unlabeled2017/000000066276.jpg  \n",
      " extracting: unlabeled2017/000000247992.jpg  \n",
      " extracting: unlabeled2017/000000133643.jpg  \n",
      " extracting: unlabeled2017/000000114971.jpg  \n",
      " extracting: unlabeled2017/000000245340.jpg  \n",
      " extracting: unlabeled2017/000000330626.jpg  \n",
      " extracting: unlabeled2017/000000442315.jpg  \n",
      " extracting: unlabeled2017/000000436377.jpg  \n",
      " extracting: unlabeled2017/000000115433.jpg  \n",
      " extracting: unlabeled2017/000000480395.jpg  \n",
      " extracting: unlabeled2017/000000158592.jpg  \n",
      " extracting: unlabeled2017/000000140136.jpg  \n",
      " extracting: unlabeled2017/000000531240.jpg  \n",
      " extracting: unlabeled2017/000000068065.jpg  \n",
      " extracting: unlabeled2017/000000575517.jpg  \n",
      " extracting: unlabeled2017/000000491860.jpg  \n",
      " extracting: unlabeled2017/000000351720.jpg  \n",
      " extracting: unlabeled2017/000000433344.jpg  \n",
      " extracting: unlabeled2017/000000023365.jpg  \n",
      " extracting: unlabeled2017/000000062168.jpg  \n",
      " extracting: unlabeled2017/000000027039.jpg  \n",
      " extracting: unlabeled2017/000000345477.jpg  \n",
      " extracting: unlabeled2017/000000074314.jpg  \n",
      " extracting: unlabeled2017/000000475553.jpg  \n",
      " extracting: unlabeled2017/000000398617.jpg  \n",
      " extracting: unlabeled2017/000000165287.jpg  \n",
      " extracting: unlabeled2017/000000056986.jpg  \n",
      " extracting: unlabeled2017/000000383411.jpg  \n",
      " extracting: unlabeled2017/000000093217.jpg  \n",
      " extracting: unlabeled2017/000000463440.jpg  \n",
      " extracting: unlabeled2017/000000297079.jpg  \n",
      " extracting: unlabeled2017/000000379440.jpg  \n",
      " extracting: unlabeled2017/000000318123.jpg  \n",
      " extracting: unlabeled2017/000000280885.jpg  \n",
      " extracting: unlabeled2017/000000064920.jpg  \n",
      " extracting: unlabeled2017/000000526084.jpg  \n",
      " extracting: unlabeled2017/000000490583.jpg  \n",
      " extracting: unlabeled2017/000000027295.jpg  \n",
      " extracting: unlabeled2017/000000579984.jpg  \n",
      " extracting: unlabeled2017/000000395208.jpg  \n",
      " extracting: unlabeled2017/000000274486.jpg  \n",
      " extracting: unlabeled2017/000000497614.jpg  \n",
      " extracting: unlabeled2017/000000493226.jpg  \n",
      " extracting: unlabeled2017/000000149972.jpg  \n",
      " extracting: unlabeled2017/000000253999.jpg  \n",
      " extracting: unlabeled2017/000000320634.jpg  \n",
      " extracting: unlabeled2017/000000384393.jpg  \n",
      " extracting: unlabeled2017/000000175625.jpg  \n",
      " extracting: unlabeled2017/000000438010.jpg  \n",
      " extracting: unlabeled2017/000000401311.jpg  \n",
      " extracting: unlabeled2017/000000502579.jpg  \n",
      " extracting: unlabeled2017/000000080945.jpg  \n",
      " extracting: unlabeled2017/000000325335.jpg  \n",
      " extracting: unlabeled2017/000000393584.jpg  \n",
      " extracting: unlabeled2017/000000195312.jpg  \n",
      " extracting: unlabeled2017/000000531447.jpg  \n",
      " extracting: unlabeled2017/000000049793.jpg  \n",
      " extracting: unlabeled2017/000000033138.jpg  \n",
      " extracting: unlabeled2017/000000192695.jpg  \n",
      " extracting: unlabeled2017/000000401579.jpg  \n",
      " extracting: unlabeled2017/000000136837.jpg  \n",
      " extracting: unlabeled2017/000000089480.jpg  \n",
      " extracting: unlabeled2017/000000055177.jpg  \n",
      " extracting: unlabeled2017/000000561076.jpg  \n",
      " extracting: unlabeled2017/000000463574.jpg  \n",
      " extracting: unlabeled2017/000000421268.jpg  \n",
      " extracting: unlabeled2017/000000532836.jpg  \n",
      " extracting: unlabeled2017/000000087972.jpg  \n",
      " extracting: unlabeled2017/000000499650.jpg  \n",
      " extracting: unlabeled2017/000000295950.jpg  \n",
      " extracting: unlabeled2017/000000402190.jpg  \n",
      " extracting: unlabeled2017/000000000857.jpg  \n",
      " extracting: unlabeled2017/000000171173.jpg  \n",
      " extracting: unlabeled2017/000000348760.jpg  \n",
      " extracting: unlabeled2017/000000463148.jpg  \n",
      " extracting: unlabeled2017/000000170924.jpg  \n",
      " extracting: unlabeled2017/000000252866.jpg  \n",
      " extracting: unlabeled2017/000000473618.jpg  \n",
      " extracting: unlabeled2017/000000441590.jpg  \n",
      " extracting: unlabeled2017/000000374263.jpg  \n",
      " extracting: unlabeled2017/000000530039.jpg  \n",
      " extracting: unlabeled2017/000000035370.jpg  \n",
      " extracting: unlabeled2017/000000506028.jpg  \n",
      " extracting: unlabeled2017/000000197842.jpg  \n",
      " extracting: unlabeled2017/000000216626.jpg  \n",
      " extracting: unlabeled2017/000000343764.jpg  \n",
      " extracting: unlabeled2017/000000292286.jpg  \n",
      " extracting: unlabeled2017/000000392547.jpg  \n",
      " extracting: unlabeled2017/000000344778.jpg  \n",
      " extracting: unlabeled2017/000000383531.jpg  \n",
      " extracting: unlabeled2017/000000358007.jpg  \n",
      " extracting: unlabeled2017/000000015641.jpg  \n",
      " extracting: unlabeled2017/000000375289.jpg  \n",
      " extracting: unlabeled2017/000000014013.jpg  \n",
      " extracting: unlabeled2017/000000334436.jpg  \n",
      " extracting: unlabeled2017/000000535840.jpg  \n",
      " extracting: unlabeled2017/000000270630.jpg  \n",
      " extracting: unlabeled2017/000000497673.jpg  \n",
      " extracting: unlabeled2017/000000191700.jpg  \n",
      " extracting: unlabeled2017/000000568293.jpg  \n",
      " extracting: unlabeled2017/000000555385.jpg  \n",
      " extracting: unlabeled2017/000000010979.jpg  \n",
      " extracting: unlabeled2017/000000060613.jpg  \n",
      " extracting: unlabeled2017/000000257309.jpg  \n",
      " extracting: unlabeled2017/000000427004.jpg  \n",
      " extracting: unlabeled2017/000000104083.jpg  \n",
      " extracting: unlabeled2017/000000104239.jpg  \n",
      " extracting: unlabeled2017/000000400687.jpg  \n",
      " extracting: unlabeled2017/000000391985.jpg  \n",
      " extracting: unlabeled2017/000000297804.jpg  \n",
      " extracting: unlabeled2017/000000290244.jpg  \n",
      " extracting: unlabeled2017/000000003410.jpg  \n",
      " extracting: unlabeled2017/000000223505.jpg  \n",
      " extracting: unlabeled2017/000000221498.jpg  \n",
      " extracting: unlabeled2017/000000011955.jpg  \n",
      " extracting: unlabeled2017/000000517556.jpg  \n",
      " extracting: unlabeled2017/000000088343.jpg  \n",
      " extracting: unlabeled2017/000000047860.jpg  \n",
      " extracting: unlabeled2017/000000444109.jpg  \n",
      " extracting: unlabeled2017/000000442546.jpg  \n",
      " extracting: unlabeled2017/000000074311.jpg  \n",
      " extracting: unlabeled2017/000000500168.jpg  \n",
      " extracting: unlabeled2017/000000475637.jpg  \n",
      " extracting: unlabeled2017/000000345407.jpg  \n",
      " extracting: unlabeled2017/000000256060.jpg  \n",
      " extracting: unlabeled2017/000000128895.jpg  \n",
      " extracting: unlabeled2017/000000234771.jpg  \n",
      " extracting: unlabeled2017/000000243346.jpg  \n",
      " extracting: unlabeled2017/000000180407.jpg  \n",
      " extracting: unlabeled2017/000000168369.jpg  \n",
      " extracting: unlabeled2017/000000271927.jpg  \n",
      " extracting: unlabeled2017/000000067901.jpg  \n",
      " extracting: unlabeled2017/000000422976.jpg  \n",
      " extracting: unlabeled2017/000000208630.jpg  \n",
      " extracting: unlabeled2017/000000398946.jpg  \n",
      " extracting: unlabeled2017/000000236710.jpg  \n",
      " extracting: unlabeled2017/000000170467.jpg  \n",
      " extracting: unlabeled2017/000000545760.jpg  \n",
      " extracting: unlabeled2017/000000234525.jpg  \n",
      " extracting: unlabeled2017/000000266446.jpg  \n",
      " extracting: unlabeled2017/000000283322.jpg  \n",
      " extracting: unlabeled2017/000000016532.jpg  \n",
      " extracting: unlabeled2017/000000469872.jpg  \n",
      " extracting: unlabeled2017/000000353646.jpg  \n",
      " extracting: unlabeled2017/000000132253.jpg  \n",
      " extracting: unlabeled2017/000000531746.jpg  \n",
      " extracting: unlabeled2017/000000318744.jpg  \n",
      " extracting: unlabeled2017/000000043549.jpg  \n",
      " extracting: unlabeled2017/000000193078.jpg  \n",
      " extracting: unlabeled2017/000000046381.jpg  \n",
      " extracting: unlabeled2017/000000552087.jpg  \n",
      " extracting: unlabeled2017/000000207793.jpg  \n",
      " extracting: unlabeled2017/000000489061.jpg  \n",
      " extracting: unlabeled2017/000000407104.jpg  \n",
      " extracting: unlabeled2017/000000449006.jpg  \n",
      " extracting: unlabeled2017/000000090919.jpg  \n",
      " extracting: unlabeled2017/000000046301.jpg  \n",
      " extracting: unlabeled2017/000000118532.jpg  \n",
      " extracting: unlabeled2017/000000432434.jpg  \n",
      " extracting: unlabeled2017/000000477035.jpg  \n",
      " extracting: unlabeled2017/000000065540.jpg  \n",
      " extracting: unlabeled2017/000000340281.jpg  \n",
      " extracting: unlabeled2017/000000565498.jpg  \n",
      " extracting: unlabeled2017/000000552732.jpg  \n",
      " extracting: unlabeled2017/000000384832.jpg  \n",
      " extracting: unlabeled2017/000000177139.jpg  \n",
      " extracting: unlabeled2017/000000274943.jpg  \n",
      " extracting: unlabeled2017/000000238040.jpg  \n",
      " extracting: unlabeled2017/000000372094.jpg  \n",
      " extracting: unlabeled2017/000000512538.jpg  \n",
      " extracting: unlabeled2017/000000420429.jpg  \n",
      " extracting: unlabeled2017/000000133220.jpg  \n",
      " extracting: unlabeled2017/000000562852.jpg  \n",
      " extracting: unlabeled2017/000000358404.jpg  \n",
      " extracting: unlabeled2017/000000527245.jpg  \n",
      " extracting: unlabeled2017/000000503268.jpg  \n",
      " extracting: unlabeled2017/000000438129.jpg  \n",
      " extracting: unlabeled2017/000000189488.jpg  \n",
      " extracting: unlabeled2017/000000196189.jpg  \n",
      " extracting: unlabeled2017/000000550769.jpg  \n",
      " extracting: unlabeled2017/000000119383.jpg  \n",
      " extracting: unlabeled2017/000000047623.jpg  \n",
      " extracting: unlabeled2017/000000581547.jpg  \n",
      " extracting: unlabeled2017/000000100066.jpg  \n",
      " extracting: unlabeled2017/000000030641.jpg  \n",
      " extracting: unlabeled2017/000000090110.jpg  \n",
      " extracting: unlabeled2017/000000436423.jpg  \n",
      " extracting: unlabeled2017/000000015465.jpg  \n",
      " extracting: unlabeled2017/000000527727.jpg  \n",
      " extracting: unlabeled2017/000000161606.jpg  \n",
      " extracting: unlabeled2017/000000451233.jpg  \n",
      " extracting: unlabeled2017/000000060884.jpg  \n",
      " extracting: unlabeled2017/000000213131.jpg  \n",
      " extracting: unlabeled2017/000000194136.jpg  \n",
      " extracting: unlabeled2017/000000564995.jpg  \n",
      " extracting: unlabeled2017/000000052014.jpg  \n",
      " extracting: unlabeled2017/000000140970.jpg  \n",
      " extracting: unlabeled2017/000000320274.jpg  \n",
      " extracting: unlabeled2017/000000541647.jpg  \n",
      " extracting: unlabeled2017/000000204921.jpg  \n",
      " extracting: unlabeled2017/000000452923.jpg  \n",
      " extracting: unlabeled2017/000000034814.jpg  \n",
      " extracting: unlabeled2017/000000277974.jpg  \n",
      " extracting: unlabeled2017/000000466397.jpg  \n",
      " extracting: unlabeled2017/000000514167.jpg  \n",
      " extracting: unlabeled2017/000000073425.jpg  \n",
      " extracting: unlabeled2017/000000286873.jpg  \n",
      " extracting: unlabeled2017/000000530166.jpg  \n",
      " extracting: unlabeled2017/000000453237.jpg  \n",
      " extracting: unlabeled2017/000000108459.jpg  \n",
      " extracting: unlabeled2017/000000142605.jpg  \n",
      " extracting: unlabeled2017/000000328002.jpg  \n",
      " extracting: unlabeled2017/000000238921.jpg  \n",
      " extracting: unlabeled2017/000000275394.jpg  \n",
      " extracting: unlabeled2017/000000216671.jpg  \n",
      " extracting: unlabeled2017/000000000235.jpg  \n",
      " extracting: unlabeled2017/000000061050.jpg  \n",
      " extracting: unlabeled2017/000000398041.jpg  \n",
      " extracting: unlabeled2017/000000186153.jpg  \n",
      " extracting: unlabeled2017/000000575638.jpg  \n",
      " extracting: unlabeled2017/000000379427.jpg  \n",
      " extracting: unlabeled2017/000000528099.jpg  \n",
      " extracting: unlabeled2017/000000418370.jpg  \n",
      " extracting: unlabeled2017/000000474654.jpg  \n",
      " extracting: unlabeled2017/000000126459.jpg  \n",
      " extracting: unlabeled2017/000000216849.jpg  \n",
      " extracting: unlabeled2017/000000421786.jpg  \n",
      " extracting: unlabeled2017/000000158138.jpg  \n",
      " extracting: unlabeled2017/000000124075.jpg  \n",
      " extracting: unlabeled2017/000000460570.jpg  \n",
      " extracting: unlabeled2017/000000133695.jpg  \n",
      " extracting: unlabeled2017/000000002031.jpg  \n",
      " extracting: unlabeled2017/000000117638.jpg  \n",
      " extracting: unlabeled2017/000000348297.jpg  \n",
      " extracting: unlabeled2017/000000116743.jpg  \n",
      " extracting: unlabeled2017/000000357225.jpg  \n",
      " extracting: unlabeled2017/000000101255.jpg  \n",
      " extracting: unlabeled2017/000000457471.jpg  \n",
      " extracting: unlabeled2017/000000309196.jpg  \n",
      " extracting: unlabeled2017/000000062421.jpg  \n",
      " extracting: unlabeled2017/000000536677.jpg  \n",
      " extracting: unlabeled2017/000000362882.jpg  \n",
      " extracting: unlabeled2017/000000149247.jpg  \n",
      " extracting: unlabeled2017/000000417790.jpg  \n",
      " extracting: unlabeled2017/000000557401.jpg  \n",
      " extracting: unlabeled2017/000000452043.jpg  \n",
      " extracting: unlabeled2017/000000483504.jpg  \n",
      " extracting: unlabeled2017/000000140113.jpg  \n",
      " extracting: unlabeled2017/000000295603.jpg  \n",
      " extracting: unlabeled2017/000000063160.jpg  \n",
      " extracting: unlabeled2017/000000217452.jpg  \n",
      " extracting: unlabeled2017/000000034358.jpg  \n",
      " extracting: unlabeled2017/000000137747.jpg  \n",
      " extracting: unlabeled2017/000000123710.jpg  \n",
      " extracting: unlabeled2017/000000044945.jpg  \n",
      " extracting: unlabeled2017/000000386590.jpg  \n",
      " extracting: unlabeled2017/000000244708.jpg  \n",
      " extracting: unlabeled2017/000000365908.jpg  \n",
      " extracting: unlabeled2017/000000080259.jpg  \n",
      " extracting: unlabeled2017/000000374200.jpg  \n",
      " extracting: unlabeled2017/000000418422.jpg  \n",
      " extracting: unlabeled2017/000000539291.jpg  \n",
      " extracting: unlabeled2017/000000457350.jpg  \n",
      " extracting: unlabeled2017/000000236654.jpg  \n",
      " extracting: unlabeled2017/000000420602.jpg  \n",
      " extracting: unlabeled2017/000000262817.jpg  \n",
      " extracting: unlabeled2017/000000272965.jpg  \n",
      " extracting: unlabeled2017/000000566728.jpg  \n",
      " extracting: unlabeled2017/000000100391.jpg  \n",
      " extracting: unlabeled2017/000000395511.jpg  \n",
      " extracting: unlabeled2017/000000571282.jpg  \n",
      " extracting: unlabeled2017/000000449482.jpg  \n",
      " extracting: unlabeled2017/000000005954.jpg  \n",
      " extracting: unlabeled2017/000000215761.jpg  \n",
      " extracting: unlabeled2017/000000248870.jpg  \n",
      " extracting: unlabeled2017/000000086940.jpg  \n",
      " extracting: unlabeled2017/000000209278.jpg  \n",
      " extracting: unlabeled2017/000000132624.jpg  \n",
      " extracting: unlabeled2017/000000098492.jpg  \n",
      " extracting: unlabeled2017/000000250052.jpg  \n",
      " extracting: unlabeled2017/000000285267.jpg  \n",
      " extracting: unlabeled2017/000000087941.jpg  \n",
      " extracting: unlabeled2017/000000116054.jpg  \n",
      " extracting: unlabeled2017/000000097443.jpg  \n",
      " extracting: unlabeled2017/000000191702.jpg  \n",
      " extracting: unlabeled2017/000000289250.jpg  \n",
      " extracting: unlabeled2017/000000238325.jpg  \n",
      " extracting: unlabeled2017/000000245981.jpg  \n",
      " extracting: unlabeled2017/000000507775.jpg  \n",
      " extracting: unlabeled2017/000000449890.jpg  \n",
      " extracting: unlabeled2017/000000512891.jpg  \n",
      " extracting: unlabeled2017/000000060465.jpg  \n",
      " extracting: unlabeled2017/000000280547.jpg  \n",
      " extracting: unlabeled2017/000000158413.jpg  \n",
      " extracting: unlabeled2017/000000341897.jpg  \n",
      " extracting: unlabeled2017/000000060491.jpg  \n",
      " extracting: unlabeled2017/000000473760.jpg  \n",
      " extracting: unlabeled2017/000000080977.jpg  \n",
      " extracting: unlabeled2017/000000520632.jpg  \n",
      " extracting: unlabeled2017/000000466492.jpg  \n",
      " extracting: unlabeled2017/000000008637.jpg  \n",
      " extracting: unlabeled2017/000000541487.jpg  \n",
      " extracting: unlabeled2017/000000041158.jpg  \n",
      " extracting: unlabeled2017/000000237936.jpg  \n",
      " extracting: unlabeled2017/000000548499.jpg  \n",
      " extracting: unlabeled2017/000000115450.jpg  \n",
      " extracting: unlabeled2017/000000081564.jpg  \n",
      " extracting: unlabeled2017/000000457982.jpg  \n",
      " extracting: unlabeled2017/000000483240.jpg  \n",
      " extracting: unlabeled2017/000000395662.jpg  \n",
      " extracting: unlabeled2017/000000470086.jpg  \n",
      " extracting: unlabeled2017/000000495660.jpg  \n",
      " extracting: unlabeled2017/000000235258.jpg  \n",
      " extracting: unlabeled2017/000000256893.jpg  \n",
      " extracting: unlabeled2017/000000255921.jpg  \n",
      " extracting: unlabeled2017/000000089719.jpg  \n",
      " extracting: unlabeled2017/000000505239.jpg  \n",
      " extracting: unlabeled2017/000000417863.jpg  \n",
      " extracting: unlabeled2017/000000252947.jpg  \n",
      " extracting: unlabeled2017/000000576844.jpg  \n",
      " extracting: unlabeled2017/000000146840.jpg  \n",
      " extracting: unlabeled2017/000000252405.jpg  \n",
      " extracting: unlabeled2017/000000331973.jpg  \n",
      " extracting: unlabeled2017/000000369270.jpg  \n",
      " extracting: unlabeled2017/000000540958.jpg  \n",
      " extracting: unlabeled2017/000000212343.jpg  \n",
      " extracting: unlabeled2017/000000272052.jpg  \n",
      " extracting: unlabeled2017/000000129575.jpg  \n",
      " extracting: unlabeled2017/000000178493.jpg  \n",
      " extracting: unlabeled2017/000000362799.jpg  \n",
      " extracting: unlabeled2017/000000465928.jpg  \n",
      " extracting: unlabeled2017/000000260421.jpg  \n",
      " extracting: unlabeled2017/000000162381.jpg  \n",
      " extracting: unlabeled2017/000000386013.jpg  \n",
      " extracting: unlabeled2017/000000346443.jpg  \n",
      " extracting: unlabeled2017/000000438234.jpg  \n",
      " extracting: unlabeled2017/000000417565.jpg  \n",
      " extracting: unlabeled2017/000000495003.jpg  \n",
      " extracting: unlabeled2017/000000029186.jpg  \n",
      " extracting: unlabeled2017/000000159571.jpg  \n",
      " extracting: unlabeled2017/000000038583.jpg  \n",
      " extracting: unlabeled2017/000000336008.jpg  \n",
      " extracting: unlabeled2017/000000167434.jpg  \n",
      " extracting: unlabeled2017/000000150563.jpg  \n",
      " extracting: unlabeled2017/000000380265.jpg  \n",
      " extracting: unlabeled2017/000000253626.jpg  \n",
      " extracting: unlabeled2017/000000161264.jpg  \n",
      " extracting: unlabeled2017/000000432774.jpg  \n",
      " extracting: unlabeled2017/000000552133.jpg  \n",
      " extracting: unlabeled2017/000000132240.jpg  \n",
      " extracting: unlabeled2017/000000152569.jpg  \n",
      " extracting: unlabeled2017/000000262249.jpg  \n",
      " extracting: unlabeled2017/000000506081.jpg  \n",
      " extracting: unlabeled2017/000000211791.jpg  \n",
      " extracting: unlabeled2017/000000186141.jpg  \n",
      " extracting: unlabeled2017/000000452934.jpg  \n",
      " extracting: unlabeled2017/000000256768.jpg  \n",
      " extracting: unlabeled2017/000000278518.jpg  \n",
      " extracting: unlabeled2017/000000128316.jpg  \n",
      " extracting: unlabeled2017/000000047413.jpg  \n",
      " extracting: unlabeled2017/000000335002.jpg  \n",
      " extracting: unlabeled2017/000000334282.jpg  \n",
      " extracting: unlabeled2017/000000354637.jpg  \n",
      " extracting: unlabeled2017/000000561848.jpg  \n",
      " extracting: unlabeled2017/000000039780.jpg  \n",
      " extracting: unlabeled2017/000000189393.jpg  \n",
      " extracting: unlabeled2017/000000520010.jpg  \n",
      " extracting: unlabeled2017/000000131469.jpg  \n",
      " extracting: unlabeled2017/000000287224.jpg  \n",
      " extracting: unlabeled2017/000000444139.jpg  \n",
      " extracting: unlabeled2017/000000561536.jpg  \n",
      " extracting: unlabeled2017/000000513596.jpg  \n",
      " extracting: unlabeled2017/000000579284.jpg  \n",
      " extracting: unlabeled2017/000000254618.jpg  \n",
      " extracting: unlabeled2017/000000320727.jpg  \n",
      " extracting: unlabeled2017/000000479113.jpg  \n",
      " extracting: unlabeled2017/000000490234.jpg  \n",
      " extracting: unlabeled2017/000000181669.jpg  \n",
      " extracting: unlabeled2017/000000332679.jpg  \n",
      " extracting: unlabeled2017/000000425603.jpg  \n",
      " extracting: unlabeled2017/000000007661.jpg  \n",
      " extracting: unlabeled2017/000000106956.jpg  \n",
      " extracting: unlabeled2017/000000366369.jpg  \n",
      " extracting: unlabeled2017/000000002723.jpg  \n",
      " extracting: unlabeled2017/000000163971.jpg  \n",
      " extracting: unlabeled2017/000000249898.jpg  \n",
      " extracting: unlabeled2017/000000449265.jpg  \n",
      " extracting: unlabeled2017/000000555051.jpg  \n",
      " extracting: unlabeled2017/000000320573.jpg  \n",
      " extracting: unlabeled2017/000000568178.jpg  \n",
      " extracting: unlabeled2017/000000011199.jpg  \n",
      " extracting: unlabeled2017/000000339343.jpg  \n",
      " extracting: unlabeled2017/000000437891.jpg  \n",
      " extracting: unlabeled2017/000000520165.jpg  \n",
      " extracting: unlabeled2017/000000383130.jpg  \n",
      " extracting: unlabeled2017/000000090507.jpg  \n",
      " extracting: unlabeled2017/000000487862.jpg  \n",
      " extracting: unlabeled2017/000000149032.jpg  \n",
      " extracting: unlabeled2017/000000278759.jpg  \n",
      " extracting: unlabeled2017/000000208929.jpg  \n",
      " extracting: unlabeled2017/000000553754.jpg  \n",
      " extracting: unlabeled2017/000000173246.jpg  \n",
      " extracting: unlabeled2017/000000554428.jpg  \n",
      " extracting: unlabeled2017/000000422112.jpg  \n",
      " extracting: unlabeled2017/000000012445.jpg  \n",
      " extracting: unlabeled2017/000000373306.jpg  \n",
      " extracting: unlabeled2017/000000417581.jpg  \n",
      " extracting: unlabeled2017/000000506036.jpg  \n",
      " extracting: unlabeled2017/000000421492.jpg  \n",
      " extracting: unlabeled2017/000000166242.jpg  \n",
      " extracting: unlabeled2017/000000493548.jpg  \n",
      " extracting: unlabeled2017/000000351513.jpg  \n",
      " extracting: unlabeled2017/000000330512.jpg  \n",
      " extracting: unlabeled2017/000000126162.jpg  \n",
      " extracting: unlabeled2017/000000448960.jpg  \n",
      " extracting: unlabeled2017/000000492405.jpg  \n",
      " extracting: unlabeled2017/000000108622.jpg  \n",
      " extracting: unlabeled2017/000000241333.jpg  \n",
      " extracting: unlabeled2017/000000306558.jpg  \n",
      " extracting: unlabeled2017/000000527221.jpg  \n",
      " extracting: unlabeled2017/000000199581.jpg  \n",
      " extracting: unlabeled2017/000000553418.jpg  \n",
      " extracting: unlabeled2017/000000208885.jpg  \n",
      " extracting: unlabeled2017/000000339338.jpg  \n",
      " extracting: unlabeled2017/000000275341.jpg  \n",
      " extracting: unlabeled2017/000000577962.jpg  \n",
      " extracting: unlabeled2017/000000167053.jpg  \n",
      " extracting: unlabeled2017/000000038068.jpg  \n",
      " extracting: unlabeled2017/000000290527.jpg  \n",
      " extracting: unlabeled2017/000000155062.jpg  \n",
      " extracting: unlabeled2017/000000298624.jpg  \n",
      " extracting: unlabeled2017/000000477648.jpg  \n",
      " extracting: unlabeled2017/000000565348.jpg  \n",
      " extracting: unlabeled2017/000000193182.jpg  \n",
      " extracting: unlabeled2017/000000238614.jpg  \n",
      " extracting: unlabeled2017/000000417372.jpg  \n",
      " extracting: unlabeled2017/000000444319.jpg  \n",
      " extracting: unlabeled2017/000000445584.jpg  \n",
      " extracting: unlabeled2017/000000425075.jpg  \n",
      " extracting: unlabeled2017/000000533294.jpg  \n",
      " extracting: unlabeled2017/000000382989.jpg  \n",
      " extracting: unlabeled2017/000000235677.jpg  \n",
      " extracting: unlabeled2017/000000226647.jpg  \n",
      " extracting: unlabeled2017/000000540744.jpg  \n",
      " extracting: unlabeled2017/000000573025.jpg  \n",
      " extracting: unlabeled2017/000000424063.jpg  \n",
      " extracting: unlabeled2017/000000544976.jpg  \n",
      " extracting: unlabeled2017/000000538975.jpg  \n",
      " extracting: unlabeled2017/000000432425.jpg  \n",
      " extracting: unlabeled2017/000000189918.jpg  \n",
      " extracting: unlabeled2017/000000363381.jpg  \n",
      " extracting: unlabeled2017/000000094604.jpg  \n",
      " extracting: unlabeled2017/000000139794.jpg  \n",
      " extracting: unlabeled2017/000000183730.jpg  \n",
      " extracting: unlabeled2017/000000551852.jpg  \n",
      " extracting: unlabeled2017/000000335265.jpg  \n",
      " extracting: unlabeled2017/000000354044.jpg  \n",
      " extracting: unlabeled2017/000000190553.jpg  \n",
      " extracting: unlabeled2017/000000236734.jpg  \n",
      " extracting: unlabeled2017/000000399849.jpg  \n",
      " extracting: unlabeled2017/000000456228.jpg  \n",
      " extracting: unlabeled2017/000000567123.jpg  \n",
      " extracting: unlabeled2017/000000013270.jpg  \n",
      " extracting: unlabeled2017/000000035253.jpg  \n",
      " extracting: unlabeled2017/000000579775.jpg  \n",
      " extracting: unlabeled2017/000000384856.jpg  \n",
      " extracting: unlabeled2017/000000136703.jpg  \n",
      " extracting: unlabeled2017/000000424631.jpg  \n",
      " extracting: unlabeled2017/000000563527.jpg  \n",
      " extracting: unlabeled2017/000000381997.jpg  \n",
      " extracting: unlabeled2017/000000053963.jpg  \n",
      " extracting: unlabeled2017/000000258797.jpg  \n",
      " extracting: unlabeled2017/000000341307.jpg  \n",
      " extracting: unlabeled2017/000000238903.jpg  \n",
      " extracting: unlabeled2017/000000301779.jpg  \n",
      " extracting: unlabeled2017/000000503888.jpg  \n",
      " extracting: unlabeled2017/000000578790.jpg  \n",
      " extracting: unlabeled2017/000000068355.jpg  \n",
      " extracting: unlabeled2017/000000546637.jpg  \n",
      " extracting: unlabeled2017/000000287218.jpg  \n",
      " extracting: unlabeled2017/000000255215.jpg  \n",
      " extracting: unlabeled2017/000000371083.jpg  \n",
      " extracting: unlabeled2017/000000444614.jpg  \n",
      " extracting: unlabeled2017/000000190191.jpg  \n",
      " extracting: unlabeled2017/000000117383.jpg  \n",
      " extracting: unlabeled2017/000000041013.jpg  \n",
      " extracting: unlabeled2017/000000009120.jpg  \n",
      " extracting: unlabeled2017/000000257745.jpg  \n",
      " extracting: unlabeled2017/000000217647.jpg  \n",
      " extracting: unlabeled2017/000000468725.jpg  \n",
      " extracting: unlabeled2017/000000569695.jpg  \n",
      " extracting: unlabeled2017/000000046899.jpg  \n",
      " extracting: unlabeled2017/000000507529.jpg  \n",
      " extracting: unlabeled2017/000000281157.jpg  \n",
      " extracting: unlabeled2017/000000474236.jpg  \n",
      " extracting: unlabeled2017/000000350173.jpg  \n",
      " extracting: unlabeled2017/000000092824.jpg  \n",
      " extracting: unlabeled2017/000000509751.jpg  \n",
      " extracting: unlabeled2017/000000338916.jpg  \n",
      " extracting: unlabeled2017/000000559414.jpg  \n",
      " extracting: unlabeled2017/000000182841.jpg  \n",
      " extracting: unlabeled2017/000000140269.jpg  \n",
      " extracting: unlabeled2017/000000343261.jpg  \n",
      " extracting: unlabeled2017/000000412635.jpg  \n",
      " extracting: unlabeled2017/000000200237.jpg  \n",
      " extracting: unlabeled2017/000000346548.jpg  \n",
      " extracting: unlabeled2017/000000544594.jpg  \n",
      " extracting: unlabeled2017/000000264463.jpg  \n",
      " extracting: unlabeled2017/000000135496.jpg  \n",
      " extracting: unlabeled2017/000000129778.jpg  \n",
      " extracting: unlabeled2017/000000438813.jpg  \n",
      " extracting: unlabeled2017/000000014109.jpg  \n",
      " extracting: unlabeled2017/000000545344.jpg  \n",
      " extracting: unlabeled2017/000000003470.jpg  \n",
      " extracting: unlabeled2017/000000359622.jpg  \n",
      " extracting: unlabeled2017/000000089619.jpg  \n",
      " extracting: unlabeled2017/000000076705.jpg  \n",
      " extracting: unlabeled2017/000000028801.jpg  \n",
      " extracting: unlabeled2017/000000023583.jpg  \n",
      " extracting: unlabeled2017/000000066090.jpg  \n",
      " extracting: unlabeled2017/000000196411.jpg  \n",
      " extracting: unlabeled2017/000000366637.jpg  \n",
      " extracting: unlabeled2017/000000371551.jpg  \n",
      " extracting: unlabeled2017/000000072510.jpg  \n",
      " extracting: unlabeled2017/000000206918.jpg  \n",
      " extracting: unlabeled2017/000000110466.jpg  \n",
      " extracting: unlabeled2017/000000062720.jpg  \n",
      " extracting: unlabeled2017/000000460811.jpg  \n",
      " extracting: unlabeled2017/000000070832.jpg  \n",
      " extracting: unlabeled2017/000000468490.jpg  \n",
      " extracting: unlabeled2017/000000234788.jpg  \n",
      " extracting: unlabeled2017/000000092105.jpg  \n",
      " extracting: unlabeled2017/000000325704.jpg  \n",
      " extracting: unlabeled2017/000000085748.jpg  \n",
      " extracting: unlabeled2017/000000578134.jpg  \n",
      " extracting: unlabeled2017/000000424896.jpg  \n",
      " extracting: unlabeled2017/000000438415.jpg  \n",
      " extracting: unlabeled2017/000000254313.jpg  \n",
      " extracting: unlabeled2017/000000062835.jpg  \n",
      " extracting: unlabeled2017/000000224842.jpg  \n",
      " extracting: unlabeled2017/000000467209.jpg  \n",
      " extracting: unlabeled2017/000000448914.jpg  \n",
      " extracting: unlabeled2017/000000261859.jpg  \n",
      " extracting: unlabeled2017/000000303074.jpg  \n",
      " extracting: unlabeled2017/000000486029.jpg  \n",
      " extracting: unlabeled2017/000000114821.jpg  \n",
      " extracting: unlabeled2017/000000402366.jpg  \n",
      " extracting: unlabeled2017/000000573362.jpg  \n",
      " extracting: unlabeled2017/000000530485.jpg  \n",
      " extracting: unlabeled2017/000000308169.jpg  \n",
      " extracting: unlabeled2017/000000577347.jpg  \n",
      " extracting: unlabeled2017/000000543630.jpg  \n",
      " extracting: unlabeled2017/000000262763.jpg  \n",
      " extracting: unlabeled2017/000000353459.jpg  \n",
      " extracting: unlabeled2017/000000219555.jpg  \n",
      " extracting: unlabeled2017/000000287772.jpg  \n",
      " extracting: unlabeled2017/000000441797.jpg  \n",
      " extracting: unlabeled2017/000000283686.jpg  \n",
      " extracting: unlabeled2017/000000219706.jpg  \n",
      " extracting: unlabeled2017/000000021940.jpg  \n",
      " extracting: unlabeled2017/000000416222.jpg  \n",
      " extracting: unlabeled2017/000000099608.jpg  \n",
      " extracting: unlabeled2017/000000497999.jpg  \n",
      " extracting: unlabeled2017/000000423509.jpg  \n",
      " extracting: unlabeled2017/000000445973.jpg  \n",
      " extracting: unlabeled2017/000000263417.jpg  \n",
      " extracting: unlabeled2017/000000363846.jpg  \n",
      " extracting: unlabeled2017/000000138077.jpg  \n",
      " extracting: unlabeled2017/000000178219.jpg  \n",
      " extracting: unlabeled2017/000000269371.jpg  \n",
      " extracting: unlabeled2017/000000383036.jpg  \n",
      " extracting: unlabeled2017/000000141806.jpg  \n",
      " extracting: unlabeled2017/000000389098.jpg  \n",
      " extracting: unlabeled2017/000000305143.jpg  \n",
      " extracting: unlabeled2017/000000510514.jpg  \n",
      " extracting: unlabeled2017/000000473809.jpg  \n",
      " extracting: unlabeled2017/000000015630.jpg  \n",
      " extracting: unlabeled2017/000000023443.jpg  \n",
      " extracting: unlabeled2017/000000348470.jpg  \n",
      " extracting: unlabeled2017/000000404500.jpg  \n",
      " extracting: unlabeled2017/000000375772.jpg  \n",
      " extracting: unlabeled2017/000000103156.jpg  \n",
      " extracting: unlabeled2017/000000315661.jpg  \n",
      " extracting: unlabeled2017/000000215942.jpg  \n",
      " extracting: unlabeled2017/000000072661.jpg  \n",
      " extracting: unlabeled2017/000000455193.jpg  \n",
      " extracting: unlabeled2017/000000076520.jpg  \n",
      " extracting: unlabeled2017/000000001738.jpg  \n",
      " extracting: unlabeled2017/000000425934.jpg  \n",
      " extracting: unlabeled2017/000000293295.jpg  \n",
      " extracting: unlabeled2017/000000124668.jpg  \n",
      " extracting: unlabeled2017/000000182157.jpg  \n",
      " extracting: unlabeled2017/000000567325.jpg  \n",
      " extracting: unlabeled2017/000000391838.jpg  \n",
      " extracting: unlabeled2017/000000340966.jpg  \n",
      " extracting: unlabeled2017/000000518809.jpg  \n",
      " extracting: unlabeled2017/000000038335.jpg  \n",
      " extracting: unlabeled2017/000000456966.jpg  \n",
      " extracting: unlabeled2017/000000321484.jpg  \n",
      " extracting: unlabeled2017/000000357299.jpg  \n",
      " extracting: unlabeled2017/000000450385.jpg  \n",
      " extracting: unlabeled2017/000000141617.jpg  \n",
      " extracting: unlabeled2017/000000090525.jpg  \n",
      " extracting: unlabeled2017/000000003914.jpg  \n",
      " extracting: unlabeled2017/000000073956.jpg  \n",
      " extracting: unlabeled2017/000000488042.jpg  \n",
      " extracting: unlabeled2017/000000025884.jpg  \n",
      " extracting: unlabeled2017/000000535395.jpg  \n",
      " extracting: unlabeled2017/000000048112.jpg  \n",
      " extracting: unlabeled2017/000000439490.jpg  \n",
      " extracting: unlabeled2017/000000452252.jpg  \n",
      " extracting: unlabeled2017/000000478578.jpg  \n",
      " extracting: unlabeled2017/000000167888.jpg  \n",
      " extracting: unlabeled2017/000000089780.jpg  \n",
      " extracting: unlabeled2017/000000479223.jpg  \n",
      " extracting: unlabeled2017/000000065147.jpg  \n",
      " extracting: unlabeled2017/000000560590.jpg  \n",
      " extracting: unlabeled2017/000000143551.jpg  \n",
      " extracting: unlabeled2017/000000173972.jpg  \n",
      " extracting: unlabeled2017/000000474340.jpg  \n",
      " extracting: unlabeled2017/000000115140.jpg  \n",
      " extracting: unlabeled2017/000000253523.jpg  \n",
      " extracting: unlabeled2017/000000580730.jpg  \n",
      " extracting: unlabeled2017/000000129224.jpg  \n",
      " extracting: unlabeled2017/000000439469.jpg  \n",
      " extracting: unlabeled2017/000000297644.jpg  \n",
      " extracting: unlabeled2017/000000047541.jpg  \n",
      " extracting: unlabeled2017/000000372899.jpg  \n",
      " extracting: unlabeled2017/000000243751.jpg  \n",
      " extracting: unlabeled2017/000000381188.jpg  \n",
      " extracting: unlabeled2017/000000155363.jpg  \n",
      " extracting: unlabeled2017/000000538406.jpg  \n",
      " extracting: unlabeled2017/000000233161.jpg  \n",
      " extracting: unlabeled2017/000000494861.jpg  \n",
      " extracting: unlabeled2017/000000487821.jpg  \n",
      " extracting: unlabeled2017/000000372313.jpg  \n",
      " extracting: unlabeled2017/000000467560.jpg  \n",
      " extracting: unlabeled2017/000000081498.jpg  \n",
      " extracting: unlabeled2017/000000473880.jpg  \n",
      " extracting: unlabeled2017/000000335444.jpg  \n",
      " extracting: unlabeled2017/000000493037.jpg  \n",
      " extracting: unlabeled2017/000000399440.jpg  \n",
      " extracting: unlabeled2017/000000472698.jpg  \n",
      " extracting: unlabeled2017/000000328107.jpg  \n",
      " extracting: unlabeled2017/000000384881.jpg  \n",
      " extracting: unlabeled2017/000000566490.jpg  \n",
      " extracting: unlabeled2017/000000498684.jpg  \n",
      " extracting: unlabeled2017/000000434627.jpg  \n",
      " extracting: unlabeled2017/000000358787.jpg  \n",
      " extracting: unlabeled2017/000000310814.jpg  \n",
      " extracting: unlabeled2017/000000071700.jpg  \n",
      " extracting: unlabeled2017/000000256020.jpg  \n",
      " extracting: unlabeled2017/000000198646.jpg  \n",
      " extracting: unlabeled2017/000000546273.jpg  \n",
      " extracting: unlabeled2017/000000365974.jpg  \n",
      " extracting: unlabeled2017/000000426524.jpg  \n",
      " extracting: unlabeled2017/000000356023.jpg  \n",
      " extracting: unlabeled2017/000000206815.jpg  \n",
      " extracting: unlabeled2017/000000239430.jpg  \n",
      " extracting: unlabeled2017/000000057203.jpg  \n",
      " extracting: unlabeled2017/000000200070.jpg  \n",
      " extracting: unlabeled2017/000000312353.jpg  \n",
      " extracting: unlabeled2017/000000120949.jpg  \n",
      " extracting: unlabeled2017/000000385116.jpg  \n",
      " extracting: unlabeled2017/000000175166.jpg  \n",
      " extracting: unlabeled2017/000000213390.jpg  \n",
      " extracting: unlabeled2017/000000068491.jpg  \n",
      " extracting: unlabeled2017/000000038062.jpg  \n",
      " extracting: unlabeled2017/000000528368.jpg  \n",
      " extracting: unlabeled2017/000000029297.jpg  \n",
      " extracting: unlabeled2017/000000246623.jpg  \n",
      " extracting: unlabeled2017/000000108300.jpg  \n",
      " extracting: unlabeled2017/000000249647.jpg  \n",
      " extracting: unlabeled2017/000000065790.jpg  \n",
      " extracting: unlabeled2017/000000522422.jpg  \n",
      " extracting: unlabeled2017/000000154834.jpg  \n",
      " extracting: unlabeled2017/000000501761.jpg  \n",
      " extracting: unlabeled2017/000000189122.jpg  \n",
      " extracting: unlabeled2017/000000298903.jpg  \n",
      " extracting: unlabeled2017/000000245439.jpg  \n",
      " extracting: unlabeled2017/000000146802.jpg  \n",
      " extracting: unlabeled2017/000000120064.jpg  \n",
      " extracting: unlabeled2017/000000328749.jpg  \n",
      " extracting: unlabeled2017/000000200809.jpg  \n",
      " extracting: unlabeled2017/000000304502.jpg  \n",
      " extracting: unlabeled2017/000000358777.jpg  \n",
      " extracting: unlabeled2017/000000268788.jpg  \n",
      " extracting: unlabeled2017/000000148626.jpg  \n",
      " extracting: unlabeled2017/000000167196.jpg  \n",
      " extracting: unlabeled2017/000000401849.jpg  \n",
      " extracting: unlabeled2017/000000287321.jpg  \n",
      " extracting: unlabeled2017/000000354473.jpg  \n",
      " extracting: unlabeled2017/000000579092.jpg  \n",
      " extracting: unlabeled2017/000000079991.jpg  \n",
      " extracting: unlabeled2017/000000341757.jpg  \n",
      " extracting: unlabeled2017/000000173603.jpg  \n",
      " extracting: unlabeled2017/000000543796.jpg  \n",
      " extracting: unlabeled2017/000000340351.jpg  \n",
      " extracting: unlabeled2017/000000406421.jpg  \n",
      " extracting: unlabeled2017/000000423210.jpg  \n",
      " extracting: unlabeled2017/000000554295.jpg  \n",
      " extracting: unlabeled2017/000000114499.jpg  \n",
      " extracting: unlabeled2017/000000023518.jpg  \n",
      " extracting: unlabeled2017/000000012688.jpg  \n",
      " extracting: unlabeled2017/000000134625.jpg  \n",
      " extracting: unlabeled2017/000000363681.jpg  \n",
      " extracting: unlabeled2017/000000246282.jpg  \n",
      " extracting: unlabeled2017/000000179952.jpg  \n",
      " extracting: unlabeled2017/000000566567.jpg  \n",
      " extracting: unlabeled2017/000000329647.jpg  \n",
      " extracting: unlabeled2017/000000022426.jpg  \n",
      " extracting: unlabeled2017/000000417305.jpg  \n",
      " extracting: unlabeled2017/000000449303.jpg  \n",
      " extracting: unlabeled2017/000000492086.jpg  \n",
      " extracting: unlabeled2017/000000489026.jpg  \n",
      " extracting: unlabeled2017/000000194271.jpg  \n",
      " extracting: unlabeled2017/000000203077.jpg  \n",
      " extracting: unlabeled2017/000000314263.jpg  \n",
      " extracting: unlabeled2017/000000230957.jpg  \n",
      " extracting: unlabeled2017/000000044822.jpg  \n",
      " extracting: unlabeled2017/000000537645.jpg  \n",
      " extracting: unlabeled2017/000000159613.jpg  \n",
      " extracting: unlabeled2017/000000110515.jpg  \n",
      " extracting: unlabeled2017/000000543646.jpg  \n",
      " extracting: unlabeled2017/000000306123.jpg  \n",
      " extracting: unlabeled2017/000000473273.jpg  \n",
      " extracting: unlabeled2017/000000578865.jpg  \n",
      " extracting: unlabeled2017/000000552060.jpg  \n",
      " extracting: unlabeled2017/000000167820.jpg  \n",
      " extracting: unlabeled2017/000000361155.jpg  \n",
      " extracting: unlabeled2017/000000335121.jpg  \n",
      " extracting: unlabeled2017/000000091634.jpg  \n",
      " extracting: unlabeled2017/000000478348.jpg  \n",
      " extracting: unlabeled2017/000000134360.jpg  \n",
      " extracting: unlabeled2017/000000072915.jpg  \n",
      " extracting: unlabeled2017/000000223986.jpg  \n",
      " extracting: unlabeled2017/000000205381.jpg  \n",
      " extracting: unlabeled2017/000000040316.jpg  \n",
      " extracting: unlabeled2017/000000257455.jpg  \n",
      " extracting: unlabeled2017/000000389612.jpg  \n",
      " extracting: unlabeled2017/000000470670.jpg  \n",
      " extracting: unlabeled2017/000000461374.jpg  \n",
      " extracting: unlabeled2017/000000145732.jpg  \n",
      " extracting: unlabeled2017/000000259836.jpg  \n",
      " extracting: unlabeled2017/000000071758.jpg  \n",
      " extracting: unlabeled2017/000000317427.jpg  \n",
      " extracting: unlabeled2017/000000132605.jpg  \n",
      " extracting: unlabeled2017/000000079744.jpg  \n",
      " extracting: unlabeled2017/000000236554.jpg  \n",
      " extracting: unlabeled2017/000000459901.jpg  \n",
      " extracting: unlabeled2017/000000315371.jpg  \n",
      " extracting: unlabeled2017/000000109395.jpg  \n",
      " extracting: unlabeled2017/000000425053.jpg  \n",
      " extracting: unlabeled2017/000000580755.jpg  \n",
      " extracting: unlabeled2017/000000335432.jpg  \n",
      " extracting: unlabeled2017/000000071775.jpg  \n",
      " extracting: unlabeled2017/000000292400.jpg  \n",
      " extracting: unlabeled2017/000000384205.jpg  \n",
      " extracting: unlabeled2017/000000225990.jpg  \n",
      " extracting: unlabeled2017/000000034781.jpg  \n",
      " extracting: unlabeled2017/000000014584.jpg  \n",
      " extracting: unlabeled2017/000000298531.jpg  \n",
      " extracting: unlabeled2017/000000477599.jpg  \n",
      " extracting: unlabeled2017/000000271869.jpg  \n",
      " extracting: unlabeled2017/000000285297.jpg  \n",
      " extracting: unlabeled2017/000000555721.jpg  \n",
      " extracting: unlabeled2017/000000082046.jpg  \n",
      " extracting: unlabeled2017/000000184603.jpg  \n",
      " extracting: unlabeled2017/000000362271.jpg  \n",
      " extracting: unlabeled2017/000000333017.jpg  \n",
      " extracting: unlabeled2017/000000127412.jpg  \n",
      " extracting: unlabeled2017/000000547015.jpg  \n",
      " extracting: unlabeled2017/000000475820.jpg  \n",
      " extracting: unlabeled2017/000000266795.jpg  \n",
      " extracting: unlabeled2017/000000494767.jpg  \n",
      " extracting: unlabeled2017/000000295224.jpg  \n",
      " extracting: unlabeled2017/000000174523.jpg  \n",
      " extracting: unlabeled2017/000000075354.jpg  \n",
      " extracting: unlabeled2017/000000530376.jpg  \n",
      " extracting: unlabeled2017/000000502977.jpg  \n",
      " extracting: unlabeled2017/000000199425.jpg  \n",
      " extracting: unlabeled2017/000000507577.jpg  \n",
      " extracting: unlabeled2017/000000256388.jpg  \n",
      " extracting: unlabeled2017/000000216076.jpg  \n",
      " extracting: unlabeled2017/000000391858.jpg  \n",
      " extracting: unlabeled2017/000000439005.jpg  \n",
      " extracting: unlabeled2017/000000048954.jpg  \n",
      " extracting: unlabeled2017/000000011906.jpg  \n",
      " extracting: unlabeled2017/000000328982.jpg  \n",
      " extracting: unlabeled2017/000000223976.jpg  \n",
      " extracting: unlabeled2017/000000135530.jpg  \n",
      " extracting: unlabeled2017/000000297430.jpg  \n",
      " extracting: unlabeled2017/000000320342.jpg  \n",
      " extracting: unlabeled2017/000000240446.jpg  \n",
      " extracting: unlabeled2017/000000238545.jpg  \n",
      " extracting: unlabeled2017/000000208009.jpg  \n",
      " extracting: unlabeled2017/000000133059.jpg  \n",
      " extracting: unlabeled2017/000000395277.jpg  \n",
      " extracting: unlabeled2017/000000447096.jpg  \n",
      " extracting: unlabeled2017/000000070970.jpg  \n",
      " extracting: unlabeled2017/000000559835.jpg  \n",
      " extracting: unlabeled2017/000000032721.jpg  \n",
      " extracting: unlabeled2017/000000468509.jpg  \n",
      " extracting: unlabeled2017/000000423030.jpg  \n",
      " extracting: unlabeled2017/000000469012.jpg  \n",
      " extracting: unlabeled2017/000000373624.jpg  \n",
      " extracting: unlabeled2017/000000097475.jpg  \n",
      " extracting: unlabeled2017/000000508856.jpg  \n",
      " extracting: unlabeled2017/000000549895.jpg  \n",
      " extracting: unlabeled2017/000000114550.jpg  \n",
      " extracting: unlabeled2017/000000042243.jpg  \n",
      " extracting: unlabeled2017/000000119482.jpg  \n",
      " extracting: unlabeled2017/000000007576.jpg  \n",
      " extracting: unlabeled2017/000000339443.jpg  \n",
      " extracting: unlabeled2017/000000226547.jpg  \n",
      " extracting: unlabeled2017/000000509140.jpg  \n",
      " extracting: unlabeled2017/000000039496.jpg  \n",
      " extracting: unlabeled2017/000000295621.jpg  \n",
      " extracting: unlabeled2017/000000078487.jpg  \n",
      " extracting: unlabeled2017/000000371121.jpg  \n",
      " extracting: unlabeled2017/000000194954.jpg  \n",
      " extracting: unlabeled2017/000000270884.jpg  \n",
      " extracting: unlabeled2017/000000355349.jpg  \n",
      " extracting: unlabeled2017/000000487480.jpg  \n",
      " extracting: unlabeled2017/000000238121.jpg  \n",
      " extracting: unlabeled2017/000000191333.jpg  \n",
      " extracting: unlabeled2017/000000074018.jpg  \n",
      " extracting: unlabeled2017/000000427968.jpg  \n",
      " extracting: unlabeled2017/000000389288.jpg  \n",
      " extracting: unlabeled2017/000000469891.jpg  \n",
      " extracting: unlabeled2017/000000010218.jpg  \n",
      " extracting: unlabeled2017/000000158076.jpg  \n",
      " extracting: unlabeled2017/000000470724.jpg  \n",
      " extracting: unlabeled2017/000000175882.jpg  \n",
      " extracting: unlabeled2017/000000178036.jpg  \n",
      " extracting: unlabeled2017/000000421365.jpg  \n",
      " extracting: unlabeled2017/000000245700.jpg  \n",
      " extracting: unlabeled2017/000000273595.jpg  \n",
      " extracting: unlabeled2017/000000295204.jpg  \n",
      " extracting: unlabeled2017/000000216622.jpg  \n",
      " extracting: unlabeled2017/000000570393.jpg  \n",
      " extracting: unlabeled2017/000000384311.jpg  \n",
      " extracting: unlabeled2017/000000421163.jpg  \n",
      " extracting: unlabeled2017/000000072209.jpg  \n",
      " extracting: unlabeled2017/000000342805.jpg  \n",
      " extracting: unlabeled2017/000000438977.jpg  \n",
      " extracting: unlabeled2017/000000231717.jpg  \n",
      " extracting: unlabeled2017/000000379956.jpg  \n",
      " extracting: unlabeled2017/000000234237.jpg  \n",
      " extracting: unlabeled2017/000000083418.jpg  \n",
      " extracting: unlabeled2017/000000138272.jpg  \n",
      " extracting: unlabeled2017/000000290012.jpg  \n",
      " extracting: unlabeled2017/000000558812.jpg  \n",
      " extracting: unlabeled2017/000000063165.jpg  \n",
      " extracting: unlabeled2017/000000059794.jpg  \n",
      " extracting: unlabeled2017/000000351200.jpg  \n",
      " extracting: unlabeled2017/000000436742.jpg  \n",
      " extracting: unlabeled2017/000000447338.jpg  \n",
      " extracting: unlabeled2017/000000113296.jpg  \n",
      " extracting: unlabeled2017/000000224225.jpg  \n",
      " extracting: unlabeled2017/000000339052.jpg  \n",
      " extracting: unlabeled2017/000000392437.jpg  \n",
      " extracting: unlabeled2017/000000061246.jpg  \n",
      " extracting: unlabeled2017/000000129687.jpg  \n",
      " extracting: unlabeled2017/000000360242.jpg  \n",
      " extracting: unlabeled2017/000000536687.jpg  \n",
      " extracting: unlabeled2017/000000325179.jpg  \n",
      " extracting: unlabeled2017/000000295513.jpg  \n",
      " extracting: unlabeled2017/000000088746.jpg  \n",
      " extracting: unlabeled2017/000000559918.jpg  \n",
      " extracting: unlabeled2017/000000211417.jpg  \n",
      " extracting: unlabeled2017/000000193372.jpg  \n",
      " extracting: unlabeled2017/000000333519.jpg  \n",
      " extracting: unlabeled2017/000000237322.jpg  \n",
      " extracting: unlabeled2017/000000115972.jpg  \n",
      " extracting: unlabeled2017/000000021873.jpg  \n",
      " extracting: unlabeled2017/000000211017.jpg  \n",
      " extracting: unlabeled2017/000000210227.jpg  \n",
      " extracting: unlabeled2017/000000164285.jpg  \n",
      " extracting: unlabeled2017/000000090066.jpg  \n",
      " extracting: unlabeled2017/000000522167.jpg  \n",
      " extracting: unlabeled2017/000000302096.jpg  \n",
      " extracting: unlabeled2017/000000572218.jpg  \n",
      " extracting: unlabeled2017/000000483734.jpg  \n",
      " extracting: unlabeled2017/000000283510.jpg  \n",
      " extracting: unlabeled2017/000000268089.jpg  \n",
      " extracting: unlabeled2017/000000159544.jpg  \n",
      " extracting: unlabeled2017/000000045972.jpg  \n",
      " extracting: unlabeled2017/000000467383.jpg  \n",
      " extracting: unlabeled2017/000000145848.jpg  \n",
      " extracting: unlabeled2017/000000098669.jpg  \n",
      " extracting: unlabeled2017/000000178027.jpg  \n",
      " extracting: unlabeled2017/000000220789.jpg  \n",
      " extracting: unlabeled2017/000000534254.jpg  \n",
      " extracting: unlabeled2017/000000577599.jpg  \n",
      " extracting: unlabeled2017/000000016441.jpg  \n",
      " extracting: unlabeled2017/000000149639.jpg  \n",
      " extracting: unlabeled2017/000000068268.jpg  \n",
      " extracting: unlabeled2017/000000181648.jpg  \n",
      " extracting: unlabeled2017/000000266525.jpg  \n",
      " extracting: unlabeled2017/000000403516.jpg  \n",
      " extracting: unlabeled2017/000000395924.jpg  \n",
      " extracting: unlabeled2017/000000197735.jpg  \n",
      " extracting: unlabeled2017/000000169661.jpg  \n",
      " extracting: unlabeled2017/000000200422.jpg  \n",
      " extracting: unlabeled2017/000000360171.jpg  \n",
      " extracting: unlabeled2017/000000230471.jpg  \n",
      " extracting: unlabeled2017/000000533853.jpg  \n",
      " extracting: unlabeled2017/000000401399.jpg  \n",
      " extracting: unlabeled2017/000000100828.jpg  \n",
      " extracting: unlabeled2017/000000331166.jpg  \n",
      " extracting: unlabeled2017/000000410353.jpg  \n",
      " extracting: unlabeled2017/000000576053.jpg  \n",
      " extracting: unlabeled2017/000000356312.jpg  \n",
      " extracting: unlabeled2017/000000170137.jpg  \n",
      " extracting: unlabeled2017/000000212588.jpg  \n",
      " extracting: unlabeled2017/000000139719.jpg  \n",
      " extracting: unlabeled2017/000000341045.jpg  \n",
      " extracting: unlabeled2017/000000283137.jpg  \n",
      " extracting: unlabeled2017/000000203638.jpg  \n",
      " extracting: unlabeled2017/000000283664.jpg  \n",
      " extracting: unlabeled2017/000000325168.jpg  \n",
      " extracting: unlabeled2017/000000444667.jpg  \n",
      " extracting: unlabeled2017/000000174054.jpg  \n",
      " extracting: unlabeled2017/000000337855.jpg  \n",
      " extracting: unlabeled2017/000000331494.jpg  \n",
      " extracting: unlabeled2017/000000184818.jpg  \n",
      " extracting: unlabeled2017/000000510660.jpg  \n",
      " extracting: unlabeled2017/000000102346.jpg  \n",
      " extracting: unlabeled2017/000000069010.jpg  \n",
      " extracting: unlabeled2017/000000564047.jpg  \n",
      " extracting: unlabeled2017/000000523168.jpg  \n",
      " extracting: unlabeled2017/000000221913.jpg  \n",
      " extracting: unlabeled2017/000000532738.jpg  \n",
      " extracting: unlabeled2017/000000061538.jpg  \n",
      " extracting: unlabeled2017/000000529790.jpg  \n",
      " extracting: unlabeled2017/000000267450.jpg  \n",
      " extracting: unlabeled2017/000000516773.jpg  \n",
      " extracting: unlabeled2017/000000320065.jpg  \n",
      " extracting: unlabeled2017/000000081641.jpg  \n",
      " extracting: unlabeled2017/000000411939.jpg  \n",
      " extracting: unlabeled2017/000000234404.jpg  \n",
      " extracting: unlabeled2017/000000325148.jpg  \n",
      " extracting: unlabeled2017/000000322000.jpg  \n",
      " extracting: unlabeled2017/000000472852.jpg  \n",
      " extracting: unlabeled2017/000000561443.jpg  \n",
      " extracting: unlabeled2017/000000463023.jpg  \n",
      " extracting: unlabeled2017/000000386646.jpg  \n",
      " extracting: unlabeled2017/000000442574.jpg  \n",
      " extracting: unlabeled2017/000000282582.jpg  \n",
      " extracting: unlabeled2017/000000566270.jpg  \n",
      " extracting: unlabeled2017/000000144753.jpg  \n",
      " extracting: unlabeled2017/000000457885.jpg  \n",
      " extracting: unlabeled2017/000000548676.jpg  \n",
      " extracting: unlabeled2017/000000536420.jpg  \n",
      " extracting: unlabeled2017/000000442408.jpg  \n",
      " extracting: unlabeled2017/000000397802.jpg  \n",
      " extracting: unlabeled2017/000000188144.jpg  \n",
      " extracting: unlabeled2017/000000015208.jpg  \n",
      " extracting: unlabeled2017/000000441042.jpg  \n",
      " extracting: unlabeled2017/000000465626.jpg  \n",
      " extracting: unlabeled2017/000000197823.jpg  \n",
      " extracting: unlabeled2017/000000095680.jpg  \n",
      " extracting: unlabeled2017/000000258116.jpg  \n",
      " extracting: unlabeled2017/000000372742.jpg  \n",
      " extracting: unlabeled2017/000000479147.jpg  \n",
      " extracting: unlabeled2017/000000006141.jpg  \n",
      " extracting: unlabeled2017/000000142900.jpg  \n",
      " extracting: unlabeled2017/000000171752.jpg  \n",
      " extracting: unlabeled2017/000000288183.jpg  \n",
      " extracting: unlabeled2017/000000178717.jpg  \n",
      " extracting: unlabeled2017/000000472110.jpg  \n",
      " extracting: unlabeled2017/000000236708.jpg  \n",
      " extracting: unlabeled2017/000000427971.jpg  \n",
      " extracting: unlabeled2017/000000191044.jpg  \n",
      " extracting: unlabeled2017/000000361589.jpg  \n",
      " extracting: unlabeled2017/000000242381.jpg  \n",
      " extracting: unlabeled2017/000000394027.jpg  \n",
      " extracting: unlabeled2017/000000530647.jpg  \n",
      " extracting: unlabeled2017/000000338378.jpg  \n",
      " extracting: unlabeled2017/000000334843.jpg  \n",
      " extracting: unlabeled2017/000000067625.jpg  \n",
      " extracting: unlabeled2017/000000288269.jpg  \n",
      " extracting: unlabeled2017/000000260527.jpg  \n",
      " extracting: unlabeled2017/000000114365.jpg  \n",
      " extracting: unlabeled2017/000000336698.jpg  \n",
      " extracting: unlabeled2017/000000381441.jpg  \n",
      " extracting: unlabeled2017/000000015688.jpg  \n",
      " extracting: unlabeled2017/000000539537.jpg  \n",
      " extracting: unlabeled2017/000000460096.jpg  \n",
      " extracting: unlabeled2017/000000488083.jpg  \n",
      " extracting: unlabeled2017/000000427960.jpg  \n",
      " extracting: unlabeled2017/000000365252.jpg  \n",
      " extracting: unlabeled2017/000000414656.jpg  \n",
      " extracting: unlabeled2017/000000149659.jpg  \n",
      " extracting: unlabeled2017/000000001936.jpg  \n",
      " extracting: unlabeled2017/000000368633.jpg  \n",
      " extracting: unlabeled2017/000000540533.jpg  \n",
      " extracting: unlabeled2017/000000218075.jpg  \n",
      " extracting: unlabeled2017/000000550988.jpg  \n",
      " extracting: unlabeled2017/000000386296.jpg  \n",
      " extracting: unlabeled2017/000000484550.jpg  \n",
      " extracting: unlabeled2017/000000073875.jpg  \n",
      " extracting: unlabeled2017/000000180633.jpg  \n",
      " extracting: unlabeled2017/000000001567.jpg  \n",
      " extracting: unlabeled2017/000000052535.jpg  \n",
      " extracting: unlabeled2017/000000340224.jpg  \n",
      " extracting: unlabeled2017/000000494964.jpg  \n",
      " extracting: unlabeled2017/000000217578.jpg  \n",
      " extracting: unlabeled2017/000000177624.jpg  \n",
      " extracting: unlabeled2017/000000564136.jpg  \n",
      " extracting: unlabeled2017/000000462826.jpg  \n",
      " extracting: unlabeled2017/000000161189.jpg  \n",
      " extracting: unlabeled2017/000000176937.jpg  \n",
      " extracting: unlabeled2017/000000452261.jpg  \n",
      " extracting: unlabeled2017/000000276174.jpg  \n",
      " extracting: unlabeled2017/000000049103.jpg  \n",
      " extracting: unlabeled2017/000000466814.jpg  \n",
      " extracting: unlabeled2017/000000240456.jpg  \n",
      " extracting: unlabeled2017/000000537533.jpg  \n",
      " extracting: unlabeled2017/000000106944.jpg  \n",
      " extracting: unlabeled2017/000000397795.jpg  \n",
      " extracting: unlabeled2017/000000032752.jpg  \n",
      " extracting: unlabeled2017/000000412948.jpg  \n",
      " extracting: unlabeled2017/000000498803.jpg  \n",
      " extracting: unlabeled2017/000000572244.jpg  \n",
      " extracting: unlabeled2017/000000525310.jpg  \n",
      " extracting: unlabeled2017/000000203037.jpg  \n",
      " extracting: unlabeled2017/000000402751.jpg  \n",
      " extracting: unlabeled2017/000000095525.jpg  \n",
      " extracting: unlabeled2017/000000151640.jpg  \n",
      " extracting: unlabeled2017/000000481797.jpg  \n",
      " extracting: unlabeled2017/000000174846.jpg  \n",
      " extracting: unlabeled2017/000000506794.jpg  \n",
      " extracting: unlabeled2017/000000180769.jpg  \n",
      " extracting: unlabeled2017/000000330777.jpg  \n",
      " extracting: unlabeled2017/000000371857.jpg  \n",
      " extracting: unlabeled2017/000000185288.jpg  \n",
      " extracting: unlabeled2017/000000560417.jpg  \n",
      " extracting: unlabeled2017/000000396352.jpg  \n",
      " extracting: unlabeled2017/000000170806.jpg  \n",
      " extracting: unlabeled2017/000000383352.jpg  \n",
      " extracting: unlabeled2017/000000467239.jpg  \n",
      " extracting: unlabeled2017/000000215165.jpg  \n",
      " extracting: unlabeled2017/000000344446.jpg  \n",
      " extracting: unlabeled2017/000000465189.jpg  \n",
      " extracting: unlabeled2017/000000107865.jpg  \n",
      " extracting: unlabeled2017/000000346442.jpg  \n",
      " extracting: unlabeled2017/000000217149.jpg  \n",
      " extracting: unlabeled2017/000000342038.jpg  \n",
      " extracting: unlabeled2017/000000296568.jpg  \n",
      " extracting: unlabeled2017/000000429927.jpg  \n",
      " extracting: unlabeled2017/000000562871.jpg  \n",
      " extracting: unlabeled2017/000000345017.jpg  \n",
      " extracting: unlabeled2017/000000394516.jpg  \n",
      " extracting: unlabeled2017/000000238834.jpg  \n",
      " extracting: unlabeled2017/000000188298.jpg  \n",
      " extracting: unlabeled2017/000000501391.jpg  \n",
      " extracting: unlabeled2017/000000485671.jpg  \n",
      " extracting: unlabeled2017/000000294805.jpg  \n",
      " extracting: unlabeled2017/000000001535.jpg  \n",
      " extracting: unlabeled2017/000000279520.jpg  \n",
      " extracting: unlabeled2017/000000254118.jpg  \n",
      " extracting: unlabeled2017/000000539860.jpg  \n",
      " extracting: unlabeled2017/000000291713.jpg  \n",
      " extracting: unlabeled2017/000000563579.jpg  \n",
      " extracting: unlabeled2017/000000183931.jpg  \n",
      " extracting: unlabeled2017/000000377040.jpg  \n",
      " extracting: unlabeled2017/000000049056.jpg  \n",
      " extracting: unlabeled2017/000000373173.jpg  \n",
      " extracting: unlabeled2017/000000059512.jpg  \n",
      " extracting: unlabeled2017/000000464221.jpg  \n",
      " extracting: unlabeled2017/000000113207.jpg  \n",
      " extracting: unlabeled2017/000000408544.jpg  \n",
      " extracting: unlabeled2017/000000328784.jpg  \n",
      " extracting: unlabeled2017/000000008751.jpg  \n",
      " extracting: unlabeled2017/000000265441.jpg  \n",
      " extracting: unlabeled2017/000000306345.jpg  \n",
      " extracting: unlabeled2017/000000487911.jpg  \n",
      " extracting: unlabeled2017/000000101520.jpg  \n",
      " extracting: unlabeled2017/000000280460.jpg  \n",
      " extracting: unlabeled2017/000000395117.jpg  \n",
      " extracting: unlabeled2017/000000320487.jpg  \n",
      " extracting: unlabeled2017/000000144437.jpg  \n",
      " extracting: unlabeled2017/000000268220.jpg  \n",
      " extracting: unlabeled2017/000000108178.jpg  \n",
      " extracting: unlabeled2017/000000374644.jpg  \n",
      " extracting: unlabeled2017/000000208454.jpg  \n",
      " extracting: unlabeled2017/000000151035.jpg  \n",
      " extracting: unlabeled2017/000000454381.jpg  \n",
      " extracting: unlabeled2017/000000334895.jpg  \n",
      " extracting: unlabeled2017/000000323080.jpg  \n",
      " extracting: unlabeled2017/000000020895.jpg  \n",
      " extracting: unlabeled2017/000000555331.jpg  \n",
      " extracting: unlabeled2017/000000442024.jpg  \n",
      " extracting: unlabeled2017/000000382606.jpg  \n",
      " extracting: unlabeled2017/000000557419.jpg  \n",
      " extracting: unlabeled2017/000000114772.jpg  \n",
      " extracting: unlabeled2017/000000577095.jpg  \n",
      " extracting: unlabeled2017/000000082614.jpg  \n",
      " extracting: unlabeled2017/000000399007.jpg  \n",
      " extracting: unlabeled2017/000000155178.jpg  \n",
      " extracting: unlabeled2017/000000475213.jpg  \n",
      " extracting: unlabeled2017/000000017107.jpg  \n",
      " extracting: unlabeled2017/000000309199.jpg  \n",
      " extracting: unlabeled2017/000000023225.jpg  \n",
      " extracting: unlabeled2017/000000572758.jpg  \n",
      " extracting: unlabeled2017/000000140895.jpg  \n",
      " extracting: unlabeled2017/000000553332.jpg  \n",
      " extracting: unlabeled2017/000000379110.jpg  \n",
      " extracting: unlabeled2017/000000146581.jpg  \n",
      " extracting: unlabeled2017/000000180977.jpg  \n",
      " extracting: unlabeled2017/000000223024.jpg  \n",
      " extracting: unlabeled2017/000000472877.jpg  \n",
      " extracting: unlabeled2017/000000366854.jpg  \n",
      " extracting: unlabeled2017/000000116940.jpg  \n",
      " extracting: unlabeled2017/000000365113.jpg  \n",
      " extracting: unlabeled2017/000000483592.jpg  \n",
      " extracting: unlabeled2017/000000112962.jpg  \n",
      " extracting: unlabeled2017/000000281016.jpg  \n",
      " extracting: unlabeled2017/000000114432.jpg  \n",
      " extracting: unlabeled2017/000000468179.jpg  \n",
      " extracting: unlabeled2017/000000115797.jpg  \n",
      " extracting: unlabeled2017/000000224430.jpg  \n",
      " extracting: unlabeled2017/000000242128.jpg  \n",
      " extracting: unlabeled2017/000000423766.jpg  \n",
      " extracting: unlabeled2017/000000069367.jpg  \n",
      " extracting: unlabeled2017/000000565168.jpg  \n",
      " extracting: unlabeled2017/000000422533.jpg  \n",
      " extracting: unlabeled2017/000000042792.jpg  \n",
      " extracting: unlabeled2017/000000457803.jpg  \n",
      " extracting: unlabeled2017/000000059865.jpg  \n",
      " extracting: unlabeled2017/000000064487.jpg  \n",
      " extracting: unlabeled2017/000000285116.jpg  \n",
      " extracting: unlabeled2017/000000377533.jpg  \n",
      " extracting: unlabeled2017/000000358093.jpg  \n",
      " extracting: unlabeled2017/000000384767.jpg  \n",
      " extracting: unlabeled2017/000000189972.jpg  \n",
      " extracting: unlabeled2017/000000455504.jpg  \n",
      " extracting: unlabeled2017/000000205483.jpg  \n",
      " extracting: unlabeled2017/000000065505.jpg  \n",
      " extracting: unlabeled2017/000000241655.jpg  \n",
      " extracting: unlabeled2017/000000408004.jpg  \n",
      " extracting: unlabeled2017/000000028749.jpg  \n",
      " extracting: unlabeled2017/000000466594.jpg  \n",
      " extracting: unlabeled2017/000000296272.jpg  \n",
      " extracting: unlabeled2017/000000249654.jpg  \n",
      " extracting: unlabeled2017/000000077656.jpg  \n",
      " extracting: unlabeled2017/000000444050.jpg  \n",
      " extracting: unlabeled2017/000000281360.jpg  \n",
      " extracting: unlabeled2017/000000301620.jpg  \n",
      " extracting: unlabeled2017/000000461745.jpg  \n",
      " extracting: unlabeled2017/000000284802.jpg  \n",
      " extracting: unlabeled2017/000000241253.jpg  \n",
      " extracting: unlabeled2017/000000579861.jpg  \n",
      " extracting: unlabeled2017/000000462703.jpg  \n",
      " extracting: unlabeled2017/000000556747.jpg  \n",
      " extracting: unlabeled2017/000000283337.jpg  \n",
      " extracting: unlabeled2017/000000252509.jpg  \n",
      " extracting: unlabeled2017/000000154993.jpg  \n",
      " extracting: unlabeled2017/000000138918.jpg  \n",
      " extracting: unlabeled2017/000000021098.jpg  \n",
      " extracting: unlabeled2017/000000520609.jpg  \n",
      " extracting: unlabeled2017/000000495792.jpg  \n",
      " extracting: unlabeled2017/000000306709.jpg  \n",
      " extracting: unlabeled2017/000000199083.jpg  \n",
      " extracting: unlabeled2017/000000492249.jpg  \n",
      " extracting: unlabeled2017/000000103176.jpg  \n",
      " extracting: unlabeled2017/000000006821.jpg  \n",
      " extracting: unlabeled2017/000000071180.jpg  \n",
      " extracting: unlabeled2017/000000291545.jpg  \n",
      " extracting: unlabeled2017/000000347872.jpg  \n",
      " extracting: unlabeled2017/000000505406.jpg  \n",
      " extracting: unlabeled2017/000000574878.jpg  \n",
      " extracting: unlabeled2017/000000529575.jpg  \n",
      " extracting: unlabeled2017/000000176827.jpg  \n",
      " extracting: unlabeled2017/000000040022.jpg  \n",
      " extracting: unlabeled2017/000000354757.jpg  \n",
      " extracting: unlabeled2017/000000305542.jpg  \n",
      " extracting: unlabeled2017/000000443152.jpg  \n",
      " extracting: unlabeled2017/000000375343.jpg  \n",
      " extracting: unlabeled2017/000000246882.jpg  \n",
      " extracting: unlabeled2017/000000371607.jpg  \n",
      " extracting: unlabeled2017/000000211856.jpg  \n",
      " extracting: unlabeled2017/000000101712.jpg  \n",
      " extracting: unlabeled2017/000000527605.jpg  \n",
      " extracting: unlabeled2017/000000465710.jpg  \n",
      " extracting: unlabeled2017/000000209410.jpg  \n",
      " extracting: unlabeled2017/000000309226.jpg  \n",
      " extracting: unlabeled2017/000000114444.jpg  \n",
      " extracting: unlabeled2017/000000546860.jpg  \n",
      " extracting: unlabeled2017/000000448508.jpg  \n",
      " extracting: unlabeled2017/000000574721.jpg  \n",
      " extracting: unlabeled2017/000000056694.jpg  \n",
      " extracting: unlabeled2017/000000298236.jpg  \n",
      " extracting: unlabeled2017/000000571855.jpg  \n",
      " extracting: unlabeled2017/000000420967.jpg  \n",
      " extracting: unlabeled2017/000000546439.jpg  \n",
      " extracting: unlabeled2017/000000153255.jpg  \n",
      " extracting: unlabeled2017/000000079745.jpg  \n",
      " extracting: unlabeled2017/000000456058.jpg  \n",
      " extracting: unlabeled2017/000000335313.jpg  \n",
      " extracting: unlabeled2017/000000340444.jpg  \n",
      " extracting: unlabeled2017/000000200190.jpg  \n",
      " extracting: unlabeled2017/000000144806.jpg  \n",
      " extracting: unlabeled2017/000000381776.jpg  \n",
      " extracting: unlabeled2017/000000304190.jpg  \n",
      " extracting: unlabeled2017/000000389747.jpg  \n",
      " extracting: unlabeled2017/000000418642.jpg  \n",
      " extracting: unlabeled2017/000000155963.jpg  \n",
      " extracting: unlabeled2017/000000053878.jpg  \n",
      " extracting: unlabeled2017/000000575715.jpg  \n",
      " extracting: unlabeled2017/000000526531.jpg  \n",
      " extracting: unlabeled2017/000000212913.jpg  \n",
      " extracting: unlabeled2017/000000195347.jpg  \n",
      " extracting: unlabeled2017/000000069353.jpg  \n",
      " extracting: unlabeled2017/000000346510.jpg  \n",
      " extracting: unlabeled2017/000000005760.jpg  \n",
      " extracting: unlabeled2017/000000279727.jpg  \n",
      " extracting: unlabeled2017/000000104889.jpg  \n",
      " extracting: unlabeled2017/000000183417.jpg  \n",
      " extracting: unlabeled2017/000000294959.jpg  \n",
      " extracting: unlabeled2017/000000030636.jpg  \n",
      " extracting: unlabeled2017/000000109554.jpg  \n",
      " extracting: unlabeled2017/000000144397.jpg  \n",
      " extracting: unlabeled2017/000000176678.jpg  \n",
      " extracting: unlabeled2017/000000386336.jpg  \n",
      " extracting: unlabeled2017/000000102606.jpg  \n",
      " extracting: unlabeled2017/000000381737.jpg  \n",
      " extracting: unlabeled2017/000000496560.jpg  \n",
      " extracting: unlabeled2017/000000352026.jpg  \n",
      " extracting: unlabeled2017/000000146571.jpg  \n",
      " extracting: unlabeled2017/000000143905.jpg  \n",
      " extracting: unlabeled2017/000000433040.jpg  \n",
      " extracting: unlabeled2017/000000263341.jpg  \n",
      " extracting: unlabeled2017/000000164456.jpg  \n",
      " extracting: unlabeled2017/000000352439.jpg  \n",
      " extracting: unlabeled2017/000000516202.jpg  \n",
      " extracting: unlabeled2017/000000198912.jpg  \n",
      " extracting: unlabeled2017/000000074833.jpg  \n",
      " extracting: unlabeled2017/000000199435.jpg  \n",
      " extracting: unlabeled2017/000000239614.jpg  \n",
      " extracting: unlabeled2017/000000305155.jpg  \n",
      " extracting: unlabeled2017/000000142315.jpg  \n",
      " extracting: unlabeled2017/000000465658.jpg  \n",
      " extracting: unlabeled2017/000000059976.jpg  \n",
      " extracting: unlabeled2017/000000258211.jpg  \n",
      " extracting: unlabeled2017/000000488782.jpg  \n",
      " extracting: unlabeled2017/000000501948.jpg  \n",
      " extracting: unlabeled2017/000000307338.jpg  \n",
      " extracting: unlabeled2017/000000130777.jpg  \n",
      " extracting: unlabeled2017/000000116716.jpg  \n",
      " extracting: unlabeled2017/000000511618.jpg  \n",
      " extracting: unlabeled2017/000000536824.jpg  \n",
      " extracting: unlabeled2017/000000509317.jpg  \n",
      " extracting: unlabeled2017/000000217582.jpg  \n",
      " extracting: unlabeled2017/000000549479.jpg  \n",
      " extracting: unlabeled2017/000000010443.jpg  \n",
      " extracting: unlabeled2017/000000125530.jpg  \n",
      " extracting: unlabeled2017/000000055943.jpg  \n",
      " extracting: unlabeled2017/000000508847.jpg  \n",
      " extracting: unlabeled2017/000000338845.jpg  \n",
      " extracting: unlabeled2017/000000300338.jpg  \n",
      " extracting: unlabeled2017/000000377847.jpg  \n",
      " extracting: unlabeled2017/000000379900.jpg  \n",
      " extracting: unlabeled2017/000000456951.jpg  \n",
      " extracting: unlabeled2017/000000083128.jpg  \n",
      " extracting: unlabeled2017/000000041386.jpg  \n",
      " extracting: unlabeled2017/000000254751.jpg  \n",
      " extracting: unlabeled2017/000000405805.jpg  \n",
      " extracting: unlabeled2017/000000477327.jpg  \n",
      " extracting: unlabeled2017/000000001125.jpg  \n",
      " extracting: unlabeled2017/000000072131.jpg  \n",
      " extracting: unlabeled2017/000000414116.jpg  \n",
      " extracting: unlabeled2017/000000450838.jpg  \n",
      " extracting: unlabeled2017/000000204118.jpg  \n",
      " extracting: unlabeled2017/000000571268.jpg  \n",
      " extracting: unlabeled2017/000000400927.jpg  \n",
      " extracting: unlabeled2017/000000094869.jpg  \n",
      " extracting: unlabeled2017/000000422361.jpg  \n",
      " extracting: unlabeled2017/000000418979.jpg  \n",
      " extracting: unlabeled2017/000000260254.jpg  \n",
      " extracting: unlabeled2017/000000512214.jpg  \n",
      " extracting: unlabeled2017/000000332959.jpg  \n",
      " extracting: unlabeled2017/000000397222.jpg  \n",
      " extracting: unlabeled2017/000000347499.jpg  \n",
      " extracting: unlabeled2017/000000330635.jpg  \n",
      " extracting: unlabeled2017/000000572954.jpg  \n",
      " extracting: unlabeled2017/000000579293.jpg  \n",
      " extracting: unlabeled2017/000000562867.jpg  \n",
      " extracting: unlabeled2017/000000221568.jpg  \n",
      " extracting: unlabeled2017/000000055292.jpg  \n",
      " extracting: unlabeled2017/000000357022.jpg  \n",
      " extracting: unlabeled2017/000000511893.jpg  \n",
      " extracting: unlabeled2017/000000058602.jpg  \n",
      " extracting: unlabeled2017/000000314736.jpg  \n",
      " extracting: unlabeled2017/000000448624.jpg  \n",
      " extracting: unlabeled2017/000000207113.jpg  \n",
      " extracting: unlabeled2017/000000292939.jpg  \n",
      " extracting: unlabeled2017/000000270770.jpg  \n",
      " extracting: unlabeled2017/000000488621.jpg  \n",
      " extracting: unlabeled2017/000000207919.jpg  \n",
      " extracting: unlabeled2017/000000504446.jpg  \n",
      " extracting: unlabeled2017/000000453970.jpg  \n",
      " extracting: unlabeled2017/000000405734.jpg  \n",
      " extracting: unlabeled2017/000000509200.jpg  \n",
      " extracting: unlabeled2017/000000402018.jpg  \n",
      " extracting: unlabeled2017/000000111814.jpg  \n",
      " extracting: unlabeled2017/000000457304.jpg  \n",
      " extracting: unlabeled2017/000000034913.jpg  \n",
      " extracting: unlabeled2017/000000382962.jpg  \n",
      " extracting: unlabeled2017/000000375393.jpg  \n",
      " extracting: unlabeled2017/000000073473.jpg  \n",
      " extracting: unlabeled2017/000000153664.jpg  \n",
      " extracting: unlabeled2017/000000155522.jpg  \n",
      " extracting: unlabeled2017/000000340395.jpg  \n",
      " extracting: unlabeled2017/000000416155.jpg  \n",
      " extracting: unlabeled2017/000000164757.jpg  \n",
      " extracting: unlabeled2017/000000322026.jpg  \n",
      " extracting: unlabeled2017/000000190042.jpg  \n",
      " extracting: unlabeled2017/000000347086.jpg  \n",
      " extracting: unlabeled2017/000000339832.jpg  \n",
      " extracting: unlabeled2017/000000017163.jpg  \n",
      " extracting: unlabeled2017/000000481787.jpg  \n",
      " extracting: unlabeled2017/000000190809.jpg  \n",
      " extracting: unlabeled2017/000000424178.jpg  \n",
      " extracting: unlabeled2017/000000060227.jpg  \n",
      " extracting: unlabeled2017/000000498235.jpg  \n",
      " extracting: unlabeled2017/000000561109.jpg  \n",
      " extracting: unlabeled2017/000000248679.jpg  \n",
      " extracting: unlabeled2017/000000108261.jpg  \n",
      " extracting: unlabeled2017/000000527777.jpg  \n",
      " extracting: unlabeled2017/000000418872.jpg  \n",
      " extracting: unlabeled2017/000000486663.jpg  \n",
      " extracting: unlabeled2017/000000044481.jpg  \n",
      " extracting: unlabeled2017/000000443809.jpg  \n",
      " extracting: unlabeled2017/000000110598.jpg  \n",
      " extracting: unlabeled2017/000000071665.jpg  \n",
      " extracting: unlabeled2017/000000566846.jpg  \n",
      " extracting: unlabeled2017/000000220938.jpg  \n",
      " extracting: unlabeled2017/000000050505.jpg  \n",
      " extracting: unlabeled2017/000000158741.jpg  \n",
      " extracting: unlabeled2017/000000054298.jpg  \n",
      " extracting: unlabeled2017/000000229297.jpg  \n",
      " extracting: unlabeled2017/000000525109.jpg  \n",
      " extracting: unlabeled2017/000000526661.jpg  \n",
      " extracting: unlabeled2017/000000006717.jpg  \n",
      " extracting: unlabeled2017/000000189145.jpg  \n",
      " extracting: unlabeled2017/000000330912.jpg  \n",
      " extracting: unlabeled2017/000000202793.jpg  \n",
      " extracting: unlabeled2017/000000017258.jpg  \n",
      " extracting: unlabeled2017/000000239345.jpg  \n",
      " extracting: unlabeled2017/000000390092.jpg  \n",
      " extracting: unlabeled2017/000000086096.jpg  \n",
      " extracting: unlabeled2017/000000126213.jpg  \n",
      " extracting: unlabeled2017/000000560568.jpg  \n",
      " extracting: unlabeled2017/000000382488.jpg  \n",
      " extracting: unlabeled2017/000000483244.jpg  \n",
      " extracting: unlabeled2017/000000439277.jpg  \n",
      " extracting: unlabeled2017/000000004151.jpg  \n",
      " extracting: unlabeled2017/000000286659.jpg  \n",
      " extracting: unlabeled2017/000000153493.jpg  \n",
      " extracting: unlabeled2017/000000408367.jpg  \n",
      " extracting: unlabeled2017/000000415495.jpg  \n",
      " extracting: unlabeled2017/000000559089.jpg  \n",
      " extracting: unlabeled2017/000000455253.jpg  \n",
      " extracting: unlabeled2017/000000579375.jpg  \n",
      " extracting: unlabeled2017/000000239039.jpg  \n",
      " extracting: unlabeled2017/000000131217.jpg  \n",
      " extracting: unlabeled2017/000000318085.jpg  \n",
      " extracting: unlabeled2017/000000547260.jpg  \n",
      " extracting: unlabeled2017/000000396061.jpg  \n",
      " extracting: unlabeled2017/000000416773.jpg  \n",
      " extracting: unlabeled2017/000000141658.jpg  \n",
      " extracting: unlabeled2017/000000328340.jpg  \n",
      " extracting: unlabeled2017/000000335732.jpg  \n",
      " extracting: unlabeled2017/000000066227.jpg  \n",
      " extracting: unlabeled2017/000000251239.jpg  \n",
      " extracting: unlabeled2017/000000142544.jpg  \n",
      " extracting: unlabeled2017/000000310923.jpg  \n",
      " extracting: unlabeled2017/000000115526.jpg  \n",
      " extracting: unlabeled2017/000000579837.jpg  \n",
      " extracting: unlabeled2017/000000464726.jpg  \n",
      " extracting: unlabeled2017/000000530740.jpg  \n",
      " extracting: unlabeled2017/000000485558.jpg  \n",
      " extracting: unlabeled2017/000000460233.jpg  \n",
      " extracting: unlabeled2017/000000012110.jpg  \n",
      " extracting: unlabeled2017/000000261258.jpg  \n",
      " extracting: unlabeled2017/000000310722.jpg  \n",
      " extracting: unlabeled2017/000000134723.jpg  \n",
      " extracting: unlabeled2017/000000493913.jpg  \n",
      " extracting: unlabeled2017/000000146990.jpg  \n",
      " extracting: unlabeled2017/000000056653.jpg  \n",
      " extracting: unlabeled2017/000000542455.jpg  \n",
      " extracting: unlabeled2017/000000437940.jpg  \n",
      " extracting: unlabeled2017/000000215905.jpg  \n",
      " extracting: unlabeled2017/000000535182.jpg  \n",
      " extracting: unlabeled2017/000000028272.jpg  \n",
      " extracting: unlabeled2017/000000484733.jpg  \n",
      " extracting: unlabeled2017/000000046626.jpg  \n",
      " extracting: unlabeled2017/000000542535.jpg  \n",
      " extracting: unlabeled2017/000000481882.jpg  \n",
      " extracting: unlabeled2017/000000512209.jpg  \n",
      " extracting: unlabeled2017/000000314062.jpg  \n",
      " extracting: unlabeled2017/000000573663.jpg  \n",
      " extracting: unlabeled2017/000000182081.jpg  \n",
      " extracting: unlabeled2017/000000395984.jpg  \n",
      " extracting: unlabeled2017/000000074451.jpg  \n",
      " extracting: unlabeled2017/000000259503.jpg  \n",
      " extracting: unlabeled2017/000000032780.jpg  \n",
      " extracting: unlabeled2017/000000143772.jpg  \n",
      " extracting: unlabeled2017/000000071299.jpg  \n",
      " extracting: unlabeled2017/000000293062.jpg  \n",
      " extracting: unlabeled2017/000000389854.jpg  \n",
      " extracting: unlabeled2017/000000234939.jpg  \n",
      " extracting: unlabeled2017/000000217347.jpg  \n",
      " extracting: unlabeled2017/000000017315.jpg  \n",
      " extracting: unlabeled2017/000000285413.jpg  \n",
      " extracting: unlabeled2017/000000183220.jpg  \n",
      " extracting: unlabeled2017/000000049077.jpg  \n",
      " extracting: unlabeled2017/000000172832.jpg  \n",
      " extracting: unlabeled2017/000000337840.jpg  \n",
      " extracting: unlabeled2017/000000095447.jpg  \n",
      " extracting: unlabeled2017/000000367453.jpg  \n",
      " extracting: unlabeled2017/000000427433.jpg  \n",
      " extracting: unlabeled2017/000000289946.jpg  \n",
      " extracting: unlabeled2017/000000206063.jpg  \n",
      " extracting: unlabeled2017/000000441922.jpg  \n",
      " extracting: unlabeled2017/000000411249.jpg  \n",
      " extracting: unlabeled2017/000000014725.jpg  \n",
      " extracting: unlabeled2017/000000247289.jpg  \n",
      " extracting: unlabeled2017/000000177973.jpg  \n",
      " extracting: unlabeled2017/000000404011.jpg  \n",
      " extracting: unlabeled2017/000000145613.jpg  \n",
      " extracting: unlabeled2017/000000302507.jpg  \n",
      " extracting: unlabeled2017/000000096872.jpg  \n",
      " extracting: unlabeled2017/000000120616.jpg  \n",
      " extracting: unlabeled2017/000000094891.jpg  \n",
      " extracting: unlabeled2017/000000229634.jpg  \n",
      " extracting: unlabeled2017/000000298264.jpg  \n",
      " extracting: unlabeled2017/000000077293.jpg  \n",
      " extracting: unlabeled2017/000000555604.jpg  \n",
      " extracting: unlabeled2017/000000157228.jpg  \n",
      " extracting: unlabeled2017/000000195793.jpg  \n",
      " extracting: unlabeled2017/000000000733.jpg  \n",
      " extracting: unlabeled2017/000000251823.jpg  \n",
      " extracting: unlabeled2017/000000003683.jpg  \n",
      " extracting: unlabeled2017/000000092995.jpg  \n",
      " extracting: unlabeled2017/000000500481.jpg  \n",
      " extracting: unlabeled2017/000000165125.jpg  \n",
      "/content/coco\n",
      "--2022-04-04 04:50:20--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 54.231.138.145\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|54.231.138.145|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 252907541 (241M) [application/zip]\n",
      "Saving to: ‘annotations_trainval2017.zip’\n",
      "\n",
      "annotations_trainva 100%[===================>] 241.19M  96.3MB/s    in 2.5s    \n",
      "\n",
      "2022-04-04 04:50:22 (96.3 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\n",
      "\n",
      "--2022-04-04 04:50:23--  http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.135.121\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.135.121|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1148688564 (1.1G) [application/zip]\n",
      "Saving to: ‘stuff_annotations_trainval2017.zip’\n",
      "\n",
      "stuff_annotations_t 100%[===================>]   1.07G  76.6MB/s    in 14s     \n",
      "\n",
      "2022-04-04 04:50:38 (76.0 MB/s) - ‘stuff_annotations_trainval2017.zip’ saved [1148688564/1148688564]\n",
      "\n",
      "--2022-04-04 04:50:38--  http://images.cocodataset.org/annotations/image_info_test2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.93.164\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.93.164|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1144034 (1.1M) [application/zip]\n",
      "Saving to: ‘image_info_test2017.zip’\n",
      "\n",
      "image_info_test2017 100%[===================>]   1.09M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2022-04-04 04:50:38 (9.21 MB/s) - ‘image_info_test2017.zip’ saved [1144034/1144034]\n",
      "\n",
      "--2022-04-04 04:50:38--  http://images.cocodataset.org/annotations/image_info_unlabeled2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.93.164\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.93.164|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4902013 (4.7M) [application/zip]\n",
      "Saving to: ‘image_info_unlabeled2017.zip’\n",
      "\n",
      "image_info_unlabele 100%[===================>]   4.67M  28.8MB/s    in 0.2s    \n",
      "\n",
      "2022-04-04 04:50:38 (28.8 MB/s) - ‘image_info_unlabeled2017.zip’ saved [4902013/4902013]\n",
      "\n",
      "Archive:  annotations_trainval2017.zip\n",
      "  inflating: annotations/instances_train2017.json  \n",
      "  inflating: annotations/instances_val2017.json  \n",
      "  inflating: annotations/captions_train2017.json  \n",
      "  inflating: annotations/captions_val2017.json  \n",
      "  inflating: annotations/person_keypoints_train2017.json  \n",
      "  inflating: annotations/person_keypoints_val2017.json  \n",
      "Archive:  stuff_annotations_trainval2017.zip\n",
      " extracting: annotations/stuff_train2017_pixelmaps.zip  \n",
      " extracting: annotations/stuff_val2017_pixelmaps.zip  \n",
      "  inflating: annotations/stuff_val2017.json  \n",
      "  inflating: annotations/stuff_train2017.json  \n",
      "   creating: annotations/deprecated-challenge2017/\n",
      "  inflating: annotations/deprecated-challenge2017/val-ids.txt  \n",
      "  inflating: annotations/deprecated-challenge2017/train-ids.txt  \n",
      "Archive:  image_info_test2017.zip\n",
      "  inflating: annotations/image_info_test-dev2017.json  \n",
      "  inflating: annotations/image_info_test2017.json  \n",
      "Archive:  image_info_unlabeled2017.zip\n",
      "  inflating: annotations/image_info_unlabeled2017.json  \n"
     ]
    }
   ],
   "source": [
    "%cd /content/\n",
    "!mkdir coco\n",
    "%cd coco\n",
    "!mkdir images\n",
    "%cd images\n",
    "\n",
    "!wget http://images.cocodataset.org/zips/train2017.zip\n",
    "!wget http://images.cocodataset.org/zips/val2017.zip\n",
    "!wget http://images.cocodataset.org/zips/test2017.zip\n",
    "!wget http://images.cocodataset.org/zips/unlabeled2017.zip\n",
    "\n",
    "!unzip train2017.zip\n",
    "!unzip val2017.zip\n",
    "!unzip test2017.zip\n",
    "!unzip unlabeled2017.zip\n",
    "\n",
    "!rm train2017.zip\n",
    "!rm val2017.zip\n",
    "!rm test2017.zip\n",
    "!rm unlabeled2017.zip \n",
    "\n",
    "%cd ../\n",
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!wget http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip\n",
    "!wget http://images.cocodataset.org/annotations/image_info_test2017.zip\n",
    "!wget http://images.cocodataset.org/annotations/image_info_unlabeled2017.zip\n",
    "\n",
    "!unzip annotations_trainval2017.zip\n",
    "!unzip stuff_annotations_trainval2017.zip\n",
    "!unzip image_info_test2017.zip\n",
    "!unzip image_info_unlabeled2017.zip\n",
    "\n",
    "!rm annotations_trainval2017.zip\n",
    "!rm stuff_annotations_trainval2017.zip\n",
    "!rm image_info_test2017.zip\n",
    "!rm image_info_unlabeled2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfEqyEkgJbq2",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "_-WIuh-cF9_W",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "cbea4d81-86a1-477c-f385-dd21e1db195c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mKết quả truyền trực tuyến bị cắt bớt đến 5000 dòng cuối.\u001b[0m\n",
      "Epoch: 0 | Iteration: 34971 | Classification loss: 0.33837 | Regression loss: 0.49739 | Running loss: 0.86880\n",
      "Epoch: 0 | Iteration: 34972 | Classification loss: 0.26318 | Regression loss: 0.35821 | Running loss: 0.86765\n",
      "Epoch: 0 | Iteration: 34973 | Classification loss: 0.28685 | Regression loss: 0.51659 | Running loss: 0.86707\n",
      "Epoch: 0 | Iteration: 34974 | Classification loss: 0.36548 | Regression loss: 0.57132 | Running loss: 0.86758\n",
      "Epoch: 0 | Iteration: 34975 | Classification loss: 0.28811 | Regression loss: 0.34733 | Running loss: 0.86754\n",
      "Epoch: 0 | Iteration: 34976 | Classification loss: 0.36807 | Regression loss: 0.55614 | Running loss: 0.86764\n",
      "Epoch: 0 | Iteration: 34977 | Classification loss: 0.51864 | Regression loss: 0.72973 | Running loss: 0.86862\n",
      "Epoch: 0 | Iteration: 34978 | Classification loss: 0.23994 | Regression loss: 0.39579 | Running loss: 0.86775\n",
      "Epoch: 0 | Iteration: 34979 | Classification loss: 0.45046 | Regression loss: 0.61415 | Running loss: 0.86902\n",
      "Epoch: 0 | Iteration: 34980 | Classification loss: 0.45463 | Regression loss: 0.52563 | Running loss: 0.86907\n",
      "Epoch: 0 | Iteration: 34981 | Classification loss: 2.17253 | Regression loss: 0.32269 | Running loss: 0.87270\n",
      "Epoch: 0 | Iteration: 34982 | Classification loss: 0.40385 | Regression loss: 0.52103 | Running loss: 0.87243\n",
      "Epoch: 0 | Iteration: 34983 | Classification loss: 0.56697 | Regression loss: 0.53895 | Running loss: 0.87252\n",
      "Epoch: 0 | Iteration: 34984 | Classification loss: 0.39527 | Regression loss: 0.51529 | Running loss: 0.87369\n",
      "Epoch: 0 | Iteration: 34985 | Classification loss: 0.41366 | Regression loss: 0.63286 | Running loss: 0.87430\n",
      "Epoch: 0 | Iteration: 34986 | Classification loss: 0.28016 | Regression loss: 0.33719 | Running loss: 0.87360\n",
      "Epoch: 0 | Iteration: 34987 | Classification loss: 0.40900 | Regression loss: 0.51163 | Running loss: 0.87419\n",
      "Epoch: 0 | Iteration: 34988 | Classification loss: 0.42830 | Regression loss: 0.56706 | Running loss: 0.87383\n",
      "Epoch: 0 | Iteration: 34989 | Classification loss: 0.32253 | Regression loss: 0.29173 | Running loss: 0.87287\n",
      "Epoch: 0 | Iteration: 34990 | Classification loss: 0.37467 | Regression loss: 0.42893 | Running loss: 0.87270\n",
      "Epoch: 0 | Iteration: 34991 | Classification loss: 0.32930 | Regression loss: 0.52735 | Running loss: 0.87339\n",
      "Epoch: 0 | Iteration: 34992 | Classification loss: 0.47576 | Regression loss: 0.57992 | Running loss: 0.87382\n",
      "Epoch: 0 | Iteration: 34993 | Classification loss: 0.53038 | Regression loss: 0.54004 | Running loss: 0.87410\n",
      "Epoch: 0 | Iteration: 34994 | Classification loss: 0.46169 | Regression loss: 0.67832 | Running loss: 0.87445\n",
      "Epoch: 0 | Iteration: 34995 | Classification loss: 0.35917 | Regression loss: 0.49731 | Running loss: 0.87486\n",
      "Epoch: 0 | Iteration: 34996 | Classification loss: 0.70574 | Regression loss: 0.45432 | Running loss: 0.87643\n",
      "Epoch: 0 | Iteration: 34997 | Classification loss: 0.60118 | Regression loss: 0.59170 | Running loss: 0.87731\n",
      "Epoch: 0 | Iteration: 34998 | Classification loss: 0.29074 | Regression loss: 0.31758 | Running loss: 0.87589\n",
      "Epoch: 0 | Iteration: 34999 | Classification loss: 0.45319 | Regression loss: 0.50141 | Running loss: 0.87577\n",
      "Epoch: 0 | Iteration: 35000 | Classification loss: 0.23561 | Regression loss: 0.39484 | Running loss: 0.87529\n",
      "Epoch: 0 | Iteration: 35001 | Classification loss: 0.16948 | Regression loss: 0.28548 | Running loss: 0.87409\n",
      "Epoch: 0 | Iteration: 35002 | Classification loss: 0.53761 | Regression loss: 0.49637 | Running loss: 0.87439\n",
      "Epoch: 0 | Iteration: 35003 | Classification loss: 0.36067 | Regression loss: 0.43053 | Running loss: 0.87441\n",
      "Epoch: 0 | Iteration: 35004 | Classification loss: 0.20294 | Regression loss: 0.23064 | Running loss: 0.87367\n",
      "Epoch: 0 | Iteration: 35005 | Classification loss: 0.47211 | Regression loss: 0.55142 | Running loss: 0.87396\n",
      "Epoch: 0 | Iteration: 35006 | Classification loss: 0.45331 | Regression loss: 0.32883 | Running loss: 0.87353\n",
      "Epoch: 0 | Iteration: 35007 | Classification loss: 0.23655 | Regression loss: 0.39474 | Running loss: 0.87319\n",
      "Epoch: 0 | Iteration: 35008 | Classification loss: 0.53962 | Regression loss: 0.57659 | Running loss: 0.87416\n",
      "Epoch: 0 | Iteration: 35009 | Classification loss: 0.57316 | Regression loss: 0.23061 | Running loss: 0.87392\n",
      "Epoch: 0 | Iteration: 35010 | Classification loss: 0.38819 | Regression loss: 0.62467 | Running loss: 0.87381\n",
      "Epoch: 0 | Iteration: 35011 | Classification loss: 0.77562 | Regression loss: 0.68215 | Running loss: 0.87467\n",
      "Epoch: 0 | Iteration: 35012 | Classification loss: 0.32727 | Regression loss: 0.49843 | Running loss: 0.87408\n",
      "Epoch: 0 | Iteration: 35013 | Classification loss: 0.66279 | Regression loss: 0.71940 | Running loss: 0.87524\n",
      "Epoch: 0 | Iteration: 35014 | Classification loss: 0.32564 | Regression loss: 0.48375 | Running loss: 0.87607\n",
      "Epoch: 0 | Iteration: 35015 | Classification loss: 0.36816 | Regression loss: 0.49686 | Running loss: 0.87674\n",
      "Epoch: 0 | Iteration: 35016 | Classification loss: 0.13220 | Regression loss: 0.16668 | Running loss: 0.87695\n",
      "Epoch: 0 | Iteration: 35017 | Classification loss: 0.38792 | Regression loss: 0.35560 | Running loss: 0.87735\n",
      "Epoch: 0 | Iteration: 35018 | Classification loss: 0.32060 | Regression loss: 0.40440 | Running loss: 0.87751\n",
      "Epoch: 0 | Iteration: 35019 | Classification loss: 3.10330 | Regression loss: 0.20799 | Running loss: 0.88185\n",
      "Epoch: 0 | Iteration: 35020 | Classification loss: 0.27769 | Regression loss: 0.37307 | Running loss: 0.88204\n",
      "Epoch: 0 | Iteration: 35021 | Classification loss: 0.45968 | Regression loss: 0.56796 | Running loss: 0.88307\n",
      "Epoch: 0 | Iteration: 35022 | Classification loss: 0.54457 | Regression loss: 0.55939 | Running loss: 0.88329\n",
      "Epoch: 0 | Iteration: 35023 | Classification loss: 0.66047 | Regression loss: 0.80198 | Running loss: 0.88462\n",
      "Epoch: 0 | Iteration: 35024 | Classification loss: 0.62272 | Regression loss: 0.93694 | Running loss: 0.88604\n",
      "Epoch: 0 | Iteration: 35025 | Classification loss: 0.39086 | Regression loss: 0.66046 | Running loss: 0.88655\n",
      "Epoch: 0 | Iteration: 35026 | Classification loss: 0.66627 | Regression loss: 0.30156 | Running loss: 0.88674\n",
      "Epoch: 0 | Iteration: 35027 | Classification loss: 0.31737 | Regression loss: 0.38874 | Running loss: 0.88704\n",
      "Epoch: 0 | Iteration: 35028 | Classification loss: 0.48194 | Regression loss: 0.53271 | Running loss: 0.88784\n",
      "Epoch: 0 | Iteration: 35029 | Classification loss: 0.52090 | Regression loss: 0.45248 | Running loss: 0.88735\n",
      "Epoch: 0 | Iteration: 35030 | Classification loss: 0.24815 | Regression loss: 0.54820 | Running loss: 0.88735\n",
      "Epoch: 0 | Iteration: 35031 | Classification loss: 0.64449 | Regression loss: 0.59656 | Running loss: 0.88842\n",
      "Epoch: 0 | Iteration: 35032 | Classification loss: 0.41555 | Regression loss: 0.41770 | Running loss: 0.88901\n",
      "Epoch: 0 | Iteration: 35033 | Classification loss: 0.51831 | Regression loss: 0.61988 | Running loss: 0.88970\n",
      "Epoch: 0 | Iteration: 35034 | Classification loss: 0.39970 | Regression loss: 0.43340 | Running loss: 0.88971\n",
      "Epoch: 0 | Iteration: 35035 | Classification loss: 0.25443 | Regression loss: 0.47910 | Running loss: 0.88920\n",
      "Epoch: 0 | Iteration: 35036 | Classification loss: 0.45281 | Regression loss: 0.36776 | Running loss: 0.88908\n",
      "Epoch: 0 | Iteration: 35037 | Classification loss: 0.39096 | Regression loss: 0.52325 | Running loss: 0.88877\n",
      "Epoch: 0 | Iteration: 35038 | Classification loss: 0.18900 | Regression loss: 0.34624 | Running loss: 0.88905\n",
      "Epoch: 0 | Iteration: 35039 | Classification loss: 0.53118 | Regression loss: 0.68884 | Running loss: 0.89003\n",
      "Epoch: 0 | Iteration: 35040 | Classification loss: 0.24460 | Regression loss: 0.46613 | Running loss: 0.88984\n",
      "Epoch: 0 | Iteration: 35041 | Classification loss: 0.34190 | Regression loss: 0.54467 | Running loss: 0.88941\n",
      "Epoch: 0 | Iteration: 35042 | Classification loss: 0.22874 | Regression loss: 0.45021 | Running loss: 0.88914\n",
      "Epoch: 0 | Iteration: 35043 | Classification loss: 0.57874 | Regression loss: 0.59148 | Running loss: 0.89011\n",
      "Epoch: 0 | Iteration: 35044 | Classification loss: 0.71521 | Regression loss: 0.49868 | Running loss: 0.89063\n",
      "Epoch: 0 | Iteration: 35045 | Classification loss: 0.29162 | Regression loss: 0.45566 | Running loss: 0.89077\n",
      "Epoch: 0 | Iteration: 35046 | Classification loss: 0.54576 | Regression loss: 0.72741 | Running loss: 0.89149\n",
      "Epoch: 0 | Iteration: 35047 | Classification loss: 0.56887 | Regression loss: 0.65750 | Running loss: 0.89238\n",
      "Epoch: 0 | Iteration: 35048 | Classification loss: 0.42019 | Regression loss: 0.50759 | Running loss: 0.89235\n",
      "Epoch: 0 | Iteration: 35049 | Classification loss: 0.28273 | Regression loss: 0.51326 | Running loss: 0.89240\n",
      "Epoch: 0 | Iteration: 35050 | Classification loss: 0.49943 | Regression loss: 0.27141 | Running loss: 0.89355\n",
      "Epoch: 0 | Iteration: 35051 | Classification loss: 0.32829 | Regression loss: 0.57140 | Running loss: 0.89437\n",
      "Epoch: 0 | Iteration: 35052 | Classification loss: 0.34346 | Regression loss: 0.45213 | Running loss: 0.89360\n",
      "Epoch: 0 | Iteration: 35053 | Classification loss: 0.37572 | Regression loss: 0.74372 | Running loss: 0.89460\n",
      "Epoch: 0 | Iteration: 35054 | Classification loss: 0.29578 | Regression loss: 0.30927 | Running loss: 0.89404\n",
      "Epoch: 0 | Iteration: 35055 | Classification loss: 0.44138 | Regression loss: 0.57760 | Running loss: 0.89477\n",
      "Epoch: 0 | Iteration: 35056 | Classification loss: 0.38805 | Regression loss: 0.34905 | Running loss: 0.89534\n",
      "Epoch: 0 | Iteration: 35057 | Classification loss: 0.25701 | Regression loss: 0.36347 | Running loss: 0.89504\n",
      "Epoch: 0 | Iteration: 35058 | Classification loss: 0.12009 | Regression loss: 0.30732 | Running loss: 0.89437\n",
      "Epoch: 0 | Iteration: 35059 | Classification loss: 0.33423 | Regression loss: 0.62900 | Running loss: 0.89457\n",
      "Epoch: 0 | Iteration: 35060 | Classification loss: 0.46308 | Regression loss: 0.37090 | Running loss: 0.89396\n",
      "Epoch: 0 | Iteration: 35061 | Classification loss: 0.40513 | Regression loss: 0.55923 | Running loss: 0.89413\n",
      "Epoch: 0 | Iteration: 35062 | Classification loss: 0.33992 | Regression loss: 0.28041 | Running loss: 0.89317\n",
      "Epoch: 0 | Iteration: 35063 | Classification loss: 0.32815 | Regression loss: 0.44893 | Running loss: 0.89285\n",
      "Epoch: 0 | Iteration: 35064 | Classification loss: 0.38911 | Regression loss: 0.69368 | Running loss: 0.89303\n",
      "Epoch: 0 | Iteration: 35065 | Classification loss: 0.19428 | Regression loss: 0.32988 | Running loss: 0.89211\n",
      "Epoch: 0 | Iteration: 35066 | Classification loss: 0.60948 | Regression loss: 0.70667 | Running loss: 0.89374\n",
      "Epoch: 0 | Iteration: 35067 | Classification loss: 0.17569 | Regression loss: 0.40039 | Running loss: 0.89321\n",
      "Epoch: 0 | Iteration: 35068 | Classification loss: 0.32411 | Regression loss: 0.49168 | Running loss: 0.89343\n",
      "Epoch: 0 | Iteration: 35069 | Classification loss: 0.60320 | Regression loss: 0.65135 | Running loss: 0.89352\n",
      "Epoch: 0 | Iteration: 35070 | Classification loss: 0.42634 | Regression loss: 0.53896 | Running loss: 0.89387\n",
      "Epoch: 0 | Iteration: 35071 | Classification loss: 0.40471 | Regression loss: 0.59786 | Running loss: 0.89429\n",
      "Epoch: 0 | Iteration: 35072 | Classification loss: 0.15248 | Regression loss: 0.46150 | Running loss: 0.89402\n",
      "Epoch: 0 | Iteration: 35073 | Classification loss: 0.19865 | Regression loss: 0.31437 | Running loss: 0.89286\n",
      "Epoch: 0 | Iteration: 35074 | Classification loss: 0.41443 | Regression loss: 0.51829 | Running loss: 0.89332\n",
      "Epoch: 0 | Iteration: 35075 | Classification loss: 0.28269 | Regression loss: 0.55945 | Running loss: 0.89324\n",
      "Epoch: 0 | Iteration: 35076 | Classification loss: 0.41394 | Regression loss: 0.45834 | Running loss: 0.89216\n",
      "Epoch: 0 | Iteration: 35077 | Classification loss: 0.50531 | Regression loss: 0.56818 | Running loss: 0.89294\n",
      "Epoch: 0 | Iteration: 35078 | Classification loss: 0.33947 | Regression loss: 0.59320 | Running loss: 0.89342\n",
      "Epoch: 0 | Iteration: 35079 | Classification loss: 0.29387 | Regression loss: 0.49387 | Running loss: 0.89305\n",
      "Epoch: 0 | Iteration: 35080 | Classification loss: 0.30332 | Regression loss: 0.51688 | Running loss: 0.89308\n",
      "Epoch: 0 | Iteration: 35081 | Classification loss: 0.32266 | Regression loss: 0.41761 | Running loss: 0.89305\n",
      "Epoch: 0 | Iteration: 35082 | Classification loss: 0.43138 | Regression loss: 0.30655 | Running loss: 0.89336\n",
      "Epoch: 0 | Iteration: 35083 | Classification loss: 0.58007 | Regression loss: 0.37925 | Running loss: 0.89367\n",
      "Epoch: 0 | Iteration: 35084 | Classification loss: 0.23307 | Regression loss: 0.54849 | Running loss: 0.89292\n",
      "Epoch: 0 | Iteration: 35085 | Classification loss: 0.28081 | Regression loss: 0.55053 | Running loss: 0.89218\n",
      "Epoch: 0 | Iteration: 35086 | Classification loss: 0.34565 | Regression loss: 0.38254 | Running loss: 0.89150\n",
      "Epoch: 0 | Iteration: 35087 | Classification loss: 0.45472 | Regression loss: 0.56861 | Running loss: 0.89231\n",
      "Epoch: 0 | Iteration: 35088 | Classification loss: 0.31518 | Regression loss: 0.37350 | Running loss: 0.89156\n",
      "Epoch: 0 | Iteration: 35089 | Classification loss: 0.24104 | Regression loss: 0.27797 | Running loss: 0.89067\n",
      "Epoch: 0 | Iteration: 35090 | Classification loss: 0.41925 | Regression loss: 0.47479 | Running loss: 0.89139\n",
      "Epoch: 0 | Iteration: 35091 | Classification loss: 0.27849 | Regression loss: 0.42790 | Running loss: 0.89073\n",
      "Epoch: 0 | Iteration: 35092 | Classification loss: 0.31532 | Regression loss: 0.43423 | Running loss: 0.89027\n",
      "Epoch: 0 | Iteration: 35093 | Classification loss: 0.36212 | Regression loss: 0.50170 | Running loss: 0.89010\n",
      "Epoch: 0 | Iteration: 35094 | Classification loss: 0.36920 | Regression loss: 0.36097 | Running loss: 0.88922\n",
      "Epoch: 0 | Iteration: 35095 | Classification loss: 0.33874 | Regression loss: 0.45299 | Running loss: 0.89001\n",
      "Epoch: 0 | Iteration: 35096 | Classification loss: 0.24245 | Regression loss: 0.47167 | Running loss: 0.88999\n",
      "Epoch: 0 | Iteration: 35097 | Classification loss: 0.21522 | Regression loss: 0.38678 | Running loss: 0.88944\n",
      "Epoch: 0 | Iteration: 35098 | Classification loss: 0.52832 | Regression loss: 0.42050 | Running loss: 0.88920\n",
      "Epoch: 0 | Iteration: 35099 | Classification loss: 0.26973 | Regression loss: 0.52876 | Running loss: 0.88933\n",
      "Epoch: 0 | Iteration: 35100 | Classification loss: 0.30366 | Regression loss: 0.43586 | Running loss: 0.88946\n",
      "Epoch: 0 | Iteration: 35101 | Classification loss: 0.36356 | Regression loss: 0.45718 | Running loss: 0.88953\n",
      "Epoch: 0 | Iteration: 35102 | Classification loss: 0.19110 | Regression loss: 0.38719 | Running loss: 0.88886\n",
      "Epoch: 0 | Iteration: 35103 | Classification loss: 0.26924 | Regression loss: 0.31804 | Running loss: 0.88653\n",
      "Epoch: 0 | Iteration: 35104 | Classification loss: 0.30820 | Regression loss: 0.34010 | Running loss: 0.88648\n",
      "Epoch: 0 | Iteration: 35105 | Classification loss: 0.34084 | Regression loss: 0.48672 | Running loss: 0.88665\n",
      "Epoch: 0 | Iteration: 35106 | Classification loss: 0.60211 | Regression loss: 0.73477 | Running loss: 0.88783\n",
      "Epoch: 0 | Iteration: 35107 | Classification loss: 0.46183 | Regression loss: 0.64092 | Running loss: 0.88815\n",
      "Epoch: 0 | Iteration: 35108 | Classification loss: 0.30034 | Regression loss: 0.45581 | Running loss: 0.88757\n",
      "Epoch: 0 | Iteration: 35109 | Classification loss: 0.31805 | Regression loss: 0.45390 | Running loss: 0.88703\n",
      "Epoch: 0 | Iteration: 35110 | Classification loss: 0.37930 | Regression loss: 0.45010 | Running loss: 0.88689\n",
      "Epoch: 0 | Iteration: 35111 | Classification loss: 0.36758 | Regression loss: 0.52872 | Running loss: 0.88692\n",
      "Epoch: 0 | Iteration: 35112 | Classification loss: 0.34186 | Regression loss: 0.49976 | Running loss: 0.88736\n",
      "Epoch: 0 | Iteration: 35113 | Classification loss: 0.33271 | Regression loss: 0.56687 | Running loss: 0.88687\n",
      "Epoch: 0 | Iteration: 35114 | Classification loss: 0.26402 | Regression loss: 0.30120 | Running loss: 0.88629\n",
      "Epoch: 0 | Iteration: 35115 | Classification loss: 0.23526 | Regression loss: 0.37544 | Running loss: 0.88607\n",
      "Epoch: 0 | Iteration: 35116 | Classification loss: 0.29296 | Regression loss: 0.37281 | Running loss: 0.88536\n",
      "Epoch: 0 | Iteration: 35117 | Classification loss: 0.68859 | Regression loss: 0.69167 | Running loss: 0.88595\n",
      "Epoch: 0 | Iteration: 35118 | Classification loss: 0.32099 | Regression loss: 0.53869 | Running loss: 0.88619\n",
      "Epoch: 0 | Iteration: 35119 | Classification loss: 0.18502 | Regression loss: 0.47956 | Running loss: 0.88595\n",
      "Epoch: 0 | Iteration: 35120 | Classification loss: 0.30808 | Regression loss: 0.38786 | Running loss: 0.88504\n",
      "Epoch: 0 | Iteration: 35121 | Classification loss: 0.29514 | Regression loss: 0.26670 | Running loss: 0.88434\n",
      "Epoch: 0 | Iteration: 35122 | Classification loss: 0.27863 | Regression loss: 0.38710 | Running loss: 0.88422\n",
      "Epoch: 0 | Iteration: 35123 | Classification loss: 0.40460 | Regression loss: 0.61496 | Running loss: 0.88386\n",
      "Epoch: 0 | Iteration: 35124 | Classification loss: 0.29638 | Regression loss: 0.40948 | Running loss: 0.88309\n",
      "Epoch: 0 | Iteration: 35125 | Classification loss: 0.36088 | Regression loss: 0.66998 | Running loss: 0.88375\n",
      "Epoch: 0 | Iteration: 35126 | Classification loss: 0.24047 | Regression loss: 0.43358 | Running loss: 0.88260\n",
      "Epoch: 0 | Iteration: 35127 | Classification loss: 0.43075 | Regression loss: 0.62187 | Running loss: 0.88275\n",
      "Epoch: 0 | Iteration: 35128 | Classification loss: 0.60906 | Regression loss: 0.65581 | Running loss: 0.88344\n",
      "Epoch: 0 | Iteration: 35129 | Classification loss: 0.19860 | Regression loss: 0.23032 | Running loss: 0.88164\n",
      "Epoch: 0 | Iteration: 35130 | Classification loss: 0.23043 | Regression loss: 0.32387 | Running loss: 0.88062\n",
      "Epoch: 0 | Iteration: 35131 | Classification loss: 0.53278 | Regression loss: 0.54410 | Running loss: 0.88048\n",
      "Epoch: 0 | Iteration: 35132 | Classification loss: 0.44951 | Regression loss: 0.45299 | Running loss: 0.87961\n",
      "Epoch: 0 | Iteration: 35133 | Classification loss: 0.30728 | Regression loss: 0.58052 | Running loss: 0.87922\n",
      "Epoch: 0 | Iteration: 35134 | Classification loss: 0.42059 | Regression loss: 0.53193 | Running loss: 0.87930\n",
      "Epoch: 0 | Iteration: 35135 | Classification loss: 0.41400 | Regression loss: 0.53586 | Running loss: 0.87993\n",
      "Epoch: 0 | Iteration: 35136 | Classification loss: 0.36033 | Regression loss: 0.25527 | Running loss: 0.87912\n",
      "Epoch: 0 | Iteration: 35137 | Classification loss: 0.24430 | Regression loss: 0.47271 | Running loss: 0.87889\n",
      "Epoch: 0 | Iteration: 35138 | Classification loss: 0.43022 | Regression loss: 0.40719 | Running loss: 0.87868\n",
      "Epoch: 0 | Iteration: 35139 | Classification loss: 0.38449 | Regression loss: 0.56644 | Running loss: 0.87965\n",
      "Epoch: 0 | Iteration: 35140 | Classification loss: 0.36871 | Regression loss: 0.62858 | Running loss: 0.88003\n",
      "Epoch: 0 | Iteration: 35141 | Classification loss: 0.16669 | Regression loss: 0.38801 | Running loss: 0.87813\n",
      "Epoch: 0 | Iteration: 35142 | Classification loss: 0.42480 | Regression loss: 0.57644 | Running loss: 0.87879\n",
      "Epoch: 0 | Iteration: 35143 | Classification loss: 0.67754 | Regression loss: 0.49004 | Running loss: 0.87904\n",
      "Epoch: 0 | Iteration: 35144 | Classification loss: 0.35302 | Regression loss: 0.50710 | Running loss: 0.87887\n",
      "Epoch: 0 | Iteration: 35145 | Classification loss: 0.40541 | Regression loss: 0.62381 | Running loss: 0.87870\n",
      "Epoch: 0 | Iteration: 35146 | Classification loss: 0.38156 | Regression loss: 0.29407 | Running loss: 0.87827\n",
      "Epoch: 0 | Iteration: 35147 | Classification loss: 0.46205 | Regression loss: 0.53031 | Running loss: 0.87890\n",
      "Epoch: 0 | Iteration: 35148 | Classification loss: 0.40452 | Regression loss: 0.54328 | Running loss: 0.87923\n",
      "Epoch: 0 | Iteration: 35149 | Classification loss: 0.39372 | Regression loss: 0.58228 | Running loss: 0.87943\n",
      "Epoch: 0 | Iteration: 35150 | Classification loss: 0.38313 | Regression loss: 0.59391 | Running loss: 0.87982\n",
      "Epoch: 0 | Iteration: 35151 | Classification loss: 0.27465 | Regression loss: 0.35984 | Running loss: 0.87993\n",
      "Epoch: 0 | Iteration: 35152 | Classification loss: 0.37474 | Regression loss: 0.49853 | Running loss: 0.87989\n",
      "Epoch: 0 | Iteration: 35153 | Classification loss: 0.48055 | Regression loss: 0.36537 | Running loss: 0.88074\n",
      "Epoch: 0 | Iteration: 35154 | Classification loss: 0.47028 | Regression loss: 0.46365 | Running loss: 0.88065\n",
      "Epoch: 0 | Iteration: 35155 | Classification loss: 0.26003 | Regression loss: 0.53653 | Running loss: 0.87987\n",
      "Epoch: 0 | Iteration: 35156 | Classification loss: 0.46657 | Regression loss: 0.70803 | Running loss: 0.87927\n",
      "Epoch: 0 | Iteration: 35157 | Classification loss: 0.48426 | Regression loss: 0.72366 | Running loss: 0.87986\n",
      "Epoch: 0 | Iteration: 35158 | Classification loss: 0.66242 | Regression loss: 0.52369 | Running loss: 0.88139\n",
      "Epoch: 0 | Iteration: 35159 | Classification loss: 0.21704 | Regression loss: 0.28553 | Running loss: 0.87976\n",
      "Epoch: 0 | Iteration: 35160 | Classification loss: 0.51676 | Regression loss: 0.62587 | Running loss: 0.88007\n",
      "Epoch: 0 | Iteration: 35161 | Classification loss: 0.55956 | Regression loss: 0.55156 | Running loss: 0.88029\n",
      "Epoch: 0 | Iteration: 35162 | Classification loss: 0.15572 | Regression loss: 0.46558 | Running loss: 0.87965\n",
      "Epoch: 0 | Iteration: 35163 | Classification loss: 0.42253 | Regression loss: 0.45592 | Running loss: 0.87929\n",
      "Epoch: 0 | Iteration: 35164 | Classification loss: 0.30424 | Regression loss: 0.48556 | Running loss: 0.87898\n",
      "Epoch: 0 | Iteration: 35165 | Classification loss: 0.14748 | Regression loss: 0.12922 | Running loss: 0.87729\n",
      "Epoch: 0 | Iteration: 35166 | Classification loss: 0.40378 | Regression loss: 0.43231 | Running loss: 0.87745\n",
      "Epoch: 0 | Iteration: 35167 | Classification loss: 0.39089 | Regression loss: 0.71622 | Running loss: 0.87725\n",
      "Epoch: 0 | Iteration: 35168 | Classification loss: 0.19272 | Regression loss: 0.22138 | Running loss: 0.87624\n",
      "Epoch: 0 | Iteration: 35169 | Classification loss: 0.32878 | Regression loss: 0.60130 | Running loss: 0.87630\n",
      "Epoch: 0 | Iteration: 35170 | Classification loss: 0.37456 | Regression loss: 0.52733 | Running loss: 0.87682\n",
      "Epoch: 0 | Iteration: 35171 | Classification loss: 0.21849 | Regression loss: 0.46156 | Running loss: 0.87625\n",
      "Epoch: 0 | Iteration: 35172 | Classification loss: 0.24251 | Regression loss: 0.32569 | Running loss: 0.87519\n",
      "Epoch: 0 | Iteration: 35173 | Classification loss: 0.35401 | Regression loss: 0.47276 | Running loss: 0.87480\n",
      "Epoch: 0 | Iteration: 35174 | Classification loss: 0.19793 | Regression loss: 0.37833 | Running loss: 0.87365\n",
      "Epoch: 0 | Iteration: 35175 | Classification loss: 0.19386 | Regression loss: 0.35052 | Running loss: 0.87214\n",
      "Epoch: 0 | Iteration: 35176 | Classification loss: 0.40267 | Regression loss: 0.49415 | Running loss: 0.87240\n",
      "Epoch: 0 | Iteration: 35177 | Classification loss: 0.33513 | Regression loss: 0.52836 | Running loss: 0.87291\n",
      "Epoch: 0 | Iteration: 35178 | Classification loss: 0.45479 | Regression loss: 0.42311 | Running loss: 0.87256\n",
      "Epoch: 0 | Iteration: 35179 | Classification loss: 0.36636 | Regression loss: 0.46471 | Running loss: 0.87229\n",
      "Epoch: 0 | Iteration: 35180 | Classification loss: 0.46707 | Regression loss: 0.62536 | Running loss: 0.87298\n",
      "Epoch: 0 | Iteration: 35181 | Classification loss: 0.40919 | Regression loss: 0.68373 | Running loss: 0.87367\n",
      "Epoch: 0 | Iteration: 35182 | Classification loss: 0.84503 | Regression loss: 0.50320 | Running loss: 0.87421\n",
      "Epoch: 0 | Iteration: 35183 | Classification loss: 0.50264 | Regression loss: 0.55691 | Running loss: 0.87491\n",
      "Epoch: 0 | Iteration: 35184 | Classification loss: 0.41929 | Regression loss: 0.45737 | Running loss: 0.87288\n",
      "Epoch: 0 | Iteration: 35185 | Classification loss: 0.35336 | Regression loss: 0.43760 | Running loss: 0.87418\n",
      "Epoch: 0 | Iteration: 35186 | Classification loss: 0.36585 | Regression loss: 0.48070 | Running loss: 0.87408\n",
      "Epoch: 0 | Iteration: 35187 | Classification loss: 0.55740 | Regression loss: 0.85380 | Running loss: 0.87536\n",
      "Epoch: 0 | Iteration: 35188 | Classification loss: 0.51149 | Regression loss: 0.32109 | Running loss: 0.87582\n",
      "Epoch: 0 | Iteration: 35189 | Classification loss: 0.25933 | Regression loss: 0.49467 | Running loss: 0.87562\n",
      "Epoch: 0 | Iteration: 35190 | Classification loss: 0.55872 | Regression loss: 0.64440 | Running loss: 0.87670\n",
      "Epoch: 0 | Iteration: 35191 | Classification loss: 0.33738 | Regression loss: 0.53341 | Running loss: 0.87699\n",
      "Epoch: 0 | Iteration: 35192 | Classification loss: 0.49461 | Regression loss: 0.45205 | Running loss: 0.87778\n",
      "Epoch: 0 | Iteration: 35193 | Classification loss: 0.50388 | Regression loss: 0.55717 | Running loss: 0.87863\n",
      "Epoch: 0 | Iteration: 35194 | Classification loss: 0.37007 | Regression loss: 0.58326 | Running loss: 0.87840\n",
      "Epoch: 0 | Iteration: 35195 | Classification loss: 0.47325 | Regression loss: 0.51848 | Running loss: 0.87911\n",
      "Epoch: 0 | Iteration: 35196 | Classification loss: 0.42145 | Regression loss: 0.52934 | Running loss: 0.87961\n",
      "Epoch: 0 | Iteration: 35197 | Classification loss: 0.40606 | Regression loss: 0.48038 | Running loss: 0.87962\n",
      "Epoch: 0 | Iteration: 35198 | Classification loss: 0.27221 | Regression loss: 0.50152 | Running loss: 0.87935\n",
      "Epoch: 0 | Iteration: 35199 | Classification loss: 0.36788 | Regression loss: 0.58982 | Running loss: 0.87921\n",
      "Epoch: 0 | Iteration: 35200 | Classification loss: 0.32602 | Regression loss: 0.42960 | Running loss: 0.87816\n",
      "Epoch: 0 | Iteration: 35201 | Classification loss: 0.27368 | Regression loss: 0.41232 | Running loss: 0.87796\n",
      "Epoch: 0 | Iteration: 35202 | Classification loss: 0.33130 | Regression loss: 0.45442 | Running loss: 0.87823\n",
      "Epoch: 0 | Iteration: 35203 | Classification loss: 0.41610 | Regression loss: 0.58949 | Running loss: 0.87958\n",
      "Epoch: 0 | Iteration: 35204 | Classification loss: 0.37367 | Regression loss: 0.72855 | Running loss: 0.88058\n",
      "Epoch: 0 | Iteration: 35205 | Classification loss: 0.35189 | Regression loss: 0.44118 | Running loss: 0.88041\n",
      "Epoch: 0 | Iteration: 35206 | Classification loss: 0.41056 | Regression loss: 0.59501 | Running loss: 0.88057\n",
      "Epoch: 0 | Iteration: 35207 | Classification loss: 0.27070 | Regression loss: 0.39674 | Running loss: 0.87960\n",
      "Epoch: 0 | Iteration: 35208 | Classification loss: 0.70366 | Regression loss: 0.70064 | Running loss: 0.88042\n",
      "Epoch: 0 | Iteration: 35209 | Classification loss: 0.24689 | Regression loss: 0.40953 | Running loss: 0.87995\n",
      "Epoch: 0 | Iteration: 35210 | Classification loss: 0.34767 | Regression loss: 0.62582 | Running loss: 0.88017\n",
      "Epoch: 0 | Iteration: 35211 | Classification loss: 0.33957 | Regression loss: 0.44541 | Running loss: 0.88020\n",
      "Epoch: 0 | Iteration: 35212 | Classification loss: 0.40154 | Regression loss: 0.40779 | Running loss: 0.88045\n",
      "Epoch: 0 | Iteration: 35213 | Classification loss: 0.72028 | Regression loss: 0.32629 | Running loss: 0.88034\n",
      "Epoch: 0 | Iteration: 35214 | Classification loss: 0.37644 | Regression loss: 0.60449 | Running loss: 0.88068\n",
      "Epoch: 0 | Iteration: 35215 | Classification loss: 0.36933 | Regression loss: 0.42149 | Running loss: 0.88110\n",
      "Epoch: 0 | Iteration: 35216 | Classification loss: 0.48587 | Regression loss: 0.38746 | Running loss: 0.88088\n",
      "Epoch: 0 | Iteration: 35217 | Classification loss: 0.18817 | Regression loss: 0.39994 | Running loss: 0.88061\n",
      "Epoch: 0 | Iteration: 35218 | Classification loss: 0.17436 | Regression loss: 0.31159 | Running loss: 0.87969\n",
      "Epoch: 0 | Iteration: 35219 | Classification loss: 1.47270 | Regression loss: 0.33246 | Running loss: 0.88149\n",
      "Epoch: 0 | Iteration: 35220 | Classification loss: 0.35616 | Regression loss: 0.51577 | Running loss: 0.88162\n",
      "Epoch: 0 | Iteration: 35221 | Classification loss: 0.35849 | Regression loss: 0.48274 | Running loss: 0.88187\n",
      "Epoch: 0 | Iteration: 35222 | Classification loss: 0.35520 | Regression loss: 0.35511 | Running loss: 0.88233\n",
      "Epoch: 0 | Iteration: 35223 | Classification loss: 0.53642 | Regression loss: 0.59000 | Running loss: 0.88267\n",
      "Epoch: 0 | Iteration: 35224 | Classification loss: 0.44046 | Regression loss: 0.39105 | Running loss: 0.88331\n",
      "Epoch: 0 | Iteration: 35225 | Classification loss: 0.35725 | Regression loss: 0.42138 | Running loss: 0.88239\n",
      "Epoch: 0 | Iteration: 35226 | Classification loss: 0.49534 | Regression loss: 0.52546 | Running loss: 0.88162\n",
      "Epoch: 0 | Iteration: 35227 | Classification loss: 0.40717 | Regression loss: 0.42005 | Running loss: 0.88150\n",
      "Epoch: 0 | Iteration: 35228 | Classification loss: 0.51483 | Regression loss: 0.58704 | Running loss: 0.88188\n",
      "Epoch: 0 | Iteration: 35229 | Classification loss: 0.42617 | Regression loss: 0.44166 | Running loss: 0.88213\n",
      "Epoch: 0 | Iteration: 35230 | Classification loss: 0.41613 | Regression loss: 0.42871 | Running loss: 0.88252\n",
      "Epoch: 0 | Iteration: 35231 | Classification loss: 0.60927 | Regression loss: 0.65014 | Running loss: 0.88348\n",
      "Epoch: 0 | Iteration: 35232 | Classification loss: 0.30668 | Regression loss: 0.24984 | Running loss: 0.88336\n",
      "Epoch: 0 | Iteration: 35233 | Classification loss: 0.18517 | Regression loss: 0.42964 | Running loss: 0.88241\n",
      "Epoch: 0 | Iteration: 35234 | Classification loss: 0.32931 | Regression loss: 0.37563 | Running loss: 0.88163\n",
      "Epoch: 0 | Iteration: 35235 | Classification loss: 0.79094 | Regression loss: 0.30038 | Running loss: 0.88190\n",
      "Epoch: 0 | Iteration: 35236 | Classification loss: 0.13877 | Regression loss: 0.24416 | Running loss: 0.88094\n",
      "Epoch: 0 | Iteration: 35237 | Classification loss: 0.35395 | Regression loss: 0.30695 | Running loss: 0.88077\n",
      "Epoch: 0 | Iteration: 35238 | Classification loss: 0.47713 | Regression loss: 0.67559 | Running loss: 0.88113\n",
      "Epoch: 0 | Iteration: 35239 | Classification loss: 0.46204 | Regression loss: 0.70041 | Running loss: 0.88224\n",
      "Epoch: 0 | Iteration: 35240 | Classification loss: 0.43002 | Regression loss: 0.58504 | Running loss: 0.88256\n",
      "Epoch: 0 | Iteration: 35241 | Classification loss: 0.39788 | Regression loss: 0.69863 | Running loss: 0.88310\n",
      "Epoch: 0 | Iteration: 35242 | Classification loss: 0.40185 | Regression loss: 0.60788 | Running loss: 0.88333\n",
      "Epoch: 0 | Iteration: 35243 | Classification loss: 0.22401 | Regression loss: 0.37783 | Running loss: 0.88370\n",
      "Epoch: 0 | Iteration: 35244 | Classification loss: 0.42070 | Regression loss: 0.47108 | Running loss: 0.88373\n",
      "Epoch: 0 | Iteration: 35245 | Classification loss: 0.31950 | Regression loss: 0.55391 | Running loss: 0.88443\n",
      "Epoch: 0 | Iteration: 35246 | Classification loss: 0.21079 | Regression loss: 0.52338 | Running loss: 0.88386\n",
      "Epoch: 0 | Iteration: 35247 | Classification loss: 0.31645 | Regression loss: 0.53929 | Running loss: 0.88375\n",
      "Epoch: 0 | Iteration: 35248 | Classification loss: 0.37141 | Regression loss: 0.60412 | Running loss: 0.88358\n",
      "Epoch: 0 | Iteration: 35249 | Classification loss: 0.36254 | Regression loss: 0.62616 | Running loss: 0.88318\n",
      "Epoch: 0 | Iteration: 35250 | Classification loss: 0.26332 | Regression loss: 0.42229 | Running loss: 0.88347\n",
      "Epoch: 0 | Iteration: 35251 | Classification loss: 0.46643 | Regression loss: 0.76007 | Running loss: 0.88440\n",
      "Epoch: 0 | Iteration: 35252 | Classification loss: 0.52402 | Regression loss: 0.56360 | Running loss: 0.88444\n",
      "Epoch: 0 | Iteration: 35253 | Classification loss: 0.38075 | Regression loss: 0.44126 | Running loss: 0.88399\n",
      "Epoch: 0 | Iteration: 35254 | Classification loss: 0.53462 | Regression loss: 0.65163 | Running loss: 0.88412\n",
      "Epoch: 0 | Iteration: 35255 | Classification loss: 0.36044 | Regression loss: 0.62446 | Running loss: 0.88408\n",
      "Epoch: 0 | Iteration: 35256 | Classification loss: 0.37350 | Regression loss: 0.31424 | Running loss: 0.88396\n",
      "Epoch: 0 | Iteration: 35257 | Classification loss: 0.11117 | Regression loss: 0.27305 | Running loss: 0.88282\n",
      "Epoch: 0 | Iteration: 35258 | Classification loss: 0.44500 | Regression loss: 0.75619 | Running loss: 0.88322\n",
      "Epoch: 0 | Iteration: 35259 | Classification loss: 0.45620 | Regression loss: 0.49842 | Running loss: 0.88383\n",
      "Epoch: 0 | Iteration: 35260 | Classification loss: 0.25786 | Regression loss: 0.39185 | Running loss: 0.88407\n",
      "Epoch: 0 | Iteration: 35261 | Classification loss: 0.41724 | Regression loss: 0.56132 | Running loss: 0.88371\n",
      "Epoch: 0 | Iteration: 35262 | Classification loss: 0.24522 | Regression loss: 0.54840 | Running loss: 0.88343\n",
      "Epoch: 0 | Iteration: 35263 | Classification loss: 0.50958 | Regression loss: 0.61989 | Running loss: 0.88442\n",
      "Epoch: 0 | Iteration: 35264 | Classification loss: 0.35536 | Regression loss: 0.56546 | Running loss: 0.88434\n",
      "Epoch: 0 | Iteration: 35265 | Classification loss: 0.40826 | Regression loss: 0.62174 | Running loss: 0.88431\n",
      "Epoch: 0 | Iteration: 35266 | Classification loss: 0.42518 | Regression loss: 0.65915 | Running loss: 0.88525\n",
      "Epoch: 0 | Iteration: 35267 | Classification loss: 0.46772 | Regression loss: 0.61662 | Running loss: 0.88646\n",
      "Epoch: 0 | Iteration: 35268 | Classification loss: 0.32315 | Regression loss: 0.42229 | Running loss: 0.88676\n",
      "Epoch: 0 | Iteration: 35269 | Classification loss: 0.57144 | Regression loss: 0.52364 | Running loss: 0.88753\n",
      "Epoch: 0 | Iteration: 35270 | Classification loss: 0.91775 | Regression loss: 0.34290 | Running loss: 0.88892\n",
      "Epoch: 0 | Iteration: 35271 | Classification loss: 0.38894 | Regression loss: 0.40411 | Running loss: 0.88838\n",
      "Epoch: 0 | Iteration: 35272 | Classification loss: 0.11966 | Regression loss: 0.33639 | Running loss: 0.88766\n",
      "Epoch: 0 | Iteration: 35273 | Classification loss: 0.26387 | Regression loss: 0.40066 | Running loss: 0.88737\n",
      "Epoch: 0 | Iteration: 35274 | Classification loss: 1.26452 | Regression loss: 0.48097 | Running loss: 0.88851\n",
      "Epoch: 0 | Iteration: 35275 | Classification loss: 0.16381 | Regression loss: 0.33263 | Running loss: 0.88805\n",
      "Epoch: 0 | Iteration: 35276 | Classification loss: 0.38384 | Regression loss: 0.46627 | Running loss: 0.88832\n",
      "Epoch: 0 | Iteration: 35277 | Classification loss: 0.58380 | Regression loss: 0.51422 | Running loss: 0.88875\n",
      "Epoch: 0 | Iteration: 35278 | Classification loss: 0.42148 | Regression loss: 0.57028 | Running loss: 0.88912\n",
      "Epoch: 0 | Iteration: 35279 | Classification loss: 0.27426 | Regression loss: 0.38458 | Running loss: 0.88777\n",
      "Epoch: 0 | Iteration: 35280 | Classification loss: 0.44620 | Regression loss: 0.57458 | Running loss: 0.88849\n",
      "Epoch: 0 | Iteration: 35281 | Classification loss: 0.32423 | Regression loss: 0.43413 | Running loss: 0.88799\n",
      "Epoch: 0 | Iteration: 35282 | Classification loss: 0.59876 | Regression loss: 0.54091 | Running loss: 0.88816\n",
      "Epoch: 0 | Iteration: 35283 | Classification loss: 0.46118 | Regression loss: 0.60718 | Running loss: 0.88911\n",
      "Epoch: 0 | Iteration: 35284 | Classification loss: 0.25876 | Regression loss: 0.54774 | Running loss: 0.88927\n",
      "Epoch: 0 | Iteration: 35285 | Classification loss: 0.39017 | Regression loss: 0.51681 | Running loss: 0.88885\n",
      "Epoch: 0 | Iteration: 35286 | Classification loss: 0.28881 | Regression loss: 0.43953 | Running loss: 0.88835\n",
      "Epoch: 0 | Iteration: 35287 | Classification loss: 0.59872 | Regression loss: 0.52374 | Running loss: 0.88877\n",
      "Epoch: 0 | Iteration: 35288 | Classification loss: 0.49124 | Regression loss: 0.56079 | Running loss: 0.88885\n",
      "Epoch: 0 | Iteration: 35289 | Classification loss: 0.37521 | Regression loss: 0.58803 | Running loss: 0.88799\n",
      "Epoch: 0 | Iteration: 35290 | Classification loss: 0.29905 | Regression loss: 0.56907 | Running loss: 0.88747\n",
      "Epoch: 0 | Iteration: 35291 | Classification loss: 0.35904 | Regression loss: 0.55364 | Running loss: 0.88732\n",
      "Epoch: 0 | Iteration: 35292 | Classification loss: 0.49043 | Regression loss: 0.55524 | Running loss: 0.88798\n",
      "Epoch: 0 | Iteration: 35293 | Classification loss: 0.29492 | Regression loss: 0.53054 | Running loss: 0.88877\n",
      "Epoch: 0 | Iteration: 35294 | Classification loss: 0.54531 | Regression loss: 0.78380 | Running loss: 0.88933\n",
      "Epoch: 0 | Iteration: 35295 | Classification loss: 0.20717 | Regression loss: 0.30230 | Running loss: 0.88850\n",
      "Epoch: 0 | Iteration: 35296 | Classification loss: 0.18142 | Regression loss: 0.19493 | Running loss: 0.88707\n",
      "Epoch: 0 | Iteration: 35297 | Classification loss: 0.42718 | Regression loss: 0.48577 | Running loss: 0.88724\n",
      "Epoch: 0 | Iteration: 35298 | Classification loss: 0.57605 | Regression loss: 0.64745 | Running loss: 0.88817\n",
      "Epoch: 0 | Iteration: 35299 | Classification loss: 0.33967 | Regression loss: 0.56628 | Running loss: 0.88817\n",
      "Epoch: 0 | Iteration: 35300 | Classification loss: 0.27567 | Regression loss: 0.40636 | Running loss: 0.88819\n",
      "Epoch: 0 | Iteration: 35301 | Classification loss: 0.36249 | Regression loss: 0.62773 | Running loss: 0.88801\n",
      "Epoch: 0 | Iteration: 35302 | Classification loss: 0.53977 | Regression loss: 0.50232 | Running loss: 0.88881\n",
      "Epoch: 0 | Iteration: 35303 | Classification loss: 0.34618 | Regression loss: 0.56944 | Running loss: 0.88911\n",
      "Epoch: 0 | Iteration: 35304 | Classification loss: 0.27772 | Regression loss: 0.48880 | Running loss: 0.88936\n",
      "Epoch: 0 | Iteration: 35305 | Classification loss: 0.35015 | Regression loss: 0.44873 | Running loss: 0.88955\n",
      "Epoch: 0 | Iteration: 35306 | Classification loss: 0.51727 | Regression loss: 0.56324 | Running loss: 0.88966\n",
      "Epoch: 0 | Iteration: 35307 | Classification loss: 0.33556 | Regression loss: 0.40968 | Running loss: 0.88991\n",
      "Epoch: 0 | Iteration: 35308 | Classification loss: 0.19756 | Regression loss: 0.35669 | Running loss: 0.88880\n",
      "Epoch: 0 | Iteration: 35309 | Classification loss: 0.52887 | Regression loss: 0.71727 | Running loss: 0.88914\n",
      "Epoch: 0 | Iteration: 35310 | Classification loss: 0.32469 | Regression loss: 0.76468 | Running loss: 0.88959\n",
      "Epoch: 0 | Iteration: 35311 | Classification loss: 0.31649 | Regression loss: 0.39823 | Running loss: 0.88985\n",
      "Epoch: 0 | Iteration: 35312 | Classification loss: 0.62309 | Regression loss: 0.58163 | Running loss: 0.89034\n",
      "Epoch: 0 | Iteration: 35313 | Classification loss: 0.45993 | Regression loss: 0.46193 | Running loss: 0.89071\n",
      "Epoch: 0 | Iteration: 35314 | Classification loss: 0.67099 | Regression loss: 0.37678 | Running loss: 0.89129\n",
      "Epoch: 0 | Iteration: 35315 | Classification loss: 0.20690 | Regression loss: 0.40894 | Running loss: 0.88996\n",
      "Epoch: 0 | Iteration: 35316 | Classification loss: 0.39464 | Regression loss: 0.79511 | Running loss: 0.88992\n",
      "Epoch: 0 | Iteration: 35317 | Classification loss: 0.47742 | Regression loss: 0.50400 | Running loss: 0.89027\n",
      "Epoch: 0 | Iteration: 35318 | Classification loss: 0.31298 | Regression loss: 0.33648 | Running loss: 0.89010\n",
      "Epoch: 0 | Iteration: 35319 | Classification loss: 0.33019 | Regression loss: 0.39692 | Running loss: 0.89048\n",
      "Epoch: 0 | Iteration: 35320 | Classification loss: 0.32961 | Regression loss: 0.36973 | Running loss: 0.89045\n",
      "Epoch: 0 | Iteration: 35321 | Classification loss: 0.81786 | Regression loss: 0.35675 | Running loss: 0.89139\n",
      "Epoch: 0 | Iteration: 35322 | Classification loss: 0.30005 | Regression loss: 0.51194 | Running loss: 0.89079\n",
      "Epoch: 0 | Iteration: 35323 | Classification loss: 0.55460 | Regression loss: 0.60864 | Running loss: 0.89164\n",
      "Epoch: 0 | Iteration: 35324 | Classification loss: 0.52288 | Regression loss: 0.67788 | Running loss: 0.89137\n",
      "Epoch: 0 | Iteration: 35325 | Classification loss: 0.20401 | Regression loss: 0.26836 | Running loss: 0.88999\n",
      "Epoch: 0 | Iteration: 35326 | Classification loss: 0.17020 | Regression loss: 0.36665 | Running loss: 0.88876\n",
      "Epoch: 0 | Iteration: 35327 | Classification loss: 0.28559 | Regression loss: 0.38083 | Running loss: 0.88847\n",
      "Epoch: 0 | Iteration: 35328 | Classification loss: 0.26001 | Regression loss: 0.51587 | Running loss: 0.88857\n",
      "Epoch: 0 | Iteration: 35329 | Classification loss: 0.20770 | Regression loss: 0.51049 | Running loss: 0.88833\n",
      "Epoch: 0 | Iteration: 35330 | Classification loss: 0.35602 | Regression loss: 0.56616 | Running loss: 0.88778\n",
      "Epoch: 0 | Iteration: 35331 | Classification loss: 0.25007 | Regression loss: 0.42671 | Running loss: 0.88745\n",
      "Epoch: 0 | Iteration: 35332 | Classification loss: 0.26600 | Regression loss: 0.54078 | Running loss: 0.88754\n",
      "Epoch: 0 | Iteration: 35333 | Classification loss: 0.57102 | Regression loss: 0.67184 | Running loss: 0.88858\n",
      "Epoch: 0 | Iteration: 35334 | Classification loss: 0.38997 | Regression loss: 0.55836 | Running loss: 0.88853\n",
      "Epoch: 0 | Iteration: 35335 | Classification loss: 0.39018 | Regression loss: 0.42466 | Running loss: 0.88774\n",
      "Epoch: 0 | Iteration: 35336 | Classification loss: 0.50523 | Regression loss: 0.59716 | Running loss: 0.88796\n",
      "Epoch: 0 | Iteration: 35337 | Classification loss: 0.41741 | Regression loss: 0.46599 | Running loss: 0.88874\n",
      "Epoch: 0 | Iteration: 35338 | Classification loss: 0.27194 | Regression loss: 0.49129 | Running loss: 0.88884\n",
      "Epoch: 0 | Iteration: 35339 | Classification loss: 0.46444 | Regression loss: 0.66609 | Running loss: 0.88968\n",
      "Epoch: 0 | Iteration: 35340 | Classification loss: 0.66659 | Regression loss: 0.67508 | Running loss: 0.89046\n",
      "Epoch: 0 | Iteration: 35341 | Classification loss: 0.25601 | Regression loss: 0.39255 | Running loss: 0.89009\n",
      "Epoch: 0 | Iteration: 35342 | Classification loss: 0.41016 | Regression loss: 0.45923 | Running loss: 0.88978\n",
      "Epoch: 0 | Iteration: 35343 | Classification loss: 0.25646 | Regression loss: 0.34922 | Running loss: 0.88876\n",
      "Epoch: 0 | Iteration: 35344 | Classification loss: 0.44782 | Regression loss: 0.25703 | Running loss: 0.88849\n",
      "Epoch: 0 | Iteration: 35345 | Classification loss: 0.25301 | Regression loss: 0.38086 | Running loss: 0.88761\n",
      "Epoch: 0 | Iteration: 35346 | Classification loss: 0.50755 | Regression loss: 0.68360 | Running loss: 0.88736\n",
      "Epoch: 0 | Iteration: 35347 | Classification loss: 0.44099 | Regression loss: 0.57328 | Running loss: 0.88835\n",
      "Epoch: 0 | Iteration: 35348 | Classification loss: 0.19835 | Regression loss: 0.27694 | Running loss: 0.88699\n",
      "Epoch: 0 | Iteration: 35349 | Classification loss: 0.45541 | Regression loss: 0.45818 | Running loss: 0.88747\n",
      "Epoch: 0 | Iteration: 35350 | Classification loss: 0.36350 | Regression loss: 0.52342 | Running loss: 0.88731\n",
      "Epoch: 0 | Iteration: 35351 | Classification loss: 0.48325 | Regression loss: 0.63126 | Running loss: 0.88806\n",
      "Epoch: 0 | Iteration: 35352 | Classification loss: 0.57025 | Regression loss: 0.31494 | Running loss: 0.88847\n",
      "Epoch: 0 | Iteration: 35353 | Classification loss: 0.28546 | Regression loss: 0.49977 | Running loss: 0.88823\n",
      "Epoch: 0 | Iteration: 35354 | Classification loss: 0.35030 | Regression loss: 0.59258 | Running loss: 0.88818\n",
      "Epoch: 0 | Iteration: 35355 | Classification loss: 0.28237 | Regression loss: 0.44707 | Running loss: 0.88810\n",
      "Epoch: 0 | Iteration: 35356 | Classification loss: 0.39896 | Regression loss: 0.40304 | Running loss: 0.88795\n",
      "Epoch: 0 | Iteration: 35357 | Classification loss: 0.32307 | Regression loss: 0.48474 | Running loss: 0.88771\n",
      "Epoch: 0 | Iteration: 35358 | Classification loss: 0.25052 | Regression loss: 0.37554 | Running loss: 0.88690\n",
      "Epoch: 0 | Iteration: 35359 | Classification loss: 0.25137 | Regression loss: 0.37550 | Running loss: 0.88607\n",
      "Epoch: 0 | Iteration: 35360 | Classification loss: 0.35642 | Regression loss: 0.49842 | Running loss: 0.88699\n",
      "Epoch: 0 | Iteration: 35361 | Classification loss: 0.24988 | Regression loss: 0.58773 | Running loss: 0.88639\n",
      "Epoch: 0 | Iteration: 35362 | Classification loss: 0.37142 | Regression loss: 0.52134 | Running loss: 0.88625\n",
      "Epoch: 0 | Iteration: 35363 | Classification loss: 0.36985 | Regression loss: 0.47872 | Running loss: 0.88610\n",
      "Epoch: 0 | Iteration: 35364 | Classification loss: 0.18417 | Regression loss: 0.46493 | Running loss: 0.88425\n",
      "Epoch: 0 | Iteration: 35365 | Classification loss: 0.33568 | Regression loss: 0.72233 | Running loss: 0.88443\n",
      "Epoch: 0 | Iteration: 35366 | Classification loss: 0.33411 | Regression loss: 0.33644 | Running loss: 0.88336\n",
      "Epoch: 0 | Iteration: 35367 | Classification loss: 0.42500 | Regression loss: 0.59810 | Running loss: 0.88378\n",
      "Epoch: 0 | Iteration: 35368 | Classification loss: 0.42027 | Regression loss: 0.47494 | Running loss: 0.88359\n",
      "Epoch: 0 | Iteration: 35369 | Classification loss: 0.20979 | Regression loss: 0.29722 | Running loss: 0.88289\n",
      "Epoch: 0 | Iteration: 35370 | Classification loss: 0.35367 | Regression loss: 0.57485 | Running loss: 0.88247\n",
      "Epoch: 0 | Iteration: 35371 | Classification loss: 0.40699 | Regression loss: 0.67775 | Running loss: 0.88308\n",
      "Epoch: 0 | Iteration: 35372 | Classification loss: 0.26482 | Regression loss: 0.50569 | Running loss: 0.88320\n",
      "Epoch: 0 | Iteration: 35373 | Classification loss: 0.36978 | Regression loss: 0.61401 | Running loss: 0.88362\n",
      "Epoch: 0 | Iteration: 35374 | Classification loss: 0.35455 | Regression loss: 0.47196 | Running loss: 0.88445\n",
      "Epoch: 0 | Iteration: 35375 | Classification loss: 0.41310 | Regression loss: 0.42572 | Running loss: 0.88401\n",
      "Epoch: 0 | Iteration: 35376 | Classification loss: 0.59550 | Regression loss: 0.47203 | Running loss: 0.88433\n",
      "Epoch: 0 | Iteration: 35377 | Classification loss: 0.60330 | Regression loss: 0.48080 | Running loss: 0.88471\n",
      "Epoch: 0 | Iteration: 35378 | Classification loss: 0.33554 | Regression loss: 0.38478 | Running loss: 0.88398\n",
      "Epoch: 0 | Iteration: 35379 | Classification loss: 0.29283 | Regression loss: 0.68182 | Running loss: 0.88424\n",
      "Epoch: 0 | Iteration: 35380 | Classification loss: 0.44748 | Regression loss: 0.29491 | Running loss: 0.88420\n",
      "Epoch: 0 | Iteration: 35381 | Classification loss: 0.25697 | Regression loss: 0.33185 | Running loss: 0.88389\n",
      "Epoch: 0 | Iteration: 35382 | Classification loss: 0.24313 | Regression loss: 0.38934 | Running loss: 0.88416\n",
      "Epoch: 0 | Iteration: 35383 | Classification loss: 0.19421 | Regression loss: 0.31754 | Running loss: 0.88368\n",
      "Epoch: 0 | Iteration: 35384 | Classification loss: 0.44549 | Regression loss: 0.33929 | Running loss: 0.88349\n",
      "Epoch: 0 | Iteration: 35385 | Classification loss: 0.31445 | Regression loss: 0.48380 | Running loss: 0.88319\n",
      "Epoch: 0 | Iteration: 35386 | Classification loss: 0.53045 | Regression loss: 0.50677 | Running loss: 0.88415\n",
      "Epoch: 0 | Iteration: 35387 | Classification loss: 0.43666 | Regression loss: 0.59761 | Running loss: 0.88381\n",
      "Epoch: 0 | Iteration: 35388 | Classification loss: 0.22259 | Regression loss: 0.45889 | Running loss: 0.88288\n",
      "Epoch: 0 | Iteration: 35389 | Classification loss: 0.48001 | Regression loss: 0.61143 | Running loss: 0.88306\n",
      "Epoch: 0 | Iteration: 35390 | Classification loss: 0.22917 | Regression loss: 0.31248 | Running loss: 0.88208\n",
      "Epoch: 0 | Iteration: 35391 | Classification loss: 0.17081 | Regression loss: 0.31640 | Running loss: 0.88153\n",
      "Epoch: 0 | Iteration: 35392 | Classification loss: 0.42583 | Regression loss: 0.33860 | Running loss: 0.87973\n",
      "Epoch: 0 | Iteration: 35393 | Classification loss: 0.28926 | Regression loss: 0.42052 | Running loss: 0.87899\n",
      "Epoch: 0 | Iteration: 35394 | Classification loss: 0.25051 | Regression loss: 0.41311 | Running loss: 0.87829\n",
      "Epoch: 0 | Iteration: 35395 | Classification loss: 0.33523 | Regression loss: 0.36208 | Running loss: 0.87731\n",
      "Epoch: 0 | Iteration: 35396 | Classification loss: 0.68282 | Regression loss: 0.63661 | Running loss: 0.87867\n",
      "Epoch: 0 | Iteration: 35397 | Classification loss: 0.32681 | Regression loss: 0.61618 | Running loss: 0.87905\n",
      "Epoch: 0 | Iteration: 35398 | Classification loss: 0.36085 | Regression loss: 0.54766 | Running loss: 0.87863\n",
      "Epoch: 0 | Iteration: 35399 | Classification loss: 0.36080 | Regression loss: 0.30081 | Running loss: 0.87824\n",
      "Epoch: 0 | Iteration: 35400 | Classification loss: 0.28289 | Regression loss: 0.50057 | Running loss: 0.87768\n",
      "Epoch: 0 | Iteration: 35401 | Classification loss: 0.52955 | Regression loss: 0.65644 | Running loss: 0.87823\n",
      "Epoch: 0 | Iteration: 35402 | Classification loss: 0.24700 | Regression loss: 0.51470 | Running loss: 0.87787\n",
      "Epoch: 0 | Iteration: 35403 | Classification loss: 0.36216 | Regression loss: 0.58471 | Running loss: 0.87817\n",
      "Epoch: 0 | Iteration: 35404 | Classification loss: 0.47736 | Regression loss: 0.58192 | Running loss: 0.87818\n",
      "Epoch: 0 | Iteration: 35405 | Classification loss: 0.35102 | Regression loss: 0.56596 | Running loss: 0.87864\n",
      "Epoch: 0 | Iteration: 35406 | Classification loss: 0.35501 | Regression loss: 0.30826 | Running loss: 0.87844\n",
      "Epoch: 0 | Iteration: 35407 | Classification loss: 0.24127 | Regression loss: 0.36927 | Running loss: 0.87792\n",
      "Epoch: 0 | Iteration: 35408 | Classification loss: 0.23546 | Regression loss: 0.49937 | Running loss: 0.87743\n",
      "Epoch: 0 | Iteration: 35409 | Classification loss: 0.30000 | Regression loss: 0.39268 | Running loss: 0.87717\n",
      "Epoch: 0 | Iteration: 35410 | Classification loss: 0.61619 | Regression loss: 0.43947 | Running loss: 0.87797\n",
      "Epoch: 0 | Iteration: 35411 | Classification loss: 0.11175 | Regression loss: 0.32255 | Running loss: 0.87757\n",
      "Epoch: 0 | Iteration: 35412 | Classification loss: 0.43371 | Regression loss: 0.49180 | Running loss: 0.87793\n",
      "Epoch: 0 | Iteration: 35413 | Classification loss: 0.25539 | Regression loss: 0.38540 | Running loss: 0.87679\n",
      "Epoch: 0 | Iteration: 35414 | Classification loss: 0.15721 | Regression loss: 0.34400 | Running loss: 0.87614\n",
      "Epoch: 0 | Iteration: 35415 | Classification loss: 0.31296 | Regression loss: 0.59907 | Running loss: 0.87592\n",
      "Epoch: 0 | Iteration: 35416 | Classification loss: 0.23293 | Regression loss: 0.36773 | Running loss: 0.87518\n",
      "Epoch: 0 | Iteration: 35417 | Classification loss: 0.42499 | Regression loss: 0.59192 | Running loss: 0.87538\n",
      "Epoch: 0 | Iteration: 35418 | Classification loss: 0.21208 | Regression loss: 0.42930 | Running loss: 0.87519\n",
      "Epoch: 0 | Iteration: 35419 | Classification loss: 0.45857 | Regression loss: 0.63930 | Running loss: 0.87617\n",
      "Epoch: 0 | Iteration: 35420 | Classification loss: 0.48247 | Regression loss: 0.82589 | Running loss: 0.87821\n",
      "Epoch: 0 | Iteration: 35421 | Classification loss: 0.47387 | Regression loss: 0.51834 | Running loss: 0.87858\n",
      "Epoch: 0 | Iteration: 35422 | Classification loss: 0.18110 | Regression loss: 0.38678 | Running loss: 0.87818\n",
      "Epoch: 0 | Iteration: 35423 | Classification loss: 0.15312 | Regression loss: 0.31800 | Running loss: 0.87603\n",
      "Epoch: 0 | Iteration: 35424 | Classification loss: 0.18523 | Regression loss: 0.41801 | Running loss: 0.87585\n",
      "Epoch: 0 | Iteration: 35425 | Classification loss: 0.49632 | Regression loss: 0.46846 | Running loss: 0.87617\n",
      "Epoch: 0 | Iteration: 35426 | Classification loss: 0.28277 | Regression loss: 0.40492 | Running loss: 0.87592\n",
      "Epoch: 0 | Iteration: 35427 | Classification loss: 0.32949 | Regression loss: 0.47553 | Running loss: 0.87557\n",
      "Epoch: 0 | Iteration: 35428 | Classification loss: 0.33014 | Regression loss: 0.57964 | Running loss: 0.87619\n",
      "Epoch: 0 | Iteration: 35429 | Classification loss: 0.36232 | Regression loss: 0.47786 | Running loss: 0.87582\n",
      "Epoch: 0 | Iteration: 35430 | Classification loss: 0.43021 | Regression loss: 0.53294 | Running loss: 0.87582\n",
      "Epoch: 0 | Iteration: 35431 | Classification loss: 0.46527 | Regression loss: 0.53280 | Running loss: 0.87646\n",
      "Epoch: 0 | Iteration: 35432 | Classification loss: 0.46655 | Regression loss: 0.67033 | Running loss: 0.87729\n",
      "Epoch: 0 | Iteration: 35433 | Classification loss: 0.28318 | Regression loss: 0.49401 | Running loss: 0.87688\n",
      "Epoch: 0 | Iteration: 35434 | Classification loss: 0.39183 | Regression loss: 0.47291 | Running loss: 0.87666\n",
      "Epoch: 0 | Iteration: 35435 | Classification loss: 0.38356 | Regression loss: 0.60986 | Running loss: 0.87749\n",
      "Epoch: 0 | Iteration: 35436 | Classification loss: 0.21151 | Regression loss: 0.39109 | Running loss: 0.87723\n",
      "Epoch: 0 | Iteration: 35437 | Classification loss: 0.42642 | Regression loss: 0.56398 | Running loss: 0.87784\n",
      "Epoch: 0 | Iteration: 35438 | Classification loss: 0.44964 | Regression loss: 0.75652 | Running loss: 0.87833\n",
      "Epoch: 0 | Iteration: 35439 | Classification loss: 0.40713 | Regression loss: 0.19157 | Running loss: 0.87829\n",
      "Epoch: 0 | Iteration: 35440 | Classification loss: 0.39160 | Regression loss: 0.41608 | Running loss: 0.87814\n",
      "Epoch: 0 | Iteration: 35441 | Classification loss: 0.31301 | Regression loss: 0.39945 | Running loss: 0.87828\n",
      "Epoch: 0 | Iteration: 35442 | Classification loss: 0.23494 | Regression loss: 0.45874 | Running loss: 0.87775\n",
      "Epoch: 0 | Iteration: 35443 | Classification loss: 0.67216 | Regression loss: 0.49379 | Running loss: 0.87803\n",
      "Epoch: 0 | Iteration: 35444 | Classification loss: 0.29678 | Regression loss: 0.32585 | Running loss: 0.87687\n",
      "Epoch: 0 | Iteration: 35445 | Classification loss: 0.42676 | Regression loss: 0.52085 | Running loss: 0.87704\n",
      "Epoch: 0 | Iteration: 35446 | Classification loss: 0.34034 | Regression loss: 0.48370 | Running loss: 0.87604\n",
      "Epoch: 0 | Iteration: 35447 | Classification loss: 0.43155 | Regression loss: 0.56861 | Running loss: 0.87683\n",
      "Epoch: 0 | Iteration: 35448 | Classification loss: 0.35049 | Regression loss: 0.41002 | Running loss: 0.87672\n",
      "Epoch: 0 | Iteration: 35449 | Classification loss: 0.40601 | Regression loss: 0.56374 | Running loss: 0.87730\n",
      "Epoch: 0 | Iteration: 35450 | Classification loss: 0.43950 | Regression loss: 0.48787 | Running loss: 0.87770\n",
      "Epoch: 0 | Iteration: 35451 | Classification loss: 0.41668 | Regression loss: 0.57509 | Running loss: 0.87822\n",
      "Epoch: 0 | Iteration: 35452 | Classification loss: 0.38002 | Regression loss: 0.35993 | Running loss: 0.87866\n",
      "Epoch: 0 | Iteration: 35453 | Classification loss: 0.52718 | Regression loss: 0.50546 | Running loss: 0.87934\n",
      "Epoch: 0 | Iteration: 35454 | Classification loss: 0.29003 | Regression loss: 0.43447 | Running loss: 0.87932\n",
      "Epoch: 0 | Iteration: 35455 | Classification loss: 0.28311 | Regression loss: 0.50189 | Running loss: 0.87932\n",
      "Epoch: 0 | Iteration: 35456 | Classification loss: 0.40570 | Regression loss: 0.66056 | Running loss: 0.87933\n",
      "Epoch: 0 | Iteration: 35457 | Classification loss: 0.45634 | Regression loss: 0.55292 | Running loss: 0.87981\n",
      "Epoch: 0 | Iteration: 35458 | Classification loss: 0.24899 | Regression loss: 0.42483 | Running loss: 0.88009\n",
      "Epoch: 0 | Iteration: 35459 | Classification loss: 0.30464 | Regression loss: 0.40390 | Running loss: 0.88039\n",
      "Epoch: 0 | Iteration: 35460 | Classification loss: 0.40903 | Regression loss: 0.61322 | Running loss: 0.88139\n",
      "Epoch: 0 | Iteration: 35461 | Classification loss: 0.41399 | Regression loss: 0.52191 | Running loss: 0.88113\n",
      "Epoch: 0 | Iteration: 35462 | Classification loss: 0.45962 | Regression loss: 0.62497 | Running loss: 0.88215\n",
      "Epoch: 0 | Iteration: 35463 | Classification loss: 0.29578 | Regression loss: 0.40575 | Running loss: 0.88176\n",
      "Epoch: 0 | Iteration: 35464 | Classification loss: 0.17488 | Regression loss: 0.31755 | Running loss: 0.87935\n",
      "Epoch: 0 | Iteration: 35465 | Classification loss: 0.44881 | Regression loss: 0.63634 | Running loss: 0.87943\n",
      "Epoch: 0 | Iteration: 35466 | Classification loss: 0.67457 | Regression loss: 0.49017 | Running loss: 0.87987\n",
      "Epoch: 0 | Iteration: 35467 | Classification loss: 0.44243 | Regression loss: 0.69715 | Running loss: 0.88077\n",
      "Epoch: 0 | Iteration: 35468 | Classification loss: 0.35666 | Regression loss: 0.47172 | Running loss: 0.88153\n",
      "Epoch: 0 | Iteration: 35469 | Classification loss: 0.39951 | Regression loss: 0.41153 | Running loss: 0.88108\n",
      "Epoch: 0 | Iteration: 35470 | Classification loss: 0.45232 | Regression loss: 0.50467 | Running loss: 0.88121\n",
      "Epoch: 0 | Iteration: 35471 | Classification loss: 0.39743 | Regression loss: 0.36699 | Running loss: 0.88107\n",
      "Epoch: 0 | Iteration: 35472 | Classification loss: 0.25471 | Regression loss: 0.33688 | Running loss: 0.88101\n",
      "Epoch: 0 | Iteration: 35473 | Classification loss: 0.39965 | Regression loss: 0.56814 | Running loss: 0.88134\n",
      "Epoch: 0 | Iteration: 35474 | Classification loss: 0.35813 | Regression loss: 0.41650 | Running loss: 0.88102\n",
      "Epoch: 0 | Iteration: 35475 | Classification loss: 0.47940 | Regression loss: 0.45121 | Running loss: 0.88161\n",
      "Epoch: 0 | Iteration: 35476 | Classification loss: 0.44827 | Regression loss: 0.48927 | Running loss: 0.88163\n",
      "Epoch: 0 | Iteration: 35477 | Classification loss: 0.27140 | Regression loss: 0.47756 | Running loss: 0.88063\n",
      "Epoch: 0 | Iteration: 35478 | Classification loss: 0.59917 | Regression loss: 0.69827 | Running loss: 0.88196\n",
      "Epoch: 0 | Iteration: 35479 | Classification loss: 0.30867 | Regression loss: 0.50488 | Running loss: 0.88145\n",
      "Epoch: 0 | Iteration: 35480 | Classification loss: 0.37490 | Regression loss: 0.31293 | Running loss: 0.88087\n",
      "Epoch: 0 | Iteration: 35481 | Classification loss: 0.60515 | Regression loss: 0.47825 | Running loss: 0.87805\n",
      "Epoch: 0 | Iteration: 35482 | Classification loss: 0.28822 | Regression loss: 0.63665 | Running loss: 0.87805\n",
      "Epoch: 0 | Iteration: 35483 | Classification loss: 0.35394 | Regression loss: 0.56490 | Running loss: 0.87767\n",
      "Epoch: 0 | Iteration: 35484 | Classification loss: 0.30432 | Regression loss: 0.61870 | Running loss: 0.87770\n",
      "Epoch: 0 | Iteration: 35485 | Classification loss: 0.25266 | Regression loss: 0.48247 | Running loss: 0.87707\n",
      "Epoch: 0 | Iteration: 35486 | Classification loss: 0.36240 | Regression loss: 0.44192 | Running loss: 0.87745\n",
      "Epoch: 0 | Iteration: 35487 | Classification loss: 0.32553 | Regression loss: 0.48115 | Running loss: 0.87722\n",
      "Epoch: 0 | Iteration: 35488 | Classification loss: 0.42724 | Regression loss: 0.37496 | Running loss: 0.87683\n",
      "Epoch: 0 | Iteration: 35489 | Classification loss: 0.37167 | Regression loss: 0.36209 | Running loss: 0.87707\n",
      "Epoch: 0 | Iteration: 35490 | Classification loss: 0.29770 | Regression loss: 0.34712 | Running loss: 0.87676\n",
      "Epoch: 0 | Iteration: 35491 | Classification loss: 0.28464 | Regression loss: 0.50024 | Running loss: 0.87661\n",
      "Epoch: 0 | Iteration: 35492 | Classification loss: 0.45562 | Regression loss: 0.48303 | Running loss: 0.87638\n",
      "Epoch: 0 | Iteration: 35493 | Classification loss: 0.46605 | Regression loss: 0.49464 | Running loss: 0.87616\n",
      "Epoch: 0 | Iteration: 35494 | Classification loss: 0.47657 | Regression loss: 0.54932 | Running loss: 0.87593\n",
      "Epoch: 0 | Iteration: 35495 | Classification loss: 0.30110 | Regression loss: 0.57051 | Running loss: 0.87596\n",
      "Epoch: 0 | Iteration: 35496 | Classification loss: 0.29537 | Regression loss: 0.45022 | Running loss: 0.87513\n",
      "Epoch: 0 | Iteration: 35497 | Classification loss: 0.32514 | Regression loss: 0.46061 | Running loss: 0.87432\n",
      "Epoch: 0 | Iteration: 35498 | Classification loss: 0.52378 | Regression loss: 0.69400 | Running loss: 0.87554\n",
      "Epoch: 0 | Iteration: 35499 | Classification loss: 0.33526 | Regression loss: 0.60217 | Running loss: 0.87550\n",
      "Epoch: 0 | Iteration: 35500 | Classification loss: 0.68704 | Regression loss: 0.50692 | Running loss: 0.87663\n",
      "Epoch: 0 | Iteration: 35501 | Classification loss: 0.19516 | Regression loss: 0.36842 | Running loss: 0.87685\n",
      "Epoch: 0 | Iteration: 35502 | Classification loss: 0.47889 | Regression loss: 0.55321 | Running loss: 0.87684\n",
      "Epoch: 0 | Iteration: 35503 | Classification loss: 0.41104 | Regression loss: 0.54115 | Running loss: 0.87716\n",
      "Epoch: 0 | Iteration: 35504 | Classification loss: 0.24289 | Regression loss: 0.39567 | Running loss: 0.87757\n",
      "Epoch: 0 | Iteration: 35505 | Classification loss: 0.32274 | Regression loss: 0.45950 | Running loss: 0.87709\n",
      "Epoch: 0 | Iteration: 35506 | Classification loss: 0.23944 | Regression loss: 0.50768 | Running loss: 0.87702\n",
      "Epoch: 0 | Iteration: 35507 | Classification loss: 0.35880 | Regression loss: 0.72710 | Running loss: 0.87793\n",
      "Epoch: 0 | Iteration: 35508 | Classification loss: 0.24158 | Regression loss: 0.36452 | Running loss: 0.87691\n",
      "Epoch: 0 | Iteration: 35509 | Classification loss: 0.46038 | Regression loss: 0.63898 | Running loss: 0.87750\n",
      "Epoch: 0 | Iteration: 35510 | Classification loss: 0.29040 | Regression loss: 0.41580 | Running loss: 0.87689\n",
      "Epoch: 0 | Iteration: 35511 | Classification loss: 0.49774 | Regression loss: 0.10376 | Running loss: 0.87518\n",
      "Epoch: 0 | Iteration: 35512 | Classification loss: 0.21738 | Regression loss: 0.39654 | Running loss: 0.87475\n",
      "Epoch: 0 | Iteration: 35513 | Classification loss: 0.29945 | Regression loss: 0.25481 | Running loss: 0.87310\n",
      "Epoch: 0 | Iteration: 35514 | Classification loss: 0.65027 | Regression loss: 0.62387 | Running loss: 0.87403\n",
      "Epoch: 0 | Iteration: 35515 | Classification loss: 0.11601 | Regression loss: 0.29794 | Running loss: 0.87312\n",
      "Epoch: 0 | Iteration: 35516 | Classification loss: 0.35379 | Regression loss: 0.63365 | Running loss: 0.87450\n",
      "Epoch: 0 | Iteration: 35517 | Classification loss: 0.15979 | Regression loss: 0.35655 | Running loss: 0.87405\n",
      "Epoch: 0 | Iteration: 35518 | Classification loss: 0.49566 | Regression loss: 0.51320 | Running loss: 0.87461\n",
      "Epoch: 0 | Iteration: 35519 | Classification loss: 0.51272 | Regression loss: 0.52330 | Running loss: 0.87006\n",
      "Epoch: 0 | Iteration: 35520 | Classification loss: 0.11944 | Regression loss: 0.33582 | Running loss: 0.86967\n",
      "Epoch: 0 | Iteration: 35521 | Classification loss: 0.47161 | Regression loss: 0.66155 | Running loss: 0.86988\n",
      "Epoch: 0 | Iteration: 35522 | Classification loss: 0.38670 | Regression loss: 0.36463 | Running loss: 0.86918\n",
      "Epoch: 0 | Iteration: 35523 | Classification loss: 0.29119 | Regression loss: 0.39442 | Running loss: 0.86762\n",
      "Epoch: 0 | Iteration: 35524 | Classification loss: 0.27579 | Regression loss: 0.44574 | Running loss: 0.86595\n",
      "Epoch: 0 | Iteration: 35525 | Classification loss: 0.45699 | Regression loss: 0.43600 | Running loss: 0.86563\n",
      "Epoch: 0 | Iteration: 35526 | Classification loss: 0.27026 | Regression loss: 0.50543 | Running loss: 0.86525\n",
      "Epoch: 0 | Iteration: 35527 | Classification loss: 0.37761 | Regression loss: 0.53756 | Running loss: 0.86567\n",
      "Epoch: 0 | Iteration: 35528 | Classification loss: 0.31225 | Regression loss: 0.48466 | Running loss: 0.86523\n",
      "Epoch: 0 | Iteration: 35529 | Classification loss: 0.52189 | Regression loss: 0.49002 | Running loss: 0.86531\n",
      "Epoch: 0 | Iteration: 35530 | Classification loss: 0.50388 | Regression loss: 0.15555 | Running loss: 0.86503\n",
      "Epoch: 0 | Iteration: 35531 | Classification loss: 0.42310 | Regression loss: 0.61095 | Running loss: 0.86462\n",
      "Epoch: 0 | Iteration: 35532 | Classification loss: 0.46284 | Regression loss: 0.44449 | Running loss: 0.86477\n",
      "Epoch: 0 | Iteration: 35533 | Classification loss: 0.29554 | Regression loss: 0.41444 | Running loss: 0.86391\n",
      "Epoch: 0 | Iteration: 35534 | Classification loss: 0.19570 | Regression loss: 0.31514 | Running loss: 0.86327\n",
      "Epoch: 0 | Iteration: 35535 | Classification loss: 0.07615 | Regression loss: 0.09920 | Running loss: 0.86215\n",
      "Epoch: 0 | Iteration: 35536 | Classification loss: 0.36278 | Regression loss: 0.53295 | Running loss: 0.86230\n",
      "Epoch: 0 | Iteration: 35537 | Classification loss: 0.39869 | Regression loss: 0.56300 | Running loss: 0.86240\n",
      "Epoch: 0 | Iteration: 35538 | Classification loss: 0.85256 | Regression loss: 0.67084 | Running loss: 0.86437\n",
      "Epoch: 0 | Iteration: 35539 | Classification loss: 0.37061 | Regression loss: 0.54739 | Running loss: 0.86377\n",
      "Epoch: 0 | Iteration: 35540 | Classification loss: 0.66487 | Regression loss: 0.32910 | Running loss: 0.86433\n",
      "Epoch: 0 | Iteration: 35541 | Classification loss: 0.33194 | Regression loss: 0.62040 | Running loss: 0.86447\n",
      "Epoch: 0 | Iteration: 35542 | Classification loss: 0.35676 | Regression loss: 0.53707 | Running loss: 0.86490\n",
      "Epoch: 0 | Iteration: 35543 | Classification loss: 0.33818 | Regression loss: 0.54069 | Running loss: 0.86431\n",
      "Epoch: 0 | Iteration: 35544 | Classification loss: 0.48069 | Regression loss: 0.58097 | Running loss: 0.86401\n",
      "Epoch: 0 | Iteration: 35545 | Classification loss: 0.36827 | Regression loss: 0.39569 | Running loss: 0.86404\n",
      "Epoch: 0 | Iteration: 35546 | Classification loss: 0.61185 | Regression loss: 0.45121 | Running loss: 0.86362\n",
      "Epoch: 0 | Iteration: 35547 | Classification loss: 0.07567 | Regression loss: 0.19012 | Running loss: 0.86170\n",
      "Epoch: 0 | Iteration: 35548 | Classification loss: 0.33334 | Regression loss: 0.38438 | Running loss: 0.86128\n",
      "Epoch: 0 | Iteration: 35549 | Classification loss: 0.30766 | Regression loss: 0.43858 | Running loss: 0.86118\n",
      "Epoch: 0 | Iteration: 35550 | Classification loss: 0.33275 | Regression loss: 0.38707 | Running loss: 0.86108\n",
      "Epoch: 0 | Iteration: 35551 | Classification loss: 0.58176 | Regression loss: 0.71746 | Running loss: 0.86188\n",
      "Epoch: 0 | Iteration: 35552 | Classification loss: 0.39718 | Regression loss: 0.66158 | Running loss: 0.86240\n",
      "Epoch: 0 | Iteration: 35553 | Classification loss: 0.42824 | Regression loss: 0.56625 | Running loss: 0.86215\n",
      "Epoch: 0 | Iteration: 35554 | Classification loss: 0.34206 | Regression loss: 0.54466 | Running loss: 0.86272\n",
      "Epoch: 0 | Iteration: 35555 | Classification loss: 0.82455 | Regression loss: 0.12288 | Running loss: 0.86257\n",
      "Epoch: 0 | Iteration: 35556 | Classification loss: 0.34085 | Regression loss: 0.50897 | Running loss: 0.86280\n",
      "Epoch: 0 | Iteration: 35557 | Classification loss: 0.21253 | Regression loss: 0.37716 | Running loss: 0.86274\n",
      "Epoch: 0 | Iteration: 35558 | Classification loss: 0.22778 | Regression loss: 0.42873 | Running loss: 0.86320\n",
      "Epoch: 0 | Iteration: 35559 | Classification loss: 0.32345 | Regression loss: 0.45947 | Running loss: 0.86284\n",
      "Epoch: 0 | Iteration: 35560 | Classification loss: 0.22816 | Regression loss: 0.33578 | Running loss: 0.86230\n",
      "Epoch: 0 | Iteration: 35561 | Classification loss: 0.16587 | Regression loss: 0.44659 | Running loss: 0.86159\n",
      "Epoch: 0 | Iteration: 35562 | Classification loss: 0.34889 | Regression loss: 0.56946 | Running loss: 0.86219\n",
      "Epoch: 0 | Iteration: 35563 | Classification loss: 0.13614 | Regression loss: 0.08001 | Running loss: 0.86107\n",
      "Epoch: 0 | Iteration: 35564 | Classification loss: 0.19601 | Regression loss: 0.35003 | Running loss: 0.85999\n",
      "Epoch: 0 | Iteration: 35565 | Classification loss: 0.17366 | Regression loss: 0.35133 | Running loss: 0.85999\n",
      "Epoch: 0 | Iteration: 35566 | Classification loss: 0.79186 | Regression loss: 0.62576 | Running loss: 0.86020\n",
      "Epoch: 0 | Iteration: 35567 | Classification loss: 0.45338 | Regression loss: 0.30618 | Running loss: 0.86056\n",
      "Epoch: 0 | Iteration: 35568 | Classification loss: 0.81672 | Regression loss: 0.61431 | Running loss: 0.86179\n",
      "Epoch: 0 | Iteration: 35569 | Classification loss: 0.35762 | Regression loss: 0.68568 | Running loss: 0.86137\n",
      "Epoch: 0 | Iteration: 35570 | Classification loss: 0.19257 | Regression loss: 0.46552 | Running loss: 0.86076\n",
      "Epoch: 0 | Iteration: 35571 | Classification loss: 0.39052 | Regression loss: 0.38077 | Running loss: 0.86030\n",
      "Epoch: 0 | Iteration: 35572 | Classification loss: 0.31181 | Regression loss: 0.34039 | Running loss: 0.86037\n",
      "Epoch: 0 | Iteration: 35573 | Classification loss: 0.35216 | Regression loss: 0.33635 | Running loss: 0.86072\n",
      "Epoch: 0 | Iteration: 35574 | Classification loss: 0.56896 | Regression loss: 0.65480 | Running loss: 0.86130\n",
      "Epoch: 0 | Iteration: 35575 | Classification loss: 0.31972 | Regression loss: 0.44551 | Running loss: 0.86115\n",
      "Epoch: 0 | Iteration: 35576 | Classification loss: 0.57830 | Regression loss: 0.62876 | Running loss: 0.86182\n",
      "Epoch: 0 | Iteration: 35577 | Classification loss: 0.31079 | Regression loss: 0.48997 | Running loss: 0.86128\n",
      "Epoch: 0 | Iteration: 35578 | Classification loss: 0.37340 | Regression loss: 0.46067 | Running loss: 0.86108\n",
      "Epoch: 0 | Iteration: 35579 | Classification loss: 0.17294 | Regression loss: 0.23305 | Running loss: 0.86031\n",
      "Epoch: 0 | Iteration: 35580 | Classification loss: 0.33443 | Regression loss: 0.27294 | Running loss: 0.85989\n",
      "Epoch: 0 | Iteration: 35581 | Classification loss: 0.29477 | Regression loss: 0.43314 | Running loss: 0.85986\n",
      "Epoch: 0 | Iteration: 35582 | Classification loss: 0.25980 | Regression loss: 0.44977 | Running loss: 0.85981\n",
      "Epoch: 0 | Iteration: 35583 | Classification loss: 0.23375 | Regression loss: 0.31317 | Running loss: 0.85898\n",
      "Epoch: 0 | Iteration: 35584 | Classification loss: 0.35168 | Regression loss: 0.44316 | Running loss: 0.85901\n",
      "Epoch: 0 | Iteration: 35585 | Classification loss: 0.49932 | Regression loss: 0.45926 | Running loss: 0.85926\n",
      "Epoch: 0 | Iteration: 35586 | Classification loss: 0.50630 | Regression loss: 0.41852 | Running loss: 0.85966\n",
      "Epoch: 0 | Iteration: 35587 | Classification loss: 0.17847 | Regression loss: 0.40924 | Running loss: 0.85879\n",
      "Epoch: 0 | Iteration: 35588 | Classification loss: 0.39951 | Regression loss: 0.52884 | Running loss: 0.85927\n",
      "Epoch: 0 | Iteration: 35589 | Classification loss: 0.55176 | Regression loss: 0.64234 | Running loss: 0.86062\n",
      "Epoch: 0 | Iteration: 35590 | Classification loss: 0.24573 | Regression loss: 0.49672 | Running loss: 0.86031\n",
      "Epoch: 0 | Iteration: 35591 | Classification loss: 0.20312 | Regression loss: 0.14616 | Running loss: 0.85960\n",
      "Epoch: 0 | Iteration: 35592 | Classification loss: 0.18820 | Regression loss: 0.43235 | Running loss: 0.85934\n",
      "Epoch: 0 | Iteration: 35593 | Classification loss: 0.30589 | Regression loss: 0.50543 | Running loss: 0.85923\n",
      "Epoch: 0 | Iteration: 35594 | Classification loss: 0.35951 | Regression loss: 0.44659 | Running loss: 0.85939\n",
      "Epoch: 0 | Iteration: 35595 | Classification loss: 0.20823 | Regression loss: 0.33585 | Running loss: 0.85889\n",
      "Epoch: 0 | Iteration: 35596 | Classification loss: 0.23371 | Regression loss: 0.31708 | Running loss: 0.85856\n",
      "Epoch: 0 | Iteration: 35597 | Classification loss: 0.37186 | Regression loss: 0.30374 | Running loss: 0.85871\n",
      "Epoch: 0 | Iteration: 35598 | Classification loss: 0.35398 | Regression loss: 0.67792 | Running loss: 0.85888\n",
      "Epoch: 0 | Iteration: 35599 | Classification loss: 0.35051 | Regression loss: 0.42630 | Running loss: 0.85883\n",
      "Epoch: 0 | Iteration: 35600 | Classification loss: 0.33304 | Regression loss: 0.55607 | Running loss: 0.85913\n",
      "Epoch: 0 | Iteration: 35601 | Classification loss: 0.30270 | Regression loss: 0.43476 | Running loss: 0.85897\n",
      "Epoch: 0 | Iteration: 35602 | Classification loss: 0.63873 | Regression loss: 0.60239 | Running loss: 0.86029\n",
      "Epoch: 0 | Iteration: 35603 | Classification loss: 0.36998 | Regression loss: 0.65216 | Running loss: 0.86116\n",
      "Epoch: 0 | Iteration: 35604 | Classification loss: 0.29994 | Regression loss: 0.52950 | Running loss: 0.86153\n",
      "Epoch: 0 | Iteration: 35605 | Classification loss: 0.37884 | Regression loss: 0.36051 | Running loss: 0.86135\n",
      "Epoch: 0 | Iteration: 35606 | Classification loss: 0.49337 | Regression loss: 0.49282 | Running loss: 0.86065\n",
      "Epoch: 0 | Iteration: 35607 | Classification loss: 0.38055 | Regression loss: 0.57394 | Running loss: 0.86035\n",
      "Epoch: 0 | Iteration: 35608 | Classification loss: 0.47572 | Regression loss: 0.56158 | Running loss: 0.86091\n",
      "Epoch: 0 | Iteration: 35609 | Classification loss: 0.38913 | Regression loss: 0.60063 | Running loss: 0.86135\n",
      "Epoch: 0 | Iteration: 35610 | Classification loss: 0.33666 | Regression loss: 0.40669 | Running loss: 0.86118\n",
      "Epoch: 0 | Iteration: 35611 | Classification loss: 0.49019 | Regression loss: 0.66229 | Running loss: 0.86169\n",
      "Epoch: 0 | Iteration: 35612 | Classification loss: 0.37348 | Regression loss: 0.57759 | Running loss: 0.86191\n",
      "Epoch: 0 | Iteration: 35613 | Classification loss: 0.44073 | Regression loss: 0.44836 | Running loss: 0.86189\n",
      "Epoch: 0 | Iteration: 35614 | Classification loss: 0.58515 | Regression loss: 0.59258 | Running loss: 0.86311\n",
      "Epoch: 0 | Iteration: 35615 | Classification loss: 0.33762 | Regression loss: 0.26673 | Running loss: 0.86310\n",
      "Epoch: 0 | Iteration: 35616 | Classification loss: 0.21044 | Regression loss: 0.41937 | Running loss: 0.86303\n",
      "Epoch: 0 | Iteration: 35617 | Classification loss: 0.31196 | Regression loss: 0.63826 | Running loss: 0.86217\n",
      "Epoch: 0 | Iteration: 35618 | Classification loss: 0.34948 | Regression loss: 0.50881 | Running loss: 0.86216\n",
      "Epoch: 0 | Iteration: 35619 | Classification loss: 0.45906 | Regression loss: 0.47436 | Running loss: 0.86270\n",
      "Epoch: 0 | Iteration: 35620 | Classification loss: 4.91768 | Regression loss: 0.25727 | Running loss: 0.87166\n",
      "Epoch: 0 | Iteration: 35621 | Classification loss: 0.45506 | Regression loss: 0.46303 | Running loss: 0.87237\n",
      "Epoch: 0 | Iteration: 35622 | Classification loss: 0.45977 | Regression loss: 0.73948 | Running loss: 0.87344\n",
      "Epoch: 0 | Iteration: 35623 | Classification loss: 0.20267 | Regression loss: 0.54548 | Running loss: 0.87290\n",
      "Epoch: 0 | Iteration: 35624 | Classification loss: 0.22267 | Regression loss: 0.35664 | Running loss: 0.87264\n",
      "Epoch: 0 | Iteration: 35625 | Classification loss: 0.46915 | Regression loss: 0.60922 | Running loss: 0.87274\n",
      "Epoch: 0 | Iteration: 35626 | Classification loss: 0.23877 | Regression loss: 0.46692 | Running loss: 0.87280\n",
      "Epoch: 0 | Iteration: 35627 | Classification loss: 0.45116 | Regression loss: 0.49051 | Running loss: 0.87258\n",
      "Epoch: 0 | Iteration: 35628 | Classification loss: 0.36068 | Regression loss: 0.34683 | Running loss: 0.87147\n",
      "Epoch: 0 | Iteration: 35629 | Classification loss: 0.30098 | Regression loss: 0.49760 | Running loss: 0.87220\n",
      "Epoch: 0 | Iteration: 35630 | Classification loss: 0.75970 | Regression loss: 0.80411 | Running loss: 0.87422\n",
      "Epoch: 0 | Iteration: 35631 | Classification loss: 0.30039 | Regression loss: 0.33055 | Running loss: 0.87333\n",
      "Epoch: 0 | Iteration: 35632 | Classification loss: 0.55868 | Regression loss: 0.50500 | Running loss: 0.87365\n",
      "Epoch: 0 | Iteration: 35633 | Classification loss: 0.58187 | Regression loss: 0.74711 | Running loss: 0.87454\n",
      "Epoch: 0 | Iteration: 35634 | Classification loss: 0.37134 | Regression loss: 0.49672 | Running loss: 0.87437\n",
      "Epoch: 0 | Iteration: 35635 | Classification loss: 0.43898 | Regression loss: 0.59787 | Running loss: 0.87454\n",
      "Epoch: 0 | Iteration: 35636 | Classification loss: 0.42790 | Regression loss: 0.52921 | Running loss: 0.87522\n",
      "Epoch: 0 | Iteration: 35637 | Classification loss: 0.44766 | Regression loss: 0.55374 | Running loss: 0.87579\n",
      "Epoch: 0 | Iteration: 35638 | Classification loss: 0.48246 | Regression loss: 0.54366 | Running loss: 0.87617\n",
      "Epoch: 0 | Iteration: 35639 | Classification loss: 0.45225 | Regression loss: 0.37896 | Running loss: 0.87593\n",
      "Epoch: 0 | Iteration: 35640 | Classification loss: 0.48255 | Regression loss: 0.45039 | Running loss: 0.87580\n",
      "Epoch: 0 | Iteration: 35641 | Classification loss: 0.22920 | Regression loss: 0.48968 | Running loss: 0.87613\n",
      "Epoch: 0 | Iteration: 35642 | Classification loss: 0.22041 | Regression loss: 0.35786 | Running loss: 0.87529\n",
      "Epoch: 0 | Iteration: 35643 | Classification loss: 0.38725 | Regression loss: 0.60256 | Running loss: 0.87493\n",
      "Epoch: 0 | Iteration: 35644 | Classification loss: 0.25102 | Regression loss: 0.38113 | Running loss: 0.87447\n",
      "Epoch: 0 | Iteration: 35645 | Classification loss: 0.34481 | Regression loss: 0.49776 | Running loss: 0.87410\n",
      "Epoch: 0 | Iteration: 35646 | Classification loss: 0.56530 | Regression loss: 0.74764 | Running loss: 0.87537\n",
      "Epoch: 0 | Iteration: 35647 | Classification loss: 0.23720 | Regression loss: 0.47793 | Running loss: 0.87482\n",
      "Epoch: 0 | Iteration: 35648 | Classification loss: 0.31939 | Regression loss: 0.30265 | Running loss: 0.87417\n",
      "Epoch: 0 | Iteration: 35649 | Classification loss: 0.59158 | Regression loss: 0.60564 | Running loss: 0.87461\n",
      "Epoch: 0 | Iteration: 35650 | Classification loss: 0.37445 | Regression loss: 0.63753 | Running loss: 0.87468\n",
      "Epoch: 0 | Iteration: 35651 | Classification loss: 0.20042 | Regression loss: 0.36435 | Running loss: 0.87454\n",
      "Epoch: 0 | Iteration: 35652 | Classification loss: 0.37230 | Regression loss: 0.58418 | Running loss: 0.87471\n",
      "Epoch: 0 | Iteration: 35653 | Classification loss: 0.31172 | Regression loss: 0.45140 | Running loss: 0.87454\n",
      "Epoch: 0 | Iteration: 35654 | Classification loss: 0.58801 | Regression loss: 0.66234 | Running loss: 0.87518\n",
      "Epoch: 0 | Iteration: 35655 | Classification loss: 0.43891 | Regression loss: 0.42734 | Running loss: 0.87531\n",
      "Epoch: 0 | Iteration: 35656 | Classification loss: 0.31057 | Regression loss: 0.37969 | Running loss: 0.87435\n",
      "Epoch: 0 | Iteration: 35657 | Classification loss: 0.40196 | Regression loss: 0.49629 | Running loss: 0.87373\n",
      "Epoch: 0 | Iteration: 35658 | Classification loss: 0.34337 | Regression loss: 0.69164 | Running loss: 0.87342\n",
      "Epoch: 0 | Iteration: 35659 | Classification loss: 0.56553 | Regression loss: 0.56726 | Running loss: 0.87468\n",
      "Epoch: 0 | Iteration: 35660 | Classification loss: 0.21354 | Regression loss: 0.38382 | Running loss: 0.87359\n",
      "Epoch: 0 | Iteration: 35661 | Classification loss: 0.33851 | Regression loss: 0.41396 | Running loss: 0.87288\n",
      "Epoch: 0 | Iteration: 35662 | Classification loss: 0.57395 | Regression loss: 0.67006 | Running loss: 0.87412\n",
      "Epoch: 0 | Iteration: 35663 | Classification loss: 0.37978 | Regression loss: 0.62060 | Running loss: 0.87437\n",
      "Epoch: 0 | Iteration: 35664 | Classification loss: 0.48072 | Regression loss: 0.66480 | Running loss: 0.87508\n",
      "Epoch: 0 | Iteration: 35665 | Classification loss: 0.42176 | Regression loss: 0.59199 | Running loss: 0.87655\n",
      "Epoch: 0 | Iteration: 35666 | Classification loss: 0.36507 | Regression loss: 0.67815 | Running loss: 0.87697\n",
      "Epoch: 0 | Iteration: 35667 | Classification loss: 0.39026 | Regression loss: 0.38631 | Running loss: 0.87631\n",
      "Epoch: 0 | Iteration: 35668 | Classification loss: 0.50294 | Regression loss: 0.42874 | Running loss: 0.87734\n",
      "Epoch: 0 | Iteration: 35669 | Classification loss: 0.33875 | Regression loss: 0.55151 | Running loss: 0.87726\n",
      "Epoch: 0 | Iteration: 35670 | Classification loss: 0.16902 | Regression loss: 0.31382 | Running loss: 0.87642\n",
      "Epoch: 0 | Iteration: 35671 | Classification loss: 0.32597 | Regression loss: 0.61617 | Running loss: 0.87695\n",
      "Epoch: 0 | Iteration: 35672 | Classification loss: 0.37362 | Regression loss: 0.37690 | Running loss: 0.87731\n",
      "Epoch: 0 | Iteration: 35673 | Classification loss: 0.42709 | Regression loss: 0.48709 | Running loss: 0.87749\n",
      "Epoch: 0 | Iteration: 35674 | Classification loss: 0.28460 | Regression loss: 0.43876 | Running loss: 0.87778\n",
      "Epoch: 0 | Iteration: 35675 | Classification loss: 0.38553 | Regression loss: 0.27921 | Running loss: 0.87802\n",
      "Epoch: 0 | Iteration: 35676 | Classification loss: 0.48066 | Regression loss: 0.61652 | Running loss: 0.87842\n",
      "Epoch: 0 | Iteration: 35677 | Classification loss: 0.20683 | Regression loss: 0.30858 | Running loss: 0.87773\n",
      "Epoch: 0 | Iteration: 35678 | Classification loss: 0.39899 | Regression loss: 0.58438 | Running loss: 0.87794\n",
      "Epoch: 0 | Iteration: 35679 | Classification loss: 0.42222 | Regression loss: 0.59135 | Running loss: 0.87830\n",
      "Epoch: 0 | Iteration: 35680 | Classification loss: 0.55712 | Regression loss: 0.33985 | Running loss: 0.87791\n",
      "Epoch: 0 | Iteration: 35681 | Classification loss: 0.41198 | Regression loss: 0.54502 | Running loss: 0.87764\n",
      "Epoch: 0 | Iteration: 35682 | Classification loss: 0.35749 | Regression loss: 0.53433 | Running loss: 0.87673\n",
      "Epoch: 0 | Iteration: 35683 | Classification loss: 0.36570 | Regression loss: 0.48419 | Running loss: 0.87631\n",
      "Epoch: 0 | Iteration: 35684 | Classification loss: 0.19884 | Regression loss: 0.41516 | Running loss: 0.87578\n",
      "Epoch: 0 | Iteration: 35685 | Classification loss: 0.41654 | Regression loss: 0.41410 | Running loss: 0.87586\n",
      "Epoch: 0 | Iteration: 35686 | Classification loss: 0.58036 | Regression loss: 0.63141 | Running loss: 0.87659\n",
      "Epoch: 0 | Iteration: 35687 | Classification loss: 0.44823 | Regression loss: 0.65153 | Running loss: 0.87597\n",
      "Epoch: 0 | Iteration: 35688 | Classification loss: 0.36421 | Regression loss: 0.59842 | Running loss: 0.87623\n",
      "Epoch: 0 | Iteration: 35689 | Classification loss: 0.24618 | Regression loss: 0.16695 | Running loss: 0.87555\n",
      "Epoch: 0 | Iteration: 35690 | Classification loss: 0.31909 | Regression loss: 0.32867 | Running loss: 0.87444\n",
      "Epoch: 0 | Iteration: 35691 | Classification loss: 0.20403 | Regression loss: 0.33879 | Running loss: 0.87378\n",
      "Epoch: 0 | Iteration: 35692 | Classification loss: 0.31560 | Regression loss: 0.49746 | Running loss: 0.87351\n",
      "Epoch: 0 | Iteration: 35693 | Classification loss: 0.40273 | Regression loss: 0.44305 | Running loss: 0.87308\n",
      "Epoch: 0 | Iteration: 35694 | Classification loss: 0.23586 | Regression loss: 0.30058 | Running loss: 0.87225\n",
      "Epoch: 0 | Iteration: 35695 | Classification loss: 0.49379 | Regression loss: 0.46485 | Running loss: 0.87218\n",
      "Epoch: 0 | Iteration: 35696 | Classification loss: 0.24617 | Regression loss: 0.43758 | Running loss: 0.87165\n",
      "Epoch: 0 | Iteration: 35697 | Classification loss: 0.35632 | Regression loss: 0.24748 | Running loss: 0.87108\n",
      "Epoch: 0 | Iteration: 35698 | Classification loss: 0.32778 | Regression loss: 0.45638 | Running loss: 0.87110\n",
      "Epoch: 0 | Iteration: 35699 | Classification loss: 0.43852 | Regression loss: 0.64736 | Running loss: 0.87136\n",
      "Epoch: 0 | Iteration: 35700 | Classification loss: 0.15298 | Regression loss: 0.37267 | Running loss: 0.87090\n",
      "Epoch: 0 | Iteration: 35701 | Classification loss: 0.36932 | Regression loss: 0.54868 | Running loss: 0.87136\n",
      "Epoch: 0 | Iteration: 35702 | Classification loss: 0.27493 | Regression loss: 0.38257 | Running loss: 0.87111\n",
      "Epoch: 0 | Iteration: 35703 | Classification loss: 0.32227 | Regression loss: 0.58758 | Running loss: 0.87092\n",
      "Epoch: 0 | Iteration: 35704 | Classification loss: 0.27233 | Regression loss: 0.48126 | Running loss: 0.87022\n",
      "Epoch: 0 | Iteration: 35705 | Classification loss: 0.45451 | Regression loss: 0.47463 | Running loss: 0.87049\n",
      "Epoch: 0 | Iteration: 35706 | Classification loss: 0.19327 | Regression loss: 0.35523 | Running loss: 0.86958\n",
      "Epoch: 0 | Iteration: 35707 | Classification loss: 0.48771 | Regression loss: 0.66225 | Running loss: 0.87054\n",
      "Epoch: 0 | Iteration: 35708 | Classification loss: 0.35823 | Regression loss: 0.54753 | Running loss: 0.86954\n",
      "Epoch: 0 | Iteration: 35709 | Classification loss: 0.30382 | Regression loss: 0.40037 | Running loss: 0.86964\n",
      "Epoch: 0 | Iteration: 35710 | Classification loss: 0.27096 | Regression loss: 0.37221 | Running loss: 0.86898\n",
      "Epoch: 0 | Iteration: 35711 | Classification loss: 0.24767 | Regression loss: 0.40465 | Running loss: 0.86871\n",
      "Epoch: 0 | Iteration: 35712 | Classification loss: 0.37905 | Regression loss: 0.53423 | Running loss: 0.86892\n",
      "Epoch: 0 | Iteration: 35713 | Classification loss: 2.42178 | Regression loss: 0.32501 | Running loss: 0.87232\n",
      "Epoch: 0 | Iteration: 35714 | Classification loss: 0.51316 | Regression loss: 0.51796 | Running loss: 0.87242\n",
      "Epoch: 0 | Iteration: 35715 | Classification loss: 0.52653 | Regression loss: 0.62997 | Running loss: 0.87315\n",
      "Epoch: 0 | Iteration: 35716 | Classification loss: 0.51560 | Regression loss: 0.43343 | Running loss: 0.87331\n",
      "Epoch: 0 | Iteration: 35717 | Classification loss: 0.31928 | Regression loss: 0.33467 | Running loss: 0.87344\n",
      "Epoch: 0 | Iteration: 35718 | Classification loss: 0.30989 | Regression loss: 0.38315 | Running loss: 0.87385\n",
      "Epoch: 0 | Iteration: 35719 | Classification loss: 0.45426 | Regression loss: 0.46883 | Running loss: 0.87209\n",
      "Epoch: 0 | Iteration: 35720 | Classification loss: 0.58005 | Regression loss: 0.49714 | Running loss: 0.87250\n",
      "Epoch: 0 | Iteration: 35721 | Classification loss: 0.29592 | Regression loss: 0.59834 | Running loss: 0.87260\n",
      "Epoch: 0 | Iteration: 35722 | Classification loss: 0.40034 | Regression loss: 0.54707 | Running loss: 0.87308\n",
      "Epoch: 0 | Iteration: 35723 | Classification loss: 0.44074 | Regression loss: 0.61454 | Running loss: 0.87294\n",
      "Epoch: 0 | Iteration: 35724 | Classification loss: 0.30137 | Regression loss: 0.41208 | Running loss: 0.87270\n",
      "Epoch: 0 | Iteration: 35725 | Classification loss: 0.56677 | Regression loss: 0.64661 | Running loss: 0.87357\n",
      "Epoch: 0 | Iteration: 35726 | Classification loss: 0.34692 | Regression loss: 0.65270 | Running loss: 0.87353\n",
      "Epoch: 0 | Iteration: 35727 | Classification loss: 1.02002 | Regression loss: 0.47246 | Running loss: 0.87486\n",
      "Epoch: 0 | Iteration: 35728 | Classification loss: 0.34534 | Regression loss: 0.62402 | Running loss: 0.87459\n",
      "Epoch: 0 | Iteration: 35729 | Classification loss: 0.36357 | Regression loss: 0.61262 | Running loss: 0.87481\n",
      "Epoch: 0 | Iteration: 35730 | Classification loss: 0.69314 | Regression loss: 0.62438 | Running loss: 0.87575\n",
      "Epoch: 0 | Iteration: 35731 | Classification loss: 0.27616 | Regression loss: 0.40587 | Running loss: 0.87460\n",
      "Epoch: 0 | Iteration: 35732 | Classification loss: 0.33758 | Regression loss: 0.46020 | Running loss: 0.87508\n",
      "Epoch: 0 | Iteration: 35733 | Classification loss: 0.28412 | Regression loss: 0.40395 | Running loss: 0.87523\n",
      "Epoch: 0 | Iteration: 35734 | Classification loss: 0.43514 | Regression loss: 0.69694 | Running loss: 0.87608\n",
      "Epoch: 0 | Iteration: 35735 | Classification loss: 0.20446 | Regression loss: 0.30601 | Running loss: 0.87492\n",
      "Epoch: 0 | Iteration: 35736 | Classification loss: 0.43436 | Regression loss: 0.58951 | Running loss: 0.87620\n",
      "Epoch: 0 | Iteration: 35737 | Classification loss: 0.45531 | Regression loss: 0.31102 | Running loss: 0.87641\n",
      "Epoch: 0 | Iteration: 35738 | Classification loss: 0.39021 | Regression loss: 0.37923 | Running loss: 0.87565\n",
      "Epoch: 0 | Iteration: 35739 | Classification loss: 0.29836 | Regression loss: 0.60244 | Running loss: 0.87512\n",
      "Epoch: 0 | Iteration: 35740 | Classification loss: 0.24978 | Regression loss: 0.61627 | Running loss: 0.87483\n",
      "Epoch: 0 | Iteration: 35741 | Classification loss: 0.34873 | Regression loss: 0.67852 | Running loss: 0.87469\n",
      "Epoch: 0 | Iteration: 35742 | Classification loss: 0.30667 | Regression loss: 0.31058 | Running loss: 0.87390\n",
      "Epoch: 0 | Iteration: 35743 | Classification loss: 0.36775 | Regression loss: 0.54836 | Running loss: 0.87453\n",
      "Epoch: 0 | Iteration: 35744 | Classification loss: 0.41212 | Regression loss: 0.33518 | Running loss: 0.87424\n",
      "Epoch: 0 | Iteration: 35745 | Classification loss: 0.34723 | Regression loss: 0.17022 | Running loss: 0.87353\n",
      "Epoch: 0 | Iteration: 35746 | Classification loss: 0.29682 | Regression loss: 0.46511 | Running loss: 0.87359\n",
      "Epoch: 0 | Iteration: 35747 | Classification loss: 0.36527 | Regression loss: 0.36516 | Running loss: 0.87334\n",
      "Epoch: 0 | Iteration: 35748 | Classification loss: 0.39026 | Regression loss: 0.52132 | Running loss: 0.87321\n",
      "Epoch: 0 | Iteration: 35749 | Classification loss: 0.23117 | Regression loss: 0.33381 | Running loss: 0.87236\n",
      "Epoch: 0 | Iteration: 35750 | Classification loss: 0.34799 | Regression loss: 0.52995 | Running loss: 0.87274\n",
      "Epoch: 0 | Iteration: 35751 | Classification loss: 0.40933 | Regression loss: 0.49973 | Running loss: 0.87211\n",
      "Epoch: 0 | Iteration: 35752 | Classification loss: 0.34691 | Regression loss: 0.35990 | Running loss: 0.87135\n",
      "Epoch: 0 | Iteration: 35753 | Classification loss: 0.31203 | Regression loss: 0.40979 | Running loss: 0.87115\n",
      "Epoch: 0 | Iteration: 35754 | Classification loss: 0.22042 | Regression loss: 0.54089 | Running loss: 0.87030\n",
      "Epoch: 0 | Iteration: 35755 | Classification loss: 0.47702 | Regression loss: 0.61994 | Running loss: 0.87052\n",
      "Epoch: 0 | Iteration: 35756 | Classification loss: 0.44949 | Regression loss: 0.23248 | Running loss: 0.87051\n",
      "Epoch: 0 | Iteration: 35757 | Classification loss: 0.46102 | Regression loss: 0.55303 | Running loss: 0.87177\n",
      "Epoch: 0 | Iteration: 35758 | Classification loss: 0.44037 | Regression loss: 0.47002 | Running loss: 0.87119\n",
      "Epoch: 0 | Iteration: 35759 | Classification loss: 0.25774 | Regression loss: 0.15190 | Running loss: 0.87010\n",
      "Epoch: 0 | Iteration: 35760 | Classification loss: 0.68542 | Regression loss: 0.82861 | Running loss: 0.87183\n",
      "Epoch: 0 | Iteration: 35761 | Classification loss: 0.31715 | Regression loss: 0.66330 | Running loss: 0.87183\n",
      "Epoch: 0 | Iteration: 35762 | Classification loss: 0.42744 | Regression loss: 0.46668 | Running loss: 0.87203\n",
      "Epoch: 0 | Iteration: 35763 | Classification loss: 0.23462 | Regression loss: 0.40683 | Running loss: 0.87106\n",
      "Epoch: 0 | Iteration: 35764 | Classification loss: 0.13661 | Regression loss: 0.31406 | Running loss: 0.87012\n",
      "Epoch: 0 | Iteration: 35765 | Classification loss: 0.38524 | Regression loss: 0.29709 | Running loss: 0.86942\n",
      "Epoch: 0 | Iteration: 35766 | Classification loss: 0.27137 | Regression loss: 0.31356 | Running loss: 0.86842\n",
      "Epoch: 0 | Iteration: 35767 | Classification loss: 0.78045 | Regression loss: 0.52780 | Running loss: 0.86887\n",
      "Epoch: 0 | Iteration: 35768 | Classification loss: 0.55010 | Regression loss: 0.26421 | Running loss: 0.86901\n",
      "Epoch: 0 | Iteration: 35769 | Classification loss: 0.46185 | Regression loss: 0.30574 | Running loss: 0.86835\n",
      "Epoch: 0 | Iteration: 35770 | Classification loss: 0.44402 | Regression loss: 0.52579 | Running loss: 0.86777\n",
      "Epoch: 0 | Iteration: 35771 | Classification loss: 0.33242 | Regression loss: 0.43634 | Running loss: 0.86772\n",
      "Epoch: 0 | Iteration: 35772 | Classification loss: 0.25147 | Regression loss: 0.51846 | Running loss: 0.86835\n",
      "Epoch: 0 | Iteration: 35773 | Classification loss: 0.42633 | Regression loss: 0.59032 | Running loss: 0.86905\n",
      "Epoch: 0 | Iteration: 35774 | Classification loss: 0.25381 | Regression loss: 0.43278 | Running loss: 0.86694\n",
      "Epoch: 0 | Iteration: 35775 | Classification loss: 0.19894 | Regression loss: 0.39123 | Running loss: 0.86712\n",
      "Epoch: 0 | Iteration: 35776 | Classification loss: 0.26206 | Regression loss: 0.34457 | Running loss: 0.86664\n",
      "Epoch: 0 | Iteration: 35777 | Classification loss: 0.26999 | Regression loss: 0.37918 | Running loss: 0.86574\n",
      "Epoch: 0 | Iteration: 35778 | Classification loss: 0.30105 | Regression loss: 0.48058 | Running loss: 0.86532\n",
      "Epoch: 0 | Iteration: 35779 | Classification loss: 0.36604 | Regression loss: 0.45272 | Running loss: 0.86564\n",
      "Epoch: 0 | Iteration: 35780 | Classification loss: 0.41737 | Regression loss: 0.40795 | Running loss: 0.86525\n",
      "Epoch: 0 | Iteration: 35781 | Classification loss: 0.37276 | Regression loss: 0.48555 | Running loss: 0.86545\n",
      "Epoch: 0 | Iteration: 35782 | Classification loss: 0.46221 | Regression loss: 0.61044 | Running loss: 0.86531\n",
      "Epoch: 0 | Iteration: 35783 | Classification loss: 0.25074 | Regression loss: 0.50561 | Running loss: 0.86469\n",
      "Epoch: 0 | Iteration: 35784 | Classification loss: 0.31125 | Regression loss: 0.57378 | Running loss: 0.86485\n",
      "Epoch: 0 | Iteration: 35785 | Classification loss: 0.58575 | Regression loss: 0.55437 | Running loss: 0.86531\n",
      "Epoch: 0 | Iteration: 35786 | Classification loss: 0.26134 | Regression loss: 0.49112 | Running loss: 0.86536\n",
      "Epoch: 0 | Iteration: 35787 | Classification loss: 0.33422 | Regression loss: 0.46430 | Running loss: 0.86471\n",
      "Epoch: 0 | Iteration: 35788 | Classification loss: 0.71314 | Regression loss: 0.69985 | Running loss: 0.86544\n",
      "Epoch: 0 | Iteration: 35789 | Classification loss: 0.46422 | Regression loss: 0.72336 | Running loss: 0.86588\n",
      "Epoch: 0 | Iteration: 35790 | Classification loss: 0.34831 | Regression loss: 0.44910 | Running loss: 0.86574\n",
      "Epoch: 0 | Iteration: 35791 | Classification loss: 0.26003 | Regression loss: 0.42665 | Running loss: 0.86529\n",
      "Epoch: 0 | Iteration: 35792 | Classification loss: 0.34223 | Regression loss: 0.48964 | Running loss: 0.86486\n",
      "Epoch: 0 | Iteration: 35793 | Classification loss: 0.34562 | Regression loss: 0.44018 | Running loss: 0.86478\n",
      "Epoch: 0 | Iteration: 35794 | Classification loss: 0.08504 | Regression loss: 0.24151 | Running loss: 0.86278\n",
      "Epoch: 0 | Iteration: 35795 | Classification loss: 0.48879 | Regression loss: 0.49060 | Running loss: 0.86372\n",
      "Epoch: 0 | Iteration: 35796 | Classification loss: 0.30671 | Regression loss: 0.61977 | Running loss: 0.86482\n",
      "Epoch: 0 | Iteration: 35797 | Classification loss: 0.24410 | Regression loss: 0.34021 | Running loss: 0.86416\n",
      "Epoch: 0 | Iteration: 35798 | Classification loss: 0.39396 | Regression loss: 0.56626 | Running loss: 0.86363\n",
      "Epoch: 0 | Iteration: 35799 | Classification loss: 0.30017 | Regression loss: 0.41603 | Running loss: 0.86326\n",
      "Epoch: 0 | Iteration: 35800 | Classification loss: 0.21563 | Regression loss: 0.41969 | Running loss: 0.86316\n",
      "Epoch: 0 | Iteration: 35801 | Classification loss: 0.43590 | Regression loss: 0.68051 | Running loss: 0.86341\n",
      "Epoch: 0 | Iteration: 35802 | Classification loss: 0.35224 | Regression loss: 0.47823 | Running loss: 0.86299\n",
      "Epoch: 0 | Iteration: 35803 | Classification loss: 0.36736 | Regression loss: 0.59429 | Running loss: 0.86308\n",
      "Epoch: 0 | Iteration: 35804 | Classification loss: 0.26842 | Regression loss: 0.28749 | Running loss: 0.86266\n",
      "Epoch: 0 | Iteration: 35805 | Classification loss: 0.26047 | Regression loss: 0.48310 | Running loss: 0.86255\n",
      "Epoch: 0 | Iteration: 35806 | Classification loss: 0.32295 | Regression loss: 0.44203 | Running loss: 0.86192\n",
      "Epoch: 0 | Iteration: 35807 | Classification loss: 0.27170 | Regression loss: 0.55230 | Running loss: 0.86208\n",
      "Epoch: 0 | Iteration: 35808 | Classification loss: 0.21829 | Regression loss: 0.35083 | Running loss: 0.86211\n",
      "Epoch: 0 | Iteration: 35809 | Classification loss: 0.44142 | Regression loss: 0.40317 | Running loss: 0.86130\n",
      "Epoch: 0 | Iteration: 35810 | Classification loss: 0.34731 | Regression loss: 0.54718 | Running loss: 0.86091\n",
      "Epoch: 0 | Iteration: 35811 | Classification loss: 0.15981 | Regression loss: 0.23777 | Running loss: 0.86028\n",
      "Epoch: 0 | Iteration: 35812 | Classification loss: 0.29428 | Regression loss: 0.35047 | Running loss: 0.85916\n",
      "Epoch: 0 | Iteration: 35813 | Classification loss: 0.20523 | Regression loss: 0.45519 | Running loss: 0.85864\n",
      "Epoch: 0 | Iteration: 35814 | Classification loss: 0.50843 | Regression loss: 0.56883 | Running loss: 0.85870\n",
      "Epoch: 0 | Iteration: 35815 | Classification loss: 0.26132 | Regression loss: 0.40608 | Running loss: 0.85880\n",
      "Epoch: 0 | Iteration: 35816 | Classification loss: 0.36117 | Regression loss: 0.31640 | Running loss: 0.85778\n",
      "Epoch: 0 | Iteration: 35817 | Classification loss: 0.39944 | Regression loss: 0.42534 | Running loss: 0.85746\n",
      "Epoch: 0 | Iteration: 35818 | Classification loss: 0.39838 | Regression loss: 0.47805 | Running loss: 0.85792\n",
      "Epoch: 0 | Iteration: 35819 | Classification loss: 0.23572 | Regression loss: 0.37383 | Running loss: 0.85768\n",
      "Epoch: 0 | Iteration: 35820 | Classification loss: 0.22957 | Regression loss: 0.37237 | Running loss: 0.85749\n",
      "Epoch: 0 | Iteration: 35821 | Classification loss: 0.21449 | Regression loss: 0.53395 | Running loss: 0.85663\n",
      "Epoch: 0 | Iteration: 35822 | Classification loss: 0.39484 | Regression loss: 0.46928 | Running loss: 0.85674\n",
      "Epoch: 0 | Iteration: 35823 | Classification loss: 0.32084 | Regression loss: 0.37769 | Running loss: 0.85581\n",
      "Epoch: 0 | Iteration: 35824 | Classification loss: 0.39157 | Regression loss: 0.37300 | Running loss: 0.85494\n",
      "Epoch: 0 | Iteration: 35825 | Classification loss: 0.48476 | Regression loss: 0.58551 | Running loss: 0.85613\n",
      "Epoch: 0 | Iteration: 35826 | Classification loss: 0.33523 | Regression loss: 0.61161 | Running loss: 0.85695\n",
      "Epoch: 0 | Iteration: 35827 | Classification loss: 0.34384 | Regression loss: 0.47785 | Running loss: 0.85726\n",
      "Epoch: 0 | Iteration: 35828 | Classification loss: 0.44013 | Regression loss: 0.63278 | Running loss: 0.85786\n",
      "Epoch: 0 | Iteration: 35829 | Classification loss: 0.77145 | Regression loss: 0.70973 | Running loss: 0.85938\n",
      "Epoch: 0 | Iteration: 35830 | Classification loss: 0.29671 | Regression loss: 0.39819 | Running loss: 0.85893\n",
      "Epoch: 0 | Iteration: 35831 | Classification loss: 0.35099 | Regression loss: 0.64759 | Running loss: 0.85957\n",
      "Epoch: 0 | Iteration: 35832 | Classification loss: 0.25236 | Regression loss: 0.41067 | Running loss: 0.85928\n",
      "Epoch: 0 | Iteration: 35833 | Classification loss: 0.44121 | Regression loss: 0.58041 | Running loss: 0.85884\n",
      "Epoch: 0 | Iteration: 35834 | Classification loss: 0.20350 | Regression loss: 0.27355 | Running loss: 0.85790\n",
      "Epoch: 0 | Iteration: 35835 | Classification loss: 0.61054 | Regression loss: 0.44506 | Running loss: 0.85838\n",
      "Epoch: 0 | Iteration: 35836 | Classification loss: 0.33355 | Regression loss: 0.62346 | Running loss: 0.85809\n",
      "Epoch: 0 | Iteration: 35837 | Classification loss: 0.23431 | Regression loss: 0.40563 | Running loss: 0.85760\n",
      "Epoch: 0 | Iteration: 35838 | Classification loss: 0.41837 | Regression loss: 0.57858 | Running loss: 0.85807\n",
      "Epoch: 0 | Iteration: 35839 | Classification loss: 0.26963 | Regression loss: 0.54287 | Running loss: 0.85743\n",
      "Epoch: 0 | Iteration: 35840 | Classification loss: 0.38286 | Regression loss: 0.53630 | Running loss: 0.85659\n",
      "Epoch: 0 | Iteration: 35841 | Classification loss: 0.25279 | Regression loss: 0.40501 | Running loss: 0.85661\n",
      "Epoch: 0 | Iteration: 35842 | Classification loss: 0.38762 | Regression loss: 0.61166 | Running loss: 0.85687\n",
      "Epoch: 0 | Iteration: 35843 | Classification loss: 0.39378 | Regression loss: 0.62674 | Running loss: 0.85770\n",
      "Epoch: 0 | Iteration: 35844 | Classification loss: 0.44926 | Regression loss: 0.69930 | Running loss: 0.85858\n",
      "Epoch: 0 | Iteration: 35845 | Classification loss: 0.33517 | Regression loss: 0.50076 | Running loss: 0.85899\n",
      "Epoch: 0 | Iteration: 35846 | Classification loss: 0.40316 | Regression loss: 0.41364 | Running loss: 0.85824\n",
      "Epoch: 0 | Iteration: 35847 | Classification loss: 0.37518 | Regression loss: 0.53490 | Running loss: 0.85803\n",
      "Epoch: 0 | Iteration: 35848 | Classification loss: 0.38329 | Regression loss: 0.54183 | Running loss: 0.85893\n",
      "Epoch: 0 | Iteration: 35849 | Classification loss: 0.27939 | Regression loss: 0.46600 | Running loss: 0.85859\n",
      "Epoch: 0 | Iteration: 35850 | Classification loss: 0.46591 | Regression loss: 0.36095 | Running loss: 0.85847\n",
      "Epoch: 0 | Iteration: 35851 | Classification loss: 0.34418 | Regression loss: 0.61927 | Running loss: 0.85817\n",
      "Epoch: 0 | Iteration: 35852 | Classification loss: 0.36910 | Regression loss: 0.67058 | Running loss: 0.85848\n",
      "Epoch: 0 | Iteration: 35853 | Classification loss: 0.32457 | Regression loss: 0.52720 | Running loss: 0.85861\n",
      "Epoch: 0 | Iteration: 35854 | Classification loss: 0.30414 | Regression loss: 0.40739 | Running loss: 0.85815\n",
      "Epoch: 0 | Iteration: 35855 | Classification loss: 0.43483 | Regression loss: 0.46879 | Running loss: 0.85850\n",
      "Epoch: 0 | Iteration: 35856 | Classification loss: 0.49491 | Regression loss: 0.40959 | Running loss: 0.85871\n",
      "Epoch: 0 | Iteration: 35857 | Classification loss: 0.37902 | Regression loss: 0.63422 | Running loss: 0.85912\n",
      "Epoch: 0 | Iteration: 35858 | Classification loss: 0.47605 | Regression loss: 0.35084 | Running loss: 0.85952\n",
      "Epoch: 0 | Iteration: 35859 | Classification loss: 0.16712 | Regression loss: 0.32877 | Running loss: 0.85926\n",
      "Epoch: 0 | Iteration: 35860 | Classification loss: 0.40740 | Regression loss: 0.55335 | Running loss: 0.85947\n",
      "Epoch: 0 | Iteration: 35861 | Classification loss: 0.40037 | Regression loss: 0.58928 | Running loss: 0.85977\n",
      "Epoch: 0 | Iteration: 35862 | Classification loss: 0.36411 | Regression loss: 0.45734 | Running loss: 0.85963\n",
      "Epoch: 0 | Iteration: 35863 | Classification loss: 0.40373 | Regression loss: 0.60254 | Running loss: 0.85994\n",
      "Epoch: 0 | Iteration: 35864 | Classification loss: 0.26354 | Regression loss: 0.47490 | Running loss: 0.86012\n",
      "Epoch: 0 | Iteration: 35865 | Classification loss: 0.38820 | Regression loss: 0.66407 | Running loss: 0.86011\n",
      "Epoch: 0 | Iteration: 35866 | Classification loss: 0.32523 | Regression loss: 0.33952 | Running loss: 0.86010\n",
      "Epoch: 0 | Iteration: 35867 | Classification loss: 0.42026 | Regression loss: 0.61775 | Running loss: 0.86013\n",
      "Epoch: 0 | Iteration: 35868 | Classification loss: 0.31991 | Regression loss: 0.45693 | Running loss: 0.85989\n",
      "Epoch: 0 | Iteration: 35869 | Classification loss: 0.54980 | Regression loss: 0.57894 | Running loss: 0.86114\n",
      "Epoch: 0 | Iteration: 35870 | Classification loss: 0.51274 | Regression loss: 0.60129 | Running loss: 0.86151\n",
      "Epoch: 0 | Iteration: 35871 | Classification loss: 0.65513 | Regression loss: 0.41986 | Running loss: 0.86149\n",
      "Epoch: 0 | Iteration: 35872 | Classification loss: 0.35768 | Regression loss: 0.52444 | Running loss: 0.86171\n",
      "Epoch: 0 | Iteration: 35873 | Classification loss: 0.45182 | Regression loss: 0.75087 | Running loss: 0.86215\n",
      "Epoch: 0 | Iteration: 35874 | Classification loss: 0.37635 | Regression loss: 0.56969 | Running loss: 0.86239\n",
      "Epoch: 0 | Iteration: 35875 | Classification loss: 0.42913 | Regression loss: 0.50050 | Running loss: 0.86257\n",
      "Epoch: 0 | Iteration: 35876 | Classification loss: 0.31088 | Regression loss: 0.42627 | Running loss: 0.86191\n",
      "Epoch: 0 | Iteration: 35877 | Classification loss: 0.35011 | Regression loss: 0.37449 | Running loss: 0.86119\n",
      "Epoch: 0 | Iteration: 35878 | Classification loss: 0.23516 | Regression loss: 0.41542 | Running loss: 0.86105\n",
      "Epoch: 0 | Iteration: 35879 | Classification loss: 0.27871 | Regression loss: 0.44771 | Running loss: 0.86055\n",
      "Epoch: 0 | Iteration: 35880 | Classification loss: 0.44350 | Regression loss: 0.60658 | Running loss: 0.86117\n",
      "Epoch: 0 | Iteration: 35881 | Classification loss: 0.83915 | Regression loss: 0.28548 | Running loss: 0.86224\n",
      "Epoch: 0 | Iteration: 35882 | Classification loss: 0.54859 | Regression loss: 0.57535 | Running loss: 0.86322\n",
      "Epoch: 0 | Iteration: 35883 | Classification loss: 0.39407 | Regression loss: 0.61305 | Running loss: 0.86421\n",
      "Epoch: 0 | Iteration: 35884 | Classification loss: 0.24405 | Regression loss: 0.46988 | Running loss: 0.86407\n",
      "Epoch: 0 | Iteration: 35885 | Classification loss: 0.17664 | Regression loss: 0.19479 | Running loss: 0.86322\n",
      "Epoch: 0 | Iteration: 35886 | Classification loss: 0.34673 | Regression loss: 0.42417 | Running loss: 0.86269\n",
      "Epoch: 0 | Iteration: 35887 | Classification loss: 0.23914 | Regression loss: 0.41409 | Running loss: 0.86192\n",
      "Epoch: 0 | Iteration: 35888 | Classification loss: 0.71295 | Regression loss: 0.56292 | Running loss: 0.86311\n",
      "Epoch: 0 | Iteration: 35889 | Classification loss: 0.48735 | Regression loss: 0.53348 | Running loss: 0.86297\n",
      "Epoch: 0 | Iteration: 35890 | Classification loss: 0.36618 | Regression loss: 0.69593 | Running loss: 0.86401\n",
      "Epoch: 0 | Iteration: 35891 | Classification loss: 0.31686 | Regression loss: 0.59182 | Running loss: 0.86486\n",
      "Epoch: 0 | Iteration: 35892 | Classification loss: 0.44598 | Regression loss: 0.36875 | Running loss: 0.86496\n",
      "Epoch: 0 | Iteration: 35893 | Classification loss: 0.09996 | Regression loss: 0.31686 | Running loss: 0.86437\n",
      "Epoch: 0 | Iteration: 35894 | Classification loss: 0.18586 | Regression loss: 0.36176 | Running loss: 0.86414\n",
      "Epoch: 0 | Iteration: 35895 | Classification loss: 0.39655 | Regression loss: 0.64483 | Running loss: 0.86483\n",
      "Epoch: 0 | Iteration: 35896 | Classification loss: 0.21001 | Regression loss: 0.40525 | Running loss: 0.86342\n",
      "Epoch: 0 | Iteration: 35897 | Classification loss: 0.31302 | Regression loss: 0.36691 | Running loss: 0.86289\n",
      "Epoch: 0 | Iteration: 35898 | Classification loss: 0.18144 | Regression loss: 0.24466 | Running loss: 0.86193\n",
      "Epoch: 0 | Iteration: 35899 | Classification loss: 0.60490 | Regression loss: 0.62811 | Running loss: 0.86307\n",
      "Epoch: 0 | Iteration: 35900 | Classification loss: 0.50610 | Regression loss: 0.73181 | Running loss: 0.86398\n",
      "Epoch: 0 | Iteration: 35901 | Classification loss: 0.46539 | Regression loss: 0.51883 | Running loss: 0.86358\n",
      "Epoch: 0 | Iteration: 35902 | Classification loss: 0.32548 | Regression loss: 0.40874 | Running loss: 0.86352\n",
      "Epoch: 0 | Iteration: 35903 | Classification loss: 0.27935 | Regression loss: 0.41084 | Running loss: 0.86301\n",
      "Epoch: 0 | Iteration: 35904 | Classification loss: 0.31736 | Regression loss: 0.36916 | Running loss: 0.86226\n",
      "Epoch: 0 | Iteration: 35905 | Classification loss: 0.25421 | Regression loss: 0.49805 | Running loss: 0.86193\n",
      "Epoch: 0 | Iteration: 35906 | Classification loss: 0.17214 | Regression loss: 0.31800 | Running loss: 0.86159\n",
      "Epoch: 0 | Iteration: 35907 | Classification loss: 0.22495 | Regression loss: 0.32437 | Running loss: 0.86146\n",
      "Epoch: 0 | Iteration: 35908 | Classification loss: 0.39792 | Regression loss: 0.51832 | Running loss: 0.86183\n",
      "Epoch: 0 | Iteration: 35909 | Classification loss: 0.50129 | Regression loss: 0.56477 | Running loss: 0.86257\n",
      "Epoch: 0 | Iteration: 35910 | Classification loss: 0.47268 | Regression loss: 0.44379 | Running loss: 0.86229\n",
      "Epoch: 0 | Iteration: 35911 | Classification loss: 0.17892 | Regression loss: 0.28042 | Running loss: 0.86234\n",
      "Epoch: 0 | Iteration: 35912 | Classification loss: 0.48384 | Regression loss: 0.54901 | Running loss: 0.86256\n",
      "Epoch: 0 | Iteration: 35913 | Classification loss: 0.22124 | Regression loss: 0.37465 | Running loss: 0.86247\n",
      "Epoch: 0 | Iteration: 35914 | Classification loss: 0.20452 | Regression loss: 0.49177 | Running loss: 0.86286\n",
      "Epoch: 0 | Iteration: 35915 | Classification loss: 0.31100 | Regression loss: 0.39982 | Running loss: 0.86246\n",
      "Epoch: 0 | Iteration: 35916 | Classification loss: 0.53149 | Regression loss: 0.69967 | Running loss: 0.86372\n",
      "Epoch: 0 | Iteration: 35917 | Classification loss: 0.31937 | Regression loss: 0.49356 | Running loss: 0.86331\n",
      "Epoch: 0 | Iteration: 35918 | Classification loss: 0.28459 | Regression loss: 0.49277 | Running loss: 0.86358\n",
      "Epoch: 0 | Iteration: 35919 | Classification loss: 0.29602 | Regression loss: 0.54307 | Running loss: 0.86306\n",
      "Epoch: 0 | Iteration: 35920 | Classification loss: 0.29920 | Regression loss: 0.38832 | Running loss: 0.86182\n",
      "Epoch: 0 | Iteration: 35921 | Classification loss: 0.29847 | Regression loss: 0.40488 | Running loss: 0.86125\n",
      "Epoch: 0 | Iteration: 35922 | Classification loss: 0.29461 | Regression loss: 0.42344 | Running loss: 0.86155\n",
      "Epoch: 0 | Iteration: 35923 | Classification loss: 0.43556 | Regression loss: 0.59063 | Running loss: 0.86266\n",
      "Epoch: 0 | Iteration: 35924 | Classification loss: 0.48143 | Regression loss: 0.59495 | Running loss: 0.86360\n",
      "Epoch: 0 | Iteration: 35925 | Classification loss: 0.26176 | Regression loss: 0.42522 | Running loss: 0.86305\n",
      "Epoch: 0 | Iteration: 35926 | Classification loss: 0.42628 | Regression loss: 0.30833 | Running loss: 0.86314\n",
      "Epoch: 0 | Iteration: 35927 | Classification loss: 0.30764 | Regression loss: 0.65512 | Running loss: 0.86346\n",
      "Epoch: 0 | Iteration: 35928 | Classification loss: 0.34738 | Regression loss: 0.47787 | Running loss: 0.86329\n",
      "Epoch: 0 | Iteration: 35929 | Classification loss: 0.48658 | Regression loss: 0.55553 | Running loss: 0.86369\n",
      "Epoch: 0 | Iteration: 35930 | Classification loss: 0.37607 | Regression loss: 0.47245 | Running loss: 0.86346\n",
      "Epoch: 0 | Iteration: 35931 | Classification loss: 0.39746 | Regression loss: 0.52573 | Running loss: 0.86331\n",
      "Epoch: 0 | Iteration: 35932 | Classification loss: 0.52608 | Regression loss: 0.51706 | Running loss: 0.86312\n",
      "Epoch: 0 | Iteration: 35933 | Classification loss: 0.32886 | Regression loss: 0.55899 | Running loss: 0.86335\n",
      "Epoch: 0 | Iteration: 35934 | Classification loss: 0.27021 | Regression loss: 0.38752 | Running loss: 0.86293\n",
      "Epoch: 0 | Iteration: 35935 | Classification loss: 0.15849 | Regression loss: 0.33121 | Running loss: 0.86192\n",
      "Epoch: 0 | Iteration: 35936 | Classification loss: 0.15503 | Regression loss: 0.30383 | Running loss: 0.86164\n",
      "Epoch: 0 | Iteration: 35937 | Classification loss: 0.59034 | Regression loss: 0.65321 | Running loss: 0.86214\n",
      "Epoch: 0 | Iteration: 35938 | Classification loss: 0.42934 | Regression loss: 0.40388 | Running loss: 0.86140\n",
      "Epoch: 0 | Iteration: 35939 | Classification loss: 0.52656 | Regression loss: 0.69162 | Running loss: 0.86264\n",
      "Epoch: 0 | Iteration: 35940 | Classification loss: 0.17990 | Regression loss: 0.31804 | Running loss: 0.86202\n",
      "Epoch: 0 | Iteration: 35941 | Classification loss: 0.45585 | Regression loss: 0.49126 | Running loss: 0.86249\n",
      "Epoch: 0 | Iteration: 35942 | Classification loss: 0.45277 | Regression loss: 0.45901 | Running loss: 0.86292\n",
      "Epoch: 0 | Iteration: 35943 | Classification loss: 0.59066 | Regression loss: 0.48147 | Running loss: 0.86273\n",
      "Epoch: 0 | Iteration: 35944 | Classification loss: 0.47636 | Regression loss: 0.60061 | Running loss: 0.86364\n",
      "Epoch: 0 | Iteration: 35945 | Classification loss: 0.37895 | Regression loss: 0.79997 | Running loss: 0.86411\n",
      "Epoch: 0 | Iteration: 35946 | Classification loss: 0.40592 | Regression loss: 0.60533 | Running loss: 0.86448\n",
      "Epoch: 0 | Iteration: 35947 | Classification loss: 0.36360 | Regression loss: 0.55665 | Running loss: 0.86432\n",
      "Epoch: 0 | Iteration: 35948 | Classification loss: 0.19533 | Regression loss: 0.27120 | Running loss: 0.86373\n",
      "Epoch: 0 | Iteration: 35949 | Classification loss: 0.27031 | Regression loss: 0.41978 | Running loss: 0.86317\n",
      "Epoch: 0 | Iteration: 35950 | Classification loss: 0.22638 | Regression loss: 0.58681 | Running loss: 0.86294\n",
      "Epoch: 0 | Iteration: 35951 | Classification loss: 0.26534 | Regression loss: 0.38117 | Running loss: 0.86225\n",
      "Epoch: 0 | Iteration: 35952 | Classification loss: 0.25109 | Regression loss: 0.18814 | Running loss: 0.86165\n",
      "Epoch: 0 | Iteration: 35953 | Classification loss: 0.32352 | Regression loss: 0.27302 | Running loss: 0.86078\n",
      "Epoch: 0 | Iteration: 35954 | Classification loss: 0.25291 | Regression loss: 0.51360 | Running loss: 0.86086\n",
      "Epoch: 0 | Iteration: 35955 | Classification loss: 0.37005 | Regression loss: 0.32396 | Running loss: 0.86068\n",
      "Epoch: 0 | Iteration: 35956 | Classification loss: 0.51246 | Regression loss: 0.42669 | Running loss: 0.86043\n",
      "Epoch: 0 | Iteration: 35957 | Classification loss: 0.59463 | Regression loss: 0.46905 | Running loss: 0.86054\n",
      "Epoch: 0 | Iteration: 35958 | Classification loss: 0.27791 | Regression loss: 0.73096 | Running loss: 0.86121\n",
      "Epoch: 0 | Iteration: 35959 | Classification loss: 0.78411 | Regression loss: 0.73731 | Running loss: 0.86283\n",
      "Epoch: 0 | Iteration: 35960 | Classification loss: 0.53230 | Regression loss: 0.51671 | Running loss: 0.86289\n",
      "Epoch: 0 | Iteration: 35961 | Classification loss: 0.24763 | Regression loss: 0.48392 | Running loss: 0.86248\n",
      "Epoch: 0 | Iteration: 35962 | Classification loss: 0.41136 | Regression loss: 0.48073 | Running loss: 0.86209\n",
      "Epoch: 0 | Iteration: 35963 | Classification loss: 0.39375 | Regression loss: 0.61015 | Running loss: 0.86270\n",
      "Epoch: 0 | Iteration: 35964 | Classification loss: 0.24110 | Regression loss: 0.43331 | Running loss: 0.86306\n",
      "Epoch: 0 | Iteration: 35965 | Classification loss: 0.30361 | Regression loss: 0.43756 | Running loss: 0.86237\n",
      "Epoch: 0 | Iteration: 35966 | Classification loss: 0.43179 | Regression loss: 0.60678 | Running loss: 0.86212\n",
      "Epoch: 0 | Iteration: 35967 | Classification loss: 0.74499 | Regression loss: 0.72926 | Running loss: 0.86279\n",
      "Epoch: 0 | Iteration: 35968 | Classification loss: 0.47499 | Regression loss: 0.56056 | Running loss: 0.86320\n",
      "Epoch: 0 | Iteration: 35969 | Classification loss: 0.24364 | Regression loss: 0.62327 | Running loss: 0.86332\n",
      "Epoch: 0 | Iteration: 35970 | Classification loss: 0.20573 | Regression loss: 0.29191 | Running loss: 0.86240\n",
      "Epoch: 0 | Iteration: 35971 | Classification loss: 0.30578 | Regression loss: 0.33084 | Running loss: 0.86214\n",
      "Epoch: 0 | Iteration: 35972 | Classification loss: 0.55818 | Regression loss: 0.43988 | Running loss: 0.86296\n",
      "Epoch: 0 | Iteration: 35973 | Classification loss: 0.25503 | Regression loss: 0.51651 | Running loss: 0.86256\n",
      "Epoch: 0 | Iteration: 35974 | Classification loss: 0.39966 | Regression loss: 0.27909 | Running loss: 0.86237\n",
      "Epoch: 0 | Iteration: 35975 | Classification loss: 0.52078 | Regression loss: 0.62777 | Running loss: 0.86281\n",
      "Epoch: 0 | Iteration: 35976 | Classification loss: 0.50485 | Regression loss: 0.45251 | Running loss: 0.86285\n",
      "Epoch: 0 | Iteration: 35977 | Classification loss: 0.21333 | Regression loss: 0.81423 | Running loss: 0.86340\n",
      "Epoch: 0 | Iteration: 35978 | Classification loss: 0.46619 | Regression loss: 0.55429 | Running loss: 0.86285\n",
      "Epoch: 0 | Iteration: 35979 | Classification loss: 0.39597 | Regression loss: 0.45179 | Running loss: 0.86292\n",
      "Epoch: 0 | Iteration: 35980 | Classification loss: 0.42092 | Regression loss: 0.52843 | Running loss: 0.86344\n",
      "Epoch: 0 | Iteration: 35981 | Classification loss: 0.33688 | Regression loss: 0.48698 | Running loss: 0.86292\n",
      "Epoch: 0 | Iteration: 35982 | Classification loss: 0.28687 | Regression loss: 0.50869 | Running loss: 0.86266\n",
      "Epoch: 0 | Iteration: 35983 | Classification loss: 0.30017 | Regression loss: 0.60402 | Running loss: 0.86263\n",
      "Epoch: 0 | Iteration: 35984 | Classification loss: 0.30405 | Regression loss: 0.48284 | Running loss: 0.86236\n",
      "Epoch: 0 | Iteration: 35985 | Classification loss: 0.18173 | Regression loss: 0.31661 | Running loss: 0.86189\n",
      "Epoch: 0 | Iteration: 35986 | Classification loss: 0.30763 | Regression loss: 0.41933 | Running loss: 0.86173\n",
      "Epoch: 0 | Iteration: 35987 | Classification loss: 0.65985 | Regression loss: 0.47156 | Running loss: 0.86238\n",
      "Epoch: 0 | Iteration: 35988 | Classification loss: 0.29621 | Regression loss: 0.59366 | Running loss: 0.86256\n",
      "Epoch: 0 | Iteration: 35989 | Classification loss: 0.30867 | Regression loss: 0.49915 | Running loss: 0.86271\n",
      "Epoch: 0 | Iteration: 35990 | Classification loss: 0.40810 | Regression loss: 0.70347 | Running loss: 0.86364\n",
      "Epoch: 0 | Iteration: 35991 | Classification loss: 0.37978 | Regression loss: 0.67652 | Running loss: 0.86418\n",
      "Epoch: 0 | Iteration: 35992 | Classification loss: 0.42643 | Regression loss: 0.47012 | Running loss: 0.86410\n",
      "Epoch: 0 | Iteration: 35993 | Classification loss: 0.50924 | Regression loss: 0.57000 | Running loss: 0.86434\n",
      "Epoch: 0 | Iteration: 35994 | Classification loss: 0.40348 | Regression loss: 0.43014 | Running loss: 0.86395\n",
      "Epoch: 0 | Iteration: 35995 | Classification loss: 0.36047 | Regression loss: 0.41924 | Running loss: 0.86377\n",
      "Epoch: 0 | Iteration: 35996 | Classification loss: 0.47254 | Regression loss: 0.50194 | Running loss: 0.86423\n",
      "Epoch: 0 | Iteration: 35997 | Classification loss: 0.11368 | Regression loss: 0.33054 | Running loss: 0.86354\n",
      "Epoch: 0 | Iteration: 35998 | Classification loss: 0.53741 | Regression loss: 0.37506 | Running loss: 0.86293\n",
      "Epoch: 0 | Iteration: 35999 | Classification loss: 0.48387 | Regression loss: 0.52780 | Running loss: 0.86308\n",
      "Epoch: 0 | Iteration: 36000 | Classification loss: 0.48956 | Regression loss: 0.39828 | Running loss: 0.86247\n",
      "Epoch: 0 | Iteration: 36001 | Classification loss: 0.32498 | Regression loss: 0.44903 | Running loss: 0.86289\n",
      "Epoch: 0 | Iteration: 36002 | Classification loss: 0.07685 | Regression loss: 0.21777 | Running loss: 0.86141\n",
      "Epoch: 0 | Iteration: 36003 | Classification loss: 0.30546 | Regression loss: 0.59977 | Running loss: 0.86132\n",
      "Epoch: 0 | Iteration: 36004 | Classification loss: 0.44585 | Regression loss: 0.67054 | Running loss: 0.86228\n",
      "Epoch: 0 | Iteration: 36005 | Classification loss: 0.33031 | Regression loss: 0.43639 | Running loss: 0.86224\n",
      "Epoch: 0 | Iteration: 36006 | Classification loss: 0.54008 | Regression loss: 0.37031 | Running loss: 0.86257\n",
      "Epoch: 0 | Iteration: 36007 | Classification loss: 0.31571 | Regression loss: 0.37726 | Running loss: 0.86179\n",
      "Epoch: 0 | Iteration: 36008 | Classification loss: 0.42429 | Regression loss: 0.41417 | Running loss: 0.86225\n",
      "Epoch: 0 | Iteration: 36009 | Classification loss: 0.73976 | Regression loss: 0.07909 | Running loss: 0.86169\n",
      "Epoch: 0 | Iteration: 36010 | Classification loss: 0.50486 | Regression loss: 0.69094 | Running loss: 0.86267\n",
      "Epoch: 0 | Iteration: 36011 | Classification loss: 0.33183 | Regression loss: 0.45563 | Running loss: 0.86304\n",
      "Epoch: 0 | Iteration: 36012 | Classification loss: 0.37067 | Regression loss: 0.40148 | Running loss: 0.86336\n",
      "Epoch: 0 | Iteration: 36013 | Classification loss: 0.42760 | Regression loss: 0.53032 | Running loss: 0.86416\n",
      "Epoch: 0 | Iteration: 36014 | Classification loss: 0.33182 | Regression loss: 0.60244 | Running loss: 0.86348\n",
      "Epoch: 0 | Iteration: 36015 | Classification loss: 0.39859 | Regression loss: 0.55622 | Running loss: 0.86457\n",
      "Epoch: 0 | Iteration: 36016 | Classification loss: 0.23018 | Regression loss: 0.38242 | Running loss: 0.86382\n",
      "Epoch: 0 | Iteration: 36017 | Classification loss: 0.47398 | Regression loss: 0.56924 | Running loss: 0.86487\n",
      "Epoch: 0 | Iteration: 36018 | Classification loss: 0.43324 | Regression loss: 0.75066 | Running loss: 0.86522\n",
      "Epoch: 0 | Iteration: 36019 | Classification loss: 0.35982 | Regression loss: 0.55093 | Running loss: 0.86497\n",
      "Epoch: 0 | Iteration: 36020 | Classification loss: 0.38172 | Regression loss: 0.29868 | Running loss: 0.86542\n",
      "Epoch: 0 | Iteration: 36021 | Classification loss: 0.38941 | Regression loss: 0.61923 | Running loss: 0.86517\n",
      "Epoch: 0 | Iteration: 36022 | Classification loss: 0.22243 | Regression loss: 0.27814 | Running loss: 0.86467\n",
      "Epoch: 0 | Iteration: 36023 | Classification loss: 0.25771 | Regression loss: 0.35850 | Running loss: 0.86453\n",
      "Epoch: 0 | Iteration: 36024 | Classification loss: 0.61951 | Regression loss: 0.65671 | Running loss: 0.86564\n",
      "Epoch: 0 | Iteration: 36025 | Classification loss: 0.36798 | Regression loss: 0.38229 | Running loss: 0.86535\n",
      "Epoch: 0 | Iteration: 36026 | Classification loss: 0.53730 | Regression loss: 0.47790 | Running loss: 0.86583\n",
      "Epoch: 0 | Iteration: 36027 | Classification loss: 0.19291 | Regression loss: 0.22556 | Running loss: 0.86484\n",
      "Epoch: 0 | Iteration: 36028 | Classification loss: 0.43018 | Regression loss: 0.51276 | Running loss: 0.86513\n",
      "Epoch: 0 | Iteration: 36029 | Classification loss: 0.39173 | Regression loss: 0.51584 | Running loss: 0.86492\n",
      "Epoch: 0 | Iteration: 36030 | Classification loss: 0.59075 | Regression loss: 0.77299 | Running loss: 0.86633\n",
      "Epoch: 0 | Iteration: 36031 | Classification loss: 0.41487 | Regression loss: 0.47108 | Running loss: 0.86604\n",
      "Epoch: 0 | Iteration: 36032 | Classification loss: 0.42147 | Regression loss: 0.59327 | Running loss: 0.86625\n",
      "Epoch: 0 | Iteration: 36033 | Classification loss: 0.37950 | Regression loss: 0.52326 | Running loss: 0.86664\n",
      "Epoch: 0 | Iteration: 36034 | Classification loss: 0.35993 | Regression loss: 0.42198 | Running loss: 0.86718\n",
      "Epoch: 0 | Iteration: 36035 | Classification loss: 0.16571 | Regression loss: 0.24136 | Running loss: 0.86764\n",
      "Epoch: 0 | Iteration: 36036 | Classification loss: 0.32475 | Regression loss: 0.51015 | Running loss: 0.86752\n",
      "Epoch: 0 | Iteration: 36037 | Classification loss: 0.40689 | Regression loss: 0.54136 | Running loss: 0.86749\n",
      "Epoch: 0 | Iteration: 36038 | Classification loss: 0.42691 | Regression loss: 0.57509 | Running loss: 0.86645\n",
      "Epoch: 0 | Iteration: 36039 | Classification loss: 0.28164 | Regression loss: 0.53536 | Running loss: 0.86625\n",
      "Epoch: 0 | Iteration: 36040 | Classification loss: 0.30845 | Regression loss: 0.52167 | Running loss: 0.86592\n",
      "Epoch: 0 | Iteration: 36041 | Classification loss: 0.44420 | Regression loss: 0.68319 | Running loss: 0.86627\n",
      "Epoch: 0 | Iteration: 36042 | Classification loss: 0.45266 | Regression loss: 0.55000 | Running loss: 0.86649\n",
      "Epoch: 0 | Iteration: 36043 | Classification loss: 0.36289 | Regression loss: 0.55789 | Running loss: 0.86657\n",
      "Epoch: 0 | Iteration: 36044 | Classification loss: 0.34848 | Regression loss: 0.31412 | Running loss: 0.86577\n",
      "Epoch: 0 | Iteration: 36045 | Classification loss: 0.41629 | Regression loss: 0.46639 | Running loss: 0.86601\n",
      "Epoch: 0 | Iteration: 36046 | Classification loss: 0.61334 | Regression loss: 0.75914 | Running loss: 0.86663\n",
      "Epoch: 0 | Iteration: 36047 | Classification loss: 0.24914 | Regression loss: 0.36658 | Running loss: 0.86733\n",
      "Epoch: 0 | Iteration: 36048 | Classification loss: 0.32841 | Regression loss: 0.47398 | Running loss: 0.86750\n",
      "Epoch: 0 | Iteration: 36049 | Classification loss: 0.30914 | Regression loss: 0.49327 | Running loss: 0.86761\n",
      "Epoch: 0 | Iteration: 36050 | Classification loss: 0.43689 | Regression loss: 0.58630 | Running loss: 0.86822\n",
      "Epoch: 0 | Iteration: 36051 | Classification loss: 0.38913 | Regression loss: 0.38433 | Running loss: 0.86717\n",
      "Epoch: 0 | Iteration: 36052 | Classification loss: 0.42433 | Regression loss: 0.51879 | Running loss: 0.86694\n",
      "Epoch: 0 | Iteration: 36053 | Classification loss: 0.15437 | Regression loss: 0.36846 | Running loss: 0.86599\n",
      "Epoch: 0 | Iteration: 36054 | Classification loss: 0.29079 | Regression loss: 0.36507 | Running loss: 0.86553\n",
      "Epoch: 0 | Iteration: 36055 | Classification loss: 0.23146 | Regression loss: 0.18952 | Running loss: 0.86448\n",
      "Epoch: 0 | Iteration: 36056 | Classification loss: 0.57680 | Regression loss: 0.64854 | Running loss: 0.86523\n",
      "Epoch: 0 | Iteration: 36057 | Classification loss: 0.66612 | Regression loss: 0.57025 | Running loss: 0.86652\n",
      "Epoch: 0 | Iteration: 36058 | Classification loss: 0.33009 | Regression loss: 0.48485 | Running loss: 0.86684\n",
      "Epoch: 0 | Iteration: 36059 | Classification loss: 0.23380 | Regression loss: 0.43505 | Running loss: 0.86661\n",
      "Epoch: 0 | Iteration: 36060 | Classification loss: 0.19907 | Regression loss: 0.32269 | Running loss: 0.86653\n",
      "Epoch: 0 | Iteration: 36061 | Classification loss: 0.25434 | Regression loss: 0.40184 | Running loss: 0.86661\n",
      "Epoch: 0 | Iteration: 36062 | Classification loss: 1.02461 | Regression loss: 0.87606 | Running loss: 0.86858\n",
      "Epoch: 0 | Iteration: 36063 | Classification loss: 0.47257 | Regression loss: 0.51686 | Running loss: 0.87013\n",
      "Epoch: 0 | Iteration: 36064 | Classification loss: 0.34189 | Regression loss: 0.34277 | Running loss: 0.87040\n",
      "Epoch: 0 | Iteration: 36065 | Classification loss: 0.28978 | Regression loss: 0.54383 | Running loss: 0.87102\n",
      "Epoch: 0 | Iteration: 36066 | Classification loss: 0.32512 | Regression loss: 0.43578 | Running loss: 0.86971\n",
      "Epoch: 0 | Iteration: 36067 | Classification loss: 0.17016 | Regression loss: 0.29835 | Running loss: 0.86912\n",
      "Epoch: 0 | Iteration: 36068 | Classification loss: 0.25162 | Regression loss: 0.46810 | Running loss: 0.86770\n",
      "Epoch: 0 | Iteration: 36069 | Classification loss: 0.40892 | Regression loss: 0.63711 | Running loss: 0.86771\n",
      "Epoch: 0 | Iteration: 36070 | Classification loss: 0.29997 | Regression loss: 0.47380 | Running loss: 0.86794\n",
      "Epoch: 0 | Iteration: 36071 | Classification loss: 0.18359 | Regression loss: 0.23359 | Running loss: 0.86723\n",
      "Epoch: 0 | Iteration: 36072 | Classification loss: 0.25771 | Regression loss: 0.55631 | Running loss: 0.86755\n",
      "Epoch: 0 | Iteration: 36073 | Classification loss: 0.19677 | Regression loss: 0.30151 | Running loss: 0.86717\n",
      "Epoch: 0 | Iteration: 36074 | Classification loss: 0.35680 | Regression loss: 0.57607 | Running loss: 0.86659\n",
      "Epoch: 0 | Iteration: 36075 | Classification loss: 0.13989 | Regression loss: 0.22890 | Running loss: 0.86580\n",
      "Epoch: 0 | Iteration: 36076 | Classification loss: 0.25938 | Regression loss: 0.29143 | Running loss: 0.86449\n",
      "Epoch: 0 | Iteration: 36077 | Classification loss: 0.15411 | Regression loss: 0.44108 | Running loss: 0.86408\n",
      "Epoch: 0 | Iteration: 36078 | Classification loss: 0.51090 | Regression loss: 0.57079 | Running loss: 0.86457\n",
      "Epoch: 0 | Iteration: 36079 | Classification loss: 0.39134 | Regression loss: 0.26507 | Running loss: 0.86507\n",
      "Epoch: 0 | Iteration: 36080 | Classification loss: 0.37127 | Regression loss: 0.40482 | Running loss: 0.86541\n",
      "Epoch: 0 | Iteration: 36081 | Classification loss: 0.38637 | Regression loss: 0.50585 | Running loss: 0.86574\n",
      "Epoch: 0 | Iteration: 36082 | Classification loss: 0.52534 | Regression loss: 0.53701 | Running loss: 0.86644\n",
      "Epoch: 0 | Iteration: 36083 | Classification loss: 0.48613 | Regression loss: 0.49614 | Running loss: 0.86731\n",
      "Epoch: 0 | Iteration: 36084 | Classification loss: 0.45686 | Regression loss: 0.47739 | Running loss: 0.86759\n",
      "Epoch: 0 | Iteration: 36085 | Classification loss: 0.43094 | Regression loss: 0.36395 | Running loss: 0.86726\n",
      "Epoch: 0 | Iteration: 36086 | Classification loss: 0.33408 | Regression loss: 0.51687 | Running loss: 0.86712\n",
      "Epoch: 0 | Iteration: 36087 | Classification loss: 0.43815 | Regression loss: 0.44843 | Running loss: 0.86771\n",
      "Epoch: 0 | Iteration: 36088 | Classification loss: 0.37974 | Regression loss: 0.51156 | Running loss: 0.86764\n",
      "Epoch: 0 | Iteration: 36089 | Classification loss: 0.42289 | Regression loss: 0.41403 | Running loss: 0.86693\n",
      "Epoch: 0 | Iteration: 36090 | Classification loss: 0.25966 | Regression loss: 0.57112 | Running loss: 0.86710\n",
      "Epoch: 0 | Iteration: 36091 | Classification loss: 0.18539 | Regression loss: 0.42297 | Running loss: 0.86762\n",
      "Epoch: 0 | Iteration: 36092 | Classification loss: 0.41572 | Regression loss: 0.43227 | Running loss: 0.86808\n",
      "Epoch: 0 | Iteration: 36093 | Classification loss: 0.36583 | Regression loss: 0.34442 | Running loss: 0.86787\n",
      "Epoch: 0 | Iteration: 36094 | Classification loss: 0.30096 | Regression loss: 0.44916 | Running loss: 0.86776\n",
      "Epoch: 0 | Iteration: 36095 | Classification loss: 0.30797 | Regression loss: 0.49886 | Running loss: 0.86829\n",
      "Epoch: 0 | Iteration: 36096 | Classification loss: 0.20117 | Regression loss: 0.46483 | Running loss: 0.86852\n",
      "Epoch: 0 | Iteration: 36097 | Classification loss: 0.22791 | Regression loss: 0.34099 | Running loss: 0.86830\n",
      "Epoch: 0 | Iteration: 36098 | Classification loss: 0.25233 | Regression loss: 0.40798 | Running loss: 0.86756\n",
      "Epoch: 0 | Iteration: 36099 | Classification loss: 0.55165 | Regression loss: 0.56749 | Running loss: 0.86825\n",
      "Epoch: 0 | Iteration: 36100 | Classification loss: 0.37966 | Regression loss: 0.50778 | Running loss: 0.86824\n",
      "Epoch: 0 | Iteration: 36101 | Classification loss: 0.43589 | Regression loss: 0.39860 | Running loss: 0.86844\n",
      "Epoch: 0 | Iteration: 36102 | Classification loss: 0.28904 | Regression loss: 0.44916 | Running loss: 0.86743\n",
      "Epoch: 0 | Iteration: 36103 | Classification loss: 0.27500 | Regression loss: 0.40673 | Running loss: 0.86675\n",
      "Epoch: 0 | Iteration: 36104 | Classification loss: 0.36899 | Regression loss: 0.71366 | Running loss: 0.86726\n",
      "Epoch: 0 | Iteration: 36105 | Classification loss: 0.42058 | Regression loss: 0.53814 | Running loss: 0.86770\n",
      "Epoch: 0 | Iteration: 36106 | Classification loss: 0.46372 | Regression loss: 0.42274 | Running loss: 0.86750\n",
      "Epoch: 0 | Iteration: 36107 | Classification loss: 0.30697 | Regression loss: 0.42847 | Running loss: 0.86706\n",
      "Epoch: 0 | Iteration: 36108 | Classification loss: 0.35356 | Regression loss: 0.39631 | Running loss: 0.86648\n",
      "Epoch: 0 | Iteration: 36109 | Classification loss: 0.28304 | Regression loss: 0.28364 | Running loss: 0.86564\n",
      "Epoch: 0 | Iteration: 36110 | Classification loss: 0.24280 | Regression loss: 0.39852 | Running loss: 0.86543\n",
      "Epoch: 0 | Iteration: 36111 | Classification loss: 0.47338 | Regression loss: 0.52814 | Running loss: 0.86513\n",
      "Epoch: 0 | Iteration: 36112 | Classification loss: 0.25992 | Regression loss: 0.48489 | Running loss: 0.86472\n",
      "Epoch: 0 | Iteration: 36113 | Classification loss: 0.50732 | Regression loss: 0.44273 | Running loss: 0.86484\n",
      "Epoch: 0 | Iteration: 36114 | Classification loss: 0.35117 | Regression loss: 0.40766 | Running loss: 0.86400\n",
      "Epoch: 0 | Iteration: 36115 | Classification loss: 2.01831 | Regression loss: 0.48486 | Running loss: 0.86780\n",
      "Epoch: 0 | Iteration: 36116 | Classification loss: 0.41811 | Regression loss: 0.43433 | Running loss: 0.86825\n",
      "Epoch: 0 | Iteration: 36117 | Classification loss: 0.29465 | Regression loss: 0.55718 | Running loss: 0.86805\n",
      "Epoch: 0 | Iteration: 36118 | Classification loss: 0.45277 | Regression loss: 0.58568 | Running loss: 0.86841\n",
      "Epoch: 0 | Iteration: 36119 | Classification loss: 0.36749 | Regression loss: 0.43898 | Running loss: 0.86815\n",
      "Epoch: 0 | Iteration: 36120 | Classification loss: 0.47761 | Regression loss: 0.63285 | Running loss: 0.86003\n",
      "Epoch: 0 | Iteration: 36121 | Classification loss: 0.21038 | Regression loss: 0.42460 | Running loss: 0.85946\n",
      "Epoch: 0 | Iteration: 36122 | Classification loss: 0.49724 | Regression loss: 0.55619 | Running loss: 0.85917\n",
      "Epoch: 0 | Iteration: 36123 | Classification loss: 0.33547 | Regression loss: 0.54453 | Running loss: 0.85943\n",
      "Epoch: 0 | Iteration: 36124 | Classification loss: 0.28232 | Regression loss: 0.53351 | Running loss: 0.85990\n",
      "Epoch: 0 | Iteration: 36125 | Classification loss: 0.13498 | Regression loss: 0.25373 | Running loss: 0.85853\n",
      "Epoch: 0 | Iteration: 36126 | Classification loss: 0.25266 | Regression loss: 0.49383 | Running loss: 0.85861\n",
      "Epoch: 0 | Iteration: 36127 | Classification loss: 0.27681 | Regression loss: 0.48326 | Running loss: 0.85824\n",
      "Epoch: 0 | Iteration: 36128 | Classification loss: 0.53460 | Regression loss: 0.51080 | Running loss: 0.85892\n",
      "Epoch: 0 | Iteration: 36129 | Classification loss: 0.57355 | Regression loss: 0.68021 | Running loss: 0.85983\n",
      "Epoch: 0 | Iteration: 36130 | Classification loss: 0.50481 | Regression loss: 0.31611 | Running loss: 0.85834\n",
      "Epoch: 0 | Iteration: 36131 | Classification loss: 0.21697 | Regression loss: 0.31119 | Running loss: 0.85814\n",
      "Epoch: 0 | Iteration: 36132 | Classification loss: 0.25833 | Regression loss: 0.44572 | Running loss: 0.85742\n",
      "Epoch: 0 | Iteration: 36133 | Classification loss: 0.24976 | Regression loss: 0.45950 | Running loss: 0.85618\n",
      "Epoch: 0 | Iteration: 36134 | Classification loss: 0.39579 | Regression loss: 0.36866 | Running loss: 0.85597\n",
      "Epoch: 0 | Iteration: 36135 | Classification loss: 0.46676 | Regression loss: 0.58663 | Running loss: 0.85601\n",
      "Epoch: 0 | Iteration: 36136 | Classification loss: 0.33420 | Regression loss: 0.49302 | Running loss: 0.85575\n",
      "Epoch: 0 | Iteration: 36137 | Classification loss: 0.19906 | Regression loss: 0.36456 | Running loss: 0.85487\n",
      "Epoch: 0 | Iteration: 36138 | Classification loss: 0.36867 | Regression loss: 0.48604 | Running loss: 0.85453\n",
      "Epoch: 0 | Iteration: 36139 | Classification loss: 0.52335 | Regression loss: 0.48706 | Running loss: 0.85489\n",
      "Epoch: 0 | Iteration: 36140 | Classification loss: 0.37717 | Regression loss: 0.55131 | Running loss: 0.85488\n",
      "Epoch: 0 | Iteration: 36141 | Classification loss: 0.28141 | Regression loss: 0.39087 | Running loss: 0.85478\n",
      "Epoch: 0 | Iteration: 36142 | Classification loss: 0.58729 | Regression loss: 0.76397 | Running loss: 0.85633\n",
      "Epoch: 0 | Iteration: 36143 | Classification loss: 0.41631 | Regression loss: 0.46351 | Running loss: 0.85611\n",
      "Epoch: 0 | Iteration: 36144 | Classification loss: 0.31997 | Regression loss: 0.65315 | Running loss: 0.85679\n",
      "Epoch: 0 | Iteration: 36145 | Classification loss: 0.45409 | Regression loss: 0.62243 | Running loss: 0.85726\n",
      "Epoch: 0 | Iteration: 36146 | Classification loss: 0.33290 | Regression loss: 0.48350 | Running loss: 0.85627\n",
      "Epoch: 0 | Iteration: 36147 | Classification loss: 0.32295 | Regression loss: 0.41658 | Running loss: 0.85632\n",
      "Epoch: 0 | Iteration: 36148 | Classification loss: 0.36782 | Regression loss: 0.41710 | Running loss: 0.85664\n",
      "Epoch: 0 | Iteration: 36149 | Classification loss: 0.31629 | Regression loss: 0.52591 | Running loss: 0.85593\n",
      "Epoch: 0 | Iteration: 36150 | Classification loss: 0.23606 | Regression loss: 0.47209 | Running loss: 0.85532\n",
      "Epoch: 0 | Iteration: 36151 | Classification loss: 0.39650 | Regression loss: 0.48154 | Running loss: 0.85595\n",
      "Epoch: 0 | Iteration: 36152 | Classification loss: 0.52414 | Regression loss: 0.55538 | Running loss: 0.85620\n",
      "Epoch: 0 | Iteration: 36153 | Classification loss: 0.38338 | Regression loss: 0.31726 | Running loss: 0.85607\n",
      "Epoch: 0 | Iteration: 36154 | Classification loss: 0.18810 | Regression loss: 0.38539 | Running loss: 0.85472\n",
      "Epoch: 0 | Iteration: 36155 | Classification loss: 0.42202 | Regression loss: 0.60866 | Running loss: 0.85505\n",
      "Epoch: 0 | Iteration: 36156 | Classification loss: 0.35352 | Regression loss: 0.41309 | Running loss: 0.85520\n",
      "Epoch: 0 | Iteration: 36157 | Classification loss: 0.35704 | Regression loss: 0.55484 | Running loss: 0.85523\n",
      "Epoch: 0 | Iteration: 36158 | Classification loss: 0.17252 | Regression loss: 0.26641 | Running loss: 0.85403\n",
      "Epoch: 0 | Iteration: 36159 | Classification loss: 0.56532 | Regression loss: 0.39555 | Running loss: 0.85369\n",
      "Epoch: 0 | Iteration: 36160 | Classification loss: 0.42819 | Regression loss: 0.60869 | Running loss: 0.85457\n",
      "Epoch: 0 | Iteration: 36161 | Classification loss: 0.38834 | Regression loss: 0.56844 | Running loss: 0.85498\n",
      "Epoch: 0 | Iteration: 36162 | Classification loss: 0.66289 | Regression loss: 0.45348 | Running loss: 0.85472\n",
      "Epoch: 0 | Iteration: 36163 | Classification loss: 0.37759 | Regression loss: 0.57445 | Running loss: 0.85463\n",
      "Epoch: 0 | Iteration: 36164 | Classification loss: 0.41125 | Regression loss: 0.35859 | Running loss: 0.85387\n",
      "Epoch: 0 | Iteration: 36165 | Classification loss: 0.38333 | Regression loss: 0.55132 | Running loss: 0.85372\n",
      "Epoch: 0 | Iteration: 36166 | Classification loss: 0.39607 | Regression loss: 0.53791 | Running loss: 0.85350\n",
      "Epoch: 0 | Iteration: 36167 | Classification loss: 0.46124 | Regression loss: 0.72395 | Running loss: 0.85432\n",
      "Epoch: 0 | Iteration: 36168 | Classification loss: 0.26985 | Regression loss: 0.42840 | Running loss: 0.85385\n",
      "Epoch: 0 | Iteration: 36169 | Classification loss: 0.38739 | Regression loss: 0.56379 | Running loss: 0.85397\n",
      "Epoch: 0 | Iteration: 36170 | Classification loss: 0.41451 | Regression loss: 0.55839 | Running loss: 0.85495\n",
      "Epoch: 0 | Iteration: 36171 | Classification loss: 0.17721 | Regression loss: 0.40770 | Running loss: 0.85424\n",
      "Epoch: 0 | Iteration: 36172 | Classification loss: 0.22144 | Regression loss: 0.45346 | Running loss: 0.85408\n",
      "Epoch: 0 | Iteration: 36173 | Classification loss: 0.34065 | Regression loss: 0.54962 | Running loss: 0.85404\n",
      "Epoch: 0 | Iteration: 36174 | Classification loss: 0.47112 | Regression loss: 0.62350 | Running loss: 0.85478\n",
      "Epoch: 0 | Iteration: 36175 | Classification loss: 0.33302 | Regression loss: 0.62886 | Running loss: 0.85537\n",
      "Epoch: 0 | Iteration: 36176 | Classification loss: 0.43969 | Regression loss: 0.54077 | Running loss: 0.85514\n",
      "Epoch: 0 | Iteration: 36177 | Classification loss: 0.42216 | Regression loss: 0.56866 | Running loss: 0.85609\n",
      "Epoch: 0 | Iteration: 36178 | Classification loss: 0.36293 | Regression loss: 0.43981 | Running loss: 0.85573\n",
      "Epoch: 0 | Iteration: 36179 | Classification loss: 0.57002 | Regression loss: 0.53737 | Running loss: 0.85592\n",
      "Epoch: 0 | Iteration: 36180 | Classification loss: 0.36181 | Regression loss: 0.49002 | Running loss: 0.85583\n",
      "Epoch: 0 | Iteration: 36181 | Classification loss: 0.48987 | Regression loss: 0.50023 | Running loss: 0.85589\n",
      "Epoch: 0 | Iteration: 36182 | Classification loss: 0.28442 | Regression loss: 0.43755 | Running loss: 0.85555\n",
      "Epoch: 0 | Iteration: 36183 | Classification loss: 0.31432 | Regression loss: 0.37353 | Running loss: 0.85523\n",
      "Epoch: 0 | Iteration: 36184 | Classification loss: 0.36946 | Regression loss: 0.44224 | Running loss: 0.85563\n",
      "Epoch: 0 | Iteration: 36185 | Classification loss: 0.23892 | Regression loss: 0.45999 | Running loss: 0.85536\n",
      "Epoch: 0 | Iteration: 36186 | Classification loss: 1.49062 | Regression loss: 0.22265 | Running loss: 0.85636\n",
      "Epoch: 0 | Iteration: 36187 | Classification loss: 0.15596 | Regression loss: 0.23456 | Running loss: 0.85495\n",
      "Epoch: 0 | Iteration: 36188 | Classification loss: 0.33273 | Regression loss: 0.41828 | Running loss: 0.85452\n",
      "Epoch: 0 | Iteration: 36189 | Classification loss: 0.13964 | Regression loss: 0.28809 | Running loss: 0.85455\n",
      "Epoch: 0 | Iteration: 36190 | Classification loss: 0.50723 | Regression loss: 0.73491 | Running loss: 0.85574\n",
      "Epoch: 0 | Iteration: 36191 | Classification loss: 0.45652 | Regression loss: 0.46565 | Running loss: 0.85650\n",
      "Epoch: 0 | Iteration: 36192 | Classification loss: 0.24556 | Regression loss: 0.49980 | Running loss: 0.85636\n",
      "Epoch: 0 | Iteration: 36193 | Classification loss: 0.50675 | Regression loss: 0.67840 | Running loss: 0.85704\n",
      "Epoch: 0 | Iteration: 36194 | Classification loss: 0.43216 | Regression loss: 0.60175 | Running loss: 0.85804\n",
      "Epoch: 0 | Iteration: 36195 | Classification loss: 0.41693 | Regression loss: 0.67703 | Running loss: 0.85831\n",
      "Epoch: 0 | Iteration: 36196 | Classification loss: 0.45859 | Regression loss: 0.60194 | Running loss: 0.85906\n",
      "Epoch: 0 | Iteration: 36197 | Classification loss: 0.20425 | Regression loss: 0.41612 | Running loss: 0.85910\n",
      "Epoch: 0 | Iteration: 36198 | Classification loss: 0.50481 | Regression loss: 0.46829 | Running loss: 0.85947\n",
      "Epoch: 0 | Iteration: 36199 | Classification loss: 0.38261 | Regression loss: 0.62410 | Running loss: 0.85931\n",
      "Epoch: 0 | Iteration: 36200 | Classification loss: 0.46882 | Regression loss: 0.58373 | Running loss: 0.86037\n",
      "Epoch: 0 | Iteration: 36201 | Classification loss: 0.46656 | Regression loss: 0.66305 | Running loss: 0.86079\n",
      "Epoch: 0 | Iteration: 36202 | Classification loss: 0.42328 | Regression loss: 0.46599 | Running loss: 0.86126\n",
      "Epoch: 0 | Iteration: 36203 | Classification loss: 0.43313 | Regression loss: 0.44578 | Running loss: 0.86119\n",
      "Epoch: 0 | Iteration: 36204 | Classification loss: 0.55017 | Regression loss: 0.72943 | Running loss: 0.86225\n",
      "Epoch: 0 | Iteration: 36205 | Classification loss: 0.62573 | Regression loss: 0.62088 | Running loss: 0.86288\n",
      "Epoch: 0 | Iteration: 36206 | Classification loss: 0.53757 | Regression loss: 0.52709 | Running loss: 0.86391\n",
      "Epoch: 0 | Iteration: 36207 | Classification loss: 0.32643 | Regression loss: 0.44636 | Running loss: 0.86316\n",
      "Epoch: 0 | Iteration: 36208 | Classification loss: 0.66354 | Regression loss: 0.50458 | Running loss: 0.86368\n",
      "Epoch: 0 | Iteration: 36209 | Classification loss: 0.46813 | Regression loss: 0.55062 | Running loss: 0.86431\n",
      "Epoch: 0 | Iteration: 36210 | Classification loss: 0.19005 | Regression loss: 0.35237 | Running loss: 0.86411\n",
      "Epoch: 0 | Iteration: 36211 | Classification loss: 0.42670 | Regression loss: 0.60506 | Running loss: 0.86487\n",
      "Epoch: 0 | Iteration: 36212 | Classification loss: 0.38093 | Regression loss: 0.34449 | Running loss: 0.86449\n",
      "Epoch: 0 | Iteration: 36213 | Classification loss: 0.40112 | Regression loss: 0.70931 | Running loss: 0.86122\n",
      "Epoch: 0 | Iteration: 36214 | Classification loss: 0.36626 | Regression loss: 0.45759 | Running loss: 0.86081\n",
      "Epoch: 0 | Iteration: 36215 | Classification loss: 0.58679 | Regression loss: 0.73321 | Running loss: 0.86113\n",
      "Epoch: 0 | Iteration: 36216 | Classification loss: 0.44485 | Regression loss: 0.33505 | Running loss: 0.86080\n",
      "Epoch: 0 | Iteration: 36217 | Classification loss: 0.40837 | Regression loss: 0.51832 | Running loss: 0.86134\n",
      "Epoch: 0 | Iteration: 36218 | Classification loss: 0.35147 | Regression loss: 0.54176 | Running loss: 0.86174\n",
      "Epoch: 0 | Iteration: 36219 | Classification loss: 0.25013 | Regression loss: 0.51317 | Running loss: 0.86142\n",
      "Epoch: 0 | Iteration: 36220 | Classification loss: 0.27182 | Regression loss: 0.40666 | Running loss: 0.86062\n",
      "Epoch: 0 | Iteration: 36221 | Classification loss: 0.44839 | Regression loss: 0.49784 | Running loss: 0.86073\n",
      "Epoch: 0 | Iteration: 36222 | Classification loss: 0.28137 | Regression loss: 0.44201 | Running loss: 0.86028\n",
      "Epoch: 0 | Iteration: 36223 | Classification loss: 0.36437 | Regression loss: 0.45741 | Running loss: 0.85981\n",
      "Epoch: 0 | Iteration: 36224 | Classification loss: 0.19254 | Regression loss: 0.41895 | Running loss: 0.85961\n",
      "Epoch: 0 | Iteration: 36225 | Classification loss: 0.35343 | Regression loss: 0.48765 | Running loss: 0.85886\n",
      "Epoch: 0 | Iteration: 36226 | Classification loss: 0.34884 | Regression loss: 0.42786 | Running loss: 0.85842\n",
      "Epoch: 0 | Iteration: 36227 | Classification loss: 0.46680 | Regression loss: 0.47648 | Running loss: 0.85732\n",
      "Epoch: 0 | Iteration: 36228 | Classification loss: 0.27351 | Regression loss: 0.57213 | Running loss: 0.85707\n",
      "Epoch: 0 | Iteration: 36229 | Classification loss: 0.43670 | Regression loss: 0.57118 | Running loss: 0.85714\n",
      "Epoch: 0 | Iteration: 36230 | Classification loss: 0.29398 | Regression loss: 0.43297 | Running loss: 0.85596\n",
      "Epoch: 0 | Iteration: 36231 | Classification loss: 0.52569 | Regression loss: 0.69005 | Running loss: 0.85702\n",
      "Epoch: 0 | Iteration: 36232 | Classification loss: 0.28040 | Regression loss: 0.36450 | Running loss: 0.85672\n",
      "Epoch: 0 | Iteration: 36233 | Classification loss: 0.51205 | Regression loss: 0.50114 | Running loss: 0.85737\n",
      "Epoch: 0 | Iteration: 36234 | Classification loss: 0.58205 | Regression loss: 0.57647 | Running loss: 0.85742\n",
      "Epoch: 0 | Iteration: 36235 | Classification loss: 0.47518 | Regression loss: 0.61102 | Running loss: 0.85857\n",
      "Epoch: 0 | Iteration: 36236 | Classification loss: 0.22528 | Regression loss: 0.37479 | Running loss: 0.85772\n",
      "Epoch: 0 | Iteration: 36237 | Classification loss: 0.39203 | Regression loss: 0.47390 | Running loss: 0.85792\n",
      "Epoch: 0 | Iteration: 36238 | Classification loss: 0.54105 | Regression loss: 0.34401 | Running loss: 0.85815\n",
      "Epoch: 0 | Iteration: 36239 | Classification loss: 0.33271 | Regression loss: 0.53536 | Running loss: 0.85809\n",
      "Epoch: 0 | Iteration: 36240 | Classification loss: 0.36321 | Regression loss: 0.43458 | Running loss: 0.85795\n",
      "Epoch: 0 | Iteration: 36241 | Classification loss: 0.38148 | Regression loss: 0.51086 | Running loss: 0.85768\n",
      "Epoch: 0 | Iteration: 36242 | Classification loss: 0.35134 | Regression loss: 0.39874 | Running loss: 0.85795\n",
      "Epoch: 0 | Iteration: 36243 | Classification loss: 0.11243 | Regression loss: 0.20599 | Running loss: 0.85675\n",
      "Epoch: 0 | Iteration: 36244 | Classification loss: 0.50282 | Regression loss: 0.68389 | Running loss: 0.85763\n",
      "Epoch: 0 | Iteration: 36245 | Classification loss: 0.39098 | Regression loss: 0.35038 | Running loss: 0.85808\n",
      "Epoch: 0 | Iteration: 36246 | Classification loss: 0.64880 | Regression loss: 0.81322 | Running loss: 0.85948\n",
      "Epoch: 0 | Iteration: 36247 | Classification loss: 0.31056 | Regression loss: 0.39766 | Running loss: 0.85944\n",
      "Epoch: 0 | Iteration: 36248 | Classification loss: 0.22755 | Regression loss: 0.22309 | Running loss: 0.85851\n",
      "Epoch: 0 | Iteration: 36249 | Classification loss: 0.26013 | Regression loss: 0.34330 | Running loss: 0.85859\n",
      "Epoch: 0 | Iteration: 36250 | Classification loss: 0.37043 | Regression loss: 0.53516 | Running loss: 0.85865\n",
      "Epoch: 0 | Iteration: 36251 | Classification loss: 0.43536 | Regression loss: 0.55484 | Running loss: 0.85881\n",
      "Epoch: 0 | Iteration: 36252 | Classification loss: 0.34670 | Regression loss: 0.34250 | Running loss: 0.85877\n",
      "Epoch: 0 | Iteration: 36253 | Classification loss: 0.51069 | Regression loss: 0.45082 | Running loss: 0.85925\n",
      "Epoch: 0 | Iteration: 36254 | Classification loss: 0.48218 | Regression loss: 0.52581 | Running loss: 0.85975\n",
      "Epoch: 0 | Iteration: 36255 | Classification loss: 0.21629 | Regression loss: 0.40369 | Running loss: 0.85879\n",
      "Epoch: 0 | Iteration: 36256 | Classification loss: 0.45681 | Regression loss: 0.72190 | Running loss: 0.85978\n",
      "Epoch: 0 | Iteration: 36257 | Classification loss: 0.10862 | Regression loss: 0.30984 | Running loss: 0.85859\n",
      "Epoch: 0 | Iteration: 36258 | Classification loss: 0.29376 | Regression loss: 0.47460 | Running loss: 0.85831\n",
      "Epoch: 0 | Iteration: 36259 | Classification loss: 0.44665 | Regression loss: 0.76941 | Running loss: 0.85992\n",
      "Epoch: 0 | Iteration: 36260 | Classification loss: 0.36026 | Regression loss: 0.42441 | Running loss: 0.85846\n",
      "Epoch: 0 | Iteration: 36261 | Classification loss: 0.37517 | Regression loss: 0.34464 | Running loss: 0.85794\n",
      "Epoch: 0 | Iteration: 36262 | Classification loss: 0.19720 | Regression loss: 0.30275 | Running loss: 0.85715\n",
      "Epoch: 0 | Iteration: 36263 | Classification loss: 0.32431 | Regression loss: 0.55225 | Running loss: 0.85762\n",
      "Epoch: 0 | Iteration: 36264 | Classification loss: 0.38352 | Regression loss: 0.43508 | Running loss: 0.85836\n",
      "Epoch: 0 | Iteration: 36265 | Classification loss: 0.63217 | Regression loss: 0.86235 | Running loss: 0.85998\n",
      "Epoch: 0 | Iteration: 36266 | Classification loss: 0.29945 | Regression loss: 0.41391 | Running loss: 0.86024\n",
      "Epoch: 0 | Iteration: 36267 | Classification loss: 0.34740 | Regression loss: 0.36069 | Running loss: 0.85904\n",
      "Epoch: 0 | Iteration: 36268 | Classification loss: 0.16125 | Regression loss: 0.37066 | Running loss: 0.85848\n",
      "Epoch: 0 | Iteration: 36269 | Classification loss: 0.35825 | Regression loss: 0.35798 | Running loss: 0.85837\n",
      "Epoch: 0 | Iteration: 36270 | Classification loss: 0.23039 | Regression loss: 0.35719 | Running loss: 0.85761\n",
      "Epoch: 0 | Iteration: 36271 | Classification loss: 0.28275 | Regression loss: 0.30198 | Running loss: 0.85724\n",
      "Epoch: 0 | Iteration: 36272 | Classification loss: 0.22146 | Regression loss: 0.32471 | Running loss: 0.85679\n",
      "Epoch: 0 | Iteration: 36273 | Classification loss: 0.33846 | Regression loss: 0.49802 | Running loss: 0.85643\n",
      "Epoch: 0 | Iteration: 36274 | Classification loss: 0.39204 | Regression loss: 0.49671 | Running loss: 0.85684\n",
      "Epoch: 0 | Iteration: 36275 | Classification loss: 1.35458 | Regression loss: 0.27366 | Running loss: 0.85891\n",
      "Epoch: 0 | Iteration: 36276 | Classification loss: 0.28142 | Regression loss: 0.51710 | Running loss: 0.85930\n",
      "Epoch: 0 | Iteration: 36277 | Classification loss: 0.23765 | Regression loss: 0.30060 | Running loss: 0.85908\n",
      "Epoch: 0 | Iteration: 36278 | Classification loss: 0.21382 | Regression loss: 0.29705 | Running loss: 0.85853\n",
      "Epoch: 0 | Iteration: 36279 | Classification loss: 0.42824 | Regression loss: 0.46270 | Running loss: 0.85868\n",
      "Epoch: 0 | Iteration: 36280 | Classification loss: 0.44676 | Regression loss: 0.34720 | Running loss: 0.85862\n",
      "Epoch: 0 | Iteration: 36281 | Classification loss: 0.28725 | Regression loss: 0.46990 | Running loss: 0.85841\n",
      "Epoch: 0 | Iteration: 36282 | Classification loss: 0.30188 | Regression loss: 0.46020 | Running loss: 0.85779\n",
      "Epoch: 0 | Iteration: 36283 | Classification loss: 0.39371 | Regression loss: 0.49502 | Running loss: 0.85806\n",
      "Epoch: 0 | Iteration: 36284 | Classification loss: 0.43197 | Regression loss: 0.54661 | Running loss: 0.85824\n",
      "Epoch: 0 | Iteration: 36285 | Classification loss: 0.17139 | Regression loss: 0.38613 | Running loss: 0.85708\n",
      "Epoch: 0 | Iteration: 36286 | Classification loss: 0.72655 | Regression loss: 0.65105 | Running loss: 0.85833\n",
      "Epoch: 0 | Iteration: 36287 | Classification loss: 0.48816 | Regression loss: 0.57095 | Running loss: 0.85885\n",
      "Epoch: 0 | Iteration: 36288 | Classification loss: 0.27194 | Regression loss: 0.53498 | Running loss: 0.85764\n",
      "Epoch: 0 | Iteration: 36289 | Classification loss: 0.55593 | Regression loss: 0.54988 | Running loss: 0.85747\n",
      "Epoch: 0 | Iteration: 36290 | Classification loss: 0.45895 | Regression loss: 0.53297 | Running loss: 0.85786\n",
      "Epoch: 0 | Iteration: 36291 | Classification loss: 0.11745 | Regression loss: 0.25579 | Running loss: 0.85724\n",
      "Epoch: 0 | Iteration: 36292 | Classification loss: 0.28940 | Regression loss: 0.44347 | Running loss: 0.85704\n",
      "Epoch: 0 | Iteration: 36293 | Classification loss: 0.36054 | Regression loss: 0.35668 | Running loss: 0.85690\n",
      "Epoch: 0 | Iteration: 36294 | Classification loss: 0.26656 | Regression loss: 0.36786 | Running loss: 0.85752\n",
      "Epoch: 0 | Iteration: 36295 | Classification loss: 0.33869 | Regression loss: 0.56886 | Running loss: 0.85737\n",
      "Epoch: 0 | Iteration: 36296 | Classification loss: 0.47632 | Regression loss: 0.52591 | Running loss: 0.85753\n",
      "Epoch: 0 | Iteration: 36297 | Classification loss: 0.29703 | Regression loss: 0.40235 | Running loss: 0.85776\n",
      "Epoch: 0 | Iteration: 36298 | Classification loss: 0.38373 | Regression loss: 0.64193 | Running loss: 0.85789\n",
      "Epoch: 0 | Iteration: 36299 | Classification loss: 0.45968 | Regression loss: 0.58332 | Running loss: 0.85854\n",
      "Epoch: 0 | Iteration: 36300 | Classification loss: 0.41227 | Regression loss: 0.59597 | Running loss: 0.85929\n",
      "Epoch: 0 | Iteration: 36301 | Classification loss: 0.37323 | Regression loss: 0.65295 | Running loss: 0.85911\n",
      "Epoch: 0 | Iteration: 36302 | Classification loss: 0.37235 | Regression loss: 0.57791 | Running loss: 0.85934\n",
      "Epoch: 0 | Iteration: 36303 | Classification loss: 0.20929 | Regression loss: 0.19369 | Running loss: 0.85823\n",
      "Epoch: 0 | Iteration: 36304 | Classification loss: 0.25303 | Regression loss: 0.38719 | Running loss: 0.85840\n",
      "Epoch: 0 | Iteration: 36305 | Classification loss: 0.23294 | Regression loss: 0.31106 | Running loss: 0.85800\n",
      "Epoch: 0 | Iteration: 36306 | Classification loss: 0.29317 | Regression loss: 0.45879 | Running loss: 0.85797\n",
      "Epoch: 0 | Iteration: 36307 | Classification loss: 0.39597 | Regression loss: 0.51640 | Running loss: 0.85815\n",
      "Epoch: 0 | Iteration: 36308 | Classification loss: 0.45670 | Regression loss: 0.50673 | Running loss: 0.85894\n",
      "Epoch: 0 | Iteration: 36309 | Classification loss: 0.40539 | Regression loss: 0.72739 | Running loss: 0.85951\n",
      "Epoch: 0 | Iteration: 36310 | Classification loss: 0.40940 | Regression loss: 0.43071 | Running loss: 0.85940\n",
      "Epoch: 0 | Iteration: 36311 | Classification loss: 0.44639 | Regression loss: 0.71007 | Running loss: 0.86092\n",
      "Epoch: 0 | Iteration: 36312 | Classification loss: 0.46144 | Regression loss: 0.39233 | Running loss: 0.86134\n",
      "Epoch: 0 | Iteration: 36313 | Classification loss: 0.34032 | Regression loss: 0.37523 | Running loss: 0.86145\n",
      "Epoch: 0 | Iteration: 36314 | Classification loss: 0.22624 | Regression loss: 0.39319 | Running loss: 0.86053\n",
      "Epoch: 0 | Iteration: 36315 | Classification loss: 0.29198 | Regression loss: 0.45509 | Running loss: 0.86069\n",
      "Epoch: 0 | Iteration: 36316 | Classification loss: 0.14209 | Regression loss: 0.26519 | Running loss: 0.86015\n",
      "Epoch: 0 | Iteration: 36317 | Classification loss: 0.29288 | Regression loss: 0.51621 | Running loss: 0.86012\n",
      "Epoch: 0 | Iteration: 36318 | Classification loss: 0.45776 | Regression loss: 0.59134 | Running loss: 0.86047\n",
      "Epoch: 0 | Iteration: 36319 | Classification loss: 0.45335 | Regression loss: 0.58181 | Running loss: 0.86132\n",
      "Epoch: 0 | Iteration: 36320 | Classification loss: 0.47550 | Regression loss: 0.66611 | Running loss: 0.86240\n",
      "Epoch: 0 | Iteration: 36321 | Classification loss: 0.52225 | Regression loss: 0.47495 | Running loss: 0.86290\n",
      "Epoch: 0 | Iteration: 36322 | Classification loss: 0.38825 | Regression loss: 0.63207 | Running loss: 0.86321\n",
      "Epoch: 0 | Iteration: 36323 | Classification loss: 0.29284 | Regression loss: 0.50843 | Running loss: 0.86341\n",
      "Epoch: 0 | Iteration: 36324 | Classification loss: 0.29495 | Regression loss: 0.42863 | Running loss: 0.86333\n",
      "Epoch: 0 | Iteration: 36325 | Classification loss: 0.48723 | Regression loss: 0.42163 | Running loss: 0.86301\n",
      "Epoch: 0 | Iteration: 36326 | Classification loss: 0.22663 | Regression loss: 0.42084 | Running loss: 0.86241\n",
      "Epoch: 0 | Iteration: 36327 | Classification loss: 0.44560 | Regression loss: 0.52478 | Running loss: 0.86271\n",
      "Epoch: 0 | Iteration: 36328 | Classification loss: 0.57563 | Regression loss: 0.84490 | Running loss: 0.86340\n",
      "Epoch: 0 | Iteration: 36329 | Classification loss: 0.35430 | Regression loss: 0.59939 | Running loss: 0.86235\n",
      "Epoch: 0 | Iteration: 36330 | Classification loss: 0.36167 | Regression loss: 0.39991 | Running loss: 0.86248\n",
      "Epoch: 0 | Iteration: 36331 | Classification loss: 0.33227 | Regression loss: 0.53185 | Running loss: 0.86221\n",
      "Epoch: 0 | Iteration: 36332 | Classification loss: 0.49067 | Regression loss: 0.61203 | Running loss: 0.86309\n",
      "Epoch: 0 | Iteration: 36333 | Classification loss: 0.30034 | Regression loss: 0.57228 | Running loss: 0.86279\n",
      "Epoch: 0 | Iteration: 36334 | Classification loss: 0.42033 | Regression loss: 0.50251 | Running loss: 0.86368\n",
      "Epoch: 0 | Iteration: 36335 | Classification loss: 0.25673 | Regression loss: 0.44131 | Running loss: 0.86297\n",
      "Epoch: 0 | Iteration: 36336 | Classification loss: 0.35955 | Regression loss: 0.71189 | Running loss: 0.86320\n",
      "Epoch: 0 | Iteration: 36337 | Classification loss: 0.83575 | Regression loss: 0.45710 | Running loss: 0.86450\n",
      "Epoch: 0 | Iteration: 36338 | Classification loss: 0.31699 | Regression loss: 0.39389 | Running loss: 0.86393\n",
      "Epoch: 0 | Iteration: 36339 | Classification loss: 0.31096 | Regression loss: 0.14451 | Running loss: 0.86322\n",
      "Epoch: 0 | Iteration: 36340 | Classification loss: 0.44046 | Regression loss: 0.41814 | Running loss: 0.86310\n",
      "Epoch: 0 | Iteration: 36341 | Classification loss: 0.38003 | Regression loss: 0.44819 | Running loss: 0.86344\n",
      "Epoch: 0 | Iteration: 36342 | Classification loss: 0.41435 | Regression loss: 0.65311 | Running loss: 0.86357\n",
      "Epoch: 0 | Iteration: 36343 | Classification loss: 0.41859 | Regression loss: 0.47101 | Running loss: 0.86331\n",
      "Epoch: 0 | Iteration: 36344 | Classification loss: 0.43211 | Regression loss: 0.47143 | Running loss: 0.86282\n",
      "Epoch: 0 | Iteration: 36345 | Classification loss: 0.45184 | Regression loss: 0.59348 | Running loss: 0.86324\n",
      "Epoch: 0 | Iteration: 36346 | Classification loss: 0.23640 | Regression loss: 0.31909 | Running loss: 0.86272\n",
      "Epoch: 0 | Iteration: 36347 | Classification loss: 0.41627 | Regression loss: 0.59044 | Running loss: 0.86291\n",
      "Epoch: 0 | Iteration: 36348 | Classification loss: 0.41380 | Regression loss: 0.49412 | Running loss: 0.86288\n",
      "Epoch: 0 | Iteration: 36349 | Classification loss: 0.41044 | Regression loss: 0.41380 | Running loss: 0.86303\n",
      "Epoch: 0 | Iteration: 36350 | Classification loss: 0.39984 | Regression loss: 0.49245 | Running loss: 0.86317\n",
      "Epoch: 0 | Iteration: 36351 | Classification loss: 0.39655 | Regression loss: 0.51846 | Running loss: 0.86307\n",
      "Epoch: 0 | Iteration: 36352 | Classification loss: 0.79001 | Regression loss: 0.21100 | Running loss: 0.86299\n",
      "Epoch: 0 | Iteration: 36353 | Classification loss: 0.26097 | Regression loss: 0.50836 | Running loss: 0.86283\n",
      "Epoch: 0 | Iteration: 36354 | Classification loss: 0.51131 | Regression loss: 0.70292 | Running loss: 0.86383\n",
      "Epoch: 0 | Iteration: 36355 | Classification loss: 0.27749 | Regression loss: 0.45248 | Running loss: 0.86348\n",
      "Epoch: 0 | Iteration: 36356 | Classification loss: 0.37069 | Regression loss: 0.42653 | Running loss: 0.86327\n",
      "Epoch: 0 | Iteration: 36357 | Classification loss: 0.31398 | Regression loss: 0.59872 | Running loss: 0.86307\n",
      "Epoch: 0 | Iteration: 36358 | Classification loss: 0.45738 | Regression loss: 0.70438 | Running loss: 0.86374\n",
      "Epoch: 0 | Iteration: 36359 | Classification loss: 0.39574 | Regression loss: 0.51432 | Running loss: 0.86457\n",
      "Epoch: 0 | Iteration: 36360 | Classification loss: 0.36907 | Regression loss: 0.61553 | Running loss: 0.86461\n",
      "Epoch: 0 | Iteration: 36361 | Classification loss: 0.28489 | Regression loss: 0.54597 | Running loss: 0.86430\n",
      "Epoch: 0 | Iteration: 36362 | Classification loss: 0.45980 | Regression loss: 0.56543 | Running loss: 0.86470\n",
      "Epoch: 0 | Iteration: 36363 | Classification loss: 0.41218 | Regression loss: 0.48485 | Running loss: 0.86449\n",
      "Epoch: 0 | Iteration: 36364 | Classification loss: 0.39174 | Regression loss: 0.47867 | Running loss: 0.86475\n",
      "Epoch: 0 | Iteration: 36365 | Classification loss: 0.43677 | Regression loss: 0.64485 | Running loss: 0.86481\n",
      "Epoch: 0 | Iteration: 36366 | Classification loss: 0.27320 | Regression loss: 0.42994 | Running loss: 0.86489\n",
      "Epoch: 0 | Iteration: 36367 | Classification loss: 0.31681 | Regression loss: 0.50010 | Running loss: 0.86444\n",
      "Epoch: 0 | Iteration: 36368 | Classification loss: 0.29206 | Regression loss: 0.43357 | Running loss: 0.86434\n",
      "Epoch: 0 | Iteration: 36369 | Classification loss: 0.49347 | Regression loss: 0.34275 | Running loss: 0.86376\n",
      "Epoch: 0 | Iteration: 36370 | Classification loss: 0.41486 | Regression loss: 0.74738 | Running loss: 0.86385\n",
      "Epoch: 0 | Iteration: 36371 | Classification loss: 0.37091 | Regression loss: 0.48574 | Running loss: 0.86342\n",
      "Epoch: 0 | Iteration: 36372 | Classification loss: 0.43756 | Regression loss: 0.48519 | Running loss: 0.86350\n",
      "Epoch: 0 | Iteration: 36373 | Classification loss: 0.43380 | Regression loss: 0.36706 | Running loss: 0.86269\n",
      "Epoch: 0 | Iteration: 36374 | Classification loss: 0.26624 | Regression loss: 0.32650 | Running loss: 0.86199\n",
      "Epoch: 0 | Iteration: 36375 | Classification loss: 0.49738 | Regression loss: 0.73918 | Running loss: 0.86260\n",
      "Epoch: 0 | Iteration: 36376 | Classification loss: 0.36029 | Regression loss: 0.61390 | Running loss: 0.86307\n",
      "Epoch: 0 | Iteration: 36377 | Classification loss: 0.49345 | Regression loss: 0.46478 | Running loss: 0.86354\n",
      "Epoch: 0 | Iteration: 36378 | Classification loss: 0.38238 | Regression loss: 0.56476 | Running loss: 0.86414\n",
      "Epoch: 0 | Iteration: 36379 | Classification loss: 0.41519 | Regression loss: 0.51883 | Running loss: 0.86455\n",
      "Epoch: 0 | Iteration: 36380 | Classification loss: 0.21404 | Regression loss: 0.39715 | Running loss: 0.86367\n",
      "Epoch: 0 | Iteration: 36381 | Classification loss: 0.17885 | Regression loss: 0.36903 | Running loss: 0.86252\n",
      "Epoch: 0 | Iteration: 36382 | Classification loss: 0.28327 | Regression loss: 0.36114 | Running loss: 0.86156\n",
      "Epoch: 0 | Iteration: 36383 | Classification loss: 0.20178 | Regression loss: 0.46174 | Running loss: 0.86087\n",
      "Epoch: 0 | Iteration: 36384 | Classification loss: 0.34120 | Regression loss: 0.50313 | Running loss: 0.86113\n",
      "Epoch: 0 | Iteration: 36385 | Classification loss: 0.57044 | Regression loss: 0.70717 | Running loss: 0.86295\n",
      "Epoch: 0 | Iteration: 36386 | Classification loss: 0.34674 | Regression loss: 0.44600 | Running loss: 0.86299\n",
      "Epoch: 0 | Iteration: 36387 | Classification loss: 0.45305 | Regression loss: 0.42375 | Running loss: 0.86344\n",
      "Epoch: 0 | Iteration: 36388 | Classification loss: 0.33668 | Regression loss: 0.49123 | Running loss: 0.86254\n",
      "Epoch: 0 | Iteration: 36389 | Classification loss: 0.37380 | Regression loss: 0.51212 | Running loss: 0.86227\n",
      "Epoch: 0 | Iteration: 36390 | Classification loss: 0.16194 | Regression loss: 0.36601 | Running loss: 0.86120\n",
      "Epoch: 0 | Iteration: 36391 | Classification loss: 0.44324 | Regression loss: 0.61877 | Running loss: 0.86151\n",
      "Epoch: 0 | Iteration: 36392 | Classification loss: 0.18599 | Regression loss: 0.32727 | Running loss: 0.86091\n",
      "Epoch: 0 | Iteration: 36393 | Classification loss: 0.27734 | Regression loss: 0.33680 | Running loss: 0.86130\n",
      "Epoch: 0 | Iteration: 36394 | Classification loss: 0.26966 | Regression loss: 0.50585 | Running loss: 0.86176\n",
      "Epoch: 0 | Iteration: 36395 | Classification loss: 0.52640 | Regression loss: 0.72904 | Running loss: 0.86219\n",
      "Epoch: 0 | Iteration: 36396 | Classification loss: 0.40345 | Regression loss: 0.32719 | Running loss: 0.86242\n",
      "Epoch: 0 | Iteration: 36397 | Classification loss: 0.23484 | Regression loss: 0.56363 | Running loss: 0.86265\n",
      "Epoch: 0 | Iteration: 36398 | Classification loss: 0.45114 | Regression loss: 0.53144 | Running loss: 0.86377\n",
      "Epoch: 0 | Iteration: 36399 | Classification loss: 0.35637 | Regression loss: 0.44309 | Running loss: 0.86290\n",
      "Epoch: 0 | Iteration: 36400 | Classification loss: 0.42045 | Regression loss: 0.53921 | Running loss: 0.86234\n",
      "Epoch: 0 | Iteration: 36401 | Classification loss: 0.38967 | Regression loss: 0.64047 | Running loss: 0.86243\n",
      "Epoch: 0 | Iteration: 36402 | Classification loss: 0.33610 | Regression loss: 0.59674 | Running loss: 0.86283\n",
      "Epoch: 0 | Iteration: 36403 | Classification loss: 0.36503 | Regression loss: 0.49578 | Running loss: 0.86317\n",
      "Epoch: 0 | Iteration: 36404 | Classification loss: 0.29555 | Regression loss: 0.57816 | Running loss: 0.86355\n",
      "Epoch: 0 | Iteration: 36405 | Classification loss: 0.30049 | Regression loss: 0.49465 | Running loss: 0.86363\n",
      "Epoch: 0 | Iteration: 36406 | Classification loss: 0.34034 | Regression loss: 0.61424 | Running loss: 0.86456\n",
      "Epoch: 0 | Iteration: 36407 | Classification loss: 0.28350 | Regression loss: 0.52444 | Running loss: 0.86508\n",
      "Epoch: 0 | Iteration: 36408 | Classification loss: 0.46978 | Regression loss: 0.61173 | Running loss: 0.86541\n",
      "Epoch: 0 | Iteration: 36409 | Classification loss: 0.58000 | Regression loss: 0.79124 | Running loss: 0.86602\n",
      "Epoch: 0 | Iteration: 36410 | Classification loss: 0.35502 | Regression loss: 0.52929 | Running loss: 0.86596\n",
      "Epoch: 0 | Iteration: 36411 | Classification loss: 0.30984 | Regression loss: 0.56093 | Running loss: 0.86678\n",
      "Epoch: 0 | Iteration: 36412 | Classification loss: 0.17587 | Regression loss: 0.13981 | Running loss: 0.86534\n",
      "Epoch: 0 | Iteration: 36413 | Classification loss: 0.22835 | Regression loss: 0.40597 | Running loss: 0.86542\n",
      "Epoch: 0 | Iteration: 36414 | Classification loss: 0.12609 | Regression loss: 0.25180 | Running loss: 0.86478\n",
      "Epoch: 0 | Iteration: 36415 | Classification loss: 0.19147 | Regression loss: 0.52012 | Running loss: 0.86479\n",
      "Epoch: 0 | Iteration: 36416 | Classification loss: 0.43210 | Regression loss: 0.45862 | Running loss: 0.86410\n",
      "Epoch: 0 | Iteration: 36417 | Classification loss: 0.26735 | Regression loss: 0.50711 | Running loss: 0.86403\n",
      "Epoch: 0 | Iteration: 36418 | Classification loss: 0.21416 | Regression loss: 0.49108 | Running loss: 0.86388\n",
      "Epoch: 0 | Iteration: 36419 | Classification loss: 0.28751 | Regression loss: 0.36406 | Running loss: 0.86351\n",
      "Epoch: 0 | Iteration: 36420 | Classification loss: 0.55147 | Regression loss: 0.38298 | Running loss: 0.86400\n",
      "Epoch: 0 | Iteration: 36421 | Classification loss: 0.40673 | Regression loss: 0.60898 | Running loss: 0.86463\n",
      "Epoch: 0 | Iteration: 36422 | Classification loss: 0.53321 | Regression loss: 0.69438 | Running loss: 0.86565\n",
      "Epoch: 0 | Iteration: 36423 | Classification loss: 0.45829 | Regression loss: 0.51011 | Running loss: 0.86553\n",
      "Epoch: 0 | Iteration: 36424 | Classification loss: 0.35964 | Regression loss: 0.47952 | Running loss: 0.86506\n",
      "Epoch: 0 | Iteration: 36425 | Classification loss: 0.17077 | Regression loss: 0.47397 | Running loss: 0.86497\n",
      "Epoch: 0 | Iteration: 36426 | Classification loss: 0.58108 | Regression loss: 0.44411 | Running loss: 0.86555\n",
      "Epoch: 0 | Iteration: 36427 | Classification loss: 0.34801 | Regression loss: 0.42031 | Running loss: 0.86516\n",
      "Epoch: 0 | Iteration: 36428 | Classification loss: 0.25882 | Regression loss: 0.11478 | Running loss: 0.86426\n",
      "Epoch: 0 | Iteration: 36429 | Classification loss: 0.22021 | Regression loss: 0.21534 | Running loss: 0.86305\n",
      "Epoch: 0 | Iteration: 36430 | Classification loss: 0.67530 | Regression loss: 0.72919 | Running loss: 0.86416\n",
      "Epoch: 0 | Iteration: 36431 | Classification loss: 0.32370 | Regression loss: 0.29517 | Running loss: 0.86355\n",
      "Epoch: 0 | Iteration: 36432 | Classification loss: 0.39506 | Regression loss: 0.51358 | Running loss: 0.86328\n",
      "Epoch: 0 | Iteration: 36433 | Classification loss: 0.06066 | Regression loss: 0.18038 | Running loss: 0.86199\n",
      "Epoch: 0 | Iteration: 36434 | Classification loss: 0.20908 | Regression loss: 0.57681 | Running loss: 0.86224\n",
      "Epoch: 0 | Iteration: 36435 | Classification loss: 0.27194 | Regression loss: 0.41365 | Running loss: 0.86264\n",
      "Epoch: 0 | Iteration: 36436 | Classification loss: 3.15755 | Regression loss: 0.16246 | Running loss: 0.86836\n",
      "Epoch: 0 | Iteration: 36437 | Classification loss: 0.48094 | Regression loss: 0.40949 | Running loss: 0.86765\n",
      "Epoch: 0 | Iteration: 36438 | Classification loss: 0.37066 | Regression loss: 0.36367 | Running loss: 0.86745\n",
      "Epoch: 0 | Iteration: 36439 | Classification loss: 0.26263 | Regression loss: 0.27969 | Running loss: 0.86610\n",
      "Epoch: 0 | Iteration: 36440 | Classification loss: 0.33908 | Regression loss: 0.47941 | Running loss: 0.86674\n",
      "Epoch: 0 | Iteration: 36441 | Classification loss: 0.29292 | Regression loss: 0.52767 | Running loss: 0.86649\n",
      "Epoch: 0 | Iteration: 36442 | Classification loss: 0.70460 | Regression loss: 0.57786 | Running loss: 0.86723\n",
      "Epoch: 0 | Iteration: 36443 | Classification loss: 0.41605 | Regression loss: 0.54223 | Running loss: 0.86700\n",
      "Epoch: 0 | Iteration: 36444 | Classification loss: 0.35784 | Regression loss: 0.54645 | Running loss: 0.86666\n",
      "Epoch: 0 | Iteration: 36445 | Classification loss: 0.29378 | Regression loss: 0.54825 | Running loss: 0.86599\n",
      "Epoch: 0 | Iteration: 36446 | Classification loss: 0.13333 | Regression loss: 0.29133 | Running loss: 0.86481\n",
      "Epoch: 0 | Iteration: 36447 | Classification loss: 0.45430 | Regression loss: 0.65614 | Running loss: 0.86519\n",
      "Epoch: 0 | Iteration: 36448 | Classification loss: 0.21655 | Regression loss: 0.29154 | Running loss: 0.86528\n",
      "Epoch: 0 | Iteration: 36449 | Classification loss: 0.38584 | Regression loss: 0.68092 | Running loss: 0.86603\n",
      "Epoch: 0 | Iteration: 36450 | Classification loss: 0.56760 | Regression loss: 0.71104 | Running loss: 0.86696\n",
      "Epoch: 0 | Iteration: 36451 | Classification loss: 0.40681 | Regression loss: 0.41774 | Running loss: 0.86732\n",
      "Epoch: 0 | Iteration: 36452 | Classification loss: 0.75305 | Regression loss: 0.53161 | Running loss: 0.86901\n",
      "Epoch: 0 | Iteration: 36453 | Classification loss: 0.55393 | Regression loss: 0.44767 | Running loss: 0.86982\n",
      "Epoch: 0 | Iteration: 36454 | Classification loss: 0.44075 | Regression loss: 0.49636 | Running loss: 0.87016\n",
      "Epoch: 0 | Iteration: 36455 | Classification loss: 0.41243 | Regression loss: 0.20822 | Running loss: 0.87001\n",
      "Epoch: 0 | Iteration: 36456 | Classification loss: 0.23248 | Regression loss: 0.31111 | Running loss: 0.86922\n",
      "Epoch: 0 | Iteration: 36457 | Classification loss: 0.34727 | Regression loss: 0.45204 | Running loss: 0.86869\n",
      "Epoch: 0 | Iteration: 36458 | Classification loss: 0.50986 | Regression loss: 0.47907 | Running loss: 0.86865\n",
      "Epoch: 0 | Iteration: 36459 | Classification loss: 0.27008 | Regression loss: 0.37816 | Running loss: 0.86691\n",
      "Epoch: 0 | Iteration: 36460 | Classification loss: 0.24528 | Regression loss: 0.18161 | Running loss: 0.86566\n",
      "Epoch: 0 | Iteration: 36461 | Classification loss: 0.50821 | Regression loss: 0.51417 | Running loss: 0.86624\n",
      "Epoch: 0 | Iteration: 36462 | Classification loss: 0.22750 | Regression loss: 0.42407 | Running loss: 0.86576\n",
      "Epoch: 0 | Iteration: 36463 | Classification loss: 0.17579 | Regression loss: 0.36320 | Running loss: 0.86483\n",
      "Epoch: 0 | Iteration: 36464 | Classification loss: 0.32117 | Regression loss: 0.55346 | Running loss: 0.86523\n",
      "Epoch: 0 | Iteration: 36465 | Classification loss: 0.25584 | Regression loss: 0.47381 | Running loss: 0.86521\n",
      "Epoch: 0 | Iteration: 36466 | Classification loss: 0.25539 | Regression loss: 0.16606 | Running loss: 0.86398\n",
      "Epoch: 0 | Iteration: 36467 | Classification loss: 0.33459 | Regression loss: 0.40916 | Running loss: 0.86251\n",
      "Epoch: 0 | Iteration: 36468 | Classification loss: 0.51301 | Regression loss: 0.49960 | Running loss: 0.86247\n",
      "Epoch: 0 | Iteration: 36469 | Classification loss: 0.32892 | Regression loss: 0.15608 | Running loss: 0.86170\n",
      "Epoch: 0 | Iteration: 36470 | Classification loss: 0.37572 | Regression loss: 0.61703 | Running loss: 0.86269\n",
      "Epoch: 0 | Iteration: 36471 | Classification loss: 0.52389 | Regression loss: 0.59729 | Running loss: 0.86366\n",
      "Epoch: 0 | Iteration: 36472 | Classification loss: 0.26130 | Regression loss: 0.35528 | Running loss: 0.86290\n",
      "Epoch: 0 | Iteration: 36473 | Classification loss: 0.45672 | Regression loss: 0.51251 | Running loss: 0.86330\n",
      "Epoch: 0 | Iteration: 36474 | Classification loss: 0.46273 | Regression loss: 0.64534 | Running loss: 0.86415\n",
      "Epoch: 0 | Iteration: 36475 | Classification loss: 0.49413 | Regression loss: 0.47098 | Running loss: 0.86379\n",
      "Epoch: 0 | Iteration: 36476 | Classification loss: 0.53697 | Regression loss: 0.63152 | Running loss: 0.86421\n",
      "Epoch: 0 | Iteration: 36477 | Classification loss: 0.29478 | Regression loss: 0.56081 | Running loss: 0.86387\n",
      "Epoch: 0 | Iteration: 36478 | Classification loss: 0.33442 | Regression loss: 0.41843 | Running loss: 0.86333\n",
      "Epoch: 0 | Iteration: 36479 | Classification loss: 0.31891 | Regression loss: 0.35363 | Running loss: 0.86298\n",
      "Epoch: 0 | Iteration: 36480 | Classification loss: 0.21554 | Regression loss: 0.42027 | Running loss: 0.86235\n",
      "Epoch: 0 | Iteration: 36481 | Classification loss: 0.49059 | Regression loss: 0.38584 | Running loss: 0.86246\n",
      "Epoch: 0 | Iteration: 36482 | Classification loss: 0.30873 | Regression loss: 0.68847 | Running loss: 0.86286\n",
      "Epoch: 0 | Iteration: 36483 | Classification loss: 0.51434 | Regression loss: 0.57688 | Running loss: 0.86324\n",
      "Epoch: 0 | Iteration: 36484 | Classification loss: 0.76640 | Regression loss: 0.88559 | Running loss: 0.86497\n",
      "Epoch: 0 | Iteration: 36485 | Classification loss: 0.14419 | Regression loss: 0.25049 | Running loss: 0.86476\n",
      "Epoch: 0 | Iteration: 36486 | Classification loss: 0.17421 | Regression loss: 0.19163 | Running loss: 0.86404\n",
      "Epoch: 0 | Iteration: 36487 | Classification loss: 0.37861 | Regression loss: 0.45400 | Running loss: 0.86344\n",
      "Epoch: 0 | Iteration: 36488 | Classification loss: 0.31565 | Regression loss: 0.40906 | Running loss: 0.86311\n",
      "Epoch: 0 | Iteration: 36489 | Classification loss: 0.34925 | Regression loss: 0.62100 | Running loss: 0.86343\n",
      "Epoch: 0 | Iteration: 36490 | Classification loss: 0.46365 | Regression loss: 0.47428 | Running loss: 0.86309\n",
      "Epoch: 0 | Iteration: 36491 | Classification loss: 0.18632 | Regression loss: 0.40917 | Running loss: 0.86216\n",
      "Epoch: 0 | Iteration: 36492 | Classification loss: 0.45777 | Regression loss: 0.12480 | Running loss: 0.86154\n",
      "Epoch: 0 | Iteration: 36493 | Classification loss: 0.29315 | Regression loss: 0.55104 | Running loss: 0.86107\n",
      "Epoch: 0 | Iteration: 36494 | Classification loss: 1.19753 | Regression loss: 0.16063 | Running loss: 0.86212\n",
      "Epoch: 0 | Iteration: 36495 | Classification loss: 0.54569 | Regression loss: 0.71867 | Running loss: 0.86308\n",
      "Epoch: 0 | Iteration: 36496 | Classification loss: 1.54963 | Regression loss: 0.19360 | Running loss: 0.86462\n",
      "Epoch: 0 | Iteration: 36497 | Classification loss: 0.60576 | Regression loss: 0.70452 | Running loss: 0.86635\n",
      "Epoch: 0 | Iteration: 36498 | Classification loss: 0.42493 | Regression loss: 0.48258 | Running loss: 0.86634\n",
      "Epoch: 0 | Iteration: 36499 | Classification loss: 0.29015 | Regression loss: 0.38809 | Running loss: 0.86568\n",
      "Epoch: 0 | Iteration: 36500 | Classification loss: 0.31838 | Regression loss: 0.45178 | Running loss: 0.86544\n",
      "Epoch: 0 | Iteration: 36501 | Classification loss: 0.46903 | Regression loss: 0.52669 | Running loss: 0.86589\n",
      "Epoch: 0 | Iteration: 36502 | Classification loss: 0.19011 | Regression loss: 0.35862 | Running loss: 0.86639\n",
      "Epoch: 0 | Iteration: 36503 | Classification loss: 0.29576 | Regression loss: 0.43591 | Running loss: 0.86605\n",
      "Epoch: 0 | Iteration: 36504 | Classification loss: 0.21908 | Regression loss: 0.23783 | Running loss: 0.86473\n",
      "Epoch: 0 | Iteration: 36505 | Classification loss: 0.41618 | Regression loss: 0.60870 | Running loss: 0.86524\n",
      "Epoch: 0 | Iteration: 36506 | Classification loss: 0.16725 | Regression loss: 0.38361 | Running loss: 0.86453\n",
      "Epoch: 0 | Iteration: 36507 | Classification loss: 0.58534 | Regression loss: 0.61687 | Running loss: 0.86554\n",
      "Epoch: 0 | Iteration: 36508 | Classification loss: 0.85130 | Regression loss: 0.74413 | Running loss: 0.86706\n",
      "Epoch: 0 | Iteration: 36509 | Classification loss: 0.49034 | Regression loss: 0.48169 | Running loss: 0.86736\n",
      "Epoch: 0 | Iteration: 36510 | Classification loss: 0.50552 | Regression loss: 0.46385 | Running loss: 0.86691\n",
      "Epoch: 0 | Iteration: 36511 | Classification loss: 0.60198 | Regression loss: 0.54558 | Running loss: 0.86763\n",
      "Epoch: 0 | Iteration: 36512 | Classification loss: 0.54511 | Regression loss: 0.50547 | Running loss: 0.86819\n",
      "Epoch: 0 | Iteration: 36513 | Classification loss: 0.53814 | Regression loss: 0.49999 | Running loss: 0.86835\n",
      "Epoch: 0 | Iteration: 36514 | Classification loss: 0.64305 | Regression loss: 0.66500 | Running loss: 0.86910\n",
      "Epoch: 0 | Iteration: 36515 | Classification loss: 0.14874 | Regression loss: 0.43717 | Running loss: 0.86836\n",
      "Epoch: 0 | Iteration: 36516 | Classification loss: 0.34895 | Regression loss: 0.31787 | Running loss: 0.86847\n",
      "Epoch: 0 | Iteration: 36517 | Classification loss: 0.92757 | Regression loss: 0.77362 | Running loss: 0.86978\n",
      "Epoch: 0 | Iteration: 36518 | Classification loss: 0.53863 | Regression loss: 0.59093 | Running loss: 0.86967\n",
      "Epoch: 0 | Iteration: 36519 | Classification loss: 0.47459 | Regression loss: 0.45109 | Running loss: 0.86970\n",
      "Epoch: 0 | Iteration: 36520 | Classification loss: 0.31525 | Regression loss: 0.48611 | Running loss: 0.86995\n",
      "Epoch: 0 | Iteration: 36521 | Classification loss: 0.29608 | Regression loss: 0.53358 | Running loss: 0.86959\n",
      "Epoch: 0 | Iteration: 36522 | Classification loss: 0.39428 | Regression loss: 0.44024 | Running loss: 0.87026\n",
      "Epoch: 0 | Iteration: 36523 | Classification loss: 0.42827 | Regression loss: 0.47837 | Running loss: 0.87084\n",
      "Epoch: 0 | Iteration: 36524 | Classification loss: 0.78719 | Regression loss: 0.43463 | Running loss: 0.87073\n",
      "Epoch: 0 | Iteration: 36525 | Classification loss: 0.46797 | Regression loss: 0.71165 | Running loss: 0.87159\n",
      "Epoch: 0 | Iteration: 36526 | Classification loss: 0.52782 | Regression loss: 0.14913 | Running loss: 0.87091\n",
      "Epoch: 0 | Iteration: 36527 | Classification loss: 0.48845 | Regression loss: 0.26181 | Running loss: 0.87157\n",
      "Epoch: 0 | Iteration: 36528 | Classification loss: 0.23393 | Regression loss: 0.53798 | Running loss: 0.87123\n",
      "Epoch: 0 | Iteration: 36529 | Classification loss: 0.43656 | Regression loss: 0.68976 | Running loss: 0.87167\n",
      "Epoch: 0 | Iteration: 36530 | Classification loss: 0.43405 | Regression loss: 0.55918 | Running loss: 0.87093\n",
      "Epoch: 0 | Iteration: 36531 | Classification loss: 0.49612 | Regression loss: 0.62310 | Running loss: 0.87139\n",
      "Epoch: 0 | Iteration: 36532 | Classification loss: 0.21918 | Regression loss: 0.27666 | Running loss: 0.87036\n",
      "Epoch: 0 | Iteration: 36533 | Classification loss: 0.42647 | Regression loss: 0.43017 | Running loss: 0.87026\n",
      "Epoch: 0 | Iteration: 36534 | Classification loss: 0.32383 | Regression loss: 0.23607 | Running loss: 0.86982\n",
      "Epoch: 0 | Iteration: 36535 | Classification loss: 0.17206 | Regression loss: 0.34395 | Running loss: 0.87004\n",
      "Epoch: 0 | Iteration: 36536 | Classification loss: 0.44090 | Regression loss: 0.49575 | Running loss: 0.87024\n",
      "Epoch: 0 | Iteration: 36537 | Classification loss: 0.38336 | Regression loss: 0.50596 | Running loss: 0.87012\n",
      "Epoch: 0 | Iteration: 36538 | Classification loss: 0.34786 | Regression loss: 0.44669 | Running loss: 0.86971\n",
      "Epoch: 0 | Iteration: 36539 | Classification loss: 0.09834 | Regression loss: 0.14194 | Running loss: 0.86856\n",
      "Epoch: 0 | Iteration: 36540 | Classification loss: 0.18765 | Regression loss: 0.30203 | Running loss: 0.86787\n",
      "Epoch: 0 | Iteration: 36541 | Classification loss: 0.53350 | Regression loss: 0.47422 | Running loss: 0.86764\n",
      "Epoch: 0 | Iteration: 36542 | Classification loss: 0.30754 | Regression loss: 0.37145 | Running loss: 0.86699\n",
      "Epoch: 0 | Iteration: 36543 | Classification loss: 0.55892 | Regression loss: 0.62848 | Running loss: 0.86752\n",
      "Epoch: 0 | Iteration: 36544 | Classification loss: 0.40903 | Regression loss: 0.54100 | Running loss: 0.86810\n",
      "Epoch: 0 | Iteration: 36545 | Classification loss: 0.39846 | Regression loss: 0.65762 | Running loss: 0.86844\n",
      "Epoch: 0 | Iteration: 36546 | Classification loss: 0.30079 | Regression loss: 0.43308 | Running loss: 0.86717\n",
      "Epoch: 0 | Iteration: 36547 | Classification loss: 0.25785 | Regression loss: 0.28821 | Running loss: 0.86703\n",
      "Epoch: 0 | Iteration: 36548 | Classification loss: 0.32509 | Regression loss: 0.35767 | Running loss: 0.86679\n",
      "Epoch: 0 | Iteration: 36549 | Classification loss: 0.48021 | Regression loss: 0.50363 | Running loss: 0.86715\n",
      "Epoch: 0 | Iteration: 36550 | Classification loss: 0.42113 | Regression loss: 0.40534 | Running loss: 0.86676\n",
      "Epoch: 0 | Iteration: 36551 | Classification loss: 0.34760 | Regression loss: 0.55579 | Running loss: 0.86702\n",
      "Epoch: 0 | Iteration: 36552 | Classification loss: 0.62520 | Regression loss: 0.34424 | Running loss: 0.86707\n",
      "Epoch: 0 | Iteration: 36553 | Classification loss: 0.44310 | Regression loss: 0.66404 | Running loss: 0.86824\n",
      "Epoch: 0 | Iteration: 36554 | Classification loss: 0.16780 | Regression loss: 0.29962 | Running loss: 0.86786\n",
      "Epoch: 0 | Iteration: 36555 | Classification loss: 0.51428 | Regression loss: 0.50873 | Running loss: 0.86906\n",
      "Epoch: 0 | Iteration: 36556 | Classification loss: 0.26544 | Regression loss: 0.39117 | Running loss: 0.86793\n",
      "Epoch: 0 | Iteration: 36557 | Classification loss: 0.32267 | Regression loss: 0.39779 | Running loss: 0.86690\n",
      "Epoch: 0 | Iteration: 36558 | Classification loss: 0.61352 | Regression loss: 0.16722 | Running loss: 0.86683\n",
      "Epoch: 0 | Iteration: 36559 | Classification loss: 0.50171 | Regression loss: 0.70400 | Running loss: 0.86790\n",
      "Epoch: 0 | Iteration: 36560 | Classification loss: 0.30539 | Regression loss: 0.44882 | Running loss: 0.86837\n",
      "Epoch: 0 | Iteration: 36561 | Classification loss: 0.20537 | Regression loss: 0.28454 | Running loss: 0.86803\n",
      "Epoch: 0 | Iteration: 36562 | Classification loss: 0.26626 | Regression loss: 0.49877 | Running loss: 0.86576\n",
      "Epoch: 0 | Iteration: 36563 | Classification loss: 0.21081 | Regression loss: 0.48912 | Running loss: 0.86518\n",
      "Epoch: 0 | Iteration: 36564 | Classification loss: 0.25613 | Regression loss: 0.42917 | Running loss: 0.86518\n",
      "Epoch: 0 | Iteration: 36565 | Classification loss: 0.32162 | Regression loss: 0.49510 | Running loss: 0.86515\n",
      "Epoch: 0 | Iteration: 36566 | Classification loss: 0.28236 | Regression loss: 0.41977 | Running loss: 0.86503\n",
      "Epoch: 0 | Iteration: 36567 | Classification loss: 0.53031 | Regression loss: 0.51771 | Running loss: 0.86619\n",
      "Epoch: 0 | Iteration: 36568 | Classification loss: 0.36470 | Regression loss: 0.64049 | Running loss: 0.86676\n",
      "Epoch: 0 | Iteration: 36569 | Classification loss: 0.37684 | Regression loss: 0.59419 | Running loss: 0.86661\n",
      "Epoch: 0 | Iteration: 36570 | Classification loss: 0.46747 | Regression loss: 0.70278 | Running loss: 0.86741\n",
      "Epoch: 0 | Iteration: 36571 | Classification loss: 0.34677 | Regression loss: 0.61523 | Running loss: 0.86850\n",
      "Epoch: 0 | Iteration: 36572 | Classification loss: 0.46116 | Regression loss: 0.71026 | Running loss: 0.86921\n",
      "Epoch: 0 | Iteration: 36573 | Classification loss: 0.41307 | Regression loss: 0.64978 | Running loss: 0.87034\n",
      "Epoch: 0 | Iteration: 36574 | Classification loss: 0.12088 | Regression loss: 0.24712 | Running loss: 0.86921\n",
      "Epoch: 0 | Iteration: 36575 | Classification loss: 0.91076 | Regression loss: 0.12534 | Running loss: 0.87054\n",
      "Epoch: 0 | Iteration: 36576 | Classification loss: 0.47012 | Regression loss: 0.75532 | Running loss: 0.87189\n",
      "Epoch: 0 | Iteration: 36577 | Classification loss: 0.45811 | Regression loss: 0.41276 | Running loss: 0.87245\n",
      "Epoch: 0 | Iteration: 36578 | Classification loss: 0.46915 | Regression loss: 0.49263 | Running loss: 0.87221\n",
      "Epoch: 0 | Iteration: 36579 | Classification loss: 0.33354 | Regression loss: 0.43790 | Running loss: 0.87244\n",
      "Epoch: 0 | Iteration: 36580 | Classification loss: 0.25200 | Regression loss: 0.38552 | Running loss: 0.87216\n",
      "Epoch: 0 | Iteration: 36581 | Classification loss: 0.25488 | Regression loss: 0.44458 | Running loss: 0.87177\n",
      "Epoch: 0 | Iteration: 36582 | Classification loss: 0.38699 | Regression loss: 0.49903 | Running loss: 0.87142\n",
      "Epoch: 0 | Iteration: 36583 | Classification loss: 0.50940 | Regression loss: 0.64823 | Running loss: 0.87177\n",
      "Epoch: 0 | Iteration: 36584 | Classification loss: 0.43123 | Regression loss: 0.51899 | Running loss: 0.87180\n",
      "Epoch: 0 | Iteration: 36585 | Classification loss: 0.42557 | Regression loss: 0.57196 | Running loss: 0.87221\n",
      "Epoch: 0 | Iteration: 36586 | Classification loss: 0.44710 | Regression loss: 0.52194 | Running loss: 0.87244\n",
      "Epoch: 0 | Iteration: 36587 | Classification loss: 0.42751 | Regression loss: 0.52935 | Running loss: 0.87258\n",
      "Epoch: 0 | Iteration: 36588 | Classification loss: 0.45400 | Regression loss: 0.54602 | Running loss: 0.87280\n",
      "Epoch: 0 | Iteration: 36589 | Classification loss: 0.22956 | Regression loss: 0.54693 | Running loss: 0.87268\n",
      "Epoch: 0 | Iteration: 36590 | Classification loss: 0.42353 | Regression loss: 0.43972 | Running loss: 0.87275\n",
      "Epoch: 0 | Iteration: 36591 | Classification loss: 0.46690 | Regression loss: 0.32287 | Running loss: 0.87311\n",
      "Epoch: 0 | Iteration: 36592 | Classification loss: 0.34595 | Regression loss: 0.32977 | Running loss: 0.87276\n",
      "Epoch: 0 | Iteration: 36593 | Classification loss: 0.42138 | Regression loss: 0.51718 | Running loss: 0.87322\n",
      "Epoch: 0 | Iteration: 36594 | Classification loss: 0.38508 | Regression loss: 0.52348 | Running loss: 0.87354\n",
      "Epoch: 0 | Iteration: 36595 | Classification loss: 0.41881 | Regression loss: 0.63707 | Running loss: 0.87404\n",
      "Epoch: 0 | Iteration: 36596 | Classification loss: 0.24648 | Regression loss: 0.31159 | Running loss: 0.87382\n",
      "Epoch: 0 | Iteration: 36597 | Classification loss: 0.38893 | Regression loss: 0.28359 | Running loss: 0.87403\n",
      "Epoch: 0 | Iteration: 36598 | Classification loss: 0.25274 | Regression loss: 0.49988 | Running loss: 0.87421\n",
      "Epoch: 0 | Iteration: 36599 | Classification loss: 0.18540 | Regression loss: 0.31160 | Running loss: 0.87297\n",
      "Epoch: 0 | Iteration: 36600 | Classification loss: 0.39221 | Regression loss: 0.61742 | Running loss: 0.87321\n",
      "Epoch: 0 | Iteration: 36601 | Classification loss: 0.41443 | Regression loss: 0.58812 | Running loss: 0.87355\n",
      "Epoch: 0 | Iteration: 36602 | Classification loss: 0.24760 | Regression loss: 0.32598 | Running loss: 0.87322\n",
      "Epoch: 0 | Iteration: 36603 | Classification loss: 0.32548 | Regression loss: 0.56924 | Running loss: 0.87364\n",
      "Epoch: 0 | Iteration: 36604 | Classification loss: 0.30263 | Regression loss: 0.45278 | Running loss: 0.87299\n",
      "Epoch: 0 | Iteration: 36605 | Classification loss: 0.30469 | Regression loss: 0.60105 | Running loss: 0.87288\n",
      "Epoch: 0 | Iteration: 36606 | Classification loss: 0.45172 | Regression loss: 0.63493 | Running loss: 0.87328\n",
      "Epoch: 0 | Iteration: 36607 | Classification loss: 0.13202 | Regression loss: 0.38918 | Running loss: 0.87286\n",
      "Epoch: 0 | Iteration: 36608 | Classification loss: 0.40673 | Regression loss: 0.43564 | Running loss: 0.87304\n",
      "Epoch: 0 | Iteration: 36609 | Classification loss: 0.33473 | Regression loss: 0.46426 | Running loss: 0.87351\n",
      "Epoch: 0 | Iteration: 36610 | Classification loss: 0.21433 | Regression loss: 0.49412 | Running loss: 0.87364\n",
      "Epoch: 0 | Iteration: 36611 | Classification loss: 0.23766 | Regression loss: 0.50910 | Running loss: 0.87313\n",
      "Epoch: 0 | Iteration: 36612 | Classification loss: 0.50468 | Regression loss: 0.43057 | Running loss: 0.87351\n",
      "Epoch: 0 | Iteration: 36613 | Classification loss: 0.19841 | Regression loss: 0.49376 | Running loss: 0.87300\n",
      "Epoch: 0 | Iteration: 36614 | Classification loss: 0.36999 | Regression loss: 0.37380 | Running loss: 0.87297\n",
      "Epoch: 0 | Iteration: 36615 | Classification loss: 0.43972 | Regression loss: 0.57904 | Running loss: 0.87000\n",
      "Epoch: 0 | Iteration: 36616 | Classification loss: 0.44695 | Regression loss: 0.57270 | Running loss: 0.87033\n",
      "Epoch: 0 | Iteration: 36617 | Classification loss: 0.34511 | Regression loss: 0.23777 | Running loss: 0.86979\n",
      "Epoch: 0 | Iteration: 36618 | Classification loss: 0.35358 | Regression loss: 0.49294 | Running loss: 0.86941\n",
      "Epoch: 0 | Iteration: 36619 | Classification loss: 0.32018 | Regression loss: 0.48269 | Running loss: 0.86940\n",
      "Epoch: 0 | Iteration: 36620 | Classification loss: 0.63577 | Regression loss: 0.74490 | Running loss: 0.86994\n",
      "Epoch: 0 | Iteration: 36621 | Classification loss: 0.43323 | Regression loss: 0.69788 | Running loss: 0.87094\n",
      "Epoch: 0 | Iteration: 36622 | Classification loss: 0.51640 | Regression loss: 0.37278 | Running loss: 0.87061\n",
      "Epoch: 0 | Iteration: 36623 | Classification loss: 0.68609 | Regression loss: 0.51197 | Running loss: 0.87124\n",
      "Epoch: 0 | Iteration: 36624 | Classification loss: 0.34197 | Regression loss: 0.53144 | Running loss: 0.87136\n",
      "Epoch: 0 | Iteration: 36625 | Classification loss: 0.30144 | Regression loss: 0.47229 | Running loss: 0.87213\n",
      "Epoch: 0 | Iteration: 36626 | Classification loss: 0.34135 | Regression loss: 0.44739 | Running loss: 0.87221\n",
      "Epoch: 0 | Iteration: 36627 | Classification loss: 0.31747 | Regression loss: 0.53160 | Running loss: 0.87239\n",
      "Epoch: 0 | Iteration: 36628 | Classification loss: 0.21440 | Regression loss: 0.42899 | Running loss: 0.87159\n",
      "Epoch: 0 | Iteration: 36629 | Classification loss: 0.21695 | Regression loss: 0.35502 | Running loss: 0.87022\n",
      "Epoch: 0 | Iteration: 36630 | Classification loss: 0.21355 | Regression loss: 0.40604 | Running loss: 0.86982\n",
      "Epoch: 0 | Iteration: 36631 | Classification loss: 0.50553 | Regression loss: 0.60082 | Running loss: 0.87098\n",
      "Epoch: 0 | Iteration: 36632 | Classification loss: 0.85411 | Regression loss: 0.61347 | Running loss: 0.87250\n",
      "Epoch: 0 | Iteration: 36633 | Classification loss: 0.23084 | Regression loss: 0.43043 | Running loss: 0.87241\n",
      "Epoch: 0 | Iteration: 36634 | Classification loss: 0.52304 | Regression loss: 0.64757 | Running loss: 0.87322\n",
      "Epoch: 0 | Iteration: 36635 | Classification loss: 0.53992 | Regression loss: 0.56035 | Running loss: 0.87331\n",
      "Epoch: 0 | Iteration: 36636 | Classification loss: 0.32555 | Regression loss: 0.57762 | Running loss: 0.87347\n",
      "Epoch: 0 | Iteration: 36637 | Classification loss: 0.56318 | Regression loss: 0.47244 | Running loss: 0.87441\n",
      "Epoch: 0 | Iteration: 36638 | Classification loss: 0.26657 | Regression loss: 0.39975 | Running loss: 0.87403\n",
      "Epoch: 0 | Iteration: 36639 | Classification loss: 0.42693 | Regression loss: 0.43989 | Running loss: 0.87375\n",
      "Epoch: 0 | Iteration: 36640 | Classification loss: 0.53928 | Regression loss: 0.56576 | Running loss: 0.87410\n",
      "Epoch: 0 | Iteration: 36641 | Classification loss: 0.59557 | Regression loss: 0.67990 | Running loss: 0.87531\n",
      "Epoch: 0 | Iteration: 36642 | Classification loss: 0.42312 | Regression loss: 0.41480 | Running loss: 0.87428\n",
      "Epoch: 0 | Iteration: 36643 | Classification loss: 0.38336 | Regression loss: 0.59770 | Running loss: 0.87448\n",
      "Epoch: 0 | Iteration: 36644 | Classification loss: 0.42668 | Regression loss: 0.43080 | Running loss: 0.87425\n",
      "Epoch: 0 | Iteration: 36645 | Classification loss: 0.45130 | Regression loss: 0.49824 | Running loss: 0.87400\n",
      "Epoch: 0 | Iteration: 36646 | Classification loss: 0.30102 | Regression loss: 0.28026 | Running loss: 0.87353\n",
      "Epoch: 0 | Iteration: 36647 | Classification loss: 0.43623 | Regression loss: 0.39978 | Running loss: 0.87372\n",
      "Epoch: 0 | Iteration: 36648 | Classification loss: 0.39013 | Regression loss: 0.46565 | Running loss: 0.87386\n",
      "Epoch: 0 | Iteration: 36649 | Classification loss: 0.27931 | Regression loss: 0.37321 | Running loss: 0.87348\n",
      "Epoch: 0 | Iteration: 36650 | Classification loss: 0.41933 | Regression loss: 0.46972 | Running loss: 0.87384\n",
      "Epoch: 0 | Iteration: 36651 | Classification loss: 0.33739 | Regression loss: 0.45387 | Running loss: 0.87367\n",
      "Epoch: 0 | Iteration: 36652 | Classification loss: 0.34670 | Regression loss: 0.65931 | Running loss: 0.87352\n",
      "Epoch: 0 | Iteration: 36653 | Classification loss: 0.30046 | Regression loss: 0.49071 | Running loss: 0.87370\n",
      "Epoch: 0 | Iteration: 36654 | Classification loss: 0.44902 | Regression loss: 0.58825 | Running loss: 0.87463\n",
      "Epoch: 0 | Iteration: 36655 | Classification loss: 0.25848 | Regression loss: 0.46882 | Running loss: 0.87402\n",
      "Epoch: 0 | Iteration: 36656 | Classification loss: 0.34718 | Regression loss: 0.50510 | Running loss: 0.87420\n",
      "Epoch: 0 | Iteration: 36657 | Classification loss: 0.25621 | Regression loss: 0.30530 | Running loss: 0.87349\n",
      "Epoch: 0 | Iteration: 36658 | Classification loss: 0.30914 | Regression loss: 0.31441 | Running loss: 0.87386\n",
      "Epoch: 0 | Iteration: 36659 | Classification loss: 0.48784 | Regression loss: 0.56008 | Running loss: 0.87404\n",
      "Epoch: 0 | Iteration: 36660 | Classification loss: 0.79538 | Regression loss: 0.54650 | Running loss: 0.87465\n",
      "Epoch: 0 | Iteration: 36661 | Classification loss: 0.29959 | Regression loss: 0.45644 | Running loss: 0.87425\n",
      "Epoch: 0 | Iteration: 36662 | Classification loss: 0.46001 | Regression loss: 0.65470 | Running loss: 0.87424\n",
      "Epoch: 0 | Iteration: 36663 | Classification loss: 0.37685 | Regression loss: 0.67405 | Running loss: 0.87444\n",
      "Epoch: 0 | Iteration: 36664 | Classification loss: 0.51871 | Regression loss: 0.72068 | Running loss: 0.87538\n",
      "Epoch: 0 | Iteration: 36665 | Classification loss: 0.40010 | Regression loss: 0.49499 | Running loss: 0.87530\n",
      "Epoch: 0 | Iteration: 36666 | Classification loss: 0.30929 | Regression loss: 0.42190 | Running loss: 0.87490\n",
      "Epoch: 0 | Iteration: 36667 | Classification loss: 0.48104 | Regression loss: 0.38442 | Running loss: 0.87426\n",
      "Epoch: 0 | Iteration: 36668 | Classification loss: 0.31476 | Regression loss: 0.47941 | Running loss: 0.87445\n",
      "Epoch: 0 | Iteration: 36669 | Classification loss: 0.43515 | Regression loss: 0.54512 | Running loss: 0.87451\n",
      "Epoch: 0 | Iteration: 36670 | Classification loss: 0.50594 | Regression loss: 0.75935 | Running loss: 0.87509\n",
      "Epoch: 0 | Iteration: 36671 | Classification loss: 0.35707 | Regression loss: 0.56293 | Running loss: 0.87576\n",
      "Epoch: 0 | Iteration: 36672 | Classification loss: 0.35099 | Regression loss: 0.45287 | Running loss: 0.87602\n",
      "Epoch: 0 | Iteration: 36673 | Classification loss: 0.17389 | Regression loss: 0.39203 | Running loss: 0.87537\n",
      "Epoch: 0 | Iteration: 36674 | Classification loss: 0.16849 | Regression loss: 0.25851 | Running loss: 0.87403\n",
      "Epoch: 0 | Iteration: 36675 | Classification loss: 0.19569 | Regression loss: 0.19223 | Running loss: 0.87289\n",
      "Epoch: 0 | Iteration: 36676 | Classification loss: 0.27150 | Regression loss: 0.39929 | Running loss: 0.87227\n",
      "Epoch: 0 | Iteration: 36677 | Classification loss: 0.32237 | Regression loss: 0.56328 | Running loss: 0.87206\n",
      "Epoch: 0 | Iteration: 36678 | Classification loss: 0.36434 | Regression loss: 0.33216 | Running loss: 0.87184\n",
      "Epoch: 0 | Iteration: 36679 | Classification loss: 0.42740 | Regression loss: 0.70487 | Running loss: 0.87189\n",
      "Epoch: 0 | Iteration: 36680 | Classification loss: 0.09738 | Regression loss: 0.19365 | Running loss: 0.87077\n",
      "Epoch: 0 | Iteration: 36681 | Classification loss: 0.61766 | Regression loss: 0.66276 | Running loss: 0.87135\n",
      "Epoch: 0 | Iteration: 36682 | Classification loss: 0.58727 | Regression loss: 0.66415 | Running loss: 0.87241\n",
      "Epoch: 0 | Iteration: 36683 | Classification loss: 0.44791 | Regression loss: 0.57288 | Running loss: 0.87308\n",
      "Epoch: 0 | Iteration: 36684 | Classification loss: 0.36223 | Regression loss: 0.54735 | Running loss: 0.87327\n",
      "Epoch: 0 | Iteration: 36685 | Classification loss: 0.37778 | Regression loss: 0.38278 | Running loss: 0.87340\n",
      "Epoch: 0 | Iteration: 36686 | Classification loss: 0.25187 | Regression loss: 0.39070 | Running loss: 0.87126\n",
      "Epoch: 0 | Iteration: 36687 | Classification loss: 0.21735 | Regression loss: 0.33966 | Running loss: 0.87159\n",
      "Epoch: 0 | Iteration: 36688 | Classification loss: 0.20967 | Regression loss: 0.36240 | Running loss: 0.87123\n",
      "Epoch: 0 | Iteration: 36689 | Classification loss: 0.64098 | Regression loss: 0.44163 | Running loss: 0.87254\n",
      "Epoch: 0 | Iteration: 36690 | Classification loss: 0.39355 | Regression loss: 0.42791 | Running loss: 0.87170\n",
      "Epoch: 0 | Iteration: 36691 | Classification loss: 0.50312 | Regression loss: 0.58425 | Running loss: 0.87203\n",
      "Epoch: 0 | Iteration: 36692 | Classification loss: 0.33660 | Regression loss: 0.53427 | Running loss: 0.87228\n",
      "Epoch: 0 | Iteration: 36693 | Classification loss: 0.25039 | Regression loss: 0.48416 | Running loss: 0.87138\n",
      "Epoch: 0 | Iteration: 36694 | Classification loss: 0.29251 | Regression loss: 0.44423 | Running loss: 0.87078\n",
      "Epoch: 0 | Iteration: 36695 | Classification loss: 0.41622 | Regression loss: 0.50939 | Running loss: 0.87045\n",
      "Epoch: 0 | Iteration: 36696 | Classification loss: 0.35185 | Regression loss: 0.49303 | Running loss: 0.87002\n",
      "Epoch: 0 | Iteration: 36697 | Classification loss: 0.25488 | Regression loss: 0.40246 | Running loss: 0.87009\n",
      "Epoch: 0 | Iteration: 36698 | Classification loss: 0.12138 | Regression loss: 0.31370 | Running loss: 0.86901\n",
      "Epoch: 0 | Iteration: 36699 | Classification loss: 0.39830 | Regression loss: 0.59833 | Running loss: 0.86899\n",
      "Epoch: 0 | Iteration: 36700 | Classification loss: 0.47998 | Regression loss: 0.61870 | Running loss: 0.86909\n",
      "Epoch: 0 | Iteration: 36701 | Classification loss: 0.15643 | Regression loss: 0.22154 | Running loss: 0.86758\n",
      "Epoch: 0 | Iteration: 36702 | Classification loss: 0.30279 | Regression loss: 0.41553 | Running loss: 0.86724\n",
      "Epoch: 0 | Iteration: 36703 | Classification loss: 0.20009 | Regression loss: 0.35947 | Running loss: 0.86660\n",
      "Epoch: 0 | Iteration: 36704 | Classification loss: 0.49175 | Regression loss: 0.56383 | Running loss: 0.86616\n",
      "Epoch: 0 | Iteration: 36705 | Classification loss: 0.31164 | Regression loss: 0.43307 | Running loss: 0.86515\n",
      "Epoch: 0 | Iteration: 36706 | Classification loss: 0.53623 | Regression loss: 0.50005 | Running loss: 0.86509\n",
      "Epoch: 0 | Iteration: 36707 | Classification loss: 0.43674 | Regression loss: 0.63044 | Running loss: 0.86568\n",
      "Epoch: 0 | Iteration: 36708 | Classification loss: 0.44834 | Regression loss: 0.56598 | Running loss: 0.86538\n",
      "Epoch: 0 | Iteration: 36709 | Classification loss: 0.39313 | Regression loss: 0.60912 | Running loss: 0.86534\n",
      "Epoch: 0 | Iteration: 36710 | Classification loss: 0.20739 | Regression loss: 0.29315 | Running loss: 0.86526\n",
      "Epoch: 0 | Iteration: 36711 | Classification loss: 0.27513 | Regression loss: 0.40373 | Running loss: 0.86455\n",
      "Epoch: 0 | Iteration: 36712 | Classification loss: 0.33497 | Regression loss: 0.52837 | Running loss: 0.86483\n",
      "Epoch: 0 | Iteration: 36713 | Classification loss: 0.32059 | Regression loss: 0.39147 | Running loss: 0.86403\n",
      "Epoch: 0 | Iteration: 36714 | Classification loss: 0.69367 | Regression loss: 0.62907 | Running loss: 0.86503\n",
      "Epoch: 0 | Iteration: 36715 | Classification loss: 0.36534 | Regression loss: 0.66822 | Running loss: 0.86446\n",
      "Epoch: 0 | Iteration: 36716 | Classification loss: 0.37601 | Regression loss: 0.29619 | Running loss: 0.86424\n",
      "Epoch: 0 | Iteration: 36717 | Classification loss: 0.22015 | Regression loss: 0.49942 | Running loss: 0.86383\n",
      "Epoch: 0 | Iteration: 36718 | Classification loss: 0.46207 | Regression loss: 0.58213 | Running loss: 0.86413\n",
      "Epoch: 0 | Iteration: 36719 | Classification loss: 0.26324 | Regression loss: 0.42553 | Running loss: 0.86398\n",
      "Epoch: 0 | Iteration: 36720 | Classification loss: 0.37261 | Regression loss: 0.26711 | Running loss: 0.86390\n",
      "Epoch: 0 | Iteration: 36721 | Classification loss: 0.26316 | Regression loss: 0.35399 | Running loss: 0.86324\n",
      "Epoch: 0 | Iteration: 36722 | Classification loss: 0.36000 | Regression loss: 0.50152 | Running loss: 0.86352\n",
      "Epoch: 0 | Iteration: 36723 | Classification loss: 0.40783 | Regression loss: 0.67401 | Running loss: 0.86404\n",
      "Epoch: 0 | Iteration: 36724 | Classification loss: 0.37825 | Regression loss: 0.55851 | Running loss: 0.86469\n",
      "Epoch: 0 | Iteration: 36725 | Classification loss: 0.31034 | Regression loss: 0.37151 | Running loss: 0.86437\n",
      "Epoch: 0 | Iteration: 36726 | Classification loss: 0.25795 | Regression loss: 0.53971 | Running loss: 0.86442\n",
      "Epoch: 0 | Iteration: 36727 | Classification loss: 0.12490 | Regression loss: 0.24871 | Running loss: 0.86328\n",
      "Epoch: 0 | Iteration: 36728 | Classification loss: 0.43325 | Regression loss: 0.39264 | Running loss: 0.86324\n",
      "Epoch: 0 | Iteration: 36729 | Classification loss: 0.31702 | Regression loss: 0.54086 | Running loss: 0.86294\n",
      "Epoch: 0 | Iteration: 36730 | Classification loss: 0.30897 | Regression loss: 0.61170 | Running loss: 0.86332\n",
      "Epoch: 0 | Iteration: 36731 | Classification loss: 0.36403 | Regression loss: 0.37274 | Running loss: 0.86237\n",
      "Epoch: 0 | Iteration: 36732 | Classification loss: 0.19149 | Regression loss: 0.26747 | Running loss: 0.86199\n",
      "Epoch: 0 | Iteration: 36733 | Classification loss: 0.10333 | Regression loss: 0.16054 | Running loss: 0.86050\n",
      "Epoch: 0 | Iteration: 36734 | Classification loss: 2.55413 | Regression loss: 0.25531 | Running loss: 0.86380\n",
      "Epoch: 0 | Iteration: 36735 | Classification loss: 0.22507 | Regression loss: 0.60221 | Running loss: 0.86328\n",
      "Epoch: 0 | Iteration: 36736 | Classification loss: 0.16813 | Regression loss: 0.51789 | Running loss: 0.86345\n",
      "Epoch: 0 | Iteration: 36737 | Classification loss: 0.49922 | Regression loss: 0.32769 | Running loss: 0.86337\n",
      "Epoch: 0 | Iteration: 36738 | Classification loss: 0.22688 | Regression loss: 0.51496 | Running loss: 0.86309\n",
      "Epoch: 0 | Iteration: 36739 | Classification loss: 0.47950 | Regression loss: 0.66953 | Running loss: 0.86365\n",
      "Epoch: 0 | Iteration: 36740 | Classification loss: 0.47689 | Regression loss: 0.45474 | Running loss: 0.86392\n",
      "Epoch: 0 | Iteration: 36741 | Classification loss: 0.33634 | Regression loss: 0.50961 | Running loss: 0.86382\n",
      "Epoch: 0 | Iteration: 36742 | Classification loss: 0.34322 | Regression loss: 0.37606 | Running loss: 0.86376\n",
      "Epoch: 0 | Iteration: 36743 | Classification loss: 0.36217 | Regression loss: 0.51718 | Running loss: 0.86488\n",
      "Epoch: 0 | Iteration: 36744 | Classification loss: 0.28961 | Regression loss: 0.52271 | Running loss: 0.86413\n",
      "Epoch: 0 | Iteration: 36745 | Classification loss: 0.31561 | Regression loss: 0.46192 | Running loss: 0.86421\n",
      "Epoch: 0 | Iteration: 36746 | Classification loss: 0.30114 | Regression loss: 0.39093 | Running loss: 0.86267\n",
      "Epoch: 0 | Iteration: 36747 | Classification loss: 0.27543 | Regression loss: 0.41988 | Running loss: 0.86264\n",
      "Epoch: 0 | Iteration: 36748 | Classification loss: 0.14623 | Regression loss: 0.27545 | Running loss: 0.86258\n",
      "Epoch: 0 | Iteration: 36749 | Classification loss: 0.45958 | Regression loss: 0.55673 | Running loss: 0.86341\n",
      "Epoch: 0 | Iteration: 36750 | Classification loss: 0.34098 | Regression loss: 0.46372 | Running loss: 0.86321\n",
      "Epoch: 0 | Iteration: 36751 | Classification loss: 0.37272 | Regression loss: 0.64497 | Running loss: 0.86326\n",
      "Epoch: 0 | Iteration: 36752 | Classification loss: 0.38100 | Regression loss: 0.57320 | Running loss: 0.86379\n",
      "Epoch: 0 | Iteration: 36753 | Classification loss: 0.47707 | Regression loss: 0.57172 | Running loss: 0.86397\n",
      "Epoch: 0 | Iteration: 36754 | Classification loss: 0.10558 | Regression loss: 0.22096 | Running loss: 0.86260\n",
      "Epoch: 0 | Iteration: 36755 | Classification loss: 0.44477 | Regression loss: 0.56752 | Running loss: 0.86339\n",
      "Epoch: 0 | Iteration: 36756 | Classification loss: 0.54455 | Regression loss: 0.32703 | Running loss: 0.86277\n",
      "Epoch: 0 | Iteration: 36757 | Classification loss: 0.29777 | Regression loss: 0.42951 | Running loss: 0.86339\n",
      "Epoch: 0 | Iteration: 36758 | Classification loss: 0.38461 | Regression loss: 0.61166 | Running loss: 0.86385\n",
      "Epoch: 0 | Iteration: 36759 | Classification loss: 0.42092 | Regression loss: 0.68909 | Running loss: 0.86364\n",
      "Epoch: 0 | Iteration: 36760 | Classification loss: 0.41697 | Regression loss: 0.47305 | Running loss: 0.86385\n",
      "Epoch: 0 | Iteration: 36761 | Classification loss: 0.41851 | Regression loss: 0.57185 | Running loss: 0.86439\n",
      "Epoch: 0 | Iteration: 36762 | Classification loss: 0.48011 | Regression loss: 0.25476 | Running loss: 0.86486\n",
      "Epoch: 0 | Iteration: 36763 | Classification loss: 0.49498 | Regression loss: 0.65935 | Running loss: 0.86541\n",
      "Epoch: 0 | Iteration: 36764 | Classification loss: 0.48847 | Regression loss: 0.47038 | Running loss: 0.86569\n",
      "Epoch: 0 | Iteration: 36765 | Classification loss: 0.38631 | Regression loss: 0.54323 | Running loss: 0.86456\n",
      "Epoch: 0 | Iteration: 36766 | Classification loss: 0.40375 | Regression loss: 0.60936 | Running loss: 0.86516\n",
      "Epoch: 0 | Iteration: 36767 | Classification loss: 0.32389 | Regression loss: 0.33206 | Running loss: 0.86506\n",
      "Epoch: 0 | Iteration: 36768 | Classification loss: 0.46635 | Regression loss: 0.77018 | Running loss: 0.86647\n",
      "Epoch: 0 | Iteration: 36769 | Classification loss: 0.43125 | Regression loss: 0.43261 | Running loss: 0.86676\n",
      "Epoch: 0 | Iteration: 36770 | Classification loss: 0.28305 | Regression loss: 0.53827 | Running loss: 0.86723\n",
      "Epoch: 0 | Iteration: 36771 | Classification loss: 0.19837 | Regression loss: 0.34238 | Running loss: 0.86714\n",
      "Epoch: 0 | Iteration: 36772 | Classification loss: 0.55990 | Regression loss: 0.30647 | Running loss: 0.86778\n",
      "Epoch: 0 | Iteration: 36773 | Classification loss: 0.34039 | Regression loss: 0.46755 | Running loss: 0.86773\n",
      "Epoch: 0 | Iteration: 36774 | Classification loss: 0.42640 | Regression loss: 0.56143 | Running loss: 0.86792\n",
      "Epoch: 0 | Iteration: 36775 | Classification loss: 0.32904 | Regression loss: 0.61151 | Running loss: 0.86655\n",
      "Epoch: 0 | Iteration: 36776 | Classification loss: 0.31666 | Regression loss: 0.52287 | Running loss: 0.86663\n",
      "Epoch: 0 | Iteration: 36777 | Classification loss: 0.26440 | Regression loss: 0.48139 | Running loss: 0.86705\n",
      "Epoch: 0 | Iteration: 36778 | Classification loss: 0.40607 | Regression loss: 0.72309 | Running loss: 0.86828\n",
      "Epoch: 0 | Iteration: 36779 | Classification loss: 0.47406 | Regression loss: 0.54273 | Running loss: 0.86853\n",
      "Epoch: 0 | Iteration: 36780 | Classification loss: 0.31605 | Regression loss: 0.20650 | Running loss: 0.86799\n",
      "Epoch: 0 | Iteration: 36781 | Classification loss: 0.34387 | Regression loss: 0.47333 | Running loss: 0.86811\n",
      "Epoch: 0 | Iteration: 36782 | Classification loss: 0.33029 | Regression loss: 0.48416 | Running loss: 0.86822\n",
      "Epoch: 0 | Iteration: 36783 | Classification loss: 0.23833 | Regression loss: 0.44190 | Running loss: 0.86780\n",
      "Epoch: 0 | Iteration: 36784 | Classification loss: 0.46519 | Regression loss: 0.53130 | Running loss: 0.86784\n",
      "Epoch: 0 | Iteration: 36785 | Classification loss: 0.54663 | Regression loss: 0.49254 | Running loss: 0.86880\n",
      "Epoch: 0 | Iteration: 36786 | Classification loss: 0.39751 | Regression loss: 0.31330 | Running loss: 0.86746\n",
      "Epoch: 0 | Iteration: 36787 | Classification loss: 0.40604 | Regression loss: 0.60198 | Running loss: 0.86736\n",
      "Epoch: 0 | Iteration: 36788 | Classification loss: 0.58105 | Regression loss: 0.36381 | Running loss: 0.86764\n",
      "Epoch: 0 | Iteration: 36789 | Classification loss: 0.48673 | Regression loss: 0.58355 | Running loss: 0.86757\n",
      "Epoch: 0 | Iteration: 36790 | Classification loss: 0.42850 | Regression loss: 0.74523 | Running loss: 0.86793\n",
      "Epoch: 0 | Iteration: 36791 | Classification loss: 0.43664 | Regression loss: 0.63552 | Running loss: 0.86933\n",
      "Epoch: 0 | Iteration: 36792 | Classification loss: 0.37224 | Regression loss: 0.23536 | Running loss: 0.86908\n",
      "Epoch: 0 | Iteration: 36793 | Classification loss: 0.39264 | Regression loss: 0.59760 | Running loss: 0.86962\n",
      "Epoch: 0 | Iteration: 36794 | Classification loss: 0.37603 | Regression loss: 0.57353 | Running loss: 0.87025\n",
      "Epoch: 0 | Iteration: 36795 | Classification loss: 0.52206 | Regression loss: 0.45444 | Running loss: 0.87039\n",
      "Epoch: 0 | Iteration: 36796 | Classification loss: 0.49510 | Regression loss: 0.44394 | Running loss: 0.87027\n",
      "Epoch: 0 | Iteration: 36797 | Classification loss: 0.40495 | Regression loss: 0.43783 | Running loss: 0.87055\n",
      "Epoch: 0 | Iteration: 36798 | Classification loss: 0.52182 | Regression loss: 0.55883 | Running loss: 0.87066\n",
      "Epoch: 0 | Iteration: 36799 | Classification loss: 0.37209 | Regression loss: 0.56331 | Running loss: 0.87045\n",
      "Epoch: 0 | Iteration: 36800 | Classification loss: 0.57914 | Regression loss: 0.59874 | Running loss: 0.87079\n",
      "Epoch: 0 | Iteration: 36801 | Classification loss: 0.26309 | Regression loss: 0.31225 | Running loss: 0.86989\n",
      "Epoch: 0 | Iteration: 36802 | Classification loss: 0.44409 | Regression loss: 0.71034 | Running loss: 0.87029\n",
      "Epoch: 0 | Iteration: 36803 | Classification loss: 0.32994 | Regression loss: 0.39450 | Running loss: 0.87094\n",
      "Epoch: 0 | Iteration: 36804 | Classification loss: 0.33025 | Regression loss: 0.57551 | Running loss: 0.87147\n",
      "Epoch: 0 | Iteration: 36805 | Classification loss: 0.38569 | Regression loss: 0.53332 | Running loss: 0.87222\n",
      "Epoch: 0 | Iteration: 36806 | Classification loss: 0.57368 | Regression loss: 0.69977 | Running loss: 0.87326\n",
      "Epoch: 0 | Iteration: 36807 | Classification loss: 0.58094 | Regression loss: 0.70835 | Running loss: 0.87401\n",
      "Epoch: 0 | Iteration: 36808 | Classification loss: 0.29035 | Regression loss: 0.40867 | Running loss: 0.87349\n",
      "Epoch: 0 | Iteration: 36809 | Classification loss: 0.75145 | Regression loss: 0.34921 | Running loss: 0.87342\n",
      "Epoch: 0 | Iteration: 36810 | Classification loss: 0.48318 | Regression loss: 0.62598 | Running loss: 0.87396\n",
      "Epoch: 0 | Iteration: 36811 | Classification loss: 0.38845 | Regression loss: 0.48815 | Running loss: 0.87340\n",
      "Epoch: 0 | Iteration: 36812 | Classification loss: 0.65785 | Regression loss: 0.71100 | Running loss: 0.87443\n",
      "Epoch: 0 | Iteration: 36813 | Classification loss: 0.53428 | Regression loss: 0.61354 | Running loss: 0.87529\n",
      "Epoch: 0 | Iteration: 36814 | Classification loss: 0.42754 | Regression loss: 0.37213 | Running loss: 0.87566\n",
      "Epoch: 0 | Iteration: 36815 | Classification loss: 0.65363 | Regression loss: 0.56344 | Running loss: 0.87660\n",
      "Epoch: 0 | Iteration: 36816 | Classification loss: 0.38741 | Regression loss: 0.58506 | Running loss: 0.87773\n",
      "Epoch: 0 | Iteration: 36817 | Classification loss: 0.32644 | Regression loss: 0.42266 | Running loss: 0.87761\n",
      "Epoch: 0 | Iteration: 36818 | Classification loss: 0.53290 | Regression loss: 0.73931 | Running loss: 0.87805\n",
      "Epoch: 0 | Iteration: 36819 | Classification loss: 0.46609 | Regression loss: 0.34723 | Running loss: 0.87761\n",
      "Epoch: 0 | Iteration: 36820 | Classification loss: 0.32443 | Regression loss: 0.35497 | Running loss: 0.87668\n",
      "Epoch: 0 | Iteration: 36821 | Classification loss: 0.39297 | Regression loss: 0.49708 | Running loss: 0.87647\n",
      "Epoch: 0 | Iteration: 36822 | Classification loss: 0.35620 | Regression loss: 0.44711 | Running loss: 0.87604\n",
      "Epoch: 0 | Iteration: 36823 | Classification loss: 0.63733 | Regression loss: 0.37166 | Running loss: 0.87645\n",
      "Epoch: 0 | Iteration: 36824 | Classification loss: 0.36817 | Regression loss: 0.50906 | Running loss: 0.87676\n",
      "Epoch: 0 | Iteration: 36825 | Classification loss: 0.25881 | Regression loss: 0.55422 | Running loss: 0.87657\n",
      "Epoch: 0 | Iteration: 36826 | Classification loss: 0.47682 | Regression loss: 0.56438 | Running loss: 0.87735\n",
      "Epoch: 0 | Iteration: 36827 | Classification loss: 0.35481 | Regression loss: 0.40334 | Running loss: 0.87693\n",
      "Epoch: 0 | Iteration: 36828 | Classification loss: 0.30669 | Regression loss: 0.37521 | Running loss: 0.87545\n",
      "Epoch: 0 | Iteration: 36829 | Classification loss: 0.36081 | Regression loss: 0.64980 | Running loss: 0.87557\n",
      "Epoch: 0 | Iteration: 36830 | Classification loss: 0.20683 | Regression loss: 0.29490 | Running loss: 0.87505\n",
      "Epoch: 0 | Iteration: 36831 | Classification loss: 0.54209 | Regression loss: 0.59149 | Running loss: 0.87559\n",
      "Epoch: 0 | Iteration: 36832 | Classification loss: 0.33579 | Regression loss: 0.60860 | Running loss: 0.87527\n",
      "Epoch: 0 | Iteration: 36833 | Classification loss: 0.35779 | Regression loss: 0.38610 | Running loss: 0.87501\n",
      "Epoch: 0 | Iteration: 36834 | Classification loss: 0.54373 | Regression loss: 0.48113 | Running loss: 0.87522\n",
      "Epoch: 0 | Iteration: 36835 | Classification loss: 0.54723 | Regression loss: 0.50424 | Running loss: 0.87592\n",
      "Epoch: 0 | Iteration: 36836 | Classification loss: 0.35165 | Regression loss: 0.35750 | Running loss: 0.87520\n",
      "Epoch: 0 | Iteration: 36837 | Classification loss: 0.26967 | Regression loss: 0.50010 | Running loss: 0.87415\n",
      "Epoch: 0 | Iteration: 36838 | Classification loss: 0.43782 | Regression loss: 0.45622 | Running loss: 0.87452\n",
      "Epoch: 0 | Iteration: 36839 | Classification loss: 0.52672 | Regression loss: 0.69493 | Running loss: 0.87605\n",
      "Epoch: 0 | Iteration: 36840 | Classification loss: 0.40694 | Regression loss: 0.43126 | Running loss: 0.87601\n",
      "Epoch: 0 | Iteration: 36841 | Classification loss: 0.28304 | Regression loss: 0.55453 | Running loss: 0.87603\n",
      "Epoch: 0 | Iteration: 36842 | Classification loss: 0.20696 | Regression loss: 0.27238 | Running loss: 0.87485\n",
      "Epoch: 0 | Iteration: 36843 | Classification loss: 0.22883 | Regression loss: 0.47131 | Running loss: 0.87447\n",
      "Epoch: 0 | Iteration: 36844 | Classification loss: 0.31211 | Regression loss: 0.37611 | Running loss: 0.87404\n",
      "Epoch: 0 | Iteration: 36845 | Classification loss: 0.41028 | Regression loss: 0.35088 | Running loss: 0.87347\n",
      "Epoch: 0 | Iteration: 36846 | Classification loss: 0.42280 | Regression loss: 0.45596 | Running loss: 0.87412\n",
      "Epoch: 0 | Iteration: 36847 | Classification loss: 0.38942 | Regression loss: 0.60797 | Running loss: 0.87410\n",
      "Epoch: 0 | Iteration: 36848 | Classification loss: 0.41650 | Regression loss: 0.37801 | Running loss: 0.87387\n",
      "Epoch: 0 | Iteration: 36849 | Classification loss: 0.23407 | Regression loss: 0.37673 | Running loss: 0.87345\n",
      "Epoch: 0 | Iteration: 36850 | Classification loss: 0.40311 | Regression loss: 0.54808 | Running loss: 0.87357\n",
      "Epoch: 0 | Iteration: 36851 | Classification loss: 0.41466 | Regression loss: 0.45923 | Running loss: 0.87348\n",
      "Epoch: 0 | Iteration: 36852 | Classification loss: 0.15175 | Regression loss: 0.36778 | Running loss: 0.87252\n",
      "Epoch: 0 | Iteration: 36853 | Classification loss: 0.38906 | Regression loss: 0.58817 | Running loss: 0.87294\n",
      "Epoch: 0 | Iteration: 36854 | Classification loss: 0.42928 | Regression loss: 0.29788 | Running loss: 0.87196\n",
      "Epoch: 0 | Iteration: 36855 | Classification loss: 0.35717 | Regression loss: 0.46436 | Running loss: 0.87215\n",
      "Epoch: 0 | Iteration: 36856 | Classification loss: 0.26201 | Regression loss: 0.25150 | Running loss: 0.87158\n",
      "Epoch: 0 | Iteration: 36857 | Classification loss: 0.38970 | Regression loss: 0.55518 | Running loss: 0.87164\n",
      "Epoch: 0 | Iteration: 36858 | Classification loss: 0.54123 | Regression loss: 0.80619 | Running loss: 0.87201\n",
      "Epoch: 0 | Iteration: 36859 | Classification loss: 0.32345 | Regression loss: 0.63367 | Running loss: 0.87211\n",
      "Epoch: 0 | Iteration: 36860 | Classification loss: 0.31210 | Regression loss: 0.27460 | Running loss: 0.87131\n",
      "Epoch: 0 | Iteration: 36861 | Classification loss: 0.39084 | Regression loss: 0.57635 | Running loss: 0.87158\n",
      "Epoch: 0 | Iteration: 36862 | Classification loss: 0.21791 | Regression loss: 0.45345 | Running loss: 0.87088\n",
      "Epoch: 0 | Iteration: 36863 | Classification loss: 0.43983 | Regression loss: 0.41819 | Running loss: 0.87080\n",
      "Epoch: 0 | Iteration: 36864 | Classification loss: 0.46374 | Regression loss: 0.60083 | Running loss: 0.87119\n",
      "Epoch: 0 | Iteration: 36865 | Classification loss: 0.42869 | Regression loss: 0.54133 | Running loss: 0.87096\n",
      "Epoch: 0 | Iteration: 36866 | Classification loss: 0.42243 | Regression loss: 0.54028 | Running loss: 0.87148\n",
      "Epoch: 0 | Iteration: 36867 | Classification loss: 0.33629 | Regression loss: 0.51207 | Running loss: 0.87155\n",
      "Epoch: 0 | Iteration: 36868 | Classification loss: 0.40677 | Regression loss: 0.46373 | Running loss: 0.87184\n",
      "Epoch: 0 | Iteration: 36869 | Classification loss: 0.46388 | Regression loss: 0.65911 | Running loss: 0.87241\n",
      "Epoch: 0 | Iteration: 36870 | Classification loss: 0.33142 | Regression loss: 0.27910 | Running loss: 0.87131\n",
      "Epoch: 0 | Iteration: 36871 | Classification loss: 0.62428 | Regression loss: 0.64728 | Running loss: 0.87214\n",
      "Epoch: 0 | Iteration: 36872 | Classification loss: 0.50414 | Regression loss: 0.52403 | Running loss: 0.87235\n",
      "Epoch: 0 | Iteration: 36873 | Classification loss: 0.15798 | Regression loss: 0.22384 | Running loss: 0.87151\n",
      "Epoch: 0 | Iteration: 36874 | Classification loss: 0.30895 | Regression loss: 0.53300 | Running loss: 0.87201\n",
      "Epoch: 0 | Iteration: 36875 | Classification loss: 0.46422 | Regression loss: 0.56477 | Running loss: 0.87159\n",
      "Epoch: 0 | Iteration: 36876 | Classification loss: 0.32832 | Regression loss: 0.58716 | Running loss: 0.87147\n",
      "Epoch: 0 | Iteration: 36877 | Classification loss: 0.47996 | Regression loss: 0.62198 | Running loss: 0.87176\n",
      "Epoch: 0 | Iteration: 36878 | Classification loss: 0.29610 | Regression loss: 0.42973 | Running loss: 0.87132\n",
      "Epoch: 0 | Iteration: 36879 | Classification loss: 0.36218 | Regression loss: 0.63864 | Running loss: 0.87145\n",
      "Epoch: 0 | Iteration: 36880 | Classification loss: 0.15736 | Regression loss: 0.28502 | Running loss: 0.87112\n",
      "Epoch: 0 | Iteration: 36881 | Classification loss: 0.48091 | Regression loss: 0.63947 | Running loss: 0.87226\n",
      "Epoch: 0 | Iteration: 36882 | Classification loss: 0.22487 | Regression loss: 0.46860 | Running loss: 0.87236\n",
      "Epoch: 0 | Iteration: 36883 | Classification loss: 0.41342 | Regression loss: 0.46230 | Running loss: 0.87278\n",
      "Epoch: 0 | Iteration: 36884 | Classification loss: 0.27845 | Regression loss: 0.48116 | Running loss: 0.87261\n",
      "Epoch: 0 | Iteration: 36885 | Classification loss: 0.27423 | Regression loss: 0.43832 | Running loss: 0.87148\n",
      "Epoch: 0 | Iteration: 36886 | Classification loss: 0.32738 | Regression loss: 0.48868 | Running loss: 0.87153\n",
      "Epoch: 0 | Iteration: 36887 | Classification loss: 0.24858 | Regression loss: 0.27513 | Running loss: 0.87082\n",
      "Epoch: 0 | Iteration: 36888 | Classification loss: 0.43137 | Regression loss: 0.55446 | Running loss: 0.87114\n",
      "Epoch: 0 | Iteration: 36889 | Classification loss: 0.46126 | Regression loss: 0.64402 | Running loss: 0.87158\n",
      "Epoch: 0 | Iteration: 36890 | Classification loss: 0.31170 | Regression loss: 0.57608 | Running loss: 0.87230\n",
      "Epoch: 0 | Iteration: 36891 | Classification loss: 0.35163 | Regression loss: 0.54402 | Running loss: 0.87196\n",
      "Epoch: 0 | Iteration: 36892 | Classification loss: 0.11256 | Regression loss: 0.22305 | Running loss: 0.87161\n",
      "Epoch: 0 | Iteration: 36893 | Classification loss: 0.44914 | Regression loss: 0.40125 | Running loss: 0.87208\n",
      "Epoch: 0 | Iteration: 36894 | Classification loss: 0.36839 | Regression loss: 0.50471 | Running loss: 0.87228\n",
      "Epoch: 0 | Iteration: 36895 | Classification loss: 0.29090 | Regression loss: 0.25763 | Running loss: 0.87086\n",
      "Epoch: 0 | Iteration: 36896 | Classification loss: 0.29850 | Regression loss: 0.29597 | Running loss: 0.87059\n",
      "Epoch: 0 | Iteration: 36897 | Classification loss: 0.30508 | Regression loss: 0.29467 | Running loss: 0.87019\n",
      "Epoch: 0 | Iteration: 36898 | Classification loss: 0.32471 | Regression loss: 0.44408 | Running loss: 0.86977\n",
      "Epoch: 0 | Iteration: 36899 | Classification loss: 0.40848 | Regression loss: 0.52125 | Running loss: 0.87003\n",
      "Epoch: 0 | Iteration: 36900 | Classification loss: 0.28585 | Regression loss: 0.29449 | Running loss: 0.86927\n",
      "Epoch: 0 | Iteration: 36901 | Classification loss: 0.49076 | Regression loss: 0.38615 | Running loss: 0.86896\n",
      "Epoch: 0 | Iteration: 36902 | Classification loss: 0.60381 | Regression loss: 0.30049 | Running loss: 0.86890\n",
      "Epoch: 0 | Iteration: 36903 | Classification loss: 0.67716 | Regression loss: 0.68386 | Running loss: 0.86991\n",
      "Epoch: 0 | Iteration: 36904 | Classification loss: 0.35265 | Regression loss: 0.53837 | Running loss: 0.86994\n",
      "Epoch: 0 | Iteration: 36905 | Classification loss: 0.33574 | Regression loss: 0.52313 | Running loss: 0.87007\n",
      "Epoch: 0 | Iteration: 36906 | Classification loss: 0.42535 | Regression loss: 0.56720 | Running loss: 0.87014\n",
      "Epoch: 0 | Iteration: 36907 | Classification loss: 0.39930 | Regression loss: 0.50586 | Running loss: 0.87034\n",
      "Epoch: 0 | Iteration: 36908 | Classification loss: 0.37818 | Regression loss: 0.47118 | Running loss: 0.86987\n",
      "Epoch: 0 | Iteration: 36909 | Classification loss: 0.14494 | Regression loss: 0.30058 | Running loss: 0.86802\n",
      "Epoch: 0 | Iteration: 36910 | Classification loss: 0.47767 | Regression loss: 0.55538 | Running loss: 0.86832\n",
      "Epoch: 0 | Iteration: 36911 | Classification loss: 0.28505 | Regression loss: 0.37860 | Running loss: 0.86790\n",
      "Epoch: 0 | Iteration: 36912 | Classification loss: 0.24789 | Regression loss: 0.56863 | Running loss: 0.86891\n",
      "Epoch: 0 | Iteration: 36913 | Classification loss: 0.19791 | Regression loss: 0.39735 | Running loss: 0.86883\n",
      "Epoch: 0 | Iteration: 36914 | Classification loss: 0.54970 | Regression loss: 0.50493 | Running loss: 0.87018\n",
      "Epoch: 0 | Iteration: 36915 | Classification loss: 0.34993 | Regression loss: 0.41220 | Running loss: 0.87028\n",
      "Epoch: 0 | Iteration: 36916 | Classification loss: 0.38765 | Regression loss: 0.49737 | Running loss: 0.87027\n",
      "Epoch: 0 | Iteration: 36917 | Classification loss: 0.35619 | Regression loss: 0.58906 | Running loss: 0.87061\n",
      "Epoch: 0 | Iteration: 36918 | Classification loss: 0.44519 | Regression loss: 0.51134 | Running loss: 0.87112\n",
      "Epoch: 0 | Iteration: 36919 | Classification loss: 0.28786 | Regression loss: 0.38294 | Running loss: 0.87115\n",
      "Epoch: 0 | Iteration: 36920 | Classification loss: 0.16410 | Regression loss: 0.42964 | Running loss: 0.87047\n",
      "Epoch: 0 | Iteration: 36921 | Classification loss: 0.35178 | Regression loss: 0.53010 | Running loss: 0.87021\n",
      "Epoch: 0 | Iteration: 36922 | Classification loss: 0.18055 | Regression loss: 0.17521 | Running loss: 0.86846\n",
      "Epoch: 0 | Iteration: 36923 | Classification loss: 0.39020 | Regression loss: 0.56800 | Running loss: 0.86844\n",
      "Epoch: 0 | Iteration: 36924 | Classification loss: 0.16427 | Regression loss: 0.36851 | Running loss: 0.86783\n",
      "Epoch: 0 | Iteration: 36925 | Classification loss: 7.03805 | Regression loss: 0.76570 | Running loss: 0.88215\n",
      "Epoch: 0 | Iteration: 36926 | Classification loss: 0.30062 | Regression loss: 0.31022 | Running loss: 0.88132\n",
      "Epoch: 0 | Iteration: 36927 | Classification loss: 0.31186 | Regression loss: 0.33038 | Running loss: 0.88107\n",
      "Epoch: 0 | Iteration: 36928 | Classification loss: 0.41527 | Regression loss: 0.62267 | Running loss: 0.88239\n",
      "Epoch: 0 | Iteration: 36929 | Classification loss: 0.61617 | Regression loss: 0.55363 | Running loss: 0.88386\n",
      "Epoch: 0 | Iteration: 36930 | Classification loss: 0.23468 | Regression loss: 0.55998 | Running loss: 0.88264\n",
      "Epoch: 0 | Iteration: 36931 | Classification loss: 0.24570 | Regression loss: 0.45759 | Running loss: 0.88281\n",
      "Epoch: 0 | Iteration: 36932 | Classification loss: 0.35374 | Regression loss: 0.07523 | Running loss: 0.88185\n",
      "Epoch: 0 | Iteration: 36933 | Classification loss: 0.36140 | Regression loss: 0.48096 | Running loss: 0.88306\n",
      "Epoch: 0 | Iteration: 36934 | Classification loss: 0.77167 | Regression loss: 0.51478 | Running loss: 0.88406\n",
      "Epoch: 0 | Iteration: 36935 | Classification loss: 0.41774 | Regression loss: 0.40459 | Running loss: 0.88433\n",
      "Epoch: 0 | Iteration: 36936 | Classification loss: 0.32441 | Regression loss: 0.48475 | Running loss: 0.87931\n",
      "Epoch: 0 | Iteration: 36937 | Classification loss: 0.25874 | Regression loss: 0.52460 | Running loss: 0.87909\n",
      "Epoch: 0 | Iteration: 36938 | Classification loss: 0.41992 | Regression loss: 0.63699 | Running loss: 0.87974\n",
      "Epoch: 0 | Iteration: 36939 | Classification loss: 0.34436 | Regression loss: 0.57220 | Running loss: 0.88049\n",
      "Epoch: 0 | Iteration: 36940 | Classification loss: 0.25196 | Regression loss: 0.52290 | Running loss: 0.88040\n",
      "Epoch: 0 | Iteration: 36941 | Classification loss: 0.33172 | Regression loss: 0.45873 | Running loss: 0.88034\n",
      "Epoch: 0 | Iteration: 36942 | Classification loss: 0.44219 | Regression loss: 0.39048 | Running loss: 0.87944\n",
      "Epoch: 0 | Iteration: 36943 | Classification loss: 0.40796 | Regression loss: 0.54744 | Running loss: 0.87943\n",
      "Epoch: 0 | Iteration: 36944 | Classification loss: 0.50749 | Regression loss: 0.59409 | Running loss: 0.87983\n",
      "Epoch: 0 | Iteration: 36945 | Classification loss: 0.18748 | Regression loss: 0.30685 | Running loss: 0.87913\n",
      "Epoch: 0 | Iteration: 36946 | Classification loss: 0.25664 | Regression loss: 0.48831 | Running loss: 0.87977\n",
      "Epoch: 0 | Iteration: 36947 | Classification loss: 0.58831 | Regression loss: 0.40709 | Running loss: 0.87954\n",
      "Epoch: 0 | Iteration: 36948 | Classification loss: 0.38907 | Regression loss: 0.49339 | Running loss: 0.88029\n",
      "Epoch: 0 | Iteration: 36949 | Classification loss: 0.30787 | Regression loss: 0.41058 | Running loss: 0.87960\n",
      "Epoch: 0 | Iteration: 36950 | Classification loss: 0.37251 | Regression loss: 0.52437 | Running loss: 0.87883\n",
      "Epoch: 0 | Iteration: 36951 | Classification loss: 0.34147 | Regression loss: 0.53490 | Running loss: 0.87894\n",
      "Epoch: 0 | Iteration: 36952 | Classification loss: 0.18208 | Regression loss: 0.26288 | Running loss: 0.87726\n",
      "Epoch: 0 | Iteration: 36953 | Classification loss: 0.35060 | Regression loss: 0.57390 | Running loss: 0.87710\n",
      "Epoch: 0 | Iteration: 36954 | Classification loss: 0.29541 | Regression loss: 0.34851 | Running loss: 0.87652\n",
      "Epoch: 0 | Iteration: 36955 | Classification loss: 0.37979 | Regression loss: 0.43403 | Running loss: 0.87690\n",
      "Epoch: 0 | Iteration: 36956 | Classification loss: 0.46659 | Regression loss: 0.16292 | Running loss: 0.87707\n",
      "Epoch: 0 | Iteration: 36957 | Classification loss: 0.47161 | Regression loss: 0.66927 | Running loss: 0.87776\n",
      "Epoch: 0 | Iteration: 36958 | Classification loss: 0.25356 | Regression loss: 0.42320 | Running loss: 0.87713\n",
      "Epoch: 0 | Iteration: 36959 | Classification loss: 0.30075 | Regression loss: 0.30354 | Running loss: 0.87705\n",
      "Epoch: 0 | Iteration: 36960 | Classification loss: 0.50899 | Regression loss: 0.63390 | Running loss: 0.87848\n",
      "Epoch: 0 | Iteration: 36961 | Classification loss: 0.42916 | Regression loss: 0.73998 | Running loss: 0.87877\n",
      "Epoch: 0 | Iteration: 36962 | Classification loss: 0.40720 | Regression loss: 0.61178 | Running loss: 0.87951\n",
      "Epoch: 0 | Iteration: 36963 | Classification loss: 0.56938 | Regression loss: 0.61561 | Running loss: 0.88080\n",
      "Epoch: 0 | Iteration: 36964 | Classification loss: 0.32269 | Regression loss: 0.47188 | Running loss: 0.88064\n",
      "Epoch: 0 | Iteration: 36965 | Classification loss: 0.22880 | Regression loss: 0.50762 | Running loss: 0.88065\n",
      "Epoch: 0 | Iteration: 36966 | Classification loss: 0.45438 | Regression loss: 0.54642 | Running loss: 0.88181\n",
      "Epoch: 0 | Iteration: 36967 | Classification loss: 0.31125 | Regression loss: 0.45997 | Running loss: 0.88187\n",
      "Epoch: 0 | Iteration: 36968 | Classification loss: 0.38701 | Regression loss: 0.47926 | Running loss: 0.88157\n",
      "Epoch: 0 | Iteration: 36969 | Classification loss: 0.44425 | Regression loss: 0.54852 | Running loss: 0.88259\n",
      "Epoch: 0 | Iteration: 36970 | Classification loss: 0.67421 | Regression loss: 0.49562 | Running loss: 0.88294\n",
      "Epoch: 0 | Iteration: 36971 | Classification loss: 0.34152 | Regression loss: 0.24493 | Running loss: 0.88187\n",
      "Epoch: 0 | Iteration: 36972 | Classification loss: 0.45087 | Regression loss: 0.48702 | Running loss: 0.88252\n",
      "Epoch: 0 | Iteration: 36973 | Classification loss: 0.36242 | Regression loss: 0.65730 | Running loss: 0.88262\n",
      "Epoch: 0 | Iteration: 36974 | Classification loss: 0.62909 | Regression loss: 0.61326 | Running loss: 0.88288\n",
      "Epoch: 0 | Iteration: 36975 | Classification loss: 0.27798 | Regression loss: 0.55880 | Running loss: 0.88263\n",
      "Epoch: 0 | Iteration: 36976 | Classification loss: 0.38850 | Regression loss: 0.37026 | Running loss: 0.88181\n",
      "Epoch: 0 | Iteration: 36977 | Classification loss: 0.79658 | Regression loss: 0.48880 | Running loss: 0.88267\n",
      "Epoch: 0 | Iteration: 36978 | Classification loss: 0.34508 | Regression loss: 0.46028 | Running loss: 0.88277\n",
      "Epoch: 0 | Iteration: 36979 | Classification loss: 0.51120 | Regression loss: 0.53169 | Running loss: 0.88351\n",
      "Epoch: 0 | Iteration: 36980 | Classification loss: 0.41374 | Regression loss: 0.45795 | Running loss: 0.88399\n",
      "Epoch: 0 | Iteration: 36981 | Classification loss: 0.22195 | Regression loss: 0.37559 | Running loss: 0.88343\n",
      "Epoch: 0 | Iteration: 36982 | Classification loss: 0.45939 | Regression loss: 0.46487 | Running loss: 0.88328\n",
      "Epoch: 0 | Iteration: 36983 | Classification loss: 0.33540 | Regression loss: 0.47682 | Running loss: 0.88272\n",
      "Epoch: 0 | Iteration: 36984 | Classification loss: 0.14413 | Regression loss: 0.30730 | Running loss: 0.88032\n",
      "Epoch: 0 | Iteration: 36985 | Classification loss: 0.49988 | Regression loss: 0.65949 | Running loss: 0.88185\n",
      "Epoch: 0 | Iteration: 36986 | Classification loss: 0.43975 | Regression loss: 0.74472 | Running loss: 0.88349\n",
      "Epoch: 0 | Iteration: 36987 | Classification loss: 0.47234 | Regression loss: 0.82285 | Running loss: 0.88441\n",
      "Epoch: 0 | Iteration: 36988 | Classification loss: 0.27369 | Regression loss: 0.37222 | Running loss: 0.88426\n",
      "Epoch: 0 | Iteration: 36989 | Classification loss: 0.42037 | Regression loss: 0.50998 | Running loss: 0.88418\n",
      "Epoch: 0 | Iteration: 36990 | Classification loss: 0.49115 | Regression loss: 0.39570 | Running loss: 0.88408\n",
      "Epoch: 0 | Iteration: 36991 | Classification loss: 0.33346 | Regression loss: 0.48696 | Running loss: 0.88453\n",
      "Epoch: 0 | Iteration: 36992 | Classification loss: 0.42118 | Regression loss: 0.45115 | Running loss: 0.88510\n",
      "Epoch: 0 | Iteration: 36993 | Classification loss: 0.38932 | Regression loss: 0.46479 | Running loss: 0.88512\n",
      "Epoch: 0 | Iteration: 36994 | Classification loss: 0.36957 | Regression loss: 0.52575 | Running loss: 0.88420\n",
      "Epoch: 0 | Iteration: 36995 | Classification loss: 0.28701 | Regression loss: 0.44117 | Running loss: 0.88313\n",
      "Epoch: 0 | Iteration: 36996 | Classification loss: 0.36361 | Regression loss: 0.38340 | Running loss: 0.88113\n",
      "Epoch: 0 | Iteration: 36997 | Classification loss: 0.29803 | Regression loss: 0.45125 | Running loss: 0.88001\n",
      "Epoch: 0 | Iteration: 36998 | Classification loss: 0.36062 | Regression loss: 0.52139 | Running loss: 0.87996\n",
      "Epoch: 0 | Iteration: 36999 | Classification loss: 0.24175 | Regression loss: 0.51268 | Running loss: 0.88011\n",
      "Epoch: 0 | Iteration: 37000 | Classification loss: 0.44119 | Regression loss: 0.52586 | Running loss: 0.88051\n",
      "Epoch: 0 | Iteration: 37001 | Classification loss: 0.26785 | Regression loss: 0.42810 | Running loss: 0.87991\n",
      "Epoch: 0 | Iteration: 37002 | Classification loss: 0.28998 | Regression loss: 0.39757 | Running loss: 0.88019\n",
      "Epoch: 0 | Iteration: 37003 | Classification loss: 0.64191 | Regression loss: 0.66278 | Running loss: 0.88133\n",
      "Epoch: 0 | Iteration: 37004 | Classification loss: 0.30952 | Regression loss: 0.53143 | Running loss: 0.88210\n",
      "Epoch: 0 | Iteration: 37005 | Classification loss: 0.28136 | Regression loss: 0.44708 | Running loss: 0.88151\n",
      "Epoch: 0 | Iteration: 37006 | Classification loss: 0.39010 | Regression loss: 0.50693 | Running loss: 0.88220\n",
      "Epoch: 0 | Iteration: 37007 | Classification loss: 0.30857 | Regression loss: 0.54914 | Running loss: 0.88151\n",
      "Epoch: 0 | Iteration: 37008 | Classification loss: 0.36730 | Regression loss: 0.70141 | Running loss: 0.88046\n",
      "Epoch: 0 | Iteration: 37009 | Classification loss: 0.54245 | Regression loss: 0.54737 | Running loss: 0.88069\n",
      "Epoch: 0 | Iteration: 37010 | Classification loss: 6.00563 | Regression loss: 0.16677 | Running loss: 0.89110\n",
      "Epoch: 0 | Iteration: 37011 | Classification loss: 0.22463 | Regression loss: 0.32616 | Running loss: 0.88990\n",
      "Epoch: 0 | Iteration: 37012 | Classification loss: 0.46049 | Regression loss: 0.47968 | Running loss: 0.88968\n",
      "Epoch: 0 | Iteration: 37013 | Classification loss: 0.55031 | Regression loss: 0.55475 | Running loss: 0.88982\n",
      "Epoch: 0 | Iteration: 37014 | Classification loss: 0.61117 | Regression loss: 0.27664 | Running loss: 0.88898\n",
      "Epoch: 0 | Iteration: 37015 | Classification loss: 0.62520 | Regression loss: 0.67179 | Running loss: 0.89040\n",
      "Epoch: 0 | Iteration: 37016 | Classification loss: 0.43441 | Regression loss: 0.59916 | Running loss: 0.89113\n",
      "Epoch: 0 | Iteration: 37017 | Classification loss: 0.30162 | Regression loss: 0.52222 | Running loss: 0.88938\n",
      "Epoch: 0 | Iteration: 37018 | Classification loss: 0.22837 | Regression loss: 0.35933 | Running loss: 0.88829\n",
      "Epoch: 0 | Iteration: 37019 | Classification loss: 0.19085 | Regression loss: 0.41149 | Running loss: 0.88765\n",
      "Epoch: 0 | Iteration: 37020 | Classification loss: 0.23859 | Regression loss: 0.38367 | Running loss: 0.88729\n",
      "Epoch: 0 | Iteration: 37021 | Classification loss: 0.52314 | Regression loss: 0.61340 | Running loss: 0.88790\n",
      "Epoch: 0 | Iteration: 37022 | Classification loss: 0.39890 | Regression loss: 0.54704 | Running loss: 0.88813\n",
      "Epoch: 0 | Iteration: 37023 | Classification loss: 0.36674 | Regression loss: 0.31173 | Running loss: 0.88767\n",
      "Epoch: 0 | Iteration: 37024 | Classification loss: 0.26530 | Regression loss: 0.43938 | Running loss: 0.88664\n",
      "Epoch: 0 | Iteration: 37025 | Classification loss: 0.52177 | Regression loss: 0.63381 | Running loss: 0.88659\n",
      "Epoch: 0 | Iteration: 37026 | Classification loss: 0.42526 | Regression loss: 0.57026 | Running loss: 0.88722\n",
      "Epoch: 0 | Iteration: 37027 | Classification loss: 0.36296 | Regression loss: 0.44891 | Running loss: 0.88735\n",
      "Epoch: 0 | Iteration: 37028 | Classification loss: 0.56577 | Regression loss: 0.58389 | Running loss: 0.88810\n",
      "Epoch: 0 | Iteration: 37029 | Classification loss: 0.39723 | Regression loss: 0.58874 | Running loss: 0.88782\n",
      "Epoch: 0 | Iteration: 37030 | Classification loss: 0.50911 | Regression loss: 0.50233 | Running loss: 0.88786\n",
      "Epoch: 0 | Iteration: 37031 | Classification loss: 0.29626 | Regression loss: 0.39209 | Running loss: 0.88700\n",
      "Epoch: 0 | Iteration: 37032 | Classification loss: 0.43643 | Regression loss: 0.67259 | Running loss: 0.88822\n",
      "Epoch: 0 | Iteration: 37033 | Classification loss: 0.56445 | Regression loss: 0.62229 | Running loss: 0.88888\n",
      "Epoch: 0 | Iteration: 37034 | Classification loss: 0.99127 | Regression loss: 0.30887 | Running loss: 0.89036\n",
      "Epoch: 0 | Iteration: 37035 | Classification loss: 0.32494 | Regression loss: 0.52049 | Running loss: 0.89102\n",
      "Epoch: 0 | Iteration: 37036 | Classification loss: 0.35796 | Regression loss: 0.51471 | Running loss: 0.89090\n",
      "Epoch: 0 | Iteration: 37037 | Classification loss: 0.59748 | Regression loss: 0.60837 | Running loss: 0.89153\n",
      "Epoch: 0 | Iteration: 37038 | Classification loss: 0.16803 | Regression loss: 0.39013 | Running loss: 0.89106\n",
      "Epoch: 0 | Iteration: 37039 | Classification loss: 0.45968 | Regression loss: 0.36154 | Running loss: 0.89222\n",
      "Epoch: 0 | Iteration: 37040 | Classification loss: 0.27331 | Regression loss: 0.53153 | Running loss: 0.89285\n",
      "Epoch: 0 | Iteration: 37041 | Classification loss: 0.38499 | Regression loss: 0.49995 | Running loss: 0.89260\n",
      "Epoch: 0 | Iteration: 37042 | Classification loss: 0.40812 | Regression loss: 0.61766 | Running loss: 0.89330\n",
      "Epoch: 0 | Iteration: 37043 | Classification loss: 0.33117 | Regression loss: 0.49855 | Running loss: 0.89258\n",
      "Epoch: 0 | Iteration: 37044 | Classification loss: 0.47609 | Regression loss: 0.68942 | Running loss: 0.89301\n",
      "Epoch: 0 | Iteration: 37045 | Classification loss: 0.43911 | Regression loss: 0.34471 | Running loss: 0.89247\n",
      "Epoch: 0 | Iteration: 37046 | Classification loss: 0.32423 | Regression loss: 0.56604 | Running loss: 0.89278\n",
      "Epoch: 0 | Iteration: 37047 | Classification loss: 0.27947 | Regression loss: 0.43597 | Running loss: 0.89312\n",
      "Epoch: 0 | Iteration: 37048 | Classification loss: 0.65202 | Regression loss: 0.64303 | Running loss: 0.89434\n",
      "Epoch: 0 | Iteration: 37049 | Classification loss: 0.32609 | Regression loss: 0.53284 | Running loss: 0.89409\n",
      "Epoch: 0 | Iteration: 37050 | Classification loss: 0.45037 | Regression loss: 0.47383 | Running loss: 0.89429\n",
      "Epoch: 0 | Iteration: 37051 | Classification loss: 0.39837 | Regression loss: 0.51054 | Running loss: 0.89430\n",
      "Epoch: 0 | Iteration: 37052 | Classification loss: 0.19092 | Regression loss: 0.37495 | Running loss: 0.89349\n",
      "Epoch: 0 | Iteration: 37053 | Classification loss: 0.27499 | Regression loss: 0.48988 | Running loss: 0.89281\n",
      "Epoch: 0 | Iteration: 37054 | Classification loss: 0.34644 | Regression loss: 0.60775 | Running loss: 0.89378\n",
      "Epoch: 0 | Iteration: 37055 | Classification loss: 0.38888 | Regression loss: 0.70590 | Running loss: 0.89393\n",
      "Epoch: 0 | Iteration: 37056 | Classification loss: 0.35366 | Regression loss: 0.39269 | Running loss: 0.89410\n",
      "Epoch: 0 | Iteration: 37057 | Classification loss: 0.38360 | Regression loss: 0.53099 | Running loss: 0.89449\n",
      "Epoch: 0 | Iteration: 37058 | Classification loss: 0.37383 | Regression loss: 0.42123 | Running loss: 0.89452\n",
      "Epoch: 0 | Iteration: 37059 | Classification loss: 0.32103 | Regression loss: 0.35820 | Running loss: 0.89347\n",
      "Epoch: 0 | Iteration: 37060 | Classification loss: 0.42583 | Regression loss: 0.57504 | Running loss: 0.89396\n",
      "Epoch: 0 | Iteration: 37061 | Classification loss: 0.29385 | Regression loss: 0.30714 | Running loss: 0.89418\n",
      "Epoch: 0 | Iteration: 37062 | Classification loss: 0.64432 | Regression loss: 0.57202 | Running loss: 0.89509\n",
      "Epoch: 0 | Iteration: 37063 | Classification loss: 0.43828 | Regression loss: 0.63766 | Running loss: 0.89584\n",
      "Epoch: 0 | Iteration: 37064 | Classification loss: 0.36550 | Regression loss: 0.54175 | Running loss: 0.89628\n",
      "Epoch: 0 | Iteration: 37065 | Classification loss: 0.23477 | Regression loss: 0.44538 | Running loss: 0.89601\n",
      "Epoch: 0 | Iteration: 37066 | Classification loss: 0.46264 | Regression loss: 0.67580 | Running loss: 0.89688\n",
      "Epoch: 0 | Iteration: 37067 | Classification loss: 0.35182 | Regression loss: 0.49639 | Running loss: 0.89648\n",
      "Epoch: 0 | Iteration: 37068 | Classification loss: 0.52894 | Regression loss: 0.64727 | Running loss: 0.89682\n",
      "Epoch: 0 | Iteration: 37069 | Classification loss: 0.48363 | Regression loss: 0.38407 | Running loss: 0.89662\n",
      "Epoch: 0 | Iteration: 37070 | Classification loss: 0.37250 | Regression loss: 0.54102 | Running loss: 0.89610\n",
      "Epoch: 0 | Iteration: 37071 | Classification loss: 0.25643 | Regression loss: 0.26531 | Running loss: 0.89522\n",
      "Epoch: 0 | Iteration: 37072 | Classification loss: 0.53920 | Regression loss: 0.64024 | Running loss: 0.89524\n",
      "Epoch: 0 | Iteration: 37073 | Classification loss: 0.18601 | Regression loss: 0.21409 | Running loss: 0.89391\n",
      "Epoch: 0 | Iteration: 37074 | Classification loss: 0.40355 | Regression loss: 0.58291 | Running loss: 0.89515\n",
      "Epoch: 0 | Iteration: 37075 | Classification loss: 0.56067 | Regression loss: 0.46385 | Running loss: 0.89513\n",
      "Epoch: 0 | Iteration: 37076 | Classification loss: 0.48974 | Regression loss: 0.68927 | Running loss: 0.89504\n",
      "Epoch: 0 | Iteration: 37077 | Classification loss: 0.41934 | Regression loss: 0.61039 | Running loss: 0.89535\n",
      "Epoch: 0 | Iteration: 37078 | Classification loss: 0.13177 | Regression loss: 0.54955 | Running loss: 0.89479\n",
      "Epoch: 0 | Iteration: 37079 | Classification loss: 0.37589 | Regression loss: 0.63835 | Running loss: 0.89528\n",
      "Epoch: 0 | Iteration: 37080 | Classification loss: 0.37908 | Regression loss: 0.44304 | Running loss: 0.89565\n",
      "Epoch: 0 | Iteration: 37081 | Classification loss: 0.20159 | Regression loss: 0.41435 | Running loss: 0.89548\n",
      "Epoch: 0 | Iteration: 37082 | Classification loss: 0.43377 | Regression loss: 0.45548 | Running loss: 0.89549\n",
      "Epoch: 0 | Iteration: 37083 | Classification loss: 0.53114 | Regression loss: 0.62066 | Running loss: 0.89547\n",
      "Epoch: 0 | Iteration: 37084 | Classification loss: 0.24421 | Regression loss: 0.40035 | Running loss: 0.89486\n",
      "Epoch: 0 | Iteration: 37085 | Classification loss: 0.29995 | Regression loss: 0.34781 | Running loss: 0.89416\n",
      "Epoch: 0 | Iteration: 37086 | Classification loss: 0.13462 | Regression loss: 0.35783 | Running loss: 0.89321\n",
      "Epoch: 0 | Iteration: 37087 | Classification loss: 0.50857 | Regression loss: 0.60296 | Running loss: 0.89352\n",
      "Epoch: 0 | Iteration: 37088 | Classification loss: 0.38642 | Regression loss: 0.48925 | Running loss: 0.89327\n",
      "Epoch: 0 | Iteration: 37089 | Classification loss: 0.21270 | Regression loss: 0.43451 | Running loss: 0.89301\n",
      "Epoch: 0 | Iteration: 37090 | Classification loss: 0.24013 | Regression loss: 0.32593 | Running loss: 0.89242\n",
      "Epoch: 0 | Iteration: 37091 | Classification loss: 0.19007 | Regression loss: 0.32290 | Running loss: 0.89186\n",
      "Epoch: 0 | Iteration: 37092 | Classification loss: 0.31459 | Regression loss: 0.51962 | Running loss: 0.89218\n",
      "Epoch: 0 | Iteration: 37093 | Classification loss: 0.23824 | Regression loss: 0.37698 | Running loss: 0.89153\n",
      "Epoch: 0 | Iteration: 37094 | Classification loss: 0.44100 | Regression loss: 0.57360 | Running loss: 0.89175\n",
      "Epoch: 0 | Iteration: 37095 | Classification loss: 0.53188 | Regression loss: 0.56348 | Running loss: 0.89183\n",
      "Epoch: 0 | Iteration: 37096 | Classification loss: 0.60965 | Regression loss: 0.85250 | Running loss: 0.89363\n",
      "Epoch: 0 | Iteration: 37097 | Classification loss: 0.46348 | Regression loss: 0.63159 | Running loss: 0.89448\n",
      "Epoch: 0 | Iteration: 37098 | Classification loss: 0.16363 | Regression loss: 0.41307 | Running loss: 0.89413\n",
      "Epoch: 0 | Iteration: 37099 | Classification loss: 0.28267 | Regression loss: 0.28352 | Running loss: 0.89427\n",
      "Epoch: 0 | Iteration: 37100 | Classification loss: 0.28989 | Regression loss: 0.45591 | Running loss: 0.89374\n",
      "Epoch: 0 | Iteration: 37101 | Classification loss: 0.53331 | Regression loss: 0.71006 | Running loss: 0.89422\n",
      "Epoch: 0 | Iteration: 37102 | Classification loss: 0.23375 | Regression loss: 0.32240 | Running loss: 0.89418\n",
      "Epoch: 0 | Iteration: 37103 | Classification loss: 0.25048 | Regression loss: 0.50528 | Running loss: 0.89391\n",
      "Epoch: 0 | Iteration: 37104 | Classification loss: 0.43119 | Regression loss: 0.44146 | Running loss: 0.89414\n",
      "Epoch: 0 | Iteration: 37105 | Classification loss: 0.33491 | Regression loss: 0.42058 | Running loss: 0.89384\n",
      "Epoch: 0 | Iteration: 37106 | Classification loss: 0.47287 | Regression loss: 0.49032 | Running loss: 0.89359\n",
      "Epoch: 0 | Iteration: 37107 | Classification loss: 0.37732 | Regression loss: 0.43343 | Running loss: 0.89417\n",
      "Epoch: 0 | Iteration: 37108 | Classification loss: 0.34274 | Regression loss: 0.54057 | Running loss: 0.89425\n",
      "Epoch: 0 | Iteration: 37109 | Classification loss: 0.38120 | Regression loss: 0.59108 | Running loss: 0.89460\n",
      "Epoch: 0 | Iteration: 37110 | Classification loss: 0.38035 | Regression loss: 0.58464 | Running loss: 0.89511\n",
      "Epoch: 0 | Iteration: 37111 | Classification loss: 0.25574 | Regression loss: 0.27926 | Running loss: 0.89469\n",
      "Epoch: 0 | Iteration: 37112 | Classification loss: 0.34213 | Regression loss: 0.26816 | Running loss: 0.89404\n",
      "Epoch: 0 | Iteration: 37113 | Classification loss: 0.58622 | Regression loss: 0.63616 | Running loss: 0.89510\n",
      "Epoch: 0 | Iteration: 37114 | Classification loss: 0.43973 | Regression loss: 0.62039 | Running loss: 0.89573\n",
      "Epoch: 0 | Iteration: 37115 | Classification loss: 0.34999 | Regression loss: 0.41333 | Running loss: 0.89522\n",
      "Epoch: 0 | Iteration: 37116 | Classification loss: 0.31375 | Regression loss: 0.45093 | Running loss: 0.89471\n",
      "Epoch: 0 | Iteration: 37117 | Classification loss: 0.22329 | Regression loss: 0.37914 | Running loss: 0.89475\n",
      "Epoch: 0 | Iteration: 37118 | Classification loss: 0.43606 | Regression loss: 0.51529 | Running loss: 0.89496\n",
      "Epoch: 0 | Iteration: 37119 | Classification loss: 0.17076 | Regression loss: 0.42557 | Running loss: 0.89455\n",
      "Epoch: 0 | Iteration: 37120 | Classification loss: 0.32722 | Regression loss: 0.45465 | Running loss: 0.89335\n",
      "Epoch: 0 | Iteration: 37121 | Classification loss: 0.40882 | Regression loss: 0.56429 | Running loss: 0.89304\n",
      "Epoch: 0 | Iteration: 37122 | Classification loss: 0.28443 | Regression loss: 0.40664 | Running loss: 0.89264\n",
      "Epoch: 0 | Iteration: 37123 | Classification loss: 0.31877 | Regression loss: 0.41106 | Running loss: 0.89170\n",
      "Epoch: 0 | Iteration: 37124 | Classification loss: 0.20975 | Regression loss: 0.20169 | Running loss: 0.89078\n",
      "Epoch: 0 | Iteration: 37125 | Classification loss: 0.35124 | Regression loss: 0.51336 | Running loss: 0.89096\n",
      "Epoch: 0 | Iteration: 37126 | Classification loss: 0.29153 | Regression loss: 0.48297 | Running loss: 0.89093\n",
      "Epoch: 0 | Iteration: 37127 | Classification loss: 0.17299 | Regression loss: 0.12453 | Running loss: 0.88983\n",
      "Epoch: 0 | Iteration: 37128 | Classification loss: 0.36271 | Regression loss: 0.46105 | Running loss: 0.89019\n",
      "Epoch: 0 | Iteration: 37129 | Classification loss: 0.38638 | Regression loss: 0.59302 | Running loss: 0.89100\n",
      "Epoch: 0 | Iteration: 37130 | Classification loss: 0.34156 | Regression loss: 0.64294 | Running loss: 0.89173\n",
      "Epoch: 0 | Iteration: 37131 | Classification loss: 0.28423 | Regression loss: 0.36707 | Running loss: 0.89082\n",
      "Epoch: 0 | Iteration: 37132 | Classification loss: 0.18540 | Regression loss: 0.00000 | Running loss: 0.88826\n",
      "Epoch: 0 | Iteration: 37133 | Classification loss: 0.40334 | Regression loss: 0.16622 | Running loss: 0.88808\n",
      "Epoch: 0 | Iteration: 37134 | Classification loss: 0.30461 | Regression loss: 0.48341 | Running loss: 0.88731\n",
      "Epoch: 0 | Iteration: 37135 | Classification loss: 0.45177 | Regression loss: 0.34500 | Running loss: 0.88670\n",
      "Epoch: 0 | Iteration: 37136 | Classification loss: 0.46381 | Regression loss: 0.68891 | Running loss: 0.88720\n",
      "Epoch: 0 | Iteration: 37137 | Classification loss: 0.51411 | Regression loss: 0.38464 | Running loss: 0.88693\n",
      "Epoch: 0 | Iteration: 37138 | Classification loss: 0.45329 | Regression loss: 0.31605 | Running loss: 0.88714\n",
      "Epoch: 0 | Iteration: 37139 | Classification loss: 0.40038 | Regression loss: 0.80431 | Running loss: 0.88781\n",
      "Epoch: 0 | Iteration: 37140 | Classification loss: 0.51006 | Regression loss: 0.62938 | Running loss: 0.88788\n",
      "Epoch: 0 | Iteration: 37141 | Classification loss: 0.19608 | Regression loss: 0.37872 | Running loss: 0.88648\n",
      "Epoch: 0 | Iteration: 37142 | Classification loss: 0.16417 | Regression loss: 0.33746 | Running loss: 0.88581\n",
      "Epoch: 0 | Iteration: 37143 | Classification loss: 0.43597 | Regression loss: 0.41713 | Running loss: 0.88555\n",
      "Epoch: 0 | Iteration: 37144 | Classification loss: 0.25889 | Regression loss: 0.43415 | Running loss: 0.88522\n",
      "Epoch: 0 | Iteration: 37145 | Classification loss: 0.12903 | Regression loss: 0.54796 | Running loss: 0.88468\n",
      "Epoch: 0 | Iteration: 37146 | Classification loss: 0.46453 | Regression loss: 0.45495 | Running loss: 0.88535\n",
      "Epoch: 0 | Iteration: 37147 | Classification loss: 0.46832 | Regression loss: 0.53376 | Running loss: 0.88569\n",
      "Epoch: 0 | Iteration: 37148 | Classification loss: 0.61377 | Regression loss: 0.73923 | Running loss: 0.88668\n",
      "Epoch: 0 | Iteration: 37149 | Classification loss: 0.42020 | Regression loss: 0.62899 | Running loss: 0.88747\n",
      "Epoch: 0 | Iteration: 37150 | Classification loss: 0.41720 | Regression loss: 0.33789 | Running loss: 0.88720\n",
      "Epoch: 0 | Iteration: 37151 | Classification loss: 0.20407 | Regression loss: 0.37451 | Running loss: 0.88678\n",
      "Epoch: 0 | Iteration: 37152 | Classification loss: 0.38008 | Regression loss: 0.49202 | Running loss: 0.88651\n",
      "Epoch: 0 | Iteration: 37153 | Classification loss: 0.32595 | Regression loss: 0.16327 | Running loss: 0.88591\n",
      "Epoch: 0 | Iteration: 37154 | Classification loss: 0.19356 | Regression loss: 0.23996 | Running loss: 0.88470\n",
      "Epoch: 0 | Iteration: 37155 | Classification loss: 0.15349 | Regression loss: 0.28462 | Running loss: 0.88412\n",
      "Epoch: 0 | Iteration: 37156 | Classification loss: 0.39493 | Regression loss: 0.51867 | Running loss: 0.88424\n",
      "Epoch: 0 | Iteration: 37157 | Classification loss: 0.32309 | Regression loss: 0.41715 | Running loss: 0.88460\n",
      "Epoch: 0 | Iteration: 37158 | Classification loss: 0.35407 | Regression loss: 0.55346 | Running loss: 0.88517\n",
      "Epoch: 0 | Iteration: 37159 | Classification loss: 0.26711 | Regression loss: 0.51703 | Running loss: 0.88464\n",
      "Epoch: 0 | Iteration: 37160 | Classification loss: 0.40550 | Regression loss: 0.55506 | Running loss: 0.88388\n",
      "Epoch: 0 | Iteration: 37161 | Classification loss: 0.36188 | Regression loss: 0.54529 | Running loss: 0.88418\n",
      "Epoch: 0 | Iteration: 37162 | Classification loss: 0.44040 | Regression loss: 0.62336 | Running loss: 0.88408\n",
      "Epoch: 0 | Iteration: 37163 | Classification loss: 0.20680 | Regression loss: 0.39977 | Running loss: 0.88319\n",
      "Epoch: 0 | Iteration: 37164 | Classification loss: 0.33542 | Regression loss: 0.63047 | Running loss: 0.88264\n",
      "Epoch: 0 | Iteration: 37165 | Classification loss: 0.25694 | Regression loss: 0.45262 | Running loss: 0.88227\n",
      "Epoch: 0 | Iteration: 37166 | Classification loss: 0.37555 | Regression loss: 0.42372 | Running loss: 0.88241\n",
      "Epoch: 0 | Iteration: 37167 | Classification loss: 0.54190 | Regression loss: 0.49658 | Running loss: 0.88276\n",
      "Epoch: 0 | Iteration: 37168 | Classification loss: 0.46346 | Regression loss: 0.43444 | Running loss: 0.88296\n",
      "Epoch: 0 | Iteration: 37169 | Classification loss: 0.59172 | Regression loss: 0.58062 | Running loss: 0.88335\n",
      "Epoch: 0 | Iteration: 37170 | Classification loss: 0.39194 | Regression loss: 0.48694 | Running loss: 0.88257\n",
      "Epoch: 0 | Iteration: 37171 | Classification loss: 0.22698 | Regression loss: 0.38505 | Running loss: 0.88196\n",
      "Epoch: 0 | Iteration: 37172 | Classification loss: 0.26963 | Regression loss: 0.41816 | Running loss: 0.88173\n",
      "Epoch: 0 | Iteration: 37173 | Classification loss: 0.38051 | Regression loss: 0.48595 | Running loss: 0.88233\n",
      "Epoch: 0 | Iteration: 37174 | Classification loss: 0.60709 | Regression loss: 0.61553 | Running loss: 0.88392\n",
      "Epoch: 0 | Iteration: 37175 | Classification loss: 0.49800 | Regression loss: 0.51362 | Running loss: 0.88517\n",
      "Epoch: 0 | Iteration: 37176 | Classification loss: 0.55190 | Regression loss: 0.69748 | Running loss: 0.88632\n",
      "Epoch: 0 | Iteration: 37177 | Classification loss: 0.37441 | Regression loss: 0.61259 | Running loss: 0.88653\n",
      "Epoch: 0 | Iteration: 37178 | Classification loss: 0.32994 | Regression loss: 0.42631 | Running loss: 0.88665\n",
      "Epoch: 0 | Iteration: 37179 | Classification loss: 0.40570 | Regression loss: 0.49561 | Running loss: 0.88618\n",
      "Epoch: 0 | Iteration: 37180 | Classification loss: 0.12690 | Regression loss: 0.38489 | Running loss: 0.88663\n",
      "Epoch: 0 | Iteration: 37181 | Classification loss: 0.24558 | Regression loss: 0.42173 | Running loss: 0.88540\n",
      "Epoch: 0 | Iteration: 37182 | Classification loss: 0.35190 | Regression loss: 0.64271 | Running loss: 0.88489\n",
      "Epoch: 0 | Iteration: 37183 | Classification loss: 0.41844 | Regression loss: 0.53257 | Running loss: 0.88475\n",
      "Epoch: 0 | Iteration: 37184 | Classification loss: 0.12480 | Regression loss: 0.12868 | Running loss: 0.88343\n",
      "Epoch: 0 | Iteration: 37185 | Classification loss: 0.26822 | Regression loss: 0.50988 | Running loss: 0.88347\n",
      "Epoch: 0 | Iteration: 37186 | Classification loss: 0.46771 | Regression loss: 0.53314 | Running loss: 0.88419\n",
      "Epoch: 0 | Iteration: 37187 | Classification loss: 0.26687 | Regression loss: 0.63643 | Running loss: 0.88488\n",
      "Epoch: 0 | Iteration: 37188 | Classification loss: 0.25064 | Regression loss: 0.44524 | Running loss: 0.88513\n",
      "Epoch: 0 | Iteration: 37189 | Classification loss: 0.23814 | Regression loss: 0.43196 | Running loss: 0.88430\n",
      "Epoch: 0 | Iteration: 37190 | Classification loss: 0.73362 | Regression loss: 0.76260 | Running loss: 0.88565\n",
      "Epoch: 0 | Iteration: 37191 | Classification loss: 0.47881 | Regression loss: 0.46499 | Running loss: 0.88536\n",
      "Epoch: 0 | Iteration: 37192 | Classification loss: 0.61080 | Regression loss: 0.68967 | Running loss: 0.88622\n",
      "Epoch: 0 | Iteration: 37193 | Classification loss: 0.55950 | Regression loss: 0.53242 | Running loss: 0.88694\n",
      "Epoch: 0 | Iteration: 37194 | Classification loss: 0.40697 | Regression loss: 0.55299 | Running loss: 0.88738\n",
      "Epoch: 0 | Iteration: 37195 | Classification loss: 0.37600 | Regression loss: 0.50108 | Running loss: 0.88729\n",
      "Epoch: 0 | Iteration: 37196 | Classification loss: 0.38242 | Regression loss: 0.41526 | Running loss: 0.88719\n",
      "Epoch: 0 | Iteration: 37197 | Classification loss: 0.44234 | Regression loss: 0.67704 | Running loss: 0.88812\n",
      "Epoch: 0 | Iteration: 37198 | Classification loss: 0.42432 | Regression loss: 0.53531 | Running loss: 0.88916\n",
      "Epoch: 0 | Iteration: 37199 | Classification loss: 0.38057 | Regression loss: 0.67606 | Running loss: 0.88928\n",
      "Epoch: 0 | Iteration: 37200 | Classification loss: 0.44719 | Regression loss: 0.62307 | Running loss: 0.88923\n",
      "Epoch: 0 | Iteration: 37201 | Classification loss: 0.32250 | Regression loss: 0.50450 | Running loss: 0.89013\n",
      "Epoch: 0 | Iteration: 37202 | Classification loss: 0.18742 | Regression loss: 0.21584 | Running loss: 0.88950\n",
      "Epoch: 0 | Iteration: 37203 | Classification loss: 0.43428 | Regression loss: 0.72684 | Running loss: 0.89070\n",
      "Epoch: 0 | Iteration: 37204 | Classification loss: 0.51099 | Regression loss: 0.36787 | Running loss: 0.89035\n",
      "Epoch: 0 | Iteration: 37205 | Classification loss: 0.26179 | Regression loss: 0.38008 | Running loss: 0.89014\n",
      "Epoch: 0 | Iteration: 37206 | Classification loss: 0.62355 | Regression loss: 0.40892 | Running loss: 0.89013\n",
      "Epoch: 0 | Iteration: 37207 | Classification loss: 0.39309 | Regression loss: 0.51933 | Running loss: 0.88982\n",
      "Epoch: 0 | Iteration: 37208 | Classification loss: 0.40007 | Regression loss: 0.64662 | Running loss: 0.88989\n",
      "Epoch: 0 | Iteration: 37209 | Classification loss: 0.25698 | Regression loss: 0.49505 | Running loss: 0.88939\n",
      "Epoch: 0 | Iteration: 37210 | Classification loss: 0.38592 | Regression loss: 0.35956 | Running loss: 0.88988\n",
      "Epoch: 0 | Iteration: 37211 | Classification loss: 0.48865 | Regression loss: 0.39045 | Running loss: 0.89028\n",
      "Epoch: 0 | Iteration: 37212 | Classification loss: 0.53286 | Regression loss: 0.38823 | Running loss: 0.89039\n",
      "Epoch: 0 | Iteration: 37213 | Classification loss: 0.41277 | Regression loss: 0.46445 | Running loss: 0.89072\n",
      "Epoch: 0 | Iteration: 37214 | Classification loss: 0.53548 | Regression loss: 0.50244 | Running loss: 0.89015\n",
      "Epoch: 0 | Iteration: 37215 | Classification loss: 0.25656 | Regression loss: 0.46242 | Running loss: 0.88952\n",
      "Epoch: 0 | Iteration: 37216 | Classification loss: 0.36904 | Regression loss: 0.47024 | Running loss: 0.88986\n",
      "Epoch: 0 | Iteration: 37217 | Classification loss: 0.30603 | Regression loss: 0.43677 | Running loss: 0.88991\n",
      "Epoch: 0 | Iteration: 37218 | Classification loss: 0.45515 | Regression loss: 0.40633 | Running loss: 0.88954\n",
      "Epoch: 0 | Iteration: 37219 | Classification loss: 0.38442 | Regression loss: 0.58082 | Running loss: 0.89009\n",
      "Epoch: 0 | Iteration: 37220 | Classification loss: 0.14129 | Regression loss: 0.35836 | Running loss: 0.88981\n",
      "Epoch: 0 | Iteration: 37221 | Classification loss: 0.38938 | Regression loss: 0.56254 | Running loss: 0.89048\n",
      "Epoch: 0 | Iteration: 37222 | Classification loss: 0.20553 | Regression loss: 0.33425 | Running loss: 0.88984\n",
      "Epoch: 0 | Iteration: 37223 | Classification loss: 0.39781 | Regression loss: 0.53910 | Running loss: 0.88955\n",
      "Epoch: 0 | Iteration: 37224 | Classification loss: 0.28887 | Regression loss: 0.30265 | Running loss: 0.88886\n",
      "Epoch: 0 | Iteration: 37225 | Classification loss: 0.29955 | Regression loss: 0.33963 | Running loss: 0.88877\n",
      "Epoch: 0 | Iteration: 37226 | Classification loss: 0.27292 | Regression loss: 0.32305 | Running loss: 0.88837\n",
      "Epoch: 0 | Iteration: 37227 | Classification loss: 0.29082 | Regression loss: 0.53552 | Running loss: 0.88927\n",
      "Epoch: 0 | Iteration: 37228 | Classification loss: 0.46351 | Regression loss: 0.60600 | Running loss: 0.88976\n",
      "Epoch: 0 | Iteration: 37229 | Classification loss: 0.42692 | Regression loss: 0.40805 | Running loss: 0.88972\n",
      "Epoch: 0 | Iteration: 37230 | Classification loss: 0.20904 | Regression loss: 0.35330 | Running loss: 0.88900\n",
      "Epoch: 0 | Iteration: 37231 | Classification loss: 0.32132 | Regression loss: 0.55443 | Running loss: 0.88928\n",
      "Epoch: 0 | Iteration: 37232 | Classification loss: 0.19184 | Regression loss: 0.31003 | Running loss: 0.88936\n",
      "Epoch: 0 | Iteration: 37233 | Classification loss: 0.32105 | Regression loss: 0.42971 | Running loss: 0.89034\n",
      "Epoch: 0 | Iteration: 37234 | Classification loss: 0.52065 | Regression loss: 0.43427 | Running loss: 0.88663\n",
      "Epoch: 0 | Iteration: 37235 | Classification loss: 0.50774 | Regression loss: 0.24579 | Running loss: 0.88648\n",
      "Epoch: 0 | Iteration: 37236 | Classification loss: 0.61604 | Regression loss: 0.59701 | Running loss: 0.88753\n",
      "Epoch: 0 | Iteration: 37237 | Classification loss: 0.51325 | Regression loss: 0.46083 | Running loss: 0.88783\n",
      "Epoch: 0 | Iteration: 37238 | Classification loss: 0.20128 | Regression loss: 0.48135 | Running loss: 0.88771\n",
      "Epoch: 0 | Iteration: 37239 | Classification loss: 0.47224 | Regression loss: 0.71162 | Running loss: 0.88778\n",
      "Epoch: 0 | Iteration: 37240 | Classification loss: 0.31687 | Regression loss: 0.53008 | Running loss: 0.88761\n",
      "Epoch: 0 | Iteration: 37241 | Classification loss: 0.28947 | Regression loss: 0.58284 | Running loss: 0.88766\n",
      "Epoch: 0 | Iteration: 37242 | Classification loss: 0.28419 | Regression loss: 0.55556 | Running loss: 0.88790\n",
      "Epoch: 0 | Iteration: 37243 | Classification loss: 0.29427 | Regression loss: 0.28905 | Running loss: 0.88731\n",
      "Epoch: 0 | Iteration: 37244 | Classification loss: 0.45189 | Regression loss: 0.53322 | Running loss: 0.88766\n",
      "Epoch: 0 | Iteration: 37245 | Classification loss: 0.33682 | Regression loss: 0.56522 | Running loss: 0.88791\n",
      "Epoch: 0 | Iteration: 37246 | Classification loss: 0.28254 | Regression loss: 0.48464 | Running loss: 0.88806\n",
      "Epoch: 0 | Iteration: 37247 | Classification loss: 0.56159 | Regression loss: 0.51558 | Running loss: 0.88882\n",
      "Epoch: 0 | Iteration: 37248 | Classification loss: 0.28497 | Regression loss: 0.33550 | Running loss: 0.88922\n",
      "Epoch: 0 | Iteration: 37249 | Classification loss: 0.32558 | Regression loss: 0.54813 | Running loss: 0.88893\n",
      "Epoch: 0 | Iteration: 37250 | Classification loss: 0.37222 | Regression loss: 0.58637 | Running loss: 0.88924\n",
      "Epoch: 0 | Iteration: 37251 | Classification loss: 0.37836 | Regression loss: 0.32783 | Running loss: 0.88862\n",
      "Epoch: 0 | Iteration: 37252 | Classification loss: 0.29086 | Regression loss: 0.30386 | Running loss: 0.88790\n",
      "Epoch: 0 | Iteration: 37253 | Classification loss: 1.05437 | Regression loss: 0.31492 | Running loss: 0.88854\n",
      "Epoch: 0 | Iteration: 37254 | Classification loss: 0.74968 | Regression loss: 0.64465 | Running loss: 0.89068\n",
      "Epoch: 0 | Iteration: 37255 | Classification loss: 0.36489 | Regression loss: 0.60568 | Running loss: 0.89059\n",
      "Epoch: 0 | Iteration: 37256 | Classification loss: 0.51197 | Regression loss: 0.37730 | Running loss: 0.89063\n",
      "Epoch: 0 | Iteration: 37257 | Classification loss: 0.32294 | Regression loss: 0.53007 | Running loss: 0.89088\n",
      "Epoch: 0 | Iteration: 37258 | Classification loss: 0.43606 | Regression loss: 0.63807 | Running loss: 0.89104\n",
      "Epoch: 0 | Iteration: 37259 | Classification loss: 0.30552 | Regression loss: 0.59318 | Running loss: 0.89061\n",
      "Epoch: 0 | Iteration: 37260 | Classification loss: 0.23276 | Regression loss: 0.51159 | Running loss: 0.89032\n",
      "Epoch: 0 | Iteration: 37261 | Classification loss: 0.39315 | Regression loss: 0.62685 | Running loss: 0.89038\n",
      "Epoch: 0 | Iteration: 37262 | Classification loss: 0.41309 | Regression loss: 0.56751 | Running loss: 0.89087\n",
      "Epoch: 0 | Iteration: 37263 | Classification loss: 0.22831 | Regression loss: 0.37248 | Running loss: 0.88976\n",
      "Epoch: 0 | Iteration: 37264 | Classification loss: 0.36721 | Regression loss: 0.59326 | Running loss: 0.88977\n",
      "Epoch: 0 | Iteration: 37265 | Classification loss: 0.55130 | Regression loss: 0.67751 | Running loss: 0.89037\n",
      "Epoch: 0 | Iteration: 37266 | Classification loss: 0.18982 | Regression loss: 0.22008 | Running loss: 0.88916\n",
      "Epoch: 0 | Iteration: 37267 | Classification loss: 0.25790 | Regression loss: 0.26589 | Running loss: 0.88890\n",
      "Epoch: 0 | Iteration: 37268 | Classification loss: 0.33791 | Regression loss: 0.61631 | Running loss: 0.88833\n",
      "Epoch: 0 | Iteration: 37269 | Classification loss: 0.38189 | Regression loss: 0.52789 | Running loss: 0.88842\n",
      "Epoch: 0 | Iteration: 37270 | Classification loss: 0.34445 | Regression loss: 0.55862 | Running loss: 0.88859\n",
      "Epoch: 0 | Iteration: 37271 | Classification loss: 0.47347 | Regression loss: 0.58094 | Running loss: 0.88961\n",
      "Epoch: 0 | Iteration: 37272 | Classification loss: 0.24727 | Regression loss: 0.35658 | Running loss: 0.88909\n",
      "Epoch: 0 | Iteration: 37273 | Classification loss: 0.40351 | Regression loss: 0.53900 | Running loss: 0.88936\n",
      "Epoch: 0 | Iteration: 37274 | Classification loss: 0.20472 | Regression loss: 0.15746 | Running loss: 0.88811\n",
      "Epoch: 0 | Iteration: 37275 | Classification loss: 0.47743 | Regression loss: 0.60879 | Running loss: 0.88840\n",
      "Epoch: 0 | Iteration: 37276 | Classification loss: 0.43469 | Regression loss: 0.46226 | Running loss: 0.88851\n",
      "Epoch: 0 | Iteration: 37277 | Classification loss: 0.37001 | Regression loss: 0.56169 | Running loss: 0.88888\n",
      "Epoch: 0 | Iteration: 37278 | Classification loss: 0.53368 | Regression loss: 0.49105 | Running loss: 0.88868\n",
      "Epoch: 0 | Iteration: 37279 | Classification loss: 0.56982 | Regression loss: 0.52052 | Running loss: 0.88882\n",
      "Epoch: 0 | Iteration: 37280 | Classification loss: 0.19442 | Regression loss: 0.30625 | Running loss: 0.88878\n",
      "Epoch: 0 | Iteration: 37281 | Classification loss: 0.12363 | Regression loss: 0.18209 | Running loss: 0.88776\n",
      "Epoch: 0 | Iteration: 37282 | Classification loss: 0.47130 | Regression loss: 0.43957 | Running loss: 0.88795\n",
      "Epoch: 0 | Iteration: 37283 | Classification loss: 0.26370 | Regression loss: 0.40647 | Running loss: 0.88793\n",
      "Epoch: 0 | Iteration: 37284 | Classification loss: 0.43459 | Regression loss: 0.57543 | Running loss: 0.88796\n",
      "Epoch: 0 | Iteration: 37285 | Classification loss: 0.23375 | Regression loss: 0.41231 | Running loss: 0.88717\n",
      "Epoch: 0 | Iteration: 37286 | Classification loss: 0.45204 | Regression loss: 0.63729 | Running loss: 0.88793\n",
      "Epoch: 0 | Iteration: 37287 | Classification loss: 0.16728 | Regression loss: 0.49991 | Running loss: 0.88725\n",
      "Epoch: 0 | Iteration: 37288 | Classification loss: 0.26990 | Regression loss: 0.27737 | Running loss: 0.88645\n",
      "Epoch: 0 | Iteration: 37289 | Classification loss: 0.42145 | Regression loss: 0.72113 | Running loss: 0.88659\n",
      "Epoch: 0 | Iteration: 37290 | Classification loss: 0.23055 | Regression loss: 0.30672 | Running loss: 0.88532\n",
      "Epoch: 0 | Iteration: 37291 | Classification loss: 0.45033 | Regression loss: 0.55474 | Running loss: 0.88519\n",
      "Epoch: 0 | Iteration: 37292 | Classification loss: 0.59721 | Regression loss: 0.55947 | Running loss: 0.88629\n",
      "Epoch: 0 | Iteration: 37293 | Classification loss: 0.30195 | Regression loss: 0.40214 | Running loss: 0.88571\n",
      "Epoch: 0 | Iteration: 37294 | Classification loss: 0.40963 | Regression loss: 0.57521 | Running loss: 0.88578\n",
      "Epoch: 0 | Iteration: 37295 | Classification loss: 0.28917 | Regression loss: 0.24954 | Running loss: 0.88491\n",
      "Epoch: 0 | Iteration: 37296 | Classification loss: 0.21535 | Regression loss: 0.42679 | Running loss: 0.88431\n",
      "Epoch: 0 | Iteration: 37297 | Classification loss: 0.20339 | Regression loss: 0.55134 | Running loss: 0.88414\n",
      "Epoch: 0 | Iteration: 37298 | Classification loss: 0.19347 | Regression loss: 0.44226 | Running loss: 0.88325\n",
      "Epoch: 0 | Iteration: 37299 | Classification loss: 0.21945 | Regression loss: 0.28642 | Running loss: 0.88239\n",
      "Epoch: 0 | Iteration: 37300 | Classification loss: 0.33357 | Regression loss: 0.37809 | Running loss: 0.88146\n",
      "Epoch: 0 | Iteration: 37301 | Classification loss: 0.26821 | Regression loss: 0.45941 | Running loss: 0.88176\n",
      "Epoch: 0 | Iteration: 37302 | Classification loss: 0.14534 | Regression loss: 0.30023 | Running loss: 0.88034\n",
      "Epoch: 0 | Iteration: 37303 | Classification loss: 0.68258 | Regression loss: 0.86100 | Running loss: 0.88198\n",
      "Epoch: 0 | Iteration: 37304 | Classification loss: 0.26501 | Regression loss: 0.55283 | Running loss: 0.88181\n",
      "Epoch: 0 | Iteration: 37305 | Classification loss: 0.18235 | Regression loss: 0.38752 | Running loss: 0.88111\n",
      "Epoch: 0 | Iteration: 37306 | Classification loss: 0.43996 | Regression loss: 0.60007 | Running loss: 0.88064\n",
      "Epoch: 0 | Iteration: 37307 | Classification loss: 0.52502 | Regression loss: 0.55904 | Running loss: 0.88023\n",
      "Epoch: 0 | Iteration: 37308 | Classification loss: 0.36773 | Regression loss: 0.40811 | Running loss: 0.88038\n",
      "Epoch: 0 | Iteration: 37309 | Classification loss: 0.34426 | Regression loss: 0.54629 | Running loss: 0.87996\n",
      "Epoch: 0 | Iteration: 37310 | Classification loss: 0.22768 | Regression loss: 0.49425 | Running loss: 0.87919\n",
      "Epoch: 0 | Iteration: 37311 | Classification loss: 0.49169 | Regression loss: 0.40244 | Running loss: 0.87922\n",
      "Epoch: 0 | Iteration: 37312 | Classification loss: 0.24755 | Regression loss: 0.36462 | Running loss: 0.87771\n",
      "Epoch: 0 | Iteration: 37313 | Classification loss: 0.27013 | Regression loss: 0.39063 | Running loss: 0.87674\n",
      "Epoch: 0 | Iteration: 37314 | Classification loss: 0.42901 | Regression loss: 0.72135 | Running loss: 0.87744\n",
      "Epoch: 0 | Iteration: 37315 | Classification loss: 0.24356 | Regression loss: 0.45865 | Running loss: 0.87641\n",
      "Epoch: 0 | Iteration: 37316 | Classification loss: 0.33222 | Regression loss: 0.65537 | Running loss: 0.87644\n",
      "Epoch: 0 | Iteration: 37317 | Classification loss: 0.22842 | Regression loss: 0.60202 | Running loss: 0.87660\n",
      "Epoch: 0 | Iteration: 37318 | Classification loss: 0.23242 | Regression loss: 0.34333 | Running loss: 0.87521\n",
      "Epoch: 0 | Iteration: 37319 | Classification loss: 0.21629 | Regression loss: 0.34018 | Running loss: 0.87470\n",
      "Epoch: 0 | Iteration: 37320 | Classification loss: 0.41168 | Regression loss: 0.59057 | Running loss: 0.87534\n",
      "Epoch: 0 | Iteration: 37321 | Classification loss: 0.43241 | Regression loss: 0.43648 | Running loss: 0.87530\n",
      "Epoch: 0 | Iteration: 37322 | Classification loss: 0.40399 | Regression loss: 0.47553 | Running loss: 0.87545\n",
      "Epoch: 0 | Iteration: 37323 | Classification loss: 0.34172 | Regression loss: 0.62435 | Running loss: 0.87537\n",
      "Epoch: 0 | Iteration: 37324 | Classification loss: 0.34735 | Regression loss: 0.55767 | Running loss: 0.87542\n",
      "Epoch: 0 | Iteration: 37325 | Classification loss: 0.86097 | Regression loss: 0.48663 | Running loss: 0.87649\n",
      "Epoch: 0 | Iteration: 37326 | Classification loss: 0.41042 | Regression loss: 0.53257 | Running loss: 0.87629\n",
      "Epoch: 0 | Iteration: 37327 | Classification loss: 0.28242 | Regression loss: 0.37351 | Running loss: 0.87609\n",
      "Epoch: 0 | Iteration: 37328 | Classification loss: 0.29994 | Regression loss: 0.49585 | Running loss: 0.87632\n",
      "Epoch: 0 | Iteration: 37329 | Classification loss: 0.55806 | Regression loss: 0.56185 | Running loss: 0.87654\n",
      "Epoch: 0 | Iteration: 37330 | Classification loss: 0.32916 | Regression loss: 0.53693 | Running loss: 0.87726\n",
      "Epoch: 0 | Iteration: 37331 | Classification loss: 0.27137 | Regression loss: 0.58718 | Running loss: 0.87671\n",
      "Epoch: 0 | Iteration: 37332 | Classification loss: 0.50745 | Regression loss: 0.59212 | Running loss: 0.87702\n",
      "Epoch: 0 | Iteration: 37333 | Classification loss: 0.41206 | Regression loss: 0.61005 | Running loss: 0.87758\n",
      "Epoch: 0 | Iteration: 37334 | Classification loss: 0.37651 | Regression loss: 0.49700 | Running loss: 0.87728\n",
      "Epoch: 0 | Iteration: 37335 | Classification loss: 0.12260 | Regression loss: 0.29132 | Running loss: 0.87600\n",
      "Epoch: 0 | Iteration: 37336 | Classification loss: 0.33891 | Regression loss: 0.60315 | Running loss: 0.87647\n",
      "Epoch: 0 | Iteration: 37337 | Classification loss: 0.50657 | Regression loss: 0.58332 | Running loss: 0.87711\n",
      "Epoch: 0 | Iteration: 37338 | Classification loss: 0.50522 | Regression loss: 0.57632 | Running loss: 0.87748\n",
      "Epoch: 0 | Iteration: 37339 | Classification loss: 0.21371 | Regression loss: 0.37458 | Running loss: 0.87622\n",
      "Epoch: 0 | Iteration: 37340 | Classification loss: 0.45657 | Regression loss: 0.73127 | Running loss: 0.87692\n",
      "Epoch: 0 | Iteration: 37341 | Classification loss: 0.34223 | Regression loss: 0.48387 | Running loss: 0.87689\n",
      "Epoch: 0 | Iteration: 37342 | Classification loss: 0.41171 | Regression loss: 0.56691 | Running loss: 0.87789\n",
      "Epoch: 0 | Iteration: 37343 | Classification loss: 0.25167 | Regression loss: 0.17335 | Running loss: 0.87734\n",
      "Epoch: 0 | Iteration: 37344 | Classification loss: 0.24470 | Regression loss: 0.37049 | Running loss: 0.87720\n",
      "Epoch: 0 | Iteration: 37345 | Classification loss: 0.52115 | Regression loss: 0.29003 | Running loss: 0.87730\n",
      "Epoch: 0 | Iteration: 37346 | Classification loss: 0.35331 | Regression loss: 0.44878 | Running loss: 0.87714\n",
      "Epoch: 0 | Iteration: 37347 | Classification loss: 0.65322 | Regression loss: 0.39619 | Running loss: 0.87725\n",
      "Epoch: 0 | Iteration: 37348 | Classification loss: 0.25058 | Regression loss: 0.36133 | Running loss: 0.87688\n",
      "Epoch: 0 | Iteration: 37349 | Classification loss: 0.36091 | Regression loss: 0.46617 | Running loss: 0.87731\n",
      "Epoch: 0 | Iteration: 37350 | Classification loss: 0.54022 | Regression loss: 0.35587 | Running loss: 0.87720\n",
      "Epoch: 0 | Iteration: 37351 | Classification loss: 0.34596 | Regression loss: 0.32672 | Running loss: 0.87680\n",
      "Epoch: 0 | Iteration: 37352 | Classification loss: 0.42117 | Regression loss: 0.55181 | Running loss: 0.87771\n",
      "Epoch: 0 | Iteration: 37353 | Classification loss: 0.36516 | Regression loss: 0.44773 | Running loss: 0.87738\n",
      "Epoch: 0 | Iteration: 37354 | Classification loss: 0.42641 | Regression loss: 0.51617 | Running loss: 0.87781\n",
      "Epoch: 0 | Iteration: 37355 | Classification loss: 0.42583 | Regression loss: 0.64668 | Running loss: 0.87831\n",
      "Epoch: 0 | Iteration: 37356 | Classification loss: 0.23167 | Regression loss: 0.55308 | Running loss: 0.87886\n",
      "Epoch: 0 | Iteration: 37357 | Classification loss: 0.30504 | Regression loss: 0.53840 | Running loss: 0.87865\n",
      "Epoch: 0 | Iteration: 37358 | Classification loss: 0.42271 | Regression loss: 0.55336 | Running loss: 0.87791\n",
      "Epoch: 0 | Iteration: 37359 | Classification loss: 0.54182 | Regression loss: 0.53608 | Running loss: 0.87815\n",
      "Epoch: 0 | Iteration: 37360 | Classification loss: 0.56543 | Regression loss: 0.51051 | Running loss: 0.87913\n",
      "Epoch: 0 | Iteration: 37361 | Classification loss: 0.41192 | Regression loss: 0.58292 | Running loss: 0.87918\n",
      "Epoch: 0 | Iteration: 37362 | Classification loss: 1.41398 | Regression loss: 0.22285 | Running loss: 0.88112\n",
      "Epoch: 0 | Iteration: 37363 | Classification loss: 0.65987 | Regression loss: 0.40491 | Running loss: 0.88153\n",
      "Epoch: 0 | Iteration: 37364 | Classification loss: 0.39925 | Regression loss: 0.50495 | Running loss: 0.88121\n",
      "Epoch: 0 | Iteration: 37365 | Classification loss: 0.22887 | Regression loss: 0.31762 | Running loss: 0.88036\n",
      "Epoch: 0 | Iteration: 37366 | Classification loss: 0.37385 | Regression loss: 0.62330 | Running loss: 0.88043\n",
      "Epoch: 0 | Iteration: 37367 | Classification loss: 0.20763 | Regression loss: 0.22158 | Running loss: 0.87959\n",
      "Epoch: 0 | Iteration: 37368 | Classification loss: 0.31060 | Regression loss: 0.45063 | Running loss: 0.87937\n",
      "Epoch: 0 | Iteration: 37369 | Classification loss: 0.33216 | Regression loss: 0.56515 | Running loss: 0.87892\n",
      "Epoch: 0 | Iteration: 37370 | Classification loss: 0.33413 | Regression loss: 0.52255 | Running loss: 0.87941\n",
      "Epoch: 0 | Iteration: 37371 | Classification loss: 0.42266 | Regression loss: 0.67036 | Running loss: 0.87906\n",
      "Epoch: 0 | Iteration: 37372 | Classification loss: 0.36690 | Regression loss: 0.51178 | Running loss: 0.87876\n",
      "Epoch: 0 | Iteration: 37373 | Classification loss: 0.09374 | Regression loss: 0.24092 | Running loss: 0.87866\n",
      "Epoch: 0 | Iteration: 37374 | Classification loss: 0.45025 | Regression loss: 0.59812 | Running loss: 0.87908\n",
      "Epoch: 0 | Iteration: 37375 | Classification loss: 0.43783 | Regression loss: 0.64417 | Running loss: 0.87918\n",
      "Epoch: 0 | Iteration: 37376 | Classification loss: 0.17436 | Regression loss: 0.32075 | Running loss: 0.87834\n",
      "Epoch: 0 | Iteration: 37377 | Classification loss: 0.30233 | Regression loss: 0.50352 | Running loss: 0.87775\n",
      "Epoch: 0 | Iteration: 37378 | Classification loss: 0.12089 | Regression loss: 0.26044 | Running loss: 0.87706\n",
      "Epoch: 0 | Iteration: 37379 | Classification loss: 0.18528 | Regression loss: 0.39294 | Running loss: 0.87622\n",
      "Epoch: 0 | Iteration: 37380 | Classification loss: 0.05091 | Regression loss: 0.29226 | Running loss: 0.87602\n",
      "Epoch: 0 | Iteration: 37381 | Classification loss: 0.39778 | Regression loss: 0.59886 | Running loss: 0.87577\n",
      "Epoch: 0 | Iteration: 37382 | Classification loss: 0.40801 | Regression loss: 0.58425 | Running loss: 0.87637\n",
      "Epoch: 0 | Iteration: 37383 | Classification loss: 0.40415 | Regression loss: 0.61587 | Running loss: 0.87666\n",
      "Epoch: 0 | Iteration: 37384 | Classification loss: 0.74441 | Regression loss: 0.69688 | Running loss: 0.87802\n",
      "Epoch: 0 | Iteration: 37385 | Classification loss: 0.33066 | Regression loss: 0.41097 | Running loss: 0.87808\n",
      "Epoch: 0 | Iteration: 37386 | Classification loss: 0.28585 | Regression loss: 0.32449 | Running loss: 0.87767\n",
      "Epoch: 0 | Iteration: 37387 | Classification loss: 0.38820 | Regression loss: 0.23710 | Running loss: 0.87787\n",
      "Epoch: 0 | Iteration: 37388 | Classification loss: 0.33153 | Regression loss: 0.53949 | Running loss: 0.87764\n",
      "Epoch: 0 | Iteration: 37389 | Classification loss: 0.41327 | Regression loss: 0.67558 | Running loss: 0.87761\n",
      "Epoch: 0 | Iteration: 37390 | Classification loss: 0.32039 | Regression loss: 0.15229 | Running loss: 0.87678\n",
      "Epoch: 0 | Iteration: 37391 | Classification loss: 0.76454 | Regression loss: 0.39626 | Running loss: 0.87731\n",
      "Epoch: 0 | Iteration: 37392 | Classification loss: 0.35983 | Regression loss: 0.32187 | Running loss: 0.87800\n",
      "Epoch: 0 | Iteration: 37393 | Classification loss: 0.18249 | Regression loss: 0.24236 | Running loss: 0.87715\n",
      "Epoch: 0 | Iteration: 37394 | Classification loss: 0.48363 | Regression loss: 0.71407 | Running loss: 0.87780\n",
      "Epoch: 0 | Iteration: 37395 | Classification loss: 0.18756 | Regression loss: 0.33828 | Running loss: 0.87775\n",
      "Epoch: 0 | Iteration: 37396 | Classification loss: 0.47040 | Regression loss: 0.57402 | Running loss: 0.87865\n",
      "Epoch: 0 | Iteration: 37397 | Classification loss: 0.51190 | Regression loss: 0.64583 | Running loss: 0.87977\n",
      "Epoch: 0 | Iteration: 37398 | Classification loss: 0.61587 | Regression loss: 0.69883 | Running loss: 0.88086\n",
      "Epoch: 0 | Iteration: 37399 | Classification loss: 0.24064 | Regression loss: 0.38209 | Running loss: 0.88025\n",
      "Epoch: 0 | Iteration: 37400 | Classification loss: 0.48776 | Regression loss: 0.61497 | Running loss: 0.88129\n",
      "Epoch: 0 | Iteration: 37401 | Classification loss: 0.30894 | Regression loss: 0.45826 | Running loss: 0.88107\n",
      "Epoch: 0 | Iteration: 37402 | Classification loss: 0.34589 | Regression loss: 0.60533 | Running loss: 0.88116\n",
      "Epoch: 0 | Iteration: 37403 | Classification loss: 0.37541 | Regression loss: 0.59122 | Running loss: 0.88038\n",
      "Epoch: 0 | Iteration: 37404 | Classification loss: 0.21495 | Regression loss: 0.34943 | Running loss: 0.87972\n",
      "Epoch: 0 | Iteration: 37405 | Classification loss: 0.47037 | Regression loss: 0.56139 | Running loss: 0.88007\n",
      "Epoch: 0 | Iteration: 37406 | Classification loss: 0.44818 | Regression loss: 0.44327 | Running loss: 0.87987\n",
      "Epoch: 0 | Iteration: 37407 | Classification loss: 0.32670 | Regression loss: 0.54147 | Running loss: 0.87979\n",
      "Epoch: 0 | Iteration: 37408 | Classification loss: 0.49013 | Regression loss: 0.71091 | Running loss: 0.88050\n",
      "Epoch: 0 | Iteration: 37409 | Classification loss: 0.35642 | Regression loss: 0.30076 | Running loss: 0.88092\n",
      "Epoch: 0 | Iteration: 37410 | Classification loss: 0.15893 | Regression loss: 0.38483 | Running loss: 0.87994\n",
      "Epoch: 0 | Iteration: 37411 | Classification loss: 0.44597 | Regression loss: 0.46412 | Running loss: 0.88043\n",
      "Epoch: 0 | Iteration: 37412 | Classification loss: 0.44203 | Regression loss: 0.73243 | Running loss: 0.88115\n",
      "Epoch: 0 | Iteration: 37413 | Classification loss: 0.21642 | Regression loss: 0.28675 | Running loss: 0.88097\n",
      "Epoch: 0 | Iteration: 37414 | Classification loss: 0.32498 | Regression loss: 0.41610 | Running loss: 0.88034\n",
      "Epoch: 0 | Iteration: 37415 | Classification loss: 0.22781 | Regression loss: 0.45222 | Running loss: 0.88017\n",
      "Epoch: 0 | Iteration: 37416 | Classification loss: 0.26416 | Regression loss: 0.33189 | Running loss: 0.87960\n",
      "Epoch: 0 | Iteration: 37417 | Classification loss: 0.21433 | Regression loss: 0.41701 | Running loss: 0.87897\n",
      "Epoch: 0 | Iteration: 37418 | Classification loss: 0.43433 | Regression loss: 0.69781 | Running loss: 0.87932\n",
      "Epoch: 0 | Iteration: 37419 | Classification loss: 0.22146 | Regression loss: 0.50210 | Running loss: 0.87942\n",
      "Epoch: 0 | Iteration: 37420 | Classification loss: 0.37763 | Regression loss: 0.58647 | Running loss: 0.88017\n",
      "Epoch: 0 | Iteration: 37421 | Classification loss: 0.39953 | Regression loss: 0.30555 | Running loss: 0.87981\n",
      "Epoch: 0 | Iteration: 37422 | Classification loss: 0.28638 | Regression loss: 0.39789 | Running loss: 0.88047\n",
      "Epoch: 0 | Iteration: 37423 | Classification loss: 0.54610 | Regression loss: 0.62142 | Running loss: 0.88089\n",
      "Epoch: 0 | Iteration: 37424 | Classification loss: 0.22708 | Regression loss: 0.55489 | Running loss: 0.88139\n",
      "Epoch: 0 | Iteration: 37425 | Classification loss: 0.33027 | Regression loss: 0.57735 | Running loss: 0.86759\n",
      "Epoch: 0 | Iteration: 37426 | Classification loss: 0.44392 | Regression loss: 0.60342 | Running loss: 0.86847\n",
      "Epoch: 0 | Iteration: 37427 | Classification loss: 0.54545 | Regression loss: 0.64782 | Running loss: 0.86957\n",
      "Epoch: 0 | Iteration: 37428 | Classification loss: 0.49415 | Regression loss: 0.63506 | Running loss: 0.86975\n",
      "Epoch: 0 | Iteration: 37429 | Classification loss: 0.54193 | Regression loss: 0.67698 | Running loss: 0.86985\n",
      "Epoch: 0 | Iteration: 37430 | Classification loss: 0.22363 | Regression loss: 0.52706 | Running loss: 0.86976\n",
      "Epoch: 0 | Iteration: 37431 | Classification loss: 0.43314 | Regression loss: 0.80394 | Running loss: 0.87083\n",
      "Epoch: 0 | Iteration: 37432 | Classification loss: 0.31451 | Regression loss: 0.43273 | Running loss: 0.87147\n",
      "Epoch: 0 | Iteration: 37433 | Classification loss: 0.46025 | Regression loss: 0.54519 | Running loss: 0.87179\n",
      "Epoch: 0 | Iteration: 37434 | Classification loss: 0.65771 | Regression loss: 0.53216 | Running loss: 0.87160\n",
      "Epoch: 0 | Iteration: 37435 | Classification loss: 0.30276 | Regression loss: 0.32022 | Running loss: 0.87120\n",
      "Epoch: 0 | Iteration: 37436 | Classification loss: 0.26063 | Regression loss: 0.42108 | Running loss: 0.87095\n",
      "Epoch: 0 | Iteration: 37437 | Classification loss: 0.36069 | Regression loss: 0.51148 | Running loss: 0.87112\n",
      "Epoch: 0 | Iteration: 37438 | Classification loss: 0.36209 | Regression loss: 0.46786 | Running loss: 0.87067\n",
      "Epoch: 0 | Iteration: 37439 | Classification loss: 0.35118 | Regression loss: 0.27973 | Running loss: 0.87010\n",
      "Epoch: 0 | Iteration: 37440 | Classification loss: 0.36942 | Regression loss: 0.59530 | Running loss: 0.87048\n",
      "Epoch: 0 | Iteration: 37441 | Classification loss: 0.52729 | Regression loss: 0.43861 | Running loss: 0.87083\n",
      "Epoch: 0 | Iteration: 37442 | Classification loss: 0.63589 | Regression loss: 0.59941 | Running loss: 0.87163\n",
      "Epoch: 0 | Iteration: 37443 | Classification loss: 0.27186 | Regression loss: 0.49737 | Running loss: 0.87126\n",
      "Epoch: 0 | Iteration: 37444 | Classification loss: 0.26963 | Regression loss: 0.36570 | Running loss: 0.87033\n",
      "Epoch: 0 | Iteration: 37445 | Classification loss: 0.26709 | Regression loss: 0.39059 | Running loss: 0.87066\n",
      "Epoch: 0 | Iteration: 37446 | Classification loss: 0.34212 | Regression loss: 0.44287 | Running loss: 0.87074\n",
      "Epoch: 0 | Iteration: 37447 | Classification loss: 0.38841 | Regression loss: 0.40704 | Running loss: 0.87034\n",
      "Epoch: 0 | Iteration: 37448 | Classification loss: 0.69772 | Regression loss: 0.66739 | Running loss: 0.87130\n",
      "Epoch: 0 | Iteration: 37449 | Classification loss: 0.43839 | Regression loss: 0.65226 | Running loss: 0.87205\n",
      "Epoch: 0 | Iteration: 37450 | Classification loss: 0.28866 | Regression loss: 0.59319 | Running loss: 0.87202\n",
      "Epoch: 0 | Iteration: 37451 | Classification loss: 0.14126 | Regression loss: 0.43943 | Running loss: 0.87142\n",
      "Epoch: 0 | Iteration: 37452 | Classification loss: 0.48463 | Regression loss: 0.23646 | Running loss: 0.87198\n",
      "Epoch: 0 | Iteration: 37453 | Classification loss: 0.64984 | Regression loss: 0.47576 | Running loss: 0.87238\n",
      "Epoch: 0 | Iteration: 37454 | Classification loss: 0.43886 | Regression loss: 0.55200 | Running loss: 0.87307\n",
      "Epoch: 0 | Iteration: 37455 | Classification loss: 0.50074 | Regression loss: 0.33279 | Running loss: 0.87311\n",
      "Epoch: 0 | Iteration: 37456 | Classification loss: 0.43173 | Regression loss: 0.44174 | Running loss: 0.87360\n",
      "Epoch: 0 | Iteration: 37457 | Classification loss: 0.36978 | Regression loss: 0.49474 | Running loss: 0.87305\n",
      "Epoch: 0 | Iteration: 37458 | Classification loss: 0.24699 | Regression loss: 0.34907 | Running loss: 0.87289\n",
      "Epoch: 0 | Iteration: 37459 | Classification loss: 0.37674 | Regression loss: 0.51916 | Running loss: 0.87347\n",
      "Epoch: 0 | Iteration: 37460 | Classification loss: 0.41141 | Regression loss: 0.62813 | Running loss: 0.87326\n",
      "Epoch: 0 | Iteration: 37461 | Classification loss: 0.29452 | Regression loss: 0.93800 | Running loss: 0.87339\n",
      "Epoch: 0 | Iteration: 37462 | Classification loss: 0.23800 | Regression loss: 0.32885 | Running loss: 0.87248\n",
      "Epoch: 0 | Iteration: 37463 | Classification loss: 0.37870 | Regression loss: 0.57173 | Running loss: 0.87202\n",
      "Epoch: 0 | Iteration: 37464 | Classification loss: 0.41199 | Regression loss: 0.61509 | Running loss: 0.87248\n",
      "Epoch: 0 | Iteration: 37465 | Classification loss: 0.40905 | Regression loss: 0.37793 | Running loss: 0.87258\n",
      "Epoch: 0 | Iteration: 37466 | Classification loss: 0.35373 | Regression loss: 0.52733 | Running loss: 0.87234\n",
      "Epoch: 0 | Iteration: 37467 | Classification loss: 0.32825 | Regression loss: 0.62303 | Running loss: 0.87270\n",
      "Epoch: 0 | Iteration: 37468 | Classification loss: 0.34398 | Regression loss: 0.57730 | Running loss: 0.87281\n",
      "Epoch: 0 | Iteration: 37469 | Classification loss: 0.50957 | Regression loss: 0.59449 | Running loss: 0.87303\n",
      "Epoch: 0 | Iteration: 37470 | Classification loss: 0.41643 | Regression loss: 0.65477 | Running loss: 0.87284\n",
      "Epoch: 0 | Iteration: 37471 | Classification loss: 0.25548 | Regression loss: 0.38139 | Running loss: 0.87294\n",
      "Epoch: 0 | Iteration: 37472 | Classification loss: 0.28353 | Regression loss: 0.46916 | Running loss: 0.87257\n",
      "Epoch: 0 | Iteration: 37473 | Classification loss: 0.44203 | Regression loss: 0.42059 | Running loss: 0.87225\n",
      "Epoch: 0 | Iteration: 37474 | Classification loss: 0.56183 | Regression loss: 0.46642 | Running loss: 0.87183\n",
      "Epoch: 0 | Iteration: 37475 | Classification loss: 0.37328 | Regression loss: 0.47094 | Running loss: 0.87184\n",
      "Epoch: 0 | Iteration: 37476 | Classification loss: 0.20868 | Regression loss: 0.51743 | Running loss: 0.87178\n",
      "Epoch: 0 | Iteration: 37477 | Classification loss: 0.40125 | Regression loss: 0.61982 | Running loss: 0.87125\n",
      "Epoch: 0 | Iteration: 37478 | Classification loss: 0.29594 | Regression loss: 0.41116 | Running loss: 0.87105\n",
      "Epoch: 0 | Iteration: 37479 | Classification loss: 0.29614 | Regression loss: 0.35343 | Running loss: 0.87026\n",
      "Epoch: 0 | Iteration: 37480 | Classification loss: 0.20989 | Regression loss: 0.25001 | Running loss: 0.86944\n",
      "Epoch: 0 | Iteration: 37481 | Classification loss: 0.31831 | Regression loss: 0.49765 | Running loss: 0.86988\n",
      "Epoch: 0 | Iteration: 37482 | Classification loss: 0.55696 | Regression loss: 0.41003 | Running loss: 0.86996\n",
      "Epoch: 0 | Iteration: 37483 | Classification loss: 0.34717 | Regression loss: 0.43870 | Running loss: 0.86991\n",
      "Epoch: 0 | Iteration: 37484 | Classification loss: 0.41018 | Regression loss: 0.48034 | Running loss: 0.87079\n",
      "Epoch: 0 | Iteration: 37485 | Classification loss: 0.50811 | Regression loss: 0.48725 | Running loss: 0.87046\n",
      "Epoch: 0 | Iteration: 37486 | Classification loss: 0.17972 | Regression loss: 0.57673 | Running loss: 0.86960\n",
      "Epoch: 0 | Iteration: 37487 | Classification loss: 0.41719 | Regression loss: 0.68766 | Running loss: 0.86922\n",
      "Epoch: 0 | Iteration: 37488 | Classification loss: 0.39215 | Regression loss: 0.56422 | Running loss: 0.86984\n",
      "Epoch: 0 | Iteration: 37489 | Classification loss: 0.35934 | Regression loss: 0.28394 | Running loss: 0.86927\n",
      "Epoch: 0 | Iteration: 37490 | Classification loss: 0.38095 | Regression loss: 0.42024 | Running loss: 0.86910\n",
      "Epoch: 0 | Iteration: 37491 | Classification loss: 1.63740 | Regression loss: 0.39733 | Running loss: 0.87153\n",
      "Epoch: 0 | Iteration: 37492 | Classification loss: 0.57929 | Regression loss: 0.53146 | Running loss: 0.87200\n",
      "Epoch: 0 | Iteration: 37493 | Classification loss: 0.34644 | Regression loss: 0.22282 | Running loss: 0.87143\n",
      "Epoch: 0 | Iteration: 37494 | Classification loss: 0.20012 | Regression loss: 0.25887 | Running loss: 0.87056\n",
      "Epoch: 0 | Iteration: 37495 | Classification loss: 0.19535 | Regression loss: 0.36213 | Running loss: 0.87022\n",
      "Epoch: 0 | Iteration: 37496 | Classification loss: 0.33570 | Regression loss: 0.34882 | Running loss: 0.87009\n",
      "Epoch: 0 | Iteration: 37497 | Classification loss: 0.14215 | Regression loss: 0.23143 | Running loss: 0.86934\n",
      "Epoch: 0 | Iteration: 37498 | Classification loss: 0.31448 | Regression loss: 0.40159 | Running loss: 0.86901\n",
      "Epoch: 0 | Iteration: 37499 | Classification loss: 0.26243 | Regression loss: 0.48536 | Running loss: 0.86900\n",
      "Epoch: 0 | Iteration: 37500 | Classification loss: 0.41774 | Regression loss: 0.56740 | Running loss: 0.86903\n",
      "Epoch: 0 | Iteration: 37501 | Classification loss: 0.24168 | Regression loss: 0.56824 | Running loss: 0.86926\n",
      "Epoch: 0 | Iteration: 37502 | Classification loss: 0.25565 | Regression loss: 0.46037 | Running loss: 0.86932\n",
      "Epoch: 0 | Iteration: 37503 | Classification loss: 0.13390 | Regression loss: 0.28755 | Running loss: 0.86755\n",
      "Epoch: 0 | Iteration: 37504 | Classification loss: 0.32853 | Regression loss: 0.45514 | Running loss: 0.86744\n",
      "Epoch: 0 | Iteration: 37505 | Classification loss: 0.18682 | Regression loss: 0.46605 | Running loss: 0.86729\n",
      "Epoch: 0 | Iteration: 37506 | Classification loss: 0.47431 | Regression loss: 0.44950 | Running loss: 0.86734\n",
      "Epoch: 0 | Iteration: 37507 | Classification loss: 0.24018 | Regression loss: 0.56665 | Running loss: 0.86724\n",
      "Epoch: 0 | Iteration: 37508 | Classification loss: 0.43404 | Regression loss: 0.56742 | Running loss: 0.86710\n",
      "Epoch: 0 | Iteration: 37509 | Classification loss: 0.30690 | Regression loss: 0.23159 | Running loss: 0.86600\n",
      "Epoch: 0 | Iteration: 37510 | Classification loss: 0.31661 | Regression loss: 0.33732 | Running loss: 0.85496\n",
      "Epoch: 0 | Iteration: 37511 | Classification loss: 0.32681 | Regression loss: 0.37710 | Running loss: 0.85527\n",
      "Epoch: 0 | Iteration: 37512 | Classification loss: 0.48808 | Regression loss: 0.68333 | Running loss: 0.85573\n",
      "Epoch: 0 | Iteration: 37513 | Classification loss: 0.44376 | Regression loss: 0.56979 | Running loss: 0.85555\n",
      "Epoch: 0 | Iteration: 37514 | Classification loss: 0.22835 | Regression loss: 0.46094 | Running loss: 0.85515\n",
      "Epoch: 0 | Iteration: 37515 | Classification loss: 0.29700 | Regression loss: 0.43148 | Running loss: 0.85402\n",
      "Epoch: 0 | Iteration: 37516 | Classification loss: 0.42272 | Regression loss: 0.47106 | Running loss: 0.85374\n",
      "Epoch: 0 | Iteration: 37517 | Classification loss: 0.38452 | Regression loss: 0.45983 | Running loss: 0.85378\n",
      "Epoch: 0 | Iteration: 37518 | Classification loss: 0.32482 | Regression loss: 0.53586 | Running loss: 0.85432\n",
      "Epoch: 0 | Iteration: 37519 | Classification loss: 0.94608 | Regression loss: 0.72237 | Running loss: 0.85646\n",
      "Epoch: 0 | Iteration: 37520 | Classification loss: 0.22732 | Regression loss: 0.32368 | Running loss: 0.85631\n",
      "Epoch: 0 | Iteration: 37521 | Classification loss: 0.30241 | Regression loss: 0.62621 | Running loss: 0.85590\n",
      "Epoch: 0 | Iteration: 37522 | Classification loss: 0.24130 | Regression loss: 0.49441 | Running loss: 0.85548\n",
      "Epoch: 0 | Iteration: 37523 | Classification loss: 0.41674 | Regression loss: 0.56564 | Running loss: 0.85609\n",
      "Epoch: 0 | Iteration: 37524 | Classification loss: 0.18546 | Regression loss: 0.46825 | Running loss: 0.85598\n",
      "Epoch: 0 | Iteration: 37525 | Classification loss: 0.24384 | Regression loss: 0.34454 | Running loss: 0.85485\n",
      "Epoch: 0 | Iteration: 37526 | Classification loss: 0.32390 | Regression loss: 0.55068 | Running loss: 0.85461\n",
      "Epoch: 0 | Iteration: 37527 | Classification loss: 0.46138 | Regression loss: 0.46413 | Running loss: 0.85483\n",
      "Epoch: 0 | Iteration: 37528 | Classification loss: 0.13285 | Regression loss: 0.43700 | Running loss: 0.85367\n",
      "Epoch: 0 | Iteration: 37529 | Classification loss: 0.23367 | Regression loss: 0.47031 | Running loss: 0.85311\n",
      "Epoch: 0 | Iteration: 37530 | Classification loss: 0.19147 | Regression loss: 0.40957 | Running loss: 0.85229\n",
      "Epoch: 0 | Iteration: 37531 | Classification loss: 0.37701 | Regression loss: 0.57415 | Running loss: 0.85282\n",
      "Epoch: 0 | Iteration: 37532 | Classification loss: 0.54285 | Regression loss: 0.64121 | Running loss: 0.85297\n",
      "Epoch: 0 | Iteration: 37533 | Classification loss: 0.25990 | Regression loss: 0.41678 | Running loss: 0.85195\n",
      "Epoch: 0 | Iteration: 37534 | Classification loss: 0.15163 | Regression loss: 0.26973 | Running loss: 0.85019\n",
      "Epoch: 0 | Iteration: 37535 | Classification loss: 0.19477 | Regression loss: 0.37722 | Running loss: 0.84964\n",
      "Epoch: 0 | Iteration: 37536 | Classification loss: 0.15839 | Regression loss: 0.16335 | Running loss: 0.84854\n",
      "Epoch: 0 | Iteration: 37537 | Classification loss: 0.25955 | Regression loss: 0.50757 | Running loss: 0.84766\n",
      "Epoch: 0 | Iteration: 37538 | Classification loss: 0.31763 | Regression loss: 0.49224 | Running loss: 0.84816\n",
      "Epoch: 0 | Iteration: 37539 | Classification loss: 0.19098 | Regression loss: 0.46922 | Running loss: 0.84784\n",
      "Epoch: 0 | Iteration: 37540 | Classification loss: 0.33364 | Regression loss: 0.50903 | Running loss: 0.84792\n",
      "Epoch: 0 | Iteration: 37541 | Classification loss: 0.37224 | Regression loss: 0.66248 | Running loss: 0.84822\n",
      "Epoch: 0 | Iteration: 37542 | Classification loss: 0.41062 | Regression loss: 0.64027 | Running loss: 0.84827\n",
      "Epoch: 0 | Iteration: 37543 | Classification loss: 0.58467 | Regression loss: 0.72658 | Running loss: 0.84923\n",
      "Epoch: 0 | Iteration: 37544 | Classification loss: 0.23943 | Regression loss: 0.41296 | Running loss: 0.84821\n",
      "Epoch: 0 | Iteration: 37545 | Classification loss: 0.35220 | Regression loss: 0.51755 | Running loss: 0.84838\n",
      "Epoch: 0 | Iteration: 37546 | Classification loss: 0.47786 | Regression loss: 0.67526 | Running loss: 0.84890\n",
      "Epoch: 0 | Iteration: 37547 | Classification loss: 0.34842 | Regression loss: 0.37867 | Running loss: 0.84893\n",
      "Epoch: 0 | Iteration: 37548 | Classification loss: 0.33923 | Regression loss: 0.52419 | Running loss: 0.84806\n",
      "Epoch: 0 | Iteration: 37549 | Classification loss: 0.27322 | Regression loss: 0.50870 | Running loss: 0.84791\n",
      "Epoch: 0 | Iteration: 37550 | Classification loss: 0.52875 | Regression loss: 0.65724 | Running loss: 0.84843\n",
      "Epoch: 0 | Iteration: 37551 | Classification loss: 0.66303 | Regression loss: 0.22502 | Running loss: 0.84839\n",
      "Epoch: 0 | Iteration: 37552 | Classification loss: 0.27653 | Regression loss: 0.75284 | Running loss: 0.84932\n",
      "Epoch: 0 | Iteration: 37553 | Classification loss: 0.35819 | Regression loss: 0.64797 | Running loss: 0.84980\n",
      "Epoch: 0 | Iteration: 37554 | Classification loss: 0.35864 | Regression loss: 0.44550 | Running loss: 0.84950\n",
      "Epoch: 0 | Iteration: 37555 | Classification loss: 0.55805 | Regression loss: 0.52055 | Running loss: 0.84947\n",
      "Epoch: 0 | Iteration: 37556 | Classification loss: 0.39263 | Regression loss: 0.57360 | Running loss: 0.84991\n",
      "Epoch: 0 | Iteration: 37557 | Classification loss: 0.27050 | Regression loss: 0.32307 | Running loss: 0.84927\n",
      "Epoch: 0 | Iteration: 37558 | Classification loss: 1.13403 | Regression loss: 0.25299 | Running loss: 0.85045\n",
      "Epoch: 0 | Iteration: 37559 | Classification loss: 0.32203 | Regression loss: 0.51441 | Running loss: 0.85076\n",
      "Epoch: 0 | Iteration: 37560 | Classification loss: 0.38871 | Regression loss: 0.68141 | Running loss: 0.85090\n",
      "Epoch: 0 | Iteration: 37561 | Classification loss: 0.25625 | Regression loss: 0.49900 | Running loss: 0.85121\n",
      "Epoch: 0 | Iteration: 37562 | Classification loss: 0.31237 | Regression loss: 0.52232 | Running loss: 0.85045\n",
      "Epoch: 0 | Iteration: 37563 | Classification loss: 0.25034 | Regression loss: 0.45069 | Running loss: 0.84970\n",
      "Epoch: 0 | Iteration: 37564 | Classification loss: 0.73755 | Regression loss: 0.65919 | Running loss: 0.85068\n",
      "Epoch: 0 | Iteration: 37565 | Classification loss: 0.27213 | Regression loss: 0.38106 | Running loss: 0.85062\n",
      "Epoch: 0 | Iteration: 37566 | Classification loss: 0.35851 | Regression loss: 0.47798 | Running loss: 0.85002\n",
      "Epoch: 0 | Iteration: 37567 | Classification loss: 0.52942 | Regression loss: 0.43576 | Running loss: 0.85025\n",
      "Epoch: 0 | Iteration: 37568 | Classification loss: 0.50419 | Regression loss: 0.36218 | Running loss: 0.84963\n",
      "Epoch: 0 | Iteration: 37569 | Classification loss: 0.53515 | Regression loss: 0.54624 | Running loss: 0.85006\n",
      "Epoch: 0 | Iteration: 37570 | Classification loss: 0.07026 | Regression loss: 0.16239 | Running loss: 0.84870\n",
      "Epoch: 0 | Iteration: 37571 | Classification loss: 0.43682 | Regression loss: 0.62377 | Running loss: 0.84978\n",
      "Epoch: 0 | Iteration: 37572 | Classification loss: 0.29897 | Regression loss: 0.47543 | Running loss: 0.84897\n",
      "Epoch: 0 | Iteration: 37573 | Classification loss: 0.46646 | Regression loss: 0.57105 | Running loss: 0.85024\n",
      "Epoch: 0 | Iteration: 37574 | Classification loss: 0.28034 | Regression loss: 0.52573 | Running loss: 0.84988\n",
      "Epoch: 0 | Iteration: 37575 | Classification loss: 0.43026 | Regression loss: 0.43320 | Running loss: 0.84956\n",
      "Epoch: 0 | Iteration: 37576 | Classification loss: 0.24721 | Regression loss: 0.30013 | Running loss: 0.84830\n",
      "Epoch: 0 | Iteration: 37577 | Classification loss: 0.25646 | Regression loss: 0.41041 | Running loss: 0.84757\n",
      "Epoch: 0 | Iteration: 37578 | Classification loss: 0.37883 | Regression loss: 0.52867 | Running loss: 0.84802\n",
      "Epoch: 0 | Iteration: 37579 | Classification loss: 0.40266 | Regression loss: 0.66015 | Running loss: 0.84812\n",
      "Epoch: 0 | Iteration: 37580 | Classification loss: 0.41076 | Regression loss: 0.50028 | Running loss: 0.84830\n",
      "Epoch: 0 | Iteration: 37581 | Classification loss: 0.33680 | Regression loss: 0.51425 | Running loss: 0.84877\n",
      "Epoch: 0 | Iteration: 37582 | Classification loss: 0.09837 | Regression loss: 0.12210 | Running loss: 0.84743\n",
      "Epoch: 0 | Iteration: 37583 | Classification loss: 0.29678 | Regression loss: 0.36029 | Running loss: 0.84644\n",
      "Epoch: 0 | Iteration: 37584 | Classification loss: 0.18557 | Regression loss: 0.24750 | Running loss: 0.84602\n",
      "Epoch: 0 | Iteration: 37585 | Classification loss: 0.39998 | Regression loss: 0.32479 | Running loss: 0.84617\n",
      "Epoch: 0 | Iteration: 37586 | Classification loss: 0.34995 | Regression loss: 0.51416 | Running loss: 0.84691\n",
      "Epoch: 0 | Iteration: 37587 | Classification loss: 0.22439 | Regression loss: 0.43245 | Running loss: 0.84600\n",
      "Epoch: 0 | Iteration: 37588 | Classification loss: 0.32088 | Regression loss: 0.62523 | Running loss: 0.84615\n",
      "Epoch: 0 | Iteration: 37589 | Classification loss: 0.33575 | Regression loss: 0.61786 | Running loss: 0.84676\n",
      "Epoch: 0 | Iteration: 37590 | Classification loss: 0.35089 | Regression loss: 0.35688 | Running loss: 0.84704\n",
      "Epoch: 0 | Iteration: 37591 | Classification loss: 0.32691 | Regression loss: 0.61776 | Running loss: 0.84791\n",
      "Epoch: 0 | Iteration: 37592 | Classification loss: 0.10800 | Regression loss: 0.26350 | Running loss: 0.84698\n",
      "Epoch: 0 | Iteration: 37593 | Classification loss: 0.41759 | Regression loss: 0.61475 | Running loss: 0.84781\n",
      "Epoch: 0 | Iteration: 37594 | Classification loss: 0.35700 | Regression loss: 0.55371 | Running loss: 0.84761\n",
      "Epoch: 0 | Iteration: 37595 | Classification loss: 0.65587 | Regression loss: 0.47061 | Running loss: 0.84767\n",
      "Epoch: 0 | Iteration: 37596 | Classification loss: 0.48505 | Regression loss: 0.53859 | Running loss: 0.84679\n",
      "Epoch: 0 | Iteration: 37597 | Classification loss: 0.28219 | Regression loss: 0.58141 | Running loss: 0.84633\n",
      "Epoch: 0 | Iteration: 37598 | Classification loss: 0.54821 | Regression loss: 0.42484 | Running loss: 0.84712\n",
      "Epoch: 0 | Iteration: 37599 | Classification loss: 0.17654 | Regression loss: 0.34856 | Running loss: 0.84704\n",
      "Epoch: 0 | Iteration: 37600 | Classification loss: 0.39962 | Regression loss: 0.67716 | Running loss: 0.84770\n",
      "Epoch: 0 | Iteration: 37601 | Classification loss: 0.59840 | Regression loss: 0.59921 | Running loss: 0.84761\n",
      "Epoch: 0 | Iteration: 37602 | Classification loss: 0.51811 | Regression loss: 0.51901 | Running loss: 0.84857\n",
      "Epoch: 0 | Iteration: 37603 | Classification loss: 0.36674 | Regression loss: 0.44705 | Running loss: 0.84869\n",
      "Epoch: 0 | Iteration: 37604 | Classification loss: 0.20049 | Regression loss: 0.44514 | Running loss: 0.84823\n",
      "Epoch: 0 | Iteration: 37605 | Classification loss: 0.49740 | Regression loss: 0.78986 | Running loss: 0.84930\n",
      "Epoch: 0 | Iteration: 37606 | Classification loss: 0.32951 | Regression loss: 0.41859 | Running loss: 0.84887\n",
      "Epoch: 0 | Iteration: 37607 | Classification loss: 0.35158 | Regression loss: 0.50631 | Running loss: 0.84896\n",
      "Epoch: 0 | Iteration: 37608 | Classification loss: 0.44945 | Regression loss: 0.61640 | Running loss: 0.84933\n",
      "Epoch: 0 | Iteration: 37609 | Classification loss: 0.42527 | Regression loss: 0.58277 | Running loss: 0.84940\n",
      "Epoch: 0 | Iteration: 37610 | Classification loss: 0.30196 | Regression loss: 0.50836 | Running loss: 0.84909\n",
      "Epoch: 0 | Iteration: 37611 | Classification loss: 0.31527 | Regression loss: 0.48997 | Running loss: 0.84963\n",
      "Epoch: 0 | Iteration: 37612 | Classification loss: 0.40097 | Regression loss: 0.32417 | Running loss: 0.84986\n",
      "Epoch: 0 | Iteration: 37613 | Classification loss: 0.56827 | Regression loss: 0.67121 | Running loss: 0.84989\n",
      "Epoch: 0 | Iteration: 37614 | Classification loss: 0.26597 | Regression loss: 0.45602 | Running loss: 0.84922\n",
      "Epoch: 0 | Iteration: 37615 | Classification loss: 0.34810 | Regression loss: 0.44924 | Running loss: 0.84928\n",
      "Epoch: 0 | Iteration: 37616 | Classification loss: 0.89108 | Regression loss: 0.61622 | Running loss: 0.85077\n",
      "Epoch: 0 | Iteration: 37617 | Classification loss: 0.31691 | Regression loss: 0.67811 | Running loss: 0.85156\n",
      "Epoch: 0 | Iteration: 37618 | Classification loss: 0.46540 | Regression loss: 0.45008 | Running loss: 0.85148\n",
      "Epoch: 0 | Iteration: 37619 | Classification loss: 0.63839 | Regression loss: 0.72806 | Running loss: 0.85302\n",
      "Epoch: 0 | Iteration: 37620 | Classification loss: 0.33779 | Regression loss: 0.46223 | Running loss: 0.85306\n",
      "Epoch: 0 | Iteration: 37621 | Classification loss: 0.39504 | Regression loss: 0.59873 | Running loss: 0.85310\n",
      "Epoch: 0 | Iteration: 37622 | Classification loss: 0.21850 | Regression loss: 0.43547 | Running loss: 0.85303\n",
      "Epoch: 0 | Iteration: 37623 | Classification loss: 0.77207 | Regression loss: 0.32942 | Running loss: 0.85377\n",
      "Epoch: 0 | Iteration: 37624 | Classification loss: 0.27363 | Regression loss: 0.38455 | Running loss: 0.85426\n",
      "Epoch: 0 | Iteration: 37625 | Classification loss: 0.37978 | Regression loss: 0.47646 | Running loss: 0.85425\n",
      "Epoch: 0 | Iteration: 37626 | Classification loss: 0.63168 | Regression loss: 0.25042 | Running loss: 0.85446\n",
      "Epoch: 0 | Iteration: 37627 | Classification loss: 0.34819 | Regression loss: 0.77478 | Running loss: 0.85611\n",
      "Epoch: 0 | Iteration: 37628 | Classification loss: 0.34488 | Regression loss: 0.52396 | Running loss: 0.85620\n",
      "Epoch: 0 | Iteration: 37629 | Classification loss: 0.52404 | Regression loss: 0.62241 | Running loss: 0.85654\n",
      "Epoch: 0 | Iteration: 37630 | Classification loss: 0.52857 | Regression loss: 0.40113 | Running loss: 0.85643\n",
      "Epoch: 0 | Iteration: 37631 | Classification loss: 0.42785 | Regression loss: 0.56853 | Running loss: 0.85712\n",
      "Epoch: 0 | Iteration: 37632 | Classification loss: 0.14147 | Regression loss: 0.21768 | Running loss: 0.85747\n",
      "Epoch: 0 | Iteration: 37633 | Classification loss: 0.38603 | Regression loss: 0.44863 | Running loss: 0.85800\n",
      "Epoch: 0 | Iteration: 37634 | Classification loss: 0.49779 | Regression loss: 0.41257 | Running loss: 0.85824\n",
      "Epoch: 0 | Iteration: 37635 | Classification loss: 0.37971 | Regression loss: 0.48684 | Running loss: 0.85838\n",
      "Epoch: 0 | Iteration: 37636 | Classification loss: 0.29743 | Regression loss: 0.58216 | Running loss: 0.85783\n",
      "Epoch: 0 | Iteration: 37637 | Classification loss: 0.46160 | Regression loss: 0.50250 | Running loss: 0.85796\n",
      "Epoch: 0 | Iteration: 37638 | Classification loss: 0.44248 | Regression loss: 0.53879 | Running loss: 0.85839\n",
      "Epoch: 0 | Iteration: 37639 | Classification loss: 0.16839 | Regression loss: 0.38151 | Running loss: 0.85708\n",
      "Epoch: 0 | Iteration: 37640 | Classification loss: 0.26616 | Regression loss: 0.43841 | Running loss: 0.85621\n",
      "Epoch: 0 | Iteration: 37641 | Classification loss: 0.38735 | Regression loss: 0.54921 | Running loss: 0.85693\n",
      "Epoch: 0 | Iteration: 37642 | Classification loss: 0.45230 | Regression loss: 0.43727 | Running loss: 0.85771\n",
      "Epoch: 0 | Iteration: 37643 | Classification loss: 0.42397 | Regression loss: 0.36650 | Running loss: 0.85758\n",
      "Epoch: 0 | Iteration: 37644 | Classification loss: 0.30232 | Regression loss: 0.46821 | Running loss: 0.85774\n",
      "Epoch: 0 | Iteration: 37645 | Classification loss: 0.48170 | Regression loss: 0.54719 | Running loss: 0.85844\n",
      "Epoch: 0 | Iteration: 37646 | Classification loss: 0.14010 | Regression loss: 0.31450 | Running loss: 0.85751\n",
      "Epoch: 0 | Iteration: 37647 | Classification loss: 0.39869 | Regression loss: 0.66479 | Running loss: 0.85763\n",
      "Epoch: 0 | Iteration: 37648 | Classification loss: 0.94419 | Regression loss: 0.51822 | Running loss: 0.85785\n",
      "Epoch: 0 | Iteration: 37649 | Classification loss: 0.35701 | Regression loss: 0.54586 | Running loss: 0.85756\n",
      "Epoch: 0 | Iteration: 37650 | Classification loss: 0.44785 | Regression loss: 0.58958 | Running loss: 0.85813\n",
      "Epoch: 0 | Iteration: 37651 | Classification loss: 0.44439 | Regression loss: 0.54211 | Running loss: 0.85894\n",
      "Epoch: 0 | Iteration: 37652 | Classification loss: 0.24191 | Regression loss: 0.45189 | Running loss: 0.85858\n",
      "Epoch: 0 | Iteration: 37653 | Classification loss: 0.41943 | Regression loss: 0.34943 | Running loss: 0.85914\n",
      "Epoch: 0 | Iteration: 37654 | Classification loss: 0.26211 | Regression loss: 0.43808 | Running loss: 0.85968\n",
      "Epoch: 0 | Iteration: 37655 | Classification loss: 0.10744 | Regression loss: 0.26542 | Running loss: 0.85955\n",
      "Epoch: 0 | Iteration: 37656 | Classification loss: 0.35271 | Regression loss: 0.61845 | Running loss: 0.85966\n",
      "Epoch: 0 | Iteration: 37657 | Classification loss: 0.38490 | Regression loss: 0.59523 | Running loss: 0.86014\n",
      "Epoch: 0 | Iteration: 37658 | Classification loss: 0.47374 | Regression loss: 0.49475 | Running loss: 0.86026\n",
      "Epoch: 0 | Iteration: 37659 | Classification loss: 0.49664 | Regression loss: 0.58743 | Running loss: 0.86086\n",
      "Epoch: 0 | Iteration: 37660 | Classification loss: 0.39780 | Regression loss: 0.49707 | Running loss: 0.86073\n",
      "Epoch: 0 | Iteration: 37661 | Classification loss: 0.45525 | Regression loss: 0.34925 | Running loss: 0.86053\n",
      "Epoch: 0 | Iteration: 37662 | Classification loss: 0.99974 | Regression loss: 0.76392 | Running loss: 0.86193\n",
      "Epoch: 0 | Iteration: 37663 | Classification loss: 0.17731 | Regression loss: 0.28975 | Running loss: 0.86165\n",
      "Epoch: 0 | Iteration: 37664 | Classification loss: 0.10740 | Regression loss: 0.31022 | Running loss: 0.86055\n",
      "Epoch: 0 | Iteration: 37665 | Classification loss: 0.49856 | Regression loss: 0.62944 | Running loss: 0.86139\n",
      "Epoch: 0 | Iteration: 37666 | Classification loss: 0.47608 | Regression loss: 0.55134 | Running loss: 0.86184\n",
      "Epoch: 0 | Iteration: 37667 | Classification loss: 0.19277 | Regression loss: 0.25014 | Running loss: 0.86065\n",
      "Epoch: 0 | Iteration: 37668 | Classification loss: 0.21596 | Regression loss: 0.31890 | Running loss: 0.85993\n",
      "Epoch: 0 | Iteration: 37669 | Classification loss: 0.19183 | Regression loss: 0.28257 | Running loss: 0.85853\n",
      "Epoch: 0 | Iteration: 37670 | Classification loss: 0.28881 | Regression loss: 0.57199 | Running loss: 0.85850\n",
      "Epoch: 0 | Iteration: 37671 | Classification loss: 0.12896 | Regression loss: 0.47981 | Running loss: 0.85849\n",
      "Epoch: 0 | Iteration: 37672 | Classification loss: 0.31248 | Regression loss: 0.34688 | Running loss: 0.85843\n",
      "Epoch: 0 | Iteration: 37673 | Classification loss: 0.07390 | Regression loss: 0.29342 | Running loss: 0.85743\n",
      "Epoch: 0 | Iteration: 37674 | Classification loss: 0.29938 | Regression loss: 0.42389 | Running loss: 0.85643\n",
      "Epoch: 0 | Iteration: 37675 | Classification loss: 0.30027 | Regression loss: 0.28006 | Running loss: 0.85557\n",
      "Epoch: 0 | Iteration: 37676 | Classification loss: 0.29642 | Regression loss: 0.50223 | Running loss: 0.85467\n",
      "Epoch: 0 | Iteration: 37677 | Classification loss: 0.39777 | Regression loss: 0.60191 | Running loss: 0.85470\n",
      "Epoch: 0 | Iteration: 37678 | Classification loss: 0.27175 | Regression loss: 0.48986 | Running loss: 0.85471\n",
      "Epoch: 0 | Iteration: 37679 | Classification loss: 0.20451 | Regression loss: 0.26528 | Running loss: 0.85384\n",
      "Epoch: 0 | Iteration: 37680 | Classification loss: 0.25114 | Regression loss: 0.53773 | Running loss: 0.85440\n",
      "Epoch: 0 | Iteration: 37681 | Classification loss: 0.31684 | Regression loss: 0.48214 | Running loss: 0.85466\n",
      "Epoch: 0 | Iteration: 37682 | Classification loss: 0.45205 | Regression loss: 0.60662 | Running loss: 0.85479\n",
      "Epoch: 0 | Iteration: 37683 | Classification loss: 0.19095 | Regression loss: 0.30849 | Running loss: 0.85389\n",
      "Epoch: 0 | Iteration: 37684 | Classification loss: 0.77611 | Regression loss: 0.39837 | Running loss: 0.85573\n",
      "Epoch: 0 | Iteration: 37685 | Classification loss: 0.14652 | Regression loss: 0.22734 | Running loss: 0.85492\n",
      "Epoch: 0 | Iteration: 37686 | Classification loss: 0.24785 | Regression loss: 0.40882 | Running loss: 0.85423\n",
      "Epoch: 0 | Iteration: 37687 | Classification loss: 0.21478 | Regression loss: 0.32243 | Running loss: 0.85350\n",
      "Epoch: 0 | Iteration: 37688 | Classification loss: 0.30026 | Regression loss: 0.29383 | Running loss: 0.85330\n",
      "Epoch: 0 | Iteration: 37689 | Classification loss: 0.36624 | Regression loss: 0.57693 | Running loss: 0.85384\n",
      "Epoch: 0 | Iteration: 37690 | Classification loss: 0.45057 | Regression loss: 0.54982 | Running loss: 0.85285\n",
      "Epoch: 0 | Iteration: 37691 | Classification loss: 0.29631 | Regression loss: 0.23568 | Running loss: 0.85203\n",
      "Epoch: 0 | Iteration: 37692 | Classification loss: 0.56278 | Regression loss: 0.37546 | Running loss: 0.85130\n",
      "Epoch: 0 | Iteration: 37693 | Classification loss: 0.26772 | Regression loss: 0.30118 | Running loss: 0.85026\n",
      "Epoch: 0 | Iteration: 37694 | Classification loss: 0.18211 | Regression loss: 0.52260 | Running loss: 0.84975\n",
      "Epoch: 0 | Iteration: 37695 | Classification loss: 0.35839 | Regression loss: 0.45985 | Running loss: 0.84963\n",
      "Epoch: 0 | Iteration: 37696 | Classification loss: 0.30110 | Regression loss: 0.52623 | Running loss: 0.84969\n",
      "Epoch: 0 | Iteration: 37697 | Classification loss: 0.09633 | Regression loss: 0.28842 | Running loss: 0.84822\n",
      "Epoch: 0 | Iteration: 37698 | Classification loss: 0.42377 | Regression loss: 0.47864 | Running loss: 0.84810\n",
      "Epoch: 0 | Iteration: 37699 | Classification loss: 0.36835 | Regression loss: 0.60524 | Running loss: 0.84794\n",
      "Epoch: 0 | Iteration: 37700 | Classification loss: 0.12619 | Regression loss: 0.30617 | Running loss: 0.84666\n",
      "Epoch: 0 | Iteration: 37701 | Classification loss: 0.61306 | Regression loss: 0.51011 | Running loss: 0.84725\n",
      "Epoch: 0 | Iteration: 37702 | Classification loss: 0.35904 | Regression loss: 0.44189 | Running loss: 0.84805\n",
      "Epoch: 0 | Iteration: 37703 | Classification loss: 0.64158 | Regression loss: 0.38257 | Running loss: 0.84778\n",
      "Epoch: 0 | Iteration: 37704 | Classification loss: 0.33399 | Regression loss: 0.37845 | Running loss: 0.84744\n",
      "Epoch: 0 | Iteration: 37705 | Classification loss: 0.21522 | Regression loss: 0.44900 | Running loss: 0.84749\n",
      "Epoch: 0 | Iteration: 37706 | Classification loss: 0.67787 | Regression loss: 0.46967 | Running loss: 0.84772\n",
      "Epoch: 0 | Iteration: 37707 | Classification loss: 0.45357 | Regression loss: 0.33927 | Running loss: 0.84748\n",
      "Epoch: 0 | Iteration: 37708 | Classification loss: 0.28841 | Regression loss: 0.45464 | Running loss: 0.84687\n",
      "Epoch: 0 | Iteration: 37709 | Classification loss: 0.79800 | Regression loss: 0.39640 | Running loss: 0.84776\n",
      "Epoch: 0 | Iteration: 37710 | Classification loss: 0.14325 | Regression loss: 0.55758 | Running loss: 0.84767\n",
      "Epoch: 0 | Iteration: 37711 | Classification loss: 0.32810 | Regression loss: 0.57256 | Running loss: 0.84771\n",
      "Epoch: 0 | Iteration: 37712 | Classification loss: 0.35635 | Regression loss: 0.76437 | Running loss: 0.84811\n",
      "Epoch: 0 | Iteration: 37713 | Classification loss: 0.22453 | Regression loss: 0.23933 | Running loss: 0.84728\n",
      "Epoch: 0 | Iteration: 37714 | Classification loss: 0.40740 | Regression loss: 0.46614 | Running loss: 0.84695\n",
      "Epoch: 0 | Iteration: 37715 | Classification loss: 0.31229 | Regression loss: 0.46153 | Running loss: 0.84706\n",
      "Epoch: 0 | Iteration: 37716 | Classification loss: 0.41346 | Regression loss: 0.46385 | Running loss: 0.84714\n",
      "Epoch: 0 | Iteration: 37717 | Classification loss: 0.19278 | Regression loss: 0.27075 | Running loss: 0.84658\n",
      "Epoch: 0 | Iteration: 37718 | Classification loss: 0.27449 | Regression loss: 0.59435 | Running loss: 0.84660\n",
      "Epoch: 0 | Iteration: 37719 | Classification loss: 0.35589 | Regression loss: 0.40167 | Running loss: 0.84618\n",
      "Epoch: 0 | Iteration: 37720 | Classification loss: 0.31079 | Regression loss: 0.49158 | Running loss: 0.84679\n",
      "Epoch: 0 | Iteration: 37721 | Classification loss: 0.41138 | Regression loss: 0.67905 | Running loss: 0.84706\n",
      "Epoch: 0 | Iteration: 37722 | Classification loss: 0.39385 | Regression loss: 0.59188 | Running loss: 0.84795\n",
      "Epoch: 0 | Iteration: 37723 | Classification loss: 0.30743 | Regression loss: 0.51023 | Running loss: 0.84772\n",
      "Epoch: 0 | Iteration: 37724 | Classification loss: 0.27996 | Regression loss: 0.43438 | Running loss: 0.84796\n",
      "Epoch: 0 | Iteration: 37725 | Classification loss: 0.70034 | Regression loss: 0.57174 | Running loss: 0.84923\n",
      "Epoch: 0 | Iteration: 37726 | Classification loss: 0.44317 | Regression loss: 0.57600 | Running loss: 0.85007\n",
      "Epoch: 0 | Iteration: 37727 | Classification loss: 0.41731 | Regression loss: 0.58272 | Running loss: 0.85042\n",
      "Epoch: 0 | Iteration: 37728 | Classification loss: 0.52338 | Regression loss: 0.47558 | Running loss: 0.85028\n",
      "Epoch: 0 | Iteration: 37729 | Classification loss: 0.17628 | Regression loss: 0.38193 | Running loss: 0.84973\n",
      "Epoch: 0 | Iteration: 37730 | Classification loss: 0.38795 | Regression loss: 0.47786 | Running loss: 0.85033\n",
      "Epoch: 0 | Iteration: 37731 | Classification loss: 0.26401 | Regression loss: 0.32042 | Running loss: 0.84975\n",
      "Epoch: 0 | Iteration: 37732 | Classification loss: 0.64631 | Regression loss: 0.49462 | Running loss: 0.85103\n",
      "Epoch: 0 | Iteration: 37733 | Classification loss: 0.37593 | Regression loss: 0.42338 | Running loss: 0.85113\n",
      "Epoch: 0 | Iteration: 37734 | Classification loss: 0.46471 | Regression loss: 0.47368 | Running loss: 0.85109\n",
      "Epoch: 0 | Iteration: 37735 | Classification loss: 0.47091 | Regression loss: 0.42317 | Running loss: 0.85137\n",
      "Epoch: 0 | Iteration: 37736 | Classification loss: 0.43415 | Regression loss: 0.56145 | Running loss: 0.85094\n",
      "Epoch: 0 | Iteration: 37737 | Classification loss: 0.45479 | Regression loss: 0.57497 | Running loss: 0.85105\n",
      "Epoch: 0 | Iteration: 37738 | Classification loss: 0.37645 | Regression loss: 0.61684 | Running loss: 0.85167\n",
      "Epoch: 0 | Iteration: 37739 | Classification loss: 0.34602 | Regression loss: 0.44045 | Running loss: 0.85088\n",
      "Epoch: 0 | Iteration: 37740 | Classification loss: 0.33994 | Regression loss: 0.57706 | Running loss: 0.85102\n",
      "Epoch: 0 | Iteration: 37741 | Classification loss: 0.46407 | Regression loss: 0.63632 | Running loss: 0.85147\n",
      "Epoch: 0 | Iteration: 37742 | Classification loss: 0.25909 | Regression loss: 0.37851 | Running loss: 0.85107\n",
      "Epoch: 0 | Iteration: 37743 | Classification loss: 0.15869 | Regression loss: 0.46045 | Running loss: 0.85114\n",
      "Epoch: 0 | Iteration: 37744 | Classification loss: 0.37725 | Regression loss: 0.63114 | Running loss: 0.85119\n",
      "Epoch: 0 | Iteration: 37745 | Classification loss: 0.52478 | Regression loss: 0.63624 | Running loss: 0.85170\n",
      "Epoch: 0 | Iteration: 37746 | Classification loss: 0.66933 | Regression loss: 0.89440 | Running loss: 0.85330\n",
      "Epoch: 0 | Iteration: 37747 | Classification loss: 0.52576 | Regression loss: 0.55221 | Running loss: 0.85330\n",
      "Epoch: 0 | Iteration: 37748 | Classification loss: 0.34654 | Regression loss: 0.47910 | Running loss: 0.85371\n",
      "Epoch: 0 | Iteration: 37749 | Classification loss: 0.46952 | Regression loss: 0.66523 | Running loss: 0.85423\n",
      "Epoch: 0 | Iteration: 37750 | Classification loss: 0.44341 | Regression loss: 0.74862 | Running loss: 0.85470\n",
      "Epoch: 0 | Iteration: 37751 | Classification loss: 0.47305 | Regression loss: 0.57063 | Running loss: 0.85537\n",
      "Epoch: 0 | Iteration: 37752 | Classification loss: 0.28330 | Regression loss: 0.35935 | Running loss: 0.85547\n",
      "Epoch: 0 | Iteration: 37753 | Classification loss: 0.18204 | Regression loss: 0.33826 | Running loss: 0.85377\n",
      "Epoch: 0 | Iteration: 37754 | Classification loss: 0.32819 | Regression loss: 0.49040 | Running loss: 0.85262\n",
      "Epoch: 0 | Iteration: 37755 | Classification loss: 0.56034 | Regression loss: 0.64227 | Running loss: 0.85308\n",
      "Epoch: 0 | Iteration: 37756 | Classification loss: 0.62887 | Regression loss: 0.47579 | Running loss: 0.85352\n",
      "Epoch: 0 | Iteration: 37757 | Classification loss: 0.46049 | Regression loss: 0.61731 | Running loss: 0.85396\n",
      "Epoch: 0 | Iteration: 37758 | Classification loss: 0.30219 | Regression loss: 0.40003 | Running loss: 0.85322\n",
      "Epoch: 0 | Iteration: 37759 | Classification loss: 0.44092 | Regression loss: 0.35858 | Running loss: 0.85302\n",
      "Epoch: 0 | Iteration: 37760 | Classification loss: 0.65525 | Regression loss: 0.64444 | Running loss: 0.85413\n",
      "Epoch: 0 | Iteration: 37761 | Classification loss: 0.47514 | Regression loss: 0.63784 | Running loss: 0.85432\n",
      "Epoch: 0 | Iteration: 37762 | Classification loss: 0.27758 | Regression loss: 0.50086 | Running loss: 0.85391\n",
      "Epoch: 0 | Iteration: 37763 | Classification loss: 0.60193 | Regression loss: 0.56660 | Running loss: 0.85505\n",
      "Epoch: 0 | Iteration: 37764 | Classification loss: 0.43046 | Regression loss: 0.41079 | Running loss: 0.85481\n",
      "Epoch: 0 | Iteration: 37765 | Classification loss: 0.31453 | Regression loss: 0.55574 | Running loss: 0.85409\n",
      "Epoch: 0 | Iteration: 37766 | Classification loss: 0.35866 | Regression loss: 0.59563 | Running loss: 0.85518\n",
      "Epoch: 0 | Iteration: 37767 | Classification loss: 0.38405 | Regression loss: 0.53554 | Running loss: 0.85598\n",
      "Epoch: 0 | Iteration: 37768 | Classification loss: 0.52568 | Regression loss: 0.63997 | Running loss: 0.85640\n",
      "Epoch: 0 | Iteration: 37769 | Classification loss: 0.42516 | Regression loss: 0.66444 | Running loss: 0.85676\n",
      "Epoch: 0 | Iteration: 37770 | Classification loss: 0.32222 | Regression loss: 0.47569 | Running loss: 0.85655\n",
      "Epoch: 0 | Iteration: 37771 | Classification loss: 0.42396 | Regression loss: 0.44702 | Running loss: 0.85618\n",
      "Epoch: 0 | Iteration: 37772 | Classification loss: 0.43445 | Regression loss: 0.57159 | Running loss: 0.85698\n",
      "Epoch: 0 | Iteration: 37773 | Classification loss: 0.41606 | Regression loss: 0.57265 | Running loss: 0.85708\n",
      "Epoch: 0 | Iteration: 37774 | Classification loss: 0.38291 | Regression loss: 0.38586 | Running loss: 0.85789\n",
      "Epoch: 0 | Iteration: 37775 | Classification loss: 0.29146 | Regression loss: 0.49186 | Running loss: 0.85728\n",
      "Epoch: 0 | Iteration: 37776 | Classification loss: 0.38303 | Regression loss: 0.44329 | Running loss: 0.85714\n",
      "Epoch: 0 | Iteration: 37777 | Classification loss: 0.20179 | Regression loss: 0.48747 | Running loss: 0.85666\n",
      "Epoch: 0 | Iteration: 37778 | Classification loss: 0.22718 | Regression loss: 0.39145 | Running loss: 0.85585\n",
      "Epoch: 0 | Iteration: 37779 | Classification loss: 0.51756 | Regression loss: 0.39813 | Running loss: 0.85550\n",
      "Epoch: 0 | Iteration: 37780 | Classification loss: 0.36996 | Regression loss: 0.54212 | Running loss: 0.85632\n",
      "Epoch: 0 | Iteration: 37781 | Classification loss: 0.34253 | Regression loss: 0.56972 | Running loss: 0.85753\n",
      "Epoch: 0 | Iteration: 37782 | Classification loss: 0.07857 | Regression loss: 0.33089 | Running loss: 0.85653\n",
      "Epoch: 0 | Iteration: 37783 | Classification loss: 0.28655 | Regression loss: 0.49959 | Running loss: 0.85676\n",
      "Epoch: 0 | Iteration: 37784 | Classification loss: 0.49647 | Regression loss: 0.41582 | Running loss: 0.85657\n",
      "Epoch: 0 | Iteration: 37785 | Classification loss: 0.31906 | Regression loss: 0.50134 | Running loss: 0.85692\n",
      "Epoch: 0 | Iteration: 37786 | Classification loss: 0.38886 | Regression loss: 0.55466 | Running loss: 0.85662\n",
      "Epoch: 0 | Iteration: 37787 | Classification loss: 0.30459 | Regression loss: 0.38102 | Running loss: 0.85666\n",
      "Epoch: 0 | Iteration: 37788 | Classification loss: 0.30296 | Regression loss: 0.42506 | Running loss: 0.85702\n",
      "Epoch: 0 | Iteration: 37789 | Classification loss: 0.38448 | Regression loss: 0.41451 | Running loss: 0.85633\n",
      "Epoch: 0 | Iteration: 37790 | Classification loss: 0.53485 | Regression loss: 0.52429 | Running loss: 0.85738\n",
      "Epoch: 0 | Iteration: 37791 | Classification loss: 0.41030 | Regression loss: 0.73143 | Running loss: 0.85765\n",
      "Epoch: 0 | Iteration: 37792 | Classification loss: 0.28768 | Regression loss: 0.51258 | Running loss: 0.85694\n",
      "Epoch: 0 | Iteration: 37793 | Classification loss: 0.09873 | Regression loss: 0.26255 | Running loss: 0.85625\n",
      "Epoch: 0 | Iteration: 37794 | Classification loss: 0.24929 | Regression loss: 0.39873 | Running loss: 0.85558\n",
      "Epoch: 0 | Iteration: 37795 | Classification loss: 0.42340 | Regression loss: 0.35805 | Running loss: 0.85607\n",
      "Epoch: 0 | Iteration: 37796 | Classification loss: 0.31182 | Regression loss: 0.63608 | Running loss: 0.85668\n",
      "Epoch: 0 | Iteration: 37797 | Classification loss: 0.39134 | Regression loss: 0.55622 | Running loss: 0.85706\n",
      "Epoch: 0 | Iteration: 37798 | Classification loss: 0.40609 | Regression loss: 0.61981 | Running loss: 0.85784\n",
      "Epoch: 0 | Iteration: 37799 | Classification loss: 0.22812 | Regression loss: 0.39171 | Running loss: 0.85807\n",
      "Epoch: 0 | Iteration: 37800 | Classification loss: 0.54269 | Regression loss: 0.58850 | Running loss: 0.85891\n",
      "Epoch: 0 | Iteration: 37801 | Classification loss: 0.27239 | Regression loss: 0.63108 | Running loss: 0.85926\n",
      "Epoch: 0 | Iteration: 37802 | Classification loss: 0.38389 | Regression loss: 0.45405 | Running loss: 0.86005\n",
      "Epoch: 0 | Iteration: 37803 | Classification loss: 0.53701 | Regression loss: 0.66197 | Running loss: 0.85936\n",
      "Epoch: 0 | Iteration: 37804 | Classification loss: 0.28990 | Regression loss: 0.42299 | Running loss: 0.85915\n",
      "Epoch: 0 | Iteration: 37805 | Classification loss: 0.20611 | Regression loss: 0.33663 | Running loss: 0.85909\n",
      "Epoch: 0 | Iteration: 37806 | Classification loss: 0.56566 | Regression loss: 0.45383 | Running loss: 0.85905\n",
      "Epoch: 0 | Iteration: 37807 | Classification loss: 0.32910 | Regression loss: 0.69257 | Running loss: 0.85893\n",
      "Epoch: 0 | Iteration: 37808 | Classification loss: 0.23734 | Regression loss: 0.48408 | Running loss: 0.85882\n",
      "Epoch: 0 | Iteration: 37809 | Classification loss: 0.30844 | Regression loss: 0.54409 | Running loss: 0.85874\n",
      "Epoch: 0 | Iteration: 37810 | Classification loss: 0.21331 | Regression loss: 0.19863 | Running loss: 0.85812\n",
      "Epoch: 0 | Iteration: 37811 | Classification loss: 0.35512 | Regression loss: 0.39553 | Running loss: 0.85783\n",
      "Epoch: 0 | Iteration: 37812 | Classification loss: 0.33794 | Regression loss: 0.51952 | Running loss: 0.85833\n",
      "Epoch: 0 | Iteration: 37813 | Classification loss: 0.35924 | Regression loss: 0.43091 | Running loss: 0.85858\n",
      "Epoch: 0 | Iteration: 37814 | Classification loss: 0.28052 | Regression loss: 0.34400 | Running loss: 0.85753\n",
      "Epoch: 0 | Iteration: 37815 | Classification loss: 0.37614 | Regression loss: 0.56733 | Running loss: 0.85802\n",
      "Epoch: 0 | Iteration: 37816 | Classification loss: 0.23552 | Regression loss: 0.30329 | Running loss: 0.85712\n",
      "Epoch: 0 | Iteration: 37817 | Classification loss: 0.31354 | Regression loss: 0.42696 | Running loss: 0.85694\n",
      "Epoch: 0 | Iteration: 37818 | Classification loss: 0.58725 | Regression loss: 0.62995 | Running loss: 0.85822\n",
      "Epoch: 0 | Iteration: 37819 | Classification loss: 0.27206 | Regression loss: 0.37301 | Running loss: 0.85840\n",
      "Epoch: 0 | Iteration: 37820 | Classification loss: 0.18910 | Regression loss: 0.38217 | Running loss: 0.85754\n",
      "Epoch: 0 | Iteration: 37821 | Classification loss: 0.19383 | Regression loss: 0.26174 | Running loss: 0.85671\n",
      "Epoch: 0 | Iteration: 37822 | Classification loss: 1.19121 | Regression loss: 0.13661 | Running loss: 0.85761\n",
      "Epoch: 0 | Iteration: 37823 | Classification loss: 0.48651 | Regression loss: 0.27489 | Running loss: 0.85720\n",
      "Epoch: 0 | Iteration: 37824 | Classification loss: 0.39383 | Regression loss: 0.34187 | Running loss: 0.85686\n",
      "Epoch: 0 | Iteration: 37825 | Classification loss: 0.19890 | Regression loss: 0.40319 | Running loss: 0.85537\n",
      "Epoch: 0 | Iteration: 37826 | Classification loss: 0.57444 | Regression loss: 0.57769 | Running loss: 0.85579\n",
      "Epoch: 0 | Iteration: 37827 | Classification loss: 0.32613 | Regression loss: 0.43718 | Running loss: 0.85600\n",
      "Epoch: 0 | Iteration: 37828 | Classification loss: 0.50414 | Regression loss: 0.54836 | Running loss: 0.85651\n",
      "Epoch: 0 | Iteration: 37829 | Classification loss: 0.53279 | Regression loss: 0.76000 | Running loss: 0.85686\n",
      "Epoch: 0 | Iteration: 37830 | Classification loss: 0.30266 | Regression loss: 0.45882 | Running loss: 0.85665\n",
      "Epoch: 0 | Iteration: 37831 | Classification loss: 0.44571 | Regression loss: 0.51486 | Running loss: 0.85685\n",
      "Epoch: 0 | Iteration: 37832 | Classification loss: 0.29585 | Regression loss: 0.53351 | Running loss: 0.85631\n",
      "Epoch: 0 | Iteration: 37833 | Classification loss: 0.46112 | Regression loss: 0.49975 | Running loss: 0.85619\n",
      "Epoch: 0 | Iteration: 37834 | Classification loss: 0.49611 | Regression loss: 0.67398 | Running loss: 0.85678\n",
      "Epoch: 0 | Iteration: 37835 | Classification loss: 0.40625 | Regression loss: 0.57924 | Running loss: 0.85793\n",
      "Epoch: 0 | Iteration: 37836 | Classification loss: 0.25790 | Regression loss: 0.55398 | Running loss: 0.85767\n",
      "Epoch: 0 | Iteration: 37837 | Classification loss: 0.38842 | Regression loss: 0.53476 | Running loss: 0.85733\n",
      "Epoch: 0 | Iteration: 37838 | Classification loss: 0.43761 | Regression loss: 0.51511 | Running loss: 0.85708\n",
      "Epoch: 0 | Iteration: 37839 | Classification loss: 0.32008 | Regression loss: 0.21041 | Running loss: 0.85696\n",
      "Epoch: 0 | Iteration: 37840 | Classification loss: 0.37447 | Regression loss: 0.51954 | Running loss: 0.85637\n",
      "Epoch: 0 | Iteration: 37841 | Classification loss: 0.28421 | Regression loss: 0.55841 | Running loss: 0.85641\n",
      "Epoch: 0 | Iteration: 37842 | Classification loss: 0.48084 | Regression loss: 0.64016 | Running loss: 0.85669\n",
      "Epoch: 0 | Iteration: 37843 | Classification loss: 0.31755 | Regression loss: 0.50998 | Running loss: 0.85750\n",
      "Epoch: 0 | Iteration: 37844 | Classification loss: 0.46675 | Regression loss: 0.55870 | Running loss: 0.85832\n",
      "Epoch: 0 | Iteration: 37845 | Classification loss: 0.32328 | Regression loss: 0.50130 | Running loss: 0.85834\n",
      "Epoch: 0 | Iteration: 37846 | Classification loss: 0.59202 | Regression loss: 0.46984 | Running loss: 0.85886\n",
      "Epoch: 0 | Iteration: 37847 | Classification loss: 0.70058 | Regression loss: 0.44677 | Running loss: 0.85906\n",
      "Epoch: 0 | Iteration: 37848 | Classification loss: 0.47383 | Regression loss: 0.46679 | Running loss: 0.85972\n",
      "Epoch: 0 | Iteration: 37849 | Classification loss: 0.24429 | Regression loss: 0.26863 | Running loss: 0.85909\n",
      "Epoch: 0 | Iteration: 37850 | Classification loss: 0.55863 | Regression loss: 0.68575 | Running loss: 0.85978\n",
      "Epoch: 0 | Iteration: 37851 | Classification loss: 0.25117 | Regression loss: 0.31902 | Running loss: 0.85958\n",
      "Epoch: 0 | Iteration: 37852 | Classification loss: 0.45468 | Regression loss: 0.72036 | Running loss: 0.85998\n",
      "Epoch: 0 | Iteration: 37853 | Classification loss: 0.23079 | Regression loss: 0.40648 | Running loss: 0.85963\n",
      "Epoch: 0 | Iteration: 37854 | Classification loss: 0.27220 | Regression loss: 0.38504 | Running loss: 0.85906\n",
      "Epoch: 0 | Iteration: 37855 | Classification loss: 0.65622 | Regression loss: 0.54912 | Running loss: 0.85933\n",
      "Epoch: 0 | Iteration: 37856 | Classification loss: 0.19199 | Regression loss: 0.23091 | Running loss: 0.85860\n",
      "Epoch: 0 | Iteration: 37857 | Classification loss: 0.35040 | Regression loss: 0.61041 | Running loss: 0.85884\n",
      "Epoch: 0 | Iteration: 37858 | Classification loss: 0.52970 | Regression loss: 0.40371 | Running loss: 0.85875\n",
      "Epoch: 0 | Iteration: 37859 | Classification loss: 0.38455 | Regression loss: 0.55591 | Running loss: 0.85848\n",
      "Epoch: 0 | Iteration: 37860 | Classification loss: 0.24716 | Regression loss: 0.45651 | Running loss: 0.85773\n",
      "Epoch: 0 | Iteration: 37861 | Classification loss: 0.30065 | Regression loss: 0.63162 | Running loss: 0.85761\n",
      "Epoch: 0 | Iteration: 37862 | Classification loss: 0.61409 | Regression loss: 0.61241 | Running loss: 0.85679\n",
      "Epoch: 0 | Iteration: 37863 | Classification loss: 0.52606 | Regression loss: 0.51931 | Running loss: 0.85675\n",
      "Epoch: 0 | Iteration: 37864 | Classification loss: 0.36565 | Regression loss: 0.47878 | Running loss: 0.85663\n",
      "Epoch: 0 | Iteration: 37865 | Classification loss: 0.36440 | Regression loss: 0.35671 | Running loss: 0.85698\n",
      "Epoch: 0 | Iteration: 37866 | Classification loss: 0.46969 | Regression loss: 0.40126 | Running loss: 0.85673\n",
      "Epoch: 0 | Iteration: 37867 | Classification loss: 0.34559 | Regression loss: 0.44380 | Running loss: 0.85745\n",
      "Epoch: 0 | Iteration: 37868 | Classification loss: 0.31249 | Regression loss: 0.57170 | Running loss: 0.85769\n",
      "Epoch: 0 | Iteration: 37869 | Classification loss: 0.29528 | Regression loss: 0.58489 | Running loss: 0.85766\n",
      "Epoch: 0 | Iteration: 37870 | Classification loss: 0.25450 | Regression loss: 0.37392 | Running loss: 0.85720\n",
      "Epoch: 0 | Iteration: 37871 | Classification loss: 0.29447 | Regression loss: 0.41005 | Running loss: 0.85642\n",
      "Epoch: 0 | Iteration: 37872 | Classification loss: 0.42001 | Regression loss: 0.35313 | Running loss: 0.85621\n",
      "Epoch: 0 | Iteration: 37873 | Classification loss: 0.60079 | Regression loss: 0.62900 | Running loss: 0.85800\n",
      "Epoch: 0 | Iteration: 37874 | Classification loss: 0.29959 | Regression loss: 0.43029 | Running loss: 0.85737\n",
      "Epoch: 0 | Iteration: 37875 | Classification loss: 0.35895 | Regression loss: 0.71129 | Running loss: 0.85734\n",
      "Epoch: 0 | Iteration: 37876 | Classification loss: 0.30652 | Regression loss: 0.44968 | Running loss: 0.85786\n",
      "Epoch: 0 | Iteration: 37877 | Classification loss: 0.52998 | Regression loss: 0.66673 | Running loss: 0.85865\n",
      "Epoch: 0 | Iteration: 37878 | Classification loss: 0.33937 | Regression loss: 0.60196 | Running loss: 0.85977\n",
      "Epoch: 0 | Iteration: 37879 | Classification loss: 0.33247 | Regression loss: 0.49190 | Running loss: 0.86026\n",
      "Epoch: 0 | Iteration: 37880 | Classification loss: 0.33503 | Regression loss: 0.53490 | Running loss: 0.86131\n",
      "Epoch: 0 | Iteration: 37881 | Classification loss: 0.35242 | Regression loss: 0.46696 | Running loss: 0.86096\n",
      "Epoch: 0 | Iteration: 37882 | Classification loss: 0.54180 | Regression loss: 0.05852 | Running loss: 0.86017\n",
      "Epoch: 0 | Iteration: 37883 | Classification loss: 0.62803 | Regression loss: 0.78266 | Running loss: 0.86096\n",
      "Epoch: 0 | Iteration: 37884 | Classification loss: 0.44189 | Regression loss: 0.50065 | Running loss: 0.85996\n",
      "Epoch: 0 | Iteration: 37885 | Classification loss: 0.31278 | Regression loss: 0.47184 | Running loss: 0.86004\n",
      "Epoch: 0 | Iteration: 37886 | Classification loss: 0.41053 | Regression loss: 0.46399 | Running loss: 0.86057\n",
      "Epoch: 0 | Iteration: 37887 | Classification loss: 0.51472 | Regression loss: 0.56405 | Running loss: 0.86148\n",
      "Epoch: 0 | Iteration: 37888 | Classification loss: 0.35848 | Regression loss: 0.48248 | Running loss: 0.86142\n",
      "Epoch: 0 | Iteration: 37889 | Classification loss: 0.42735 | Regression loss: 0.56984 | Running loss: 0.86124\n",
      "Epoch: 0 | Iteration: 37890 | Classification loss: 0.34923 | Regression loss: 0.51156 | Running loss: 0.86201\n",
      "Epoch: 0 | Iteration: 37891 | Classification loss: 0.26397 | Regression loss: 0.31844 | Running loss: 0.86086\n",
      "Epoch: 0 | Iteration: 37892 | Classification loss: 0.27161 | Regression loss: 0.46102 | Running loss: 0.86096\n",
      "Epoch: 0 | Iteration: 37893 | Classification loss: 0.38135 | Regression loss: 0.50726 | Running loss: 0.86188\n",
      "Epoch: 0 | Iteration: 37894 | Classification loss: 0.44894 | Regression loss: 0.15498 | Running loss: 0.86070\n",
      "Epoch: 0 | Iteration: 37895 | Classification loss: 0.32966 | Regression loss: 0.50051 | Running loss: 0.86131\n",
      "Epoch: 0 | Iteration: 37896 | Classification loss: 0.37250 | Regression loss: 0.53128 | Running loss: 0.86102\n",
      "Epoch: 0 | Iteration: 37897 | Classification loss: 0.23449 | Regression loss: 0.28423 | Running loss: 0.85975\n",
      "Epoch: 0 | Iteration: 37898 | Classification loss: 0.33431 | Regression loss: 0.52255 | Running loss: 0.85883\n",
      "Epoch: 0 | Iteration: 37899 | Classification loss: 0.41749 | Regression loss: 0.52671 | Running loss: 0.85947\n",
      "Epoch: 0 | Iteration: 37900 | Classification loss: 0.26801 | Regression loss: 0.30101 | Running loss: 0.85841\n",
      "Epoch: 0 | Iteration: 37901 | Classification loss: 0.23550 | Regression loss: 0.30812 | Running loss: 0.85796\n",
      "Epoch: 0 | Iteration: 37902 | Classification loss: 0.36602 | Regression loss: 0.58754 | Running loss: 0.85796\n",
      "Epoch: 0 | Iteration: 37903 | Classification loss: 0.40468 | Regression loss: 0.52554 | Running loss: 0.85789\n",
      "Epoch: 0 | Iteration: 37904 | Classification loss: 0.48754 | Regression loss: 0.44703 | Running loss: 0.85863\n",
      "Epoch: 0 | Iteration: 37905 | Classification loss: 0.26226 | Regression loss: 0.43118 | Running loss: 0.85795\n",
      "Epoch: 0 | Iteration: 37906 | Classification loss: 0.44606 | Regression loss: 0.35621 | Running loss: 0.85778\n",
      "Epoch: 0 | Iteration: 37907 | Classification loss: 0.13014 | Regression loss: 0.41910 | Running loss: 0.85714\n",
      "Epoch: 0 | Iteration: 37908 | Classification loss: 0.55533 | Regression loss: 0.57193 | Running loss: 0.85699\n",
      "Epoch: 0 | Iteration: 37909 | Classification loss: 0.33734 | Regression loss: 0.44809 | Running loss: 0.85725\n",
      "Epoch: 0 | Iteration: 37910 | Classification loss: 0.27449 | Regression loss: 0.44909 | Running loss: 0.85761\n",
      "Epoch: 0 | Iteration: 37911 | Classification loss: 0.39314 | Regression loss: 0.41212 | Running loss: 0.85740\n",
      "Epoch: 0 | Iteration: 37912 | Classification loss: 0.28255 | Regression loss: 0.32843 | Running loss: 0.85627\n",
      "Epoch: 0 | Iteration: 37913 | Classification loss: 0.47045 | Regression loss: 0.49110 | Running loss: 0.85719\n",
      "Epoch: 0 | Iteration: 37914 | Classification loss: 0.11586 | Regression loss: 0.26356 | Running loss: 0.85646\n",
      "Epoch: 0 | Iteration: 37915 | Classification loss: 0.21265 | Regression loss: 0.51507 | Running loss: 0.85656\n",
      "Epoch: 0 | Iteration: 37916 | Classification loss: 0.92289 | Regression loss: 0.32207 | Running loss: 0.85786\n",
      "Epoch: 0 | Iteration: 37917 | Classification loss: 0.24621 | Regression loss: 0.48788 | Running loss: 0.85806\n",
      "Epoch: 0 | Iteration: 37918 | Classification loss: 0.35908 | Regression loss: 0.55028 | Running loss: 0.85762\n",
      "Epoch: 0 | Iteration: 37919 | Classification loss: 0.16683 | Regression loss: 0.40995 | Running loss: 0.85732\n",
      "Epoch: 0 | Iteration: 37920 | Classification loss: 0.12252 | Regression loss: 0.34955 | Running loss: 0.85634\n",
      "Epoch: 0 | Iteration: 37921 | Classification loss: 0.25452 | Regression loss: 0.46458 | Running loss: 0.85637\n",
      "Epoch: 0 | Iteration: 37922 | Classification loss: 0.44996 | Regression loss: 0.68382 | Running loss: 0.85727\n",
      "Epoch: 0 | Iteration: 37923 | Classification loss: 0.41480 | Regression loss: 0.62256 | Running loss: 0.85701\n",
      "Epoch: 0 | Iteration: 37924 | Classification loss: 0.36374 | Regression loss: 0.47122 | Running loss: 0.85711\n",
      "Epoch: 0 | Iteration: 37925 | Classification loss: 0.53758 | Regression loss: 0.51656 | Running loss: 0.85741\n",
      "Epoch: 0 | Iteration: 37926 | Classification loss: 0.52562 | Regression loss: 0.22955 | Running loss: 0.85682\n",
      "Epoch: 0 | Iteration: 37927 | Classification loss: 0.24926 | Regression loss: 0.34653 | Running loss: 0.85563\n",
      "Epoch: 0 | Iteration: 37928 | Classification loss: 0.34268 | Regression loss: 0.65433 | Running loss: 0.85536\n",
      "Epoch: 0 | Iteration: 37929 | Classification loss: 0.49147 | Regression loss: 0.50935 | Running loss: 0.85493\n",
      "Epoch: 0 | Iteration: 37930 | Classification loss: 0.47868 | Regression loss: 0.40802 | Running loss: 0.85520\n",
      "Epoch: 0 | Iteration: 37931 | Classification loss: 0.29749 | Regression loss: 0.34957 | Running loss: 0.85402\n",
      "Epoch: 0 | Iteration: 37932 | Classification loss: 0.33972 | Regression loss: 0.47215 | Running loss: 0.85415\n",
      "Epoch: 0 | Iteration: 37933 | Classification loss: 0.34425 | Regression loss: 0.38779 | Running loss: 0.85360\n",
      "Epoch: 0 | Iteration: 37934 | Classification loss: 0.31818 | Regression loss: 0.49106 | Running loss: 0.85284\n",
      "Epoch: 0 | Iteration: 37935 | Classification loss: 0.23217 | Regression loss: 0.27093 | Running loss: 0.85260\n",
      "Epoch: 0 | Iteration: 37936 | Classification loss: 0.16850 | Regression loss: 0.55407 | Running loss: 0.85268\n",
      "Epoch: 0 | Iteration: 37937 | Classification loss: 1.71497 | Regression loss: 0.29308 | Running loss: 0.85495\n",
      "Epoch: 0 | Iteration: 37938 | Classification loss: 0.46216 | Regression loss: 0.42567 | Running loss: 0.85507\n",
      "Epoch: 0 | Iteration: 37939 | Classification loss: 0.26883 | Regression loss: 0.40930 | Running loss: 0.85516\n",
      "Epoch: 0 | Iteration: 37940 | Classification loss: 0.68515 | Regression loss: 0.73146 | Running loss: 0.85607\n",
      "Epoch: 0 | Iteration: 37941 | Classification loss: 0.39943 | Regression loss: 0.49452 | Running loss: 0.85592\n",
      "Epoch: 0 | Iteration: 37942 | Classification loss: 0.32668 | Regression loss: 0.48137 | Running loss: 0.85507\n",
      "Epoch: 0 | Iteration: 37943 | Classification loss: 0.39496 | Regression loss: 0.44911 | Running loss: 0.85522\n",
      "Epoch: 0 | Iteration: 37944 | Classification loss: 0.45825 | Regression loss: 0.59184 | Running loss: 0.85605\n",
      "Epoch: 0 | Iteration: 37945 | Classification loss: 0.81905 | Regression loss: 0.99262 | Running loss: 0.85835\n",
      "Epoch: 0 | Iteration: 37946 | Classification loss: 0.32180 | Regression loss: 0.59024 | Running loss: 0.85861\n",
      "Epoch: 0 | Iteration: 37947 | Classification loss: 0.41669 | Regression loss: 0.47487 | Running loss: 0.85880\n",
      "Epoch: 0 | Iteration: 37948 | Classification loss: 0.32419 | Regression loss: 0.53656 | Running loss: 0.85779\n",
      "Epoch: 0 | Iteration: 37949 | Classification loss: 0.12268 | Regression loss: 0.25270 | Running loss: 0.85636\n",
      "Epoch: 0 | Iteration: 37950 | Classification loss: 0.36085 | Regression loss: 0.64131 | Running loss: 0.85660\n",
      "Epoch: 0 | Iteration: 37951 | Classification loss: 0.31040 | Regression loss: 0.53329 | Running loss: 0.85713\n",
      "Epoch: 0 | Iteration: 37952 | Classification loss: 0.20804 | Regression loss: 0.45352 | Running loss: 0.85701\n",
      "Epoch: 0 | Iteration: 37953 | Classification loss: 0.33552 | Regression loss: 0.53891 | Running loss: 0.85651\n",
      "Epoch: 0 | Iteration: 37954 | Classification loss: 0.29122 | Regression loss: 0.47379 | Running loss: 0.85606\n",
      "Epoch: 0 | Iteration: 37955 | Classification loss: 0.42407 | Regression loss: 0.52393 | Running loss: 0.85628\n",
      "Epoch: 0 | Iteration: 37956 | Classification loss: 0.42186 | Regression loss: 0.51421 | Running loss: 0.85641\n",
      "Epoch: 0 | Iteration: 37957 | Classification loss: 0.24702 | Regression loss: 0.42602 | Running loss: 0.85603\n",
      "Epoch: 0 | Iteration: 37958 | Classification loss: 0.45444 | Regression loss: 0.44420 | Running loss: 0.85663\n",
      "Epoch: 0 | Iteration: 37959 | Classification loss: 0.15318 | Regression loss: 0.33456 | Running loss: 0.85582\n",
      "Epoch: 0 | Iteration: 37960 | Classification loss: 0.25468 | Regression loss: 0.49085 | Running loss: 0.85523\n",
      "Epoch: 0 | Iteration: 37961 | Classification loss: 0.23358 | Regression loss: 0.42715 | Running loss: 0.85408\n",
      "Epoch: 0 | Iteration: 37962 | Classification loss: 0.29892 | Regression loss: 0.25227 | Running loss: 0.85405\n",
      "Epoch: 0 | Iteration: 37963 | Classification loss: 0.41830 | Regression loss: 0.58039 | Running loss: 0.85415\n",
      "Epoch: 0 | Iteration: 37964 | Classification loss: 0.35507 | Regression loss: 0.47463 | Running loss: 0.85375\n",
      "Epoch: 0 | Iteration: 37965 | Classification loss: 0.36257 | Regression loss: 0.44535 | Running loss: 0.85380\n",
      "Epoch: 0 | Iteration: 37966 | Classification loss: 0.45813 | Regression loss: 0.52805 | Running loss: 0.85401\n",
      "Epoch: 0 | Iteration: 37967 | Classification loss: 0.31241 | Regression loss: 0.45588 | Running loss: 0.85364\n",
      "Epoch: 0 | Iteration: 37968 | Classification loss: 0.46192 | Regression loss: 0.36901 | Running loss: 0.85346\n",
      "Epoch: 0 | Iteration: 37969 | Classification loss: 0.30331 | Regression loss: 0.45063 | Running loss: 0.85276\n",
      "Epoch: 0 | Iteration: 37970 | Classification loss: 0.52243 | Regression loss: 0.63605 | Running loss: 0.85293\n",
      "Epoch: 0 | Iteration: 37971 | Classification loss: 0.33943 | Regression loss: 0.53055 | Running loss: 0.85340\n",
      "Epoch: 0 | Iteration: 37972 | Classification loss: 0.37140 | Regression loss: 0.57762 | Running loss: 0.85379\n",
      "Epoch: 0 | Iteration: 37973 | Classification loss: 0.22177 | Regression loss: 0.34382 | Running loss: 0.85320\n",
      "Epoch: 0 | Iteration: 37974 | Classification loss: 0.18773 | Regression loss: 0.42091 | Running loss: 0.85236\n",
      "Epoch: 0 | Iteration: 37975 | Classification loss: 0.44046 | Regression loss: 0.58312 | Running loss: 0.85272\n",
      "Epoch: 0 | Iteration: 37976 | Classification loss: 0.33878 | Regression loss: 0.48984 | Running loss: 0.85292\n",
      "Epoch: 0 | Iteration: 37977 | Classification loss: 0.21095 | Regression loss: 0.23017 | Running loss: 0.85176\n",
      "Epoch: 0 | Iteration: 37978 | Classification loss: 0.17319 | Regression loss: 0.13421 | Running loss: 0.85096\n",
      "Epoch: 0 | Iteration: 37979 | Classification loss: 0.28949 | Regression loss: 0.37009 | Running loss: 0.85098\n",
      "Epoch: 0 | Iteration: 37980 | Classification loss: 0.45729 | Regression loss: 0.40959 | Running loss: 0.85180\n",
      "Epoch: 0 | Iteration: 37981 | Classification loss: 0.19608 | Regression loss: 0.52996 | Running loss: 0.85162\n",
      "Epoch: 0 | Iteration: 37982 | Classification loss: 2.03735 | Regression loss: 0.56974 | Running loss: 0.85490\n",
      "Epoch: 0 | Iteration: 37983 | Classification loss: 0.15510 | Regression loss: 0.30234 | Running loss: 0.85424\n",
      "Epoch: 0 | Iteration: 37984 | Classification loss: 0.34416 | Regression loss: 0.22943 | Running loss: 0.85361\n",
      "Epoch: 0 | Iteration: 37985 | Classification loss: 0.31031 | Regression loss: 0.57710 | Running loss: 0.85339\n",
      "Epoch: 0 | Iteration: 37986 | Classification loss: 0.23562 | Regression loss: 0.38521 | Running loss: 0.85312\n",
      "Epoch: 0 | Iteration: 37987 | Classification loss: 0.31375 | Regression loss: 0.48709 | Running loss: 0.85251\n",
      "Epoch: 0 | Iteration: 37988 | Classification loss: 0.43822 | Regression loss: 0.58964 | Running loss: 0.85266\n",
      "Epoch: 0 | Iteration: 37989 | Classification loss: 0.27282 | Regression loss: 0.51094 | Running loss: 0.85294\n",
      "Epoch: 0 | Iteration: 37990 | Classification loss: 0.51166 | Regression loss: 0.40883 | Running loss: 0.85317\n",
      "Epoch: 0 | Iteration: 37991 | Classification loss: 0.41350 | Regression loss: 0.60514 | Running loss: 0.85114\n",
      "Epoch: 0 | Iteration: 37992 | Classification loss: 0.37812 | Regression loss: 0.40992 | Running loss: 0.85050\n",
      "Epoch: 0 | Iteration: 37993 | Classification loss: 0.39929 | Regression loss: 0.72073 | Running loss: 0.85160\n",
      "Epoch: 0 | Iteration: 37994 | Classification loss: 0.24968 | Regression loss: 0.29310 | Running loss: 0.85177\n",
      "Epoch: 0 | Iteration: 37995 | Classification loss: 0.23067 | Regression loss: 0.43907 | Running loss: 0.85199\n",
      "Epoch: 0 | Iteration: 37996 | Classification loss: 0.28638 | Regression loss: 0.52939 | Running loss: 0.85225\n",
      "Epoch: 0 | Iteration: 37997 | Classification loss: 0.44025 | Regression loss: 0.65318 | Running loss: 0.85369\n",
      "Epoch: 0 | Iteration: 37998 | Classification loss: 0.34558 | Regression loss: 0.50604 | Running loss: 0.85396\n",
      "Epoch: 0 | Iteration: 37999 | Classification loss: 0.36019 | Regression loss: 0.71722 | Running loss: 0.85462\n",
      "Epoch: 0 | Iteration: 38000 | Classification loss: 0.33088 | Regression loss: 0.67226 | Running loss: 0.85466\n",
      "Epoch: 0 | Iteration: 38001 | Classification loss: 0.35030 | Regression loss: 0.36085 | Running loss: 0.85446\n",
      "Epoch: 0 | Iteration: 38002 | Classification loss: 0.29723 | Regression loss: 0.50949 | Running loss: 0.85464\n",
      "Epoch: 0 | Iteration: 38003 | Classification loss: 0.30307 | Regression loss: 0.52407 | Running loss: 0.85545\n",
      "Epoch: 0 | Iteration: 38004 | Classification loss: 0.46474 | Regression loss: 0.58734 | Running loss: 0.85599\n",
      "Epoch: 0 | Iteration: 38005 | Classification loss: 0.45418 | Regression loss: 0.58625 | Running loss: 0.85677\n",
      "Epoch: 0 | Iteration: 38006 | Classification loss: 0.58205 | Regression loss: 0.67001 | Running loss: 0.85742\n",
      "Epoch: 0 | Iteration: 38007 | Classification loss: 0.46058 | Regression loss: 0.57972 | Running loss: 0.85789\n",
      "Epoch: 0 | Iteration: 38008 | Classification loss: 0.56974 | Regression loss: 0.57529 | Running loss: 0.85818\n",
      "Epoch: 0 | Iteration: 38009 | Classification loss: 0.26255 | Regression loss: 0.53499 | Running loss: 0.85870\n",
      "Epoch: 0 | Iteration: 38010 | Classification loss: 0.35074 | Regression loss: 0.51598 | Running loss: 0.85912\n",
      "Epoch: 0 | Iteration: 38011 | Classification loss: 0.34866 | Regression loss: 0.36886 | Running loss: 0.85915\n",
      "Epoch: 0 | Iteration: 38012 | Classification loss: 0.50466 | Regression loss: 0.52098 | Running loss: 0.85886\n",
      "Epoch: 0 | Iteration: 38013 | Classification loss: 0.41186 | Regression loss: 0.50430 | Running loss: 0.85866\n",
      "Epoch: 0 | Iteration: 38014 | Classification loss: 0.20207 | Regression loss: 0.39386 | Running loss: 0.85848\n",
      "Epoch: 0 | Iteration: 38015 | Classification loss: 0.36089 | Regression loss: 0.47758 | Running loss: 0.85870\n",
      "Epoch: 0 | Iteration: 38016 | Classification loss: 0.17370 | Regression loss: 0.35828 | Running loss: 0.85797\n",
      "Epoch: 0 | Iteration: 38017 | Classification loss: 0.24348 | Regression loss: 0.52209 | Running loss: 0.85781\n",
      "Epoch: 0 | Iteration: 38018 | Classification loss: 0.44684 | Regression loss: 0.60917 | Running loss: 0.85820\n",
      "Epoch: 0 | Iteration: 38019 | Classification loss: 0.26789 | Regression loss: 0.46001 | Running loss: 0.85632\n",
      "Epoch: 0 | Iteration: 38020 | Classification loss: 0.21152 | Regression loss: 0.31692 | Running loss: 0.85628\n",
      "Epoch: 0 | Iteration: 38021 | Classification loss: 0.50875 | Regression loss: 0.47312 | Running loss: 0.85638\n",
      "Epoch: 0 | Iteration: 38022 | Classification loss: 0.47387 | Regression loss: 0.57974 | Running loss: 0.85702\n",
      "Epoch: 0 | Iteration: 38023 | Classification loss: 0.34881 | Regression loss: 0.51782 | Running loss: 0.85679\n",
      "Epoch: 0 | Iteration: 38024 | Classification loss: 0.41303 | Regression loss: 0.49731 | Running loss: 0.85730\n",
      "Epoch: 0 | Iteration: 38025 | Classification loss: 0.32240 | Regression loss: 0.39564 | Running loss: 0.85756\n",
      "Epoch: 0 | Iteration: 38026 | Classification loss: 0.39516 | Regression loss: 0.52672 | Running loss: 0.85766\n",
      "Epoch: 0 | Iteration: 38027 | Classification loss: 0.32412 | Regression loss: 0.44292 | Running loss: 0.85734\n",
      "Epoch: 0 | Iteration: 38028 | Classification loss: 0.34381 | Regression loss: 0.51849 | Running loss: 0.85792\n",
      "Epoch: 0 | Iteration: 38029 | Classification loss: 0.32809 | Regression loss: 0.53995 | Running loss: 0.85825\n",
      "Epoch: 0 | Iteration: 38030 | Classification loss: 0.41387 | Regression loss: 0.49007 | Running loss: 0.85886\n",
      "Epoch: 0 | Iteration: 38031 | Classification loss: 0.38509 | Regression loss: 0.57768 | Running loss: 0.85888\n",
      "Epoch: 0 | Iteration: 38032 | Classification loss: 0.37198 | Regression loss: 0.31848 | Running loss: 0.85789\n",
      "Epoch: 0 | Iteration: 38033 | Classification loss: 0.29421 | Regression loss: 0.42294 | Running loss: 0.85798\n",
      "Epoch: 0 | Iteration: 38034 | Classification loss: 0.22548 | Regression loss: 0.43555 | Running loss: 0.85845\n",
      "Epoch: 0 | Iteration: 38035 | Classification loss: 0.63022 | Regression loss: 0.78812 | Running loss: 0.86015\n",
      "Epoch: 0 | Iteration: 38036 | Classification loss: 0.31813 | Regression loss: 0.39555 | Running loss: 0.86093\n",
      "Epoch: 0 | Iteration: 38037 | Classification loss: 0.30468 | Regression loss: 0.49331 | Running loss: 0.86099\n",
      "Epoch: 0 | Iteration: 38038 | Classification loss: 0.28163 | Regression loss: 0.29152 | Running loss: 0.86052\n",
      "Epoch: 0 | Iteration: 38039 | Classification loss: 0.63312 | Regression loss: 0.64470 | Running loss: 0.86175\n",
      "Epoch: 0 | Iteration: 38040 | Classification loss: 0.33889 | Regression loss: 0.36194 | Running loss: 0.86147\n",
      "Epoch: 0 | Iteration: 38041 | Classification loss: 0.65294 | Regression loss: 0.76224 | Running loss: 0.86223\n",
      "Epoch: 0 | Iteration: 38042 | Classification loss: 0.37137 | Regression loss: 0.39186 | Running loss: 0.86166\n",
      "Epoch: 0 | Iteration: 38043 | Classification loss: 0.30664 | Regression loss: 0.59147 | Running loss: 0.86083\n",
      "Epoch: 0 | Iteration: 38044 | Classification loss: 0.38185 | Regression loss: 0.47020 | Running loss: 0.86123\n",
      "Epoch: 0 | Iteration: 38045 | Classification loss: 0.48581 | Regression loss: 0.62115 | Running loss: 0.86170\n",
      "Epoch: 0 | Iteration: 38046 | Classification loss: 0.35619 | Regression loss: 0.61571 | Running loss: 0.86134\n",
      "Epoch: 0 | Iteration: 38047 | Classification loss: 0.28736 | Regression loss: 0.42345 | Running loss: 0.86131\n",
      "Epoch: 0 | Iteration: 38048 | Classification loss: 0.20771 | Regression loss: 0.33540 | Running loss: 0.86067\n",
      "Epoch: 0 | Iteration: 38049 | Classification loss: 0.36131 | Regression loss: 0.46930 | Running loss: 0.86077\n",
      "Epoch: 0 | Iteration: 38050 | Classification loss: 0.58037 | Regression loss: 0.71278 | Running loss: 0.86098\n",
      "Epoch: 0 | Iteration: 38051 | Classification loss: 0.44648 | Regression loss: 0.52933 | Running loss: 0.86116\n",
      "Epoch: 0 | Iteration: 38052 | Classification loss: 0.31945 | Regression loss: 0.44558 | Running loss: 0.86063\n",
      "Epoch: 0 | Iteration: 38053 | Classification loss: 0.29586 | Regression loss: 0.45245 | Running loss: 0.86011\n",
      "Epoch: 0 | Iteration: 38054 | Classification loss: 0.36792 | Regression loss: 0.66474 | Running loss: 0.86057\n",
      "Epoch: 0 | Iteration: 38055 | Classification loss: 0.44018 | Regression loss: 0.57577 | Running loss: 0.86044\n",
      "Epoch: 0 | Iteration: 38056 | Classification loss: 0.26969 | Regression loss: 0.32376 | Running loss: 0.85970\n",
      "Epoch: 0 | Iteration: 38057 | Classification loss: 0.57373 | Regression loss: 0.72615 | Running loss: 0.86111\n",
      "Epoch: 0 | Iteration: 38058 | Classification loss: 0.17009 | Regression loss: 0.41710 | Running loss: 0.85951\n",
      "Epoch: 0 | Iteration: 38059 | Classification loss: 0.46109 | Regression loss: 0.52689 | Running loss: 0.85981\n",
      "Epoch: 0 | Iteration: 38060 | Classification loss: 0.47598 | Regression loss: 0.29410 | Running loss: 0.85921\n",
      "Epoch: 0 | Iteration: 38061 | Classification loss: 0.59057 | Regression loss: 0.38823 | Running loss: 0.85966\n",
      "Epoch: 0 | Iteration: 38062 | Classification loss: 0.41866 | Regression loss: 0.65768 | Running loss: 0.86014\n",
      "Epoch: 0 | Iteration: 38063 | Classification loss: 0.40080 | Regression loss: 0.38225 | Running loss: 0.86031\n",
      "Epoch: 0 | Iteration: 38064 | Classification loss: 0.26833 | Regression loss: 0.48887 | Running loss: 0.85903\n",
      "Epoch: 0 | Iteration: 38065 | Classification loss: 0.21733 | Regression loss: 0.45739 | Running loss: 0.85907\n",
      "Epoch: 0 | Iteration: 38066 | Classification loss: 0.37111 | Regression loss: 0.42184 | Running loss: 0.85898\n",
      "Epoch: 0 | Iteration: 38067 | Classification loss: 0.67536 | Regression loss: 0.58671 | Running loss: 0.85958\n",
      "Epoch: 0 | Iteration: 38068 | Classification loss: 0.14667 | Regression loss: 0.33540 | Running loss: 0.85881\n",
      "Epoch: 0 | Iteration: 38069 | Classification loss: 0.40469 | Regression loss: 0.56558 | Running loss: 0.85859\n",
      "Epoch: 0 | Iteration: 38070 | Classification loss: 0.31470 | Regression loss: 0.27007 | Running loss: 0.85929\n",
      "Epoch: 0 | Iteration: 38071 | Classification loss: 0.47866 | Regression loss: 0.40206 | Running loss: 0.85893\n",
      "Epoch: 0 | Iteration: 38072 | Classification loss: 0.58646 | Regression loss: 0.60439 | Running loss: 0.85976\n",
      "Epoch: 0 | Iteration: 38073 | Classification loss: 0.53057 | Regression loss: 0.72535 | Running loss: 0.86020\n",
      "Epoch: 0 | Iteration: 38074 | Classification loss: 0.25194 | Regression loss: 0.42992 | Running loss: 0.85995\n",
      "Epoch: 0 | Iteration: 38075 | Classification loss: 0.46606 | Regression loss: 0.59104 | Running loss: 0.86034\n",
      "Epoch: 0 | Iteration: 38076 | Classification loss: 0.54662 | Regression loss: 0.41318 | Running loss: 0.86117\n",
      "Epoch: 0 | Iteration: 38077 | Classification loss: 0.33299 | Regression loss: 0.55199 | Running loss: 0.86160\n",
      "Epoch: 0 | Iteration: 38078 | Classification loss: 0.38498 | Regression loss: 0.53503 | Running loss: 0.86163\n",
      "Epoch: 0 | Iteration: 38079 | Classification loss: 0.38293 | Regression loss: 0.58352 | Running loss: 0.86143\n",
      "Epoch: 0 | Iteration: 38080 | Classification loss: 0.76096 | Regression loss: 0.57740 | Running loss: 0.86229\n",
      "Epoch: 0 | Iteration: 38081 | Classification loss: 0.45727 | Regression loss: 0.37405 | Running loss: 0.86225\n",
      "Epoch: 0 | Iteration: 38082 | Classification loss: 0.17188 | Regression loss: 0.27763 | Running loss: 0.86271\n",
      "Epoch: 0 | Iteration: 38083 | Classification loss: 0.41846 | Regression loss: 0.54894 | Running loss: 0.86333\n",
      "Epoch: 0 | Iteration: 38084 | Classification loss: 0.41774 | Regression loss: 0.56132 | Running loss: 0.86442\n",
      "Epoch: 0 | Iteration: 38085 | Classification loss: 0.57570 | Regression loss: 0.58397 | Running loss: 0.86529\n",
      "Epoch: 0 | Iteration: 38086 | Classification loss: 0.25381 | Regression loss: 0.46375 | Running loss: 0.86500\n",
      "Epoch: 0 | Iteration: 38087 | Classification loss: 0.34056 | Regression loss: 0.53664 | Running loss: 0.86544\n",
      "Epoch: 0 | Iteration: 38088 | Classification loss: 0.46960 | Regression loss: 0.63530 | Running loss: 0.86576\n",
      "Epoch: 0 | Iteration: 38089 | Classification loss: 0.32934 | Regression loss: 0.67817 | Running loss: 0.86586\n",
      "Epoch: 0 | Iteration: 38090 | Classification loss: 0.50452 | Regression loss: 0.71778 | Running loss: 0.86689\n",
      "Epoch: 0 | Iteration: 38091 | Classification loss: 0.19874 | Regression loss: 0.26869 | Running loss: 0.86594\n",
      "Epoch: 0 | Iteration: 38092 | Classification loss: 0.52852 | Regression loss: 0.63528 | Running loss: 0.86752\n",
      "Epoch: 0 | Iteration: 38093 | Classification loss: 0.49825 | Regression loss: 0.49918 | Running loss: 0.86745\n",
      "Epoch: 0 | Iteration: 38094 | Classification loss: 0.29363 | Regression loss: 0.36403 | Running loss: 0.86695\n",
      "Epoch: 0 | Iteration: 38095 | Classification loss: 0.16184 | Regression loss: 0.43204 | Running loss: 0.86588\n",
      "Epoch: 0 | Iteration: 38096 | Classification loss: 0.27947 | Regression loss: 0.45420 | Running loss: 0.86530\n",
      "Epoch: 0 | Iteration: 38097 | Classification loss: 0.42276 | Regression loss: 0.32728 | Running loss: 0.86507\n",
      "Epoch: 0 | Iteration: 38098 | Classification loss: 0.41668 | Regression loss: 0.44711 | Running loss: 0.86486\n",
      "Epoch: 0 | Iteration: 38099 | Classification loss: 0.43476 | Regression loss: 0.55391 | Running loss: 0.86578\n",
      "Epoch: 0 | Iteration: 38100 | Classification loss: 0.31806 | Regression loss: 0.44292 | Running loss: 0.86515\n",
      "Epoch: 0 | Iteration: 38101 | Classification loss: 0.38299 | Regression loss: 0.69142 | Running loss: 0.86490\n",
      "Epoch: 0 | Iteration: 38102 | Classification loss: 0.36051 | Regression loss: 0.40744 | Running loss: 0.86437\n",
      "Epoch: 0 | Iteration: 38103 | Classification loss: 0.56906 | Regression loss: 0.62486 | Running loss: 0.86513\n",
      "Epoch: 0 | Iteration: 38104 | Classification loss: 0.24510 | Regression loss: 0.42450 | Running loss: 0.86517\n",
      "Epoch: 0 | Iteration: 38105 | Classification loss: 0.21025 | Regression loss: 0.27727 | Running loss: 0.86357\n",
      "Epoch: 0 | Iteration: 38106 | Classification loss: 0.35700 | Regression loss: 0.62778 | Running loss: 0.86405\n",
      "Epoch: 0 | Iteration: 38107 | Classification loss: 0.80618 | Regression loss: 0.30907 | Running loss: 0.86456\n",
      "Epoch: 0 | Iteration: 38108 | Classification loss: 0.28507 | Regression loss: 0.20209 | Running loss: 0.86341\n",
      "Epoch: 0 | Iteration: 38109 | Classification loss: 0.34385 | Regression loss: 0.59049 | Running loss: 0.86326\n",
      "Epoch: 0 | Iteration: 38110 | Classification loss: 0.22299 | Regression loss: 0.28415 | Running loss: 0.86265\n",
      "Epoch: 0 | Iteration: 38111 | Classification loss: 0.32627 | Regression loss: 0.46314 | Running loss: 0.86262\n",
      "Epoch: 0 | Iteration: 38112 | Classification loss: 0.41448 | Regression loss: 0.50345 | Running loss: 0.86301\n",
      "Epoch: 0 | Iteration: 38113 | Classification loss: 0.37774 | Regression loss: 0.61263 | Running loss: 0.86251\n",
      "Epoch: 0 | Iteration: 38114 | Classification loss: 0.27419 | Regression loss: 0.27762 | Running loss: 0.86217\n",
      "Epoch: 0 | Iteration: 38115 | Classification loss: 0.26005 | Regression loss: 0.28640 | Running loss: 0.86167\n",
      "Epoch: 0 | Iteration: 38116 | Classification loss: 0.58369 | Regression loss: 0.36560 | Running loss: 0.86055\n",
      "Epoch: 0 | Iteration: 38117 | Classification loss: 0.19613 | Regression loss: 0.46902 | Running loss: 0.85989\n",
      "Epoch: 0 | Iteration: 38118 | Classification loss: 0.31633 | Regression loss: 0.46110 | Running loss: 0.85961\n",
      "Epoch: 0 | Iteration: 38119 | Classification loss: 0.45049 | Regression loss: 0.66863 | Running loss: 0.85912\n",
      "Epoch: 0 | Iteration: 38120 | Classification loss: 0.59860 | Regression loss: 0.36494 | Running loss: 0.85945\n",
      "Epoch: 0 | Iteration: 38121 | Classification loss: 0.34426 | Regression loss: 0.56572 | Running loss: 0.85928\n",
      "Epoch: 0 | Iteration: 38122 | Classification loss: 0.17540 | Regression loss: 0.30077 | Running loss: 0.85892\n",
      "Epoch: 0 | Iteration: 38123 | Classification loss: 0.25985 | Regression loss: 0.32326 | Running loss: 0.85789\n",
      "Epoch: 0 | Iteration: 38124 | Classification loss: 0.59537 | Regression loss: 0.56960 | Running loss: 0.85890\n",
      "Epoch: 0 | Iteration: 38125 | Classification loss: 0.10492 | Regression loss: 0.23330 | Running loss: 0.85786\n",
      "Epoch: 0 | Iteration: 38126 | Classification loss: 0.34008 | Regression loss: 0.44366 | Running loss: 0.85767\n",
      "Epoch: 0 | Iteration: 38127 | Classification loss: 0.15264 | Regression loss: 0.24542 | Running loss: 0.85622\n",
      "Epoch: 0 | Iteration: 38128 | Classification loss: 0.40067 | Regression loss: 0.58400 | Running loss: 0.85645\n",
      "Epoch: 0 | Iteration: 38129 | Classification loss: 0.22715 | Regression loss: 0.46873 | Running loss: 0.85555\n",
      "Epoch: 0 | Iteration: 38130 | Classification loss: 0.62080 | Regression loss: 0.58606 | Running loss: 0.85610\n",
      "Epoch: 0 | Iteration: 38131 | Classification loss: 0.44712 | Regression loss: 0.66010 | Running loss: 0.85632\n",
      "Epoch: 0 | Iteration: 38132 | Classification loss: 0.33267 | Regression loss: 0.48218 | Running loss: 0.85723\n",
      "Epoch: 0 | Iteration: 38133 | Classification loss: 0.35540 | Regression loss: 0.38665 | Running loss: 0.85705\n",
      "Epoch: 0 | Iteration: 38134 | Classification loss: 0.22410 | Regression loss: 0.38726 | Running loss: 0.85645\n",
      "Epoch: 0 | Iteration: 38135 | Classification loss: 0.44884 | Regression loss: 0.43837 | Running loss: 0.85649\n",
      "Epoch: 0 | Iteration: 38136 | Classification loss: 0.46125 | Regression loss: 0.65646 | Running loss: 0.85697\n",
      "Epoch: 0 | Iteration: 38137 | Classification loss: 0.21593 | Regression loss: 0.44338 | Running loss: 0.85636\n",
      "Epoch: 0 | Iteration: 38138 | Classification loss: 0.26129 | Regression loss: 0.37920 | Running loss: 0.85568\n",
      "Epoch: 0 | Iteration: 38139 | Classification loss: 0.39518 | Regression loss: 0.50363 | Running loss: 0.85638\n",
      "Epoch: 0 | Iteration: 38140 | Classification loss: 0.10531 | Regression loss: 0.28800 | Running loss: 0.85575\n",
      "Epoch: 0 | Iteration: 38141 | Classification loss: 0.41155 | Regression loss: 0.64923 | Running loss: 0.85600\n",
      "Epoch: 0 | Iteration: 38142 | Classification loss: 0.44540 | Regression loss: 0.61831 | Running loss: 0.85635\n",
      "Epoch: 0 | Iteration: 38143 | Classification loss: 0.48563 | Regression loss: 0.45784 | Running loss: 0.85666\n",
      "Epoch: 0 | Iteration: 38144 | Classification loss: 0.23777 | Regression loss: 0.41253 | Running loss: 0.85642\n",
      "Epoch: 0 | Iteration: 38145 | Classification loss: 0.43216 | Regression loss: 0.51706 | Running loss: 0.85626\n",
      "Epoch: 0 | Iteration: 38146 | Classification loss: 0.51095 | Regression loss: 0.58055 | Running loss: 0.85753\n",
      "Epoch: 0 | Iteration: 38147 | Classification loss: 0.18483 | Regression loss: 0.30947 | Running loss: 0.85639\n",
      "Epoch: 0 | Iteration: 38148 | Classification loss: 0.22049 | Regression loss: 0.32168 | Running loss: 0.85455\n",
      "Epoch: 0 | Iteration: 38149 | Classification loss: 0.28063 | Regression loss: 0.52139 | Running loss: 0.85435\n",
      "Epoch: 0 | Iteration: 38150 | Classification loss: 0.22692 | Regression loss: 0.59943 | Running loss: 0.85393\n",
      "Epoch: 0 | Iteration: 38151 | Classification loss: 0.46385 | Regression loss: 0.48932 | Running loss: 0.85386\n",
      "Epoch: 0 | Iteration: 38152 | Classification loss: 0.54581 | Regression loss: 0.60384 | Running loss: 0.85477\n",
      "Epoch: 0 | Iteration: 38153 | Classification loss: 0.38722 | Regression loss: 0.56880 | Running loss: 0.85515\n",
      "Epoch: 0 | Iteration: 38154 | Classification loss: 0.26290 | Regression loss: 0.31495 | Running loss: 0.85490\n",
      "Epoch: 0 | Iteration: 38155 | Classification loss: 0.53428 | Regression loss: 0.65985 | Running loss: 0.85654\n",
      "Epoch: 0 | Iteration: 38156 | Classification loss: 0.51831 | Regression loss: 0.52999 | Running loss: 0.85670\n",
      "Epoch: 0 | Iteration: 38157 | Classification loss: 0.49588 | Regression loss: 0.59064 | Running loss: 0.85691\n",
      "Epoch: 0 | Iteration: 38158 | Classification loss: 0.52375 | Regression loss: 0.39120 | Running loss: 0.85680\n",
      "Epoch: 0 | Iteration: 38159 | Classification loss: 0.45371 | Regression loss: 0.53089 | Running loss: 0.85661\n",
      "Epoch: 0 | Iteration: 38160 | Classification loss: 0.35891 | Regression loss: 0.43791 | Running loss: 0.85641\n",
      "Epoch: 0 | Iteration: 38161 | Classification loss: 0.28808 | Regression loss: 0.39786 | Running loss: 0.85617\n",
      "Epoch: 0 | Iteration: 38162 | Classification loss: 0.80209 | Regression loss: 0.38573 | Running loss: 0.85502\n",
      "Epoch: 0 | Iteration: 38163 | Classification loss: 0.24972 | Regression loss: 0.44573 | Running loss: 0.85548\n",
      "Epoch: 0 | Iteration: 38164 | Classification loss: 0.38961 | Regression loss: 0.43643 | Running loss: 0.85629\n",
      "Epoch: 0 | Iteration: 38165 | Classification loss: 0.25591 | Regression loss: 0.59497 | Running loss: 0.85574\n",
      "Epoch: 0 | Iteration: 38166 | Classification loss: 0.30484 | Regression loss: 0.62539 | Running loss: 0.85555\n",
      "Epoch: 0 | Iteration: 38167 | Classification loss: 0.31181 | Regression loss: 0.38437 | Running loss: 0.85605\n",
      "Epoch: 0 | Iteration: 38168 | Classification loss: 0.34395 | Regression loss: 0.56068 | Running loss: 0.85679\n",
      "Epoch: 0 | Iteration: 38169 | Classification loss: 0.39947 | Regression loss: 0.56448 | Running loss: 0.85777\n",
      "Epoch: 0 | Iteration: 38170 | Classification loss: 0.30472 | Regression loss: 0.43286 | Running loss: 0.85752\n",
      "Epoch: 0 | Iteration: 38171 | Classification loss: 0.35132 | Regression loss: 0.45988 | Running loss: 0.85793\n",
      "Epoch: 0 | Iteration: 38172 | Classification loss: 0.30590 | Regression loss: 0.49000 | Running loss: 0.85820\n",
      "Epoch: 0 | Iteration: 38173 | Classification loss: 0.37969 | Regression loss: 0.40121 | Running loss: 0.85903\n",
      "Epoch: 0 | Iteration: 38174 | Classification loss: 0.14286 | Regression loss: 0.33496 | Running loss: 0.85854\n",
      "Epoch: 0 | Iteration: 38175 | Classification loss: 0.36653 | Regression loss: 0.31152 | Running loss: 0.85873\n",
      "Epoch: 0 | Iteration: 38176 | Classification loss: 0.10142 | Regression loss: 0.16925 | Running loss: 0.85768\n",
      "Epoch: 0 | Iteration: 38177 | Classification loss: 0.32041 | Regression loss: 0.25688 | Running loss: 0.85683\n",
      "Epoch: 0 | Iteration: 38178 | Classification loss: 0.35920 | Regression loss: 0.49865 | Running loss: 0.85703\n",
      "Epoch: 0 | Iteration: 38179 | Classification loss: 0.32530 | Regression loss: 0.64849 | Running loss: 0.85803\n",
      "Epoch: 0 | Iteration: 38180 | Classification loss: 0.58816 | Regression loss: 0.65521 | Running loss: 0.85894\n",
      "Epoch: 0 | Iteration: 38181 | Classification loss: 0.35779 | Regression loss: 0.25295 | Running loss: 0.85857\n",
      "Epoch: 0 | Iteration: 38182 | Classification loss: 0.19395 | Regression loss: 0.32423 | Running loss: 0.85749\n",
      "Epoch: 0 | Iteration: 38183 | Classification loss: 0.21354 | Regression loss: 0.28868 | Running loss: 0.85749\n",
      "Epoch: 0 | Iteration: 38184 | Classification loss: 0.34492 | Regression loss: 0.52800 | Running loss: 0.85689\n",
      "Epoch: 0 | Iteration: 38185 | Classification loss: 0.46929 | Regression loss: 0.66094 | Running loss: 0.85840\n",
      "Epoch: 0 | Iteration: 38186 | Classification loss: 0.40964 | Regression loss: 0.58078 | Running loss: 0.85907\n",
      "Epoch: 0 | Iteration: 38187 | Classification loss: 0.17673 | Regression loss: 0.36729 | Running loss: 0.85908\n",
      "Epoch: 0 | Iteration: 38188 | Classification loss: 0.29225 | Regression loss: 0.40740 | Running loss: 0.85929\n",
      "Epoch: 0 | Iteration: 38189 | Classification loss: 0.18028 | Regression loss: 0.25836 | Running loss: 0.85828\n",
      "Epoch: 0 | Iteration: 38190 | Classification loss: 0.35427 | Regression loss: 0.53021 | Running loss: 0.85805\n",
      "Epoch: 0 | Iteration: 38191 | Classification loss: 0.24814 | Regression loss: 0.33125 | Running loss: 0.85815\n",
      "Epoch: 0 | Iteration: 38192 | Classification loss: 0.35739 | Regression loss: 0.45743 | Running loss: 0.85790\n",
      "Epoch: 0 | Iteration: 38193 | Classification loss: 0.33674 | Regression loss: 0.31337 | Running loss: 0.85806\n",
      "Epoch: 0 | Iteration: 38194 | Classification loss: 0.43374 | Regression loss: 0.44668 | Running loss: 0.85841\n",
      "Epoch: 0 | Iteration: 38195 | Classification loss: 0.36762 | Regression loss: 0.57824 | Running loss: 0.85867\n",
      "Epoch: 0 | Iteration: 38196 | Classification loss: 0.55879 | Regression loss: 0.45327 | Running loss: 0.85904\n",
      "Epoch: 0 | Iteration: 38197 | Classification loss: 0.55280 | Regression loss: 0.50857 | Running loss: 0.86039\n",
      "Epoch: 0 | Iteration: 38198 | Classification loss: 0.22440 | Regression loss: 0.22840 | Running loss: 0.85949\n",
      "Epoch: 0 | Iteration: 38199 | Classification loss: 0.13272 | Regression loss: 0.33002 | Running loss: 0.85847\n",
      "Epoch: 0 | Iteration: 38200 | Classification loss: 0.23911 | Regression loss: 0.34966 | Running loss: 0.85878\n",
      "Epoch: 0 | Iteration: 38201 | Classification loss: 0.38322 | Regression loss: 0.40988 | Running loss: 0.85812\n",
      "Epoch: 0 | Iteration: 38202 | Classification loss: 0.36844 | Regression loss: 0.40000 | Running loss: 0.85806\n",
      "Epoch: 0 | Iteration: 38203 | Classification loss: 0.13264 | Regression loss: 0.40624 | Running loss: 0.85709\n",
      "Epoch: 0 | Iteration: 38204 | Classification loss: 0.93817 | Regression loss: 0.79523 | Running loss: 0.85913\n",
      "Epoch: 0 | Iteration: 38205 | Classification loss: 0.37646 | Regression loss: 0.48646 | Running loss: 0.85953\n",
      "Epoch: 0 | Iteration: 38206 | Classification loss: 0.38319 | Regression loss: 0.50522 | Running loss: 0.85901\n",
      "Epoch: 0 | Iteration: 38207 | Classification loss: 0.35940 | Regression loss: 0.47761 | Running loss: 0.85910\n",
      "Epoch: 0 | Iteration: 38208 | Classification loss: 0.28314 | Regression loss: 0.47564 | Running loss: 0.85913\n",
      "Epoch: 0 | Iteration: 38209 | Classification loss: 0.50579 | Regression loss: 0.48169 | Running loss: 0.85871\n",
      "Epoch: 0 | Iteration: 38210 | Classification loss: 0.20036 | Regression loss: 0.36034 | Running loss: 0.85843\n",
      "Epoch: 0 | Iteration: 38211 | Classification loss: 0.21238 | Regression loss: 0.42183 | Running loss: 0.85790\n",
      "Epoch: 0 | Iteration: 38212 | Classification loss: 0.40539 | Regression loss: 0.50237 | Running loss: 0.85748\n",
      "Epoch: 0 | Iteration: 38213 | Classification loss: 0.52130 | Regression loss: 0.56519 | Running loss: 0.85872\n",
      "Epoch: 0 | Iteration: 38214 | Classification loss: 0.24162 | Regression loss: 0.44267 | Running loss: 0.85834\n",
      "Epoch: 0 | Iteration: 38215 | Classification loss: 0.22387 | Regression loss: 0.44169 | Running loss: 0.85813\n",
      "Epoch: 0 | Iteration: 38216 | Classification loss: 0.29412 | Regression loss: 0.33142 | Running loss: 0.85762\n",
      "Epoch: 0 | Iteration: 38217 | Classification loss: 0.34517 | Regression loss: 0.40694 | Running loss: 0.85820\n",
      "Epoch: 0 | Iteration: 38218 | Classification loss: 0.15926 | Regression loss: 0.32380 | Running loss: 0.85743\n",
      "Epoch: 0 | Iteration: 38219 | Classification loss: 0.33592 | Regression loss: 0.58386 | Running loss: 0.85775\n",
      "Epoch: 0 | Iteration: 38220 | Classification loss: 0.56044 | Regression loss: 0.48631 | Running loss: 0.85824\n",
      "Epoch: 0 | Iteration: 38221 | Classification loss: 0.37648 | Regression loss: 0.63233 | Running loss: 0.85808\n",
      "Epoch: 0 | Iteration: 38222 | Classification loss: 0.19800 | Regression loss: 0.24825 | Running loss: 0.85700\n",
      "Epoch: 0 | Iteration: 38223 | Classification loss: 0.62949 | Regression loss: 0.45230 | Running loss: 0.85753\n",
      "Epoch: 0 | Iteration: 38224 | Classification loss: 0.41477 | Regression loss: 0.39930 | Running loss: 0.85773\n",
      "Epoch: 0 | Iteration: 38225 | Classification loss: 0.35214 | Regression loss: 0.55409 | Running loss: 0.85700\n",
      "Epoch: 0 | Iteration: 38226 | Classification loss: 0.28141 | Regression loss: 0.58743 | Running loss: 0.85669\n",
      "Epoch: 0 | Iteration: 38227 | Classification loss: 1.20925 | Regression loss: 0.38335 | Running loss: 0.85788\n",
      "Epoch: 0 | Iteration: 38228 | Classification loss: 0.56919 | Regression loss: 0.77599 | Running loss: 0.85857\n",
      "Epoch: 0 | Iteration: 38229 | Classification loss: 0.24580 | Regression loss: 0.28613 | Running loss: 0.85852\n",
      "Epoch: 0 | Iteration: 38230 | Classification loss: 0.37389 | Regression loss: 0.54679 | Running loss: 0.85863\n",
      "Epoch: 0 | Iteration: 38231 | Classification loss: 0.13928 | Regression loss: 0.34220 | Running loss: 0.85842\n",
      "Epoch: 0 | Iteration: 38232 | Classification loss: 0.39588 | Regression loss: 0.54170 | Running loss: 0.85802\n",
      "Epoch: 0 | Iteration: 38233 | Classification loss: 0.33902 | Regression loss: 0.43674 | Running loss: 0.85797\n",
      "Epoch: 0 | Iteration: 38234 | Classification loss: 0.30269 | Regression loss: 0.36517 | Running loss: 0.85743\n",
      "Epoch: 0 | Iteration: 38235 | Classification loss: 0.22924 | Regression loss: 0.51169 | Running loss: 0.85712\n",
      "Epoch: 0 | Iteration: 38236 | Classification loss: 0.24302 | Regression loss: 0.37901 | Running loss: 0.85638\n",
      "Epoch: 0 | Iteration: 38237 | Classification loss: 0.19294 | Regression loss: 0.33120 | Running loss: 0.85536\n",
      "Epoch: 0 | Iteration: 38238 | Classification loss: 0.36277 | Regression loss: 0.31772 | Running loss: 0.85474\n",
      "Epoch: 0 | Iteration: 38239 | Classification loss: 0.23127 | Regression loss: 0.40711 | Running loss: 0.85444\n",
      "Epoch: 0 | Iteration: 38240 | Classification loss: 0.21283 | Regression loss: 0.29099 | Running loss: 0.85362\n",
      "Epoch: 0 | Iteration: 38241 | Classification loss: 0.16263 | Regression loss: 0.37668 | Running loss: 0.85249\n",
      "Epoch: 0 | Iteration: 38242 | Classification loss: 0.16189 | Regression loss: 0.34627 | Running loss: 0.85223\n",
      "Epoch: 0 | Iteration: 38243 | Classification loss: 0.33018 | Regression loss: 0.43563 | Running loss: 0.85253\n",
      "Epoch: 0 | Iteration: 38244 | Classification loss: 0.51129 | Regression loss: 0.58366 | Running loss: 0.85270\n",
      "Epoch: 0 | Iteration: 38245 | Classification loss: 0.40240 | Regression loss: 0.30254 | Running loss: 0.85179\n",
      "Epoch: 0 | Iteration: 38246 | Classification loss: 0.26760 | Regression loss: 0.36170 | Running loss: 0.84992\n",
      "Epoch: 0 | Iteration: 38247 | Classification loss: 0.29384 | Regression loss: 0.50835 | Running loss: 0.84937\n",
      "Epoch: 0 | Iteration: 38248 | Classification loss: 0.67720 | Regression loss: 0.63711 | Running loss: 0.85035\n",
      "Epoch: 0 | Iteration: 38249 | Classification loss: 0.33581 | Regression loss: 0.43533 | Running loss: 0.84962\n",
      "Epoch: 0 | Iteration: 38250 | Classification loss: 0.85846 | Regression loss: 0.78328 | Running loss: 0.85052\n",
      "Epoch: 0 | Iteration: 38251 | Classification loss: 0.52765 | Regression loss: 0.54061 | Running loss: 0.85057\n",
      "Epoch: 0 | Iteration: 38252 | Classification loss: 0.36341 | Regression loss: 0.53702 | Running loss: 0.85108\n",
      "Epoch: 0 | Iteration: 38253 | Classification loss: 0.62289 | Regression loss: 0.45956 | Running loss: 0.85221\n",
      "Epoch: 0 | Iteration: 38254 | Classification loss: 0.41013 | Regression loss: 0.26246 | Running loss: 0.85192\n",
      "Epoch: 0 | Iteration: 38255 | Classification loss: 0.34030 | Regression loss: 0.29754 | Running loss: 0.85079\n",
      "Epoch: 0 | Iteration: 38256 | Classification loss: 0.56883 | Regression loss: 0.72079 | Running loss: 0.85116\n",
      "Epoch: 0 | Iteration: 38257 | Classification loss: 0.26333 | Regression loss: 0.43731 | Running loss: 0.85040\n",
      "Epoch: 0 | Iteration: 38258 | Classification loss: 0.67712 | Regression loss: 0.60879 | Running loss: 0.85157\n",
      "Epoch: 0 | Iteration: 38259 | Classification loss: 0.39374 | Regression loss: 0.54924 | Running loss: 0.85186\n",
      "Epoch: 0 | Iteration: 38260 | Classification loss: 0.30901 | Regression loss: 0.52846 | Running loss: 0.85093\n",
      "Epoch: 0 | Iteration: 38261 | Classification loss: 0.22055 | Regression loss: 0.25898 | Running loss: 0.84966\n",
      "Epoch: 0 | Iteration: 38262 | Classification loss: 0.30523 | Regression loss: 0.50188 | Running loss: 0.84972\n",
      "Epoch: 0 | Iteration: 38263 | Classification loss: 0.53009 | Regression loss: 0.45774 | Running loss: 0.84936\n",
      "Epoch: 0 | Iteration: 38264 | Classification loss: 0.54957 | Regression loss: 0.56630 | Running loss: 0.84991\n",
      "Epoch: 0 | Iteration: 38265 | Classification loss: 0.34357 | Regression loss: 0.39871 | Running loss: 0.84965\n",
      "Epoch: 0 | Iteration: 38266 | Classification loss: 0.59279 | Regression loss: 0.67072 | Running loss: 0.85027\n",
      "Epoch: 0 | Iteration: 38267 | Classification loss: 0.51721 | Regression loss: 0.41478 | Running loss: 0.85030\n",
      "Epoch: 0 | Iteration: 38268 | Classification loss: 0.23928 | Regression loss: 0.54050 | Running loss: 0.84952\n",
      "Epoch: 0 | Iteration: 38269 | Classification loss: 0.40754 | Regression loss: 0.35319 | Running loss: 0.84887\n",
      "Epoch: 0 | Iteration: 38270 | Classification loss: 0.59629 | Regression loss: 0.59060 | Running loss: 0.84965\n",
      "Epoch: 0 | Iteration: 38271 | Classification loss: 0.47796 | Regression loss: 0.58261 | Running loss: 0.85002\n",
      "Epoch: 0 | Iteration: 38272 | Classification loss: 0.47145 | Regression loss: 0.60678 | Running loss: 0.85017\n",
      "Epoch: 0 | Iteration: 38273 | Classification loss: 0.23337 | Regression loss: 0.44981 | Running loss: 0.84956\n",
      "Epoch: 0 | Iteration: 38274 | Classification loss: 0.45549 | Regression loss: 0.54000 | Running loss: 0.85001\n",
      "Epoch: 0 | Iteration: 38275 | Classification loss: 0.45771 | Regression loss: 0.42145 | Running loss: 0.85020\n",
      "Epoch: 0 | Iteration: 38276 | Classification loss: 0.36226 | Regression loss: 0.53228 | Running loss: 0.85034\n",
      "Epoch: 0 | Iteration: 38277 | Classification loss: 0.41280 | Regression loss: 0.61551 | Running loss: 0.85102\n",
      "Epoch: 0 | Iteration: 38278 | Classification loss: 0.59767 | Regression loss: 0.66072 | Running loss: 0.85230\n",
      "Epoch: 0 | Iteration: 38279 | Classification loss: 0.30529 | Regression loss: 0.37012 | Running loss: 0.85182\n",
      "Epoch: 0 | Iteration: 38280 | Classification loss: 0.30031 | Regression loss: 0.24174 | Running loss: 0.85108\n",
      "Epoch: 0 | Iteration: 38281 | Classification loss: 0.51411 | Regression loss: 0.59615 | Running loss: 0.85147\n",
      "Epoch: 0 | Iteration: 38282 | Classification loss: 0.36958 | Regression loss: 0.56216 | Running loss: 0.85252\n",
      "Epoch: 0 | Iteration: 38283 | Classification loss: 0.23030 | Regression loss: 0.39016 | Running loss: 0.85219\n",
      "Epoch: 0 | Iteration: 38284 | Classification loss: 0.27182 | Regression loss: 0.44169 | Running loss: 0.85179\n",
      "Epoch: 0 | Iteration: 38285 | Classification loss: 0.24132 | Regression loss: 0.38370 | Running loss: 0.85140\n",
      "Epoch: 0 | Iteration: 38286 | Classification loss: 0.48650 | Regression loss: 0.62507 | Running loss: 0.85173\n",
      "Epoch: 0 | Iteration: 38287 | Classification loss: 0.47973 | Regression loss: 0.58509 | Running loss: 0.85249\n",
      "Epoch: 0 | Iteration: 38288 | Classification loss: 0.40913 | Regression loss: 0.56124 | Running loss: 0.85298\n",
      "Epoch: 0 | Iteration: 38289 | Classification loss: 0.30973 | Regression loss: 0.47793 | Running loss: 0.85295\n",
      "Epoch: 0 | Iteration: 38290 | Classification loss: 0.15657 | Regression loss: 0.36788 | Running loss: 0.85188\n",
      "Epoch: 0 | Iteration: 38291 | Classification loss: 0.19051 | Regression loss: 0.46058 | Running loss: 0.85090\n",
      "Epoch: 0 | Iteration: 38292 | Classification loss: 0.29090 | Regression loss: 0.46177 | Running loss: 0.85081\n",
      "Epoch: 0 | Iteration: 38293 | Classification loss: 0.55958 | Regression loss: 0.37137 | Running loss: 0.85195\n",
      "Epoch: 0 | Iteration: 38294 | Classification loss: 0.33045 | Regression loss: 0.35548 | Running loss: 0.85202\n",
      "Epoch: 0 | Iteration: 38295 | Classification loss: 0.42390 | Regression loss: 0.59787 | Running loss: 0.85250\n",
      "Epoch: 0 | Iteration: 38296 | Classification loss: 0.45119 | Regression loss: 0.62001 | Running loss: 0.85275\n",
      "Epoch: 0 | Iteration: 38297 | Classification loss: 0.56712 | Regression loss: 0.39151 | Running loss: 0.85277\n",
      "Epoch: 0 | Iteration: 38298 | Classification loss: 0.49084 | Regression loss: 0.53795 | Running loss: 0.85278\n",
      "Epoch: 0 | Iteration: 38299 | Classification loss: 0.43674 | Regression loss: 0.38991 | Running loss: 0.85319\n",
      "Epoch: 0 | Iteration: 38300 | Classification loss: 0.27851 | Regression loss: 0.53386 | Running loss: 0.85255\n",
      "Epoch: 0 | Iteration: 38301 | Classification loss: 0.37465 | Regression loss: 0.42151 | Running loss: 0.85234\n",
      "Epoch: 0 | Iteration: 38302 | Classification loss: 0.33984 | Regression loss: 0.34679 | Running loss: 0.85204\n",
      "Epoch: 0 | Iteration: 38303 | Classification loss: 0.26358 | Regression loss: 0.32757 | Running loss: 0.85082\n",
      "Epoch: 0 | Iteration: 38304 | Classification loss: 0.40270 | Regression loss: 0.42760 | Running loss: 0.85106\n",
      "Epoch: 0 | Iteration: 38305 | Classification loss: 0.45339 | Regression loss: 0.59488 | Running loss: 0.85207\n",
      "Epoch: 0 | Iteration: 38306 | Classification loss: 0.43218 | Regression loss: 0.47042 | Running loss: 0.85183\n",
      "Epoch: 0 | Iteration: 38307 | Classification loss: 0.56130 | Regression loss: 0.67563 | Running loss: 0.85226\n",
      "Epoch: 0 | Iteration: 38308 | Classification loss: 0.43678 | Regression loss: 0.46712 | Running loss: 0.85263\n",
      "Epoch: 0 | Iteration: 38309 | Classification loss: 0.39886 | Regression loss: 0.48604 | Running loss: 0.85269\n",
      "Epoch: 0 | Iteration: 38310 | Classification loss: 0.44998 | Regression loss: 0.38965 | Running loss: 0.85355\n",
      "Epoch: 0 | Iteration: 38311 | Classification loss: 0.51801 | Regression loss: 0.61615 | Running loss: 0.85432\n",
      "Epoch: 0 | Iteration: 38312 | Classification loss: 0.25409 | Regression loss: 0.47789 | Running loss: 0.85407\n",
      "Epoch: 0 | Iteration: 38313 | Classification loss: 0.50099 | Regression loss: 0.59730 | Running loss: 0.85468\n",
      "Epoch: 0 | Iteration: 38314 | Classification loss: 0.33607 | Regression loss: 0.28871 | Running loss: 0.85468\n",
      "Epoch: 0 | Iteration: 38315 | Classification loss: 0.37543 | Regression loss: 0.48299 | Running loss: 0.85451\n",
      "Epoch: 0 | Iteration: 38316 | Classification loss: 0.40154 | Regression loss: 0.30414 | Running loss: 0.85485\n",
      "Epoch: 0 | Iteration: 38317 | Classification loss: 0.28921 | Regression loss: 0.55592 | Running loss: 0.85505\n",
      "Epoch: 0 | Iteration: 38318 | Classification loss: 0.69308 | Regression loss: 0.48071 | Running loss: 0.85497\n",
      "Epoch: 0 | Iteration: 38319 | Classification loss: 0.36736 | Regression loss: 0.59238 | Running loss: 0.85560\n",
      "Epoch: 0 | Iteration: 38320 | Classification loss: 0.14251 | Regression loss: 0.33944 | Running loss: 0.85542\n",
      "Epoch: 0 | Iteration: 38321 | Classification loss: 0.31910 | Regression loss: 0.41020 | Running loss: 0.85597\n",
      "Epoch: 0 | Iteration: 38322 | Classification loss: 0.32370 | Regression loss: 0.35708 | Running loss: 0.85467\n",
      "Epoch: 0 | Iteration: 38323 | Classification loss: 0.19208 | Regression loss: 0.53631 | Running loss: 0.85461\n",
      "Epoch: 0 | Iteration: 38324 | Classification loss: 0.28713 | Regression loss: 0.46885 | Running loss: 0.85465\n",
      "Epoch: 0 | Iteration: 38325 | Classification loss: 0.25915 | Regression loss: 0.49558 | Running loss: 0.85495\n",
      "Epoch: 0 | Iteration: 38326 | Classification loss: 0.40327 | Regression loss: 0.47959 | Running loss: 0.85441\n",
      "Epoch: 0 | Iteration: 38327 | Classification loss: 0.19822 | Regression loss: 0.42889 | Running loss: 0.85414\n",
      "Epoch: 0 | Iteration: 38328 | Classification loss: 0.31097 | Regression loss: 0.38478 | Running loss: 0.85343\n",
      "Epoch: 0 | Iteration: 38329 | Classification loss: 0.41399 | Regression loss: 0.52325 | Running loss: 0.85272\n",
      "Epoch: 0 | Iteration: 38330 | Classification loss: 0.15957 | Regression loss: 0.33481 | Running loss: 0.85218\n",
      "Epoch: 0 | Iteration: 38331 | Classification loss: 0.32129 | Regression loss: 0.58517 | Running loss: 0.85207\n",
      "Epoch: 0 | Iteration: 38332 | Classification loss: 0.25089 | Regression loss: 0.50323 | Running loss: 0.85192\n",
      "Epoch: 0 | Iteration: 38333 | Classification loss: 0.33772 | Regression loss: 0.40527 | Running loss: 0.85149\n",
      "Epoch: 0 | Iteration: 38334 | Classification loss: 0.23131 | Regression loss: 0.23887 | Running loss: 0.85009\n",
      "Epoch: 0 | Iteration: 38335 | Classification loss: 0.33582 | Regression loss: 0.26229 | Running loss: 0.84931\n",
      "Epoch: 0 | Iteration: 38336 | Classification loss: 0.20926 | Regression loss: 0.32665 | Running loss: 0.84876\n",
      "Epoch: 0 | Iteration: 38337 | Classification loss: 0.28509 | Regression loss: 0.53012 | Running loss: 0.84855\n",
      "Epoch: 0 | Iteration: 38338 | Classification loss: 0.38742 | Regression loss: 0.60605 | Running loss: 0.84863\n",
      "Epoch: 0 | Iteration: 38339 | Classification loss: 0.45564 | Regression loss: 0.57210 | Running loss: 0.84962\n",
      "Epoch: 0 | Iteration: 38340 | Classification loss: 0.50219 | Regression loss: 0.32258 | Running loss: 0.84948\n",
      "Epoch: 0 | Iteration: 38341 | Classification loss: 0.60114 | Regression loss: 0.57829 | Running loss: 0.85016\n",
      "Epoch: 0 | Iteration: 38342 | Classification loss: 0.16904 | Regression loss: 0.52602 | Running loss: 0.84930\n",
      "Epoch: 0 | Iteration: 38343 | Classification loss: 1.46111 | Regression loss: 0.33322 | Running loss: 0.85124\n",
      "Epoch: 0 | Iteration: 38344 | Classification loss: 0.16086 | Regression loss: 0.38528 | Running loss: 0.85028\n",
      "Epoch: 0 | Iteration: 38345 | Classification loss: 0.58536 | Regression loss: 0.65063 | Running loss: 0.85110\n",
      "Epoch: 0 | Iteration: 38346 | Classification loss: 0.41916 | Regression loss: 0.66846 | Running loss: 0.85115\n",
      "Epoch: 0 | Iteration: 38347 | Classification loss: 0.48116 | Regression loss: 0.67687 | Running loss: 0.85118\n",
      "Epoch: 0 | Iteration: 38348 | Classification loss: 0.35336 | Regression loss: 0.52269 | Running loss: 0.85105\n",
      "Epoch: 0 | Iteration: 38349 | Classification loss: 0.30507 | Regression loss: 0.54185 | Running loss: 0.85171\n",
      "Epoch: 0 | Iteration: 38350 | Classification loss: 0.34966 | Regression loss: 0.45581 | Running loss: 0.85084\n",
      "Epoch: 0 | Iteration: 38351 | Classification loss: 0.31129 | Regression loss: 0.39082 | Running loss: 0.85110\n",
      "Epoch: 0 | Iteration: 38352 | Classification loss: 0.14300 | Regression loss: 0.37092 | Running loss: 0.84978\n",
      "Epoch: 0 | Iteration: 38353 | Classification loss: 0.39418 | Regression loss: 0.44953 | Running loss: 0.85019\n",
      "Epoch: 0 | Iteration: 38354 | Classification loss: 0.46333 | Regression loss: 0.70051 | Running loss: 0.85120\n",
      "Epoch: 0 | Iteration: 38355 | Classification loss: 0.52943 | Regression loss: 0.43482 | Running loss: 0.85072\n",
      "Epoch: 0 | Iteration: 38356 | Classification loss: 0.09595 | Regression loss: 0.19260 | Running loss: 0.85045\n",
      "Epoch: 0 | Iteration: 38357 | Classification loss: 0.32980 | Regression loss: 0.38619 | Running loss: 0.84996\n",
      "Epoch: 0 | Iteration: 38358 | Classification loss: 0.32769 | Regression loss: 0.44550 | Running loss: 0.84964\n",
      "Epoch: 0 | Iteration: 38359 | Classification loss: 0.31015 | Regression loss: 0.35773 | Running loss: 0.84910\n",
      "Epoch: 0 | Iteration: 38360 | Classification loss: 0.33168 | Regression loss: 0.59963 | Running loss: 0.84955\n",
      "Epoch: 0 | Iteration: 38361 | Classification loss: 0.47591 | Regression loss: 0.62596 | Running loss: 0.84989\n",
      "Epoch: 0 | Iteration: 38362 | Classification loss: 0.40993 | Regression loss: 0.59398 | Running loss: 0.84945\n",
      "Epoch: 0 | Iteration: 38363 | Classification loss: 0.32091 | Regression loss: 0.35435 | Running loss: 0.84871\n",
      "Epoch: 0 | Iteration: 38364 | Classification loss: 0.29894 | Regression loss: 0.39637 | Running loss: 0.84841\n",
      "Epoch: 0 | Iteration: 38365 | Classification loss: 0.46812 | Regression loss: 0.58891 | Running loss: 0.84908\n",
      "Epoch: 0 | Iteration: 38366 | Classification loss: 0.45437 | Regression loss: 0.52304 | Running loss: 0.84929\n",
      "Epoch: 0 | Iteration: 38367 | Classification loss: 0.50910 | Regression loss: 0.57128 | Running loss: 0.84988\n",
      "Epoch: 0 | Iteration: 38368 | Classification loss: 0.34196 | Regression loss: 0.40676 | Running loss: 0.84960\n",
      "Epoch: 0 | Iteration: 38369 | Classification loss: 0.43583 | Regression loss: 0.42469 | Running loss: 0.84957\n",
      "Epoch: 0 | Iteration: 38370 | Classification loss: 0.39707 | Regression loss: 0.45656 | Running loss: 0.85002\n",
      "Epoch: 0 | Iteration: 38371 | Classification loss: 0.34570 | Regression loss: 0.47656 | Running loss: 0.85025\n",
      "Epoch: 0 | Iteration: 38372 | Classification loss: 0.21895 | Regression loss: 0.36790 | Running loss: 0.84988\n",
      "Epoch: 0 | Iteration: 38373 | Classification loss: 0.31033 | Regression loss: 0.48647 | Running loss: 0.84901\n",
      "Epoch: 0 | Iteration: 38374 | Classification loss: 0.35028 | Regression loss: 0.57501 | Running loss: 0.84940\n",
      "Epoch: 0 | Iteration: 38375 | Classification loss: 0.23580 | Regression loss: 0.29682 | Running loss: 0.84833\n",
      "Epoch: 0 | Iteration: 38376 | Classification loss: 0.38820 | Regression loss: 0.56185 | Running loss: 0.84872\n",
      "Epoch: 0 | Iteration: 38377 | Classification loss: 0.43651 | Regression loss: 0.54263 | Running loss: 0.84828\n",
      "Epoch: 0 | Iteration: 38378 | Classification loss: 0.22539 | Regression loss: 0.43699 | Running loss: 0.84772\n",
      "Epoch: 0 | Iteration: 38379 | Classification loss: 0.39879 | Regression loss: 0.50808 | Running loss: 0.84789\n",
      "Epoch: 0 | Iteration: 38380 | Classification loss: 0.35950 | Regression loss: 0.46564 | Running loss: 0.84780\n",
      "Epoch: 0 | Iteration: 38381 | Classification loss: 0.64947 | Regression loss: 0.60689 | Running loss: 0.84867\n",
      "Epoch: 0 | Iteration: 38382 | Classification loss: 0.63718 | Regression loss: 0.81201 | Running loss: 0.85037\n",
      "Epoch: 0 | Iteration: 38383 | Classification loss: 0.22036 | Regression loss: 0.31640 | Running loss: 0.84862\n",
      "Epoch: 0 | Iteration: 38384 | Classification loss: 0.34415 | Regression loss: 0.52184 | Running loss: 0.84847\n",
      "Epoch: 0 | Iteration: 38385 | Classification loss: 0.35090 | Regression loss: 0.59930 | Running loss: 0.84880\n",
      "Epoch: 0 | Iteration: 38386 | Classification loss: 0.41620 | Regression loss: 0.65360 | Running loss: 0.84919\n",
      "Epoch: 0 | Iteration: 38387 | Classification loss: 0.51749 | Regression loss: 0.51070 | Running loss: 0.84909\n",
      "Epoch: 0 | Iteration: 38388 | Classification loss: 0.47144 | Regression loss: 0.58141 | Running loss: 0.84951\n",
      "Epoch: 0 | Iteration: 38389 | Classification loss: 0.46700 | Regression loss: 0.59141 | Running loss: 0.84964\n",
      "Epoch: 0 | Iteration: 38390 | Classification loss: 0.31302 | Regression loss: 0.63060 | Running loss: 0.84980\n",
      "Epoch: 0 | Iteration: 38391 | Classification loss: 0.45224 | Regression loss: 0.55889 | Running loss: 0.85066\n",
      "Epoch: 0 | Iteration: 38392 | Classification loss: 0.39319 | Regression loss: 0.51227 | Running loss: 0.85100\n",
      "Epoch: 0 | Iteration: 38393 | Classification loss: 0.49317 | Regression loss: 0.68680 | Running loss: 0.85159\n",
      "Epoch: 0 | Iteration: 38394 | Classification loss: 0.29401 | Regression loss: 0.48562 | Running loss: 0.85194\n",
      "Epoch: 0 | Iteration: 38395 | Classification loss: 0.46098 | Regression loss: 0.51665 | Running loss: 0.85223\n",
      "Epoch: 0 | Iteration: 38396 | Classification loss: 0.26697 | Regression loss: 0.38568 | Running loss: 0.85173\n",
      "Epoch: 0 | Iteration: 38397 | Classification loss: 0.19784 | Regression loss: 0.30797 | Running loss: 0.85171\n",
      "Epoch: 0 | Iteration: 38398 | Classification loss: 0.31646 | Regression loss: 0.56170 | Running loss: 0.85175\n",
      "Epoch: 0 | Iteration: 38399 | Classification loss: 0.47630 | Regression loss: 0.48245 | Running loss: 0.85178\n",
      "Epoch: 0 | Iteration: 38400 | Classification loss: 0.35088 | Regression loss: 0.46149 | Running loss: 0.85226\n",
      "Epoch: 0 | Iteration: 38401 | Classification loss: 0.27392 | Regression loss: 0.55159 | Running loss: 0.85283\n",
      "Epoch: 0 | Iteration: 38402 | Classification loss: 0.47726 | Regression loss: 0.58151 | Running loss: 0.85304\n",
      "Epoch: 0 | Iteration: 38403 | Classification loss: 0.27987 | Regression loss: 0.48846 | Running loss: 0.85271\n",
      "Epoch: 0 | Iteration: 38404 | Classification loss: 0.19156 | Regression loss: 0.20569 | Running loss: 0.85164\n",
      "Epoch: 0 | Iteration: 38405 | Classification loss: 0.62147 | Regression loss: 0.65544 | Running loss: 0.85281\n",
      "Epoch: 0 | Iteration: 38406 | Classification loss: 0.36812 | Regression loss: 0.46995 | Running loss: 0.85288\n",
      "Epoch: 0 | Iteration: 38407 | Classification loss: 0.50861 | Regression loss: 0.68867 | Running loss: 0.85417\n",
      "Epoch: 0 | Iteration: 38408 | Classification loss: 1.61209 | Regression loss: 0.00000 | Running loss: 0.85514\n",
      "Epoch: 0 | Iteration: 38409 | Classification loss: 0.35878 | Regression loss: 0.53795 | Running loss: 0.85537\n",
      "Epoch: 0 | Iteration: 38410 | Classification loss: 0.32711 | Regression loss: 0.46703 | Running loss: 0.85551\n",
      "Epoch: 0 | Iteration: 38411 | Classification loss: 0.67565 | Regression loss: 0.42124 | Running loss: 0.85609\n",
      "Epoch: 0 | Iteration: 38412 | Classification loss: 0.42455 | Regression loss: 0.77797 | Running loss: 0.85727\n",
      "Epoch: 0 | Iteration: 38413 | Classification loss: 0.36968 | Regression loss: 0.70974 | Running loss: 0.85751\n",
      "Epoch: 0 | Iteration: 38414 | Classification loss: 0.23590 | Regression loss: 0.27898 | Running loss: 0.85778\n",
      "Epoch: 0 | Iteration: 38415 | Classification loss: 0.28566 | Regression loss: 0.27847 | Running loss: 0.85745\n",
      "Epoch: 0 | Iteration: 38416 | Classification loss: 0.46929 | Regression loss: 0.52999 | Running loss: 0.85696\n",
      "Epoch: 0 | Iteration: 38417 | Classification loss: 0.38324 | Regression loss: 0.40768 | Running loss: 0.85708\n",
      "Epoch: 0 | Iteration: 38418 | Classification loss: 0.43528 | Regression loss: 0.51778 | Running loss: 0.85716\n",
      "Epoch: 0 | Iteration: 38419 | Classification loss: 0.57980 | Regression loss: 0.65433 | Running loss: 0.85848\n",
      "Epoch: 0 | Iteration: 38420 | Classification loss: 0.43056 | Regression loss: 0.46902 | Running loss: 0.85933\n",
      "Epoch: 0 | Iteration: 38421 | Classification loss: 0.49366 | Regression loss: 0.74160 | Running loss: 0.86037\n",
      "Epoch: 0 | Iteration: 38422 | Classification loss: 0.42793 | Regression loss: 0.59224 | Running loss: 0.86014\n",
      "Epoch: 0 | Iteration: 38423 | Classification loss: 0.19472 | Regression loss: 0.41901 | Running loss: 0.85929\n",
      "Epoch: 0 | Iteration: 38424 | Classification loss: 0.36334 | Regression loss: 0.60654 | Running loss: 0.85956\n",
      "Epoch: 0 | Iteration: 38425 | Classification loss: 1.71003 | Regression loss: 0.11113 | Running loss: 0.86109\n",
      "Epoch: 0 | Iteration: 38426 | Classification loss: 0.31855 | Regression loss: 0.45553 | Running loss: 0.86113\n",
      "Epoch: 0 | Iteration: 38427 | Classification loss: 0.39858 | Regression loss: 0.39980 | Running loss: 0.86154\n",
      "Epoch: 0 | Iteration: 38428 | Classification loss: 0.23926 | Regression loss: 0.40008 | Running loss: 0.86082\n",
      "Epoch: 0 | Iteration: 38429 | Classification loss: 0.24394 | Regression loss: 0.40757 | Running loss: 0.86012\n",
      "Epoch: 0 | Iteration: 38430 | Classification loss: 0.31459 | Regression loss: 0.54045 | Running loss: 0.86006\n",
      "Epoch: 0 | Iteration: 38431 | Classification loss: 0.23974 | Regression loss: 0.33446 | Running loss: 0.85991\n",
      "Epoch: 0 | Iteration: 38432 | Classification loss: 0.35974 | Regression loss: 0.36095 | Running loss: 0.85973\n",
      "Epoch: 0 | Iteration: 38433 | Classification loss: 0.34073 | Regression loss: 0.45306 | Running loss: 0.85986\n",
      "Epoch: 0 | Iteration: 38434 | Classification loss: 0.28525 | Regression loss: 0.33287 | Running loss: 0.85947\n",
      "Epoch: 0 | Iteration: 38435 | Classification loss: 0.38049 | Regression loss: 0.37834 | Running loss: 0.85999\n",
      "Epoch: 0 | Iteration: 38436 | Classification loss: 0.16601 | Regression loss: 0.31978 | Running loss: 0.85951\n",
      "Epoch: 0 | Iteration: 38437 | Classification loss: 0.27181 | Regression loss: 0.55607 | Running loss: 0.85715\n",
      "Epoch: 0 | Iteration: 38438 | Classification loss: 0.17926 | Regression loss: 0.30658 | Running loss: 0.85635\n",
      "Epoch: 0 | Iteration: 38439 | Classification loss: 0.51427 | Regression loss: 0.56520 | Running loss: 0.85715\n",
      "Epoch: 0 | Iteration: 38440 | Classification loss: 0.46742 | Regression loss: 0.68341 | Running loss: 0.85662\n",
      "Epoch: 0 | Iteration: 38441 | Classification loss: 0.73517 | Regression loss: 0.69205 | Running loss: 0.85768\n",
      "Epoch: 0 | Iteration: 38442 | Classification loss: 0.65877 | Regression loss: 0.46488 | Running loss: 0.85832\n",
      "Epoch: 0 | Iteration: 38443 | Classification loss: 0.36503 | Regression loss: 0.51966 | Running loss: 0.85840\n",
      "Epoch: 0 | Iteration: 38444 | Classification loss: 0.40294 | Regression loss: 0.44062 | Running loss: 0.85798\n",
      "Epoch: 0 | Iteration: 38445 | Classification loss: 0.45703 | Regression loss: 0.56456 | Running loss: 0.85640\n",
      "Epoch: 0 | Iteration: 38446 | Classification loss: 0.43382 | Regression loss: 0.37784 | Running loss: 0.85620\n",
      "Epoch: 0 | Iteration: 38447 | Classification loss: 0.48495 | Regression loss: 0.45677 | Running loss: 0.85630\n",
      "Epoch: 0 | Iteration: 38448 | Classification loss: 0.21287 | Regression loss: 0.32427 | Running loss: 0.85566\n",
      "Epoch: 0 | Iteration: 38449 | Classification loss: 0.30080 | Regression loss: 0.35901 | Running loss: 0.85623\n",
      "Epoch: 0 | Iteration: 38450 | Classification loss: 0.40300 | Regression loss: 0.48718 | Running loss: 0.85600\n",
      "Epoch: 0 | Iteration: 38451 | Classification loss: 0.38930 | Regression loss: 0.26523 | Running loss: 0.85562\n",
      "Epoch: 0 | Iteration: 38452 | Classification loss: 0.60886 | Regression loss: 0.57518 | Running loss: 0.85667\n",
      "Epoch: 0 | Iteration: 38453 | Classification loss: 0.56198 | Regression loss: 0.75809 | Running loss: 0.85756\n",
      "Epoch: 0 | Iteration: 38454 | Classification loss: 0.38908 | Regression loss: 0.56766 | Running loss: 0.85794\n",
      "Epoch: 0 | Iteration: 38455 | Classification loss: 0.21672 | Regression loss: 0.38993 | Running loss: 0.85726\n",
      "Epoch: 0 | Iteration: 38456 | Classification loss: 0.51536 | Regression loss: 0.71261 | Running loss: 0.85784\n",
      "Epoch: 0 | Iteration: 38457 | Classification loss: 0.49728 | Regression loss: 0.70314 | Running loss: 0.85890\n",
      "Epoch: 0 | Iteration: 38458 | Classification loss: 0.54824 | Regression loss: 0.56989 | Running loss: 0.85934\n",
      "Epoch: 0 | Iteration: 38459 | Classification loss: 0.28858 | Regression loss: 0.52498 | Running loss: 0.85999\n",
      "Epoch: 0 | Iteration: 38460 | Classification loss: 0.56210 | Regression loss: 0.43018 | Running loss: 0.86048\n",
      "Epoch: 0 | Iteration: 38461 | Classification loss: 0.55802 | Regression loss: 0.40643 | Running loss: 0.86109\n",
      "Epoch: 0 | Iteration: 38462 | Classification loss: 0.52476 | Regression loss: 0.59323 | Running loss: 0.86222\n",
      "Epoch: 0 | Iteration: 38463 | Classification loss: 0.38583 | Regression loss: 0.46947 | Running loss: 0.86194\n",
      "Epoch: 0 | Iteration: 38464 | Classification loss: 0.33855 | Regression loss: 0.61903 | Running loss: 0.86219\n",
      "Epoch: 0 | Iteration: 38465 | Classification loss: 0.53620 | Regression loss: 0.69697 | Running loss: 0.86304\n",
      "Epoch: 0 | Iteration: 38466 | Classification loss: 0.55240 | Regression loss: 0.67108 | Running loss: 0.86352\n",
      "Epoch: 0 | Iteration: 38467 | Classification loss: 0.28501 | Regression loss: 0.53616 | Running loss: 0.86362\n",
      "Epoch: 0 | Iteration: 38468 | Classification loss: 0.44606 | Regression loss: 0.62100 | Running loss: 0.86410\n",
      "Epoch: 0 | Iteration: 38469 | Classification loss: 0.34035 | Regression loss: 0.41758 | Running loss: 0.86410\n",
      "Epoch: 0 | Iteration: 38470 | Classification loss: 0.21578 | Regression loss: 0.35301 | Running loss: 0.86292\n",
      "Epoch: 0 | Iteration: 38471 | Classification loss: 0.47247 | Regression loss: 0.58382 | Running loss: 0.86330\n",
      "Epoch: 0 | Iteration: 38472 | Classification loss: 0.22525 | Regression loss: 0.49712 | Running loss: 0.86284\n",
      "Epoch: 0 | Iteration: 38473 | Classification loss: 0.38011 | Regression loss: 0.45554 | Running loss: 0.86338\n",
      "Epoch: 0 | Iteration: 38474 | Classification loss: 0.24436 | Regression loss: 0.39254 | Running loss: 0.86344\n",
      "Epoch: 0 | Iteration: 38475 | Classification loss: 0.57790 | Regression loss: 0.68852 | Running loss: 0.86393\n",
      "Epoch: 0 | Iteration: 38476 | Classification loss: 0.32602 | Regression loss: 0.52989 | Running loss: 0.86398\n",
      "Epoch: 0 | Iteration: 38477 | Classification loss: 0.58813 | Regression loss: 0.55892 | Running loss: 0.86539\n",
      "Epoch: 0 | Iteration: 38478 | Classification loss: 0.41013 | Regression loss: 0.58931 | Running loss: 0.86678\n",
      "Epoch: 0 | Iteration: 38479 | Classification loss: 0.36428 | Regression loss: 0.36138 | Running loss: 0.86691\n",
      "Epoch: 0 | Iteration: 38480 | Classification loss: 0.43166 | Regression loss: 0.38953 | Running loss: 0.86682\n",
      "Epoch: 0 | Iteration: 38481 | Classification loss: 0.39454 | Regression loss: 0.36284 | Running loss: 0.86688\n",
      "Epoch: 0 | Iteration: 38482 | Classification loss: 0.59991 | Regression loss: 0.55787 | Running loss: 0.86398\n",
      "Epoch: 0 | Iteration: 38483 | Classification loss: 0.44009 | Regression loss: 0.63671 | Running loss: 0.86522\n",
      "Epoch: 0 | Iteration: 38484 | Classification loss: 0.34616 | Regression loss: 0.51538 | Running loss: 0.86580\n",
      "Epoch: 0 | Iteration: 38485 | Classification loss: 0.51157 | Regression loss: 0.62145 | Running loss: 0.86629\n",
      "Epoch: 0 | Iteration: 38486 | Classification loss: 0.26225 | Regression loss: 0.28452 | Running loss: 0.86614\n",
      "Epoch: 0 | Iteration: 38487 | Classification loss: 0.44053 | Regression loss: 0.59040 | Running loss: 0.86660\n",
      "Epoch: 0 | Iteration: 38488 | Classification loss: 0.51131 | Regression loss: 0.48697 | Running loss: 0.86654\n",
      "Epoch: 0 | Iteration: 38489 | Classification loss: 0.33765 | Regression loss: 0.47906 | Running loss: 0.86661\n",
      "Epoch: 0 | Iteration: 38490 | Classification loss: 0.25183 | Regression loss: 0.35224 | Running loss: 0.86597\n",
      "Epoch: 0 | Iteration: 38491 | Classification loss: 0.33308 | Regression loss: 0.52321 | Running loss: 0.86565\n",
      "Epoch: 0 | Iteration: 38492 | Classification loss: 0.45919 | Regression loss: 0.58463 | Running loss: 0.86616\n",
      "Epoch: 0 | Iteration: 38493 | Classification loss: 0.55915 | Regression loss: 0.52483 | Running loss: 0.86609\n",
      "Epoch: 0 | Iteration: 38494 | Classification loss: 0.29609 | Regression loss: 0.40692 | Running loss: 0.86641\n",
      "Epoch: 0 | Iteration: 38495 | Classification loss: 0.43078 | Regression loss: 0.41212 | Running loss: 0.86675\n",
      "Epoch: 0 | Iteration: 38496 | Classification loss: 0.44311 | Regression loss: 0.49065 | Running loss: 0.86699\n",
      "Epoch: 0 | Iteration: 38497 | Classification loss: 0.27125 | Regression loss: 0.47190 | Running loss: 0.86629\n",
      "Epoch: 0 | Iteration: 38498 | Classification loss: 0.30182 | Regression loss: 0.38285 | Running loss: 0.86596\n",
      "Epoch: 0 | Iteration: 38499 | Classification loss: 0.40717 | Regression loss: 0.49160 | Running loss: 0.86560\n",
      "Epoch: 0 | Iteration: 38500 | Classification loss: 0.35728 | Regression loss: 0.16187 | Running loss: 0.86463\n",
      "Epoch: 0 | Iteration: 38501 | Classification loss: 0.30833 | Regression loss: 0.38246 | Running loss: 0.86459\n",
      "Epoch: 0 | Iteration: 38502 | Classification loss: 0.30707 | Regression loss: 0.56172 | Running loss: 0.86471\n",
      "Epoch: 0 | Iteration: 38503 | Classification loss: 0.44276 | Regression loss: 0.29012 | Running loss: 0.86453\n",
      "Epoch: 0 | Iteration: 38504 | Classification loss: 0.60318 | Regression loss: 0.59107 | Running loss: 0.86481\n",
      "Epoch: 0 | Iteration: 38505 | Classification loss: 0.54542 | Regression loss: 0.78157 | Running loss: 0.86538\n",
      "Epoch: 0 | Iteration: 38506 | Classification loss: 0.42560 | Regression loss: 0.50924 | Running loss: 0.86475\n",
      "Epoch: 0 | Iteration: 38507 | Classification loss: 0.49580 | Regression loss: 0.54870 | Running loss: 0.86476\n",
      "Epoch: 0 | Iteration: 38508 | Classification loss: 0.22270 | Regression loss: 0.30924 | Running loss: 0.86353\n",
      "Epoch: 0 | Iteration: 38509 | Classification loss: 0.27196 | Regression loss: 0.46886 | Running loss: 0.86342\n",
      "Epoch: 0 | Iteration: 38510 | Classification loss: 0.34742 | Regression loss: 0.60972 | Running loss: 0.86360\n",
      "Epoch: 0 | Iteration: 38511 | Classification loss: 0.36023 | Regression loss: 0.58520 | Running loss: 0.86405\n",
      "Epoch: 0 | Iteration: 38512 | Classification loss: 0.69635 | Regression loss: 0.62929 | Running loss: 0.86465\n",
      "Epoch: 0 | Iteration: 38513 | Classification loss: 0.27638 | Regression loss: 0.28116 | Running loss: 0.86394\n",
      "Epoch: 0 | Iteration: 38514 | Classification loss: 0.62468 | Regression loss: 0.76689 | Running loss: 0.86553\n",
      "Epoch: 0 | Iteration: 38515 | Classification loss: 0.15166 | Regression loss: 0.26788 | Running loss: 0.86469\n",
      "Epoch: 0 | Iteration: 38516 | Classification loss: 0.42601 | Regression loss: 0.50481 | Running loss: 0.86549\n",
      "Epoch: 0 | Iteration: 38517 | Classification loss: 0.38480 | Regression loss: 0.64231 | Running loss: 0.86601\n",
      "Epoch: 0 | Iteration: 38518 | Classification loss: 0.97398 | Regression loss: 0.67290 | Running loss: 0.86719\n",
      "Epoch: 0 | Iteration: 38519 | Classification loss: 0.21553 | Regression loss: 0.38365 | Running loss: 0.86694\n",
      "Epoch: 0 | Iteration: 38520 | Classification loss: 0.28792 | Regression loss: 0.48521 | Running loss: 0.86743\n",
      "Epoch: 0 | Iteration: 38521 | Classification loss: 0.26002 | Regression loss: 0.60281 | Running loss: 0.86719\n",
      "Epoch: 0 | Iteration: 38522 | Classification loss: 0.34097 | Regression loss: 0.37255 | Running loss: 0.86651\n",
      "Epoch: 0 | Iteration: 38523 | Classification loss: 0.40313 | Regression loss: 0.37196 | Running loss: 0.86632\n",
      "Epoch: 0 | Iteration: 38524 | Classification loss: 0.44787 | Regression loss: 0.60980 | Running loss: 0.86662\n",
      "Epoch: 0 | Iteration: 38525 | Classification loss: 0.31605 | Regression loss: 0.28009 | Running loss: 0.86637\n",
      "Epoch: 0 | Iteration: 38526 | Classification loss: 0.35291 | Regression loss: 0.59413 | Running loss: 0.86642\n",
      "Epoch: 0 | Iteration: 38527 | Classification loss: 0.27335 | Regression loss: 0.52834 | Running loss: 0.86649\n",
      "Epoch: 0 | Iteration: 38528 | Classification loss: 0.19655 | Regression loss: 0.20353 | Running loss: 0.86557\n",
      "Epoch: 0 | Iteration: 38529 | Classification loss: 0.43478 | Regression loss: 0.64476 | Running loss: 0.86599\n",
      "Epoch: 0 | Iteration: 38530 | Classification loss: 0.54545 | Regression loss: 0.51231 | Running loss: 0.86630\n",
      "Epoch: 0 | Iteration: 38531 | Classification loss: 3.82978 | Regression loss: 0.17357 | Running loss: 0.87238\n",
      "Epoch: 0 | Iteration: 38532 | Classification loss: 0.26462 | Regression loss: 0.38522 | Running loss: 0.87230\n",
      "Epoch: 0 | Iteration: 38533 | Classification loss: 0.34094 | Regression loss: 0.52917 | Running loss: 0.87261\n",
      "Epoch: 0 | Iteration: 38534 | Classification loss: 0.36078 | Regression loss: 0.50617 | Running loss: 0.87302\n",
      "Epoch: 0 | Iteration: 38535 | Classification loss: 0.40554 | Regression loss: 0.51434 | Running loss: 0.87202\n",
      "Epoch: 0 | Iteration: 38536 | Classification loss: 0.30260 | Regression loss: 0.37456 | Running loss: 0.87195\n",
      "Epoch: 0 | Iteration: 38537 | Classification loss: 0.35410 | Regression loss: 0.54944 | Running loss: 0.87216\n",
      "Epoch: 0 | Iteration: 38538 | Classification loss: 0.32651 | Regression loss: 0.41723 | Running loss: 0.87250\n",
      "Epoch: 0 | Iteration: 38539 | Classification loss: 0.54036 | Regression loss: 0.48921 | Running loss: 0.87200\n",
      "Epoch: 0 | Iteration: 38540 | Classification loss: 0.32966 | Regression loss: 0.33338 | Running loss: 0.87193\n",
      "Epoch: 0 | Iteration: 38541 | Classification loss: 0.37236 | Regression loss: 0.46166 | Running loss: 0.87077\n",
      "Epoch: 0 | Iteration: 38542 | Classification loss: 0.49091 | Regression loss: 0.68272 | Running loss: 0.87159\n",
      "Epoch: 0 | Iteration: 38543 | Classification loss: 0.30574 | Regression loss: 0.15913 | Running loss: 0.87072\n",
      "Epoch: 0 | Iteration: 38544 | Classification loss: 0.22933 | Regression loss: 0.54404 | Running loss: 0.87056\n",
      "Epoch: 0 | Iteration: 38545 | Classification loss: 0.21167 | Regression loss: 0.52655 | Running loss: 0.86983\n",
      "Epoch: 0 | Iteration: 38546 | Classification loss: 0.29381 | Regression loss: 0.53602 | Running loss: 0.86954\n",
      "Epoch: 0 | Iteration: 38547 | Classification loss: 0.67327 | Regression loss: 0.49766 | Running loss: 0.87046\n",
      "Epoch: 0 | Iteration: 38548 | Classification loss: 0.45156 | Regression loss: 0.59730 | Running loss: 0.87147\n",
      "Epoch: 0 | Iteration: 38549 | Classification loss: 0.27933 | Regression loss: 0.58715 | Running loss: 0.87154\n",
      "Epoch: 0 | Iteration: 38550 | Classification loss: 0.25915 | Regression loss: 0.40481 | Running loss: 0.87029\n",
      "Epoch: 0 | Iteration: 38551 | Classification loss: 0.53401 | Regression loss: 0.71920 | Running loss: 0.87084\n",
      "Epoch: 0 | Iteration: 38552 | Classification loss: 0.30098 | Regression loss: 0.49177 | Running loss: 0.87090\n",
      "Epoch: 0 | Iteration: 38553 | Classification loss: 0.32397 | Regression loss: 0.45819 | Running loss: 0.87096\n",
      "Epoch: 0 | Iteration: 38554 | Classification loss: 0.31280 | Regression loss: 0.53224 | Running loss: 0.87059\n",
      "Epoch: 0 | Iteration: 38555 | Classification loss: 0.46232 | Regression loss: 0.46689 | Running loss: 0.87042\n",
      "Epoch: 0 | Iteration: 38556 | Classification loss: 0.44797 | Regression loss: 0.66158 | Running loss: 0.87145\n",
      "Epoch: 0 | Iteration: 38557 | Classification loss: 0.35961 | Regression loss: 0.46367 | Running loss: 0.87049\n",
      "Epoch: 0 | Iteration: 38558 | Classification loss: 0.35055 | Regression loss: 0.53412 | Running loss: 0.87109\n",
      "Epoch: 0 | Iteration: 38559 | Classification loss: 0.24807 | Regression loss: 0.47437 | Running loss: 0.87056\n",
      "Epoch: 0 | Iteration: 38560 | Classification loss: 0.34074 | Regression loss: 0.50290 | Running loss: 0.87071\n",
      "Epoch: 0 | Iteration: 38561 | Classification loss: 0.57206 | Regression loss: 0.78780 | Running loss: 0.87147\n",
      "Epoch: 0 | Iteration: 38562 | Classification loss: 0.48642 | Regression loss: 0.43909 | Running loss: 0.87117\n",
      "Epoch: 0 | Iteration: 38563 | Classification loss: 0.55814 | Regression loss: 0.69306 | Running loss: 0.87210\n",
      "Epoch: 0 | Iteration: 38564 | Classification loss: 0.35591 | Regression loss: 0.49120 | Running loss: 0.87228\n",
      "Epoch: 0 | Iteration: 38565 | Classification loss: 0.26124 | Regression loss: 0.40037 | Running loss: 0.87226\n",
      "Epoch: 0 | Iteration: 38566 | Classification loss: 0.12782 | Regression loss: 0.46476 | Running loss: 0.87186\n",
      "Epoch: 0 | Iteration: 38567 | Classification loss: 0.12696 | Regression loss: 0.25108 | Running loss: 0.87009\n",
      "Epoch: 0 | Iteration: 38568 | Classification loss: 0.41523 | Regression loss: 0.75992 | Running loss: 0.87147\n",
      "Epoch: 0 | Iteration: 38569 | Classification loss: 0.47394 | Regression loss: 0.65377 | Running loss: 0.87179\n",
      "Epoch: 0 | Iteration: 38570 | Classification loss: 0.50562 | Regression loss: 0.53810 | Running loss: 0.87271\n",
      "Epoch: 0 | Iteration: 38571 | Classification loss: 0.42643 | Regression loss: 0.47584 | Running loss: 0.87275\n",
      "Epoch: 0 | Iteration: 38572 | Classification loss: 0.50592 | Regression loss: 0.54239 | Running loss: 0.87246\n",
      "Epoch: 0 | Iteration: 38573 | Classification loss: 0.31478 | Regression loss: 0.43165 | Running loss: 0.87145\n",
      "Epoch: 0 | Iteration: 38574 | Classification loss: 0.39437 | Regression loss: 0.48256 | Running loss: 0.87184\n",
      "Epoch: 0 | Iteration: 38575 | Classification loss: 0.30221 | Regression loss: 0.40161 | Running loss: 0.87113\n",
      "Epoch: 0 | Iteration: 38576 | Classification loss: 0.24088 | Regression loss: 0.42352 | Running loss: 0.87054\n",
      "Epoch: 0 | Iteration: 38577 | Classification loss: 0.18158 | Regression loss: 0.47161 | Running loss: 0.87007\n",
      "Epoch: 0 | Iteration: 38578 | Classification loss: 0.13955 | Regression loss: 0.28182 | Running loss: 0.86908\n",
      "Epoch: 0 | Iteration: 38579 | Classification loss: 0.47393 | Regression loss: 0.64191 | Running loss: 0.86938\n",
      "Epoch: 0 | Iteration: 38580 | Classification loss: 0.44718 | Regression loss: 0.35252 | Running loss: 0.86830\n",
      "Epoch: 0 | Iteration: 38581 | Classification loss: 0.48122 | Regression loss: 0.42521 | Running loss: 0.86845\n",
      "Epoch: 0 | Iteration: 38582 | Classification loss: 0.26716 | Regression loss: 0.49773 | Running loss: 0.86908\n",
      "Epoch: 0 | Iteration: 38583 | Classification loss: 0.30968 | Regression loss: 0.61347 | Running loss: 0.86899\n",
      "Epoch: 0 | Iteration: 38584 | Classification loss: 0.10502 | Regression loss: 0.25250 | Running loss: 0.86775\n",
      "Epoch: 0 | Iteration: 38585 | Classification loss: 0.42635 | Regression loss: 0.36318 | Running loss: 0.86701\n",
      "Epoch: 0 | Iteration: 38586 | Classification loss: 0.54353 | Regression loss: 0.67047 | Running loss: 0.86800\n",
      "Epoch: 0 | Iteration: 38587 | Classification loss: 0.42777 | Regression loss: 0.57347 | Running loss: 0.86825\n",
      "Epoch: 0 | Iteration: 38588 | Classification loss: 0.44227 | Regression loss: 0.16375 | Running loss: 0.86725\n",
      "Epoch: 0 | Iteration: 38589 | Classification loss: 0.31234 | Regression loss: 0.45103 | Running loss: 0.86676\n",
      "Epoch: 0 | Iteration: 38590 | Classification loss: 0.41563 | Regression loss: 0.50222 | Running loss: 0.86615\n",
      "Epoch: 0 | Iteration: 38591 | Classification loss: 0.30732 | Regression loss: 0.41717 | Running loss: 0.86667\n",
      "Epoch: 0 | Iteration: 38592 | Classification loss: 0.52729 | Regression loss: 0.75641 | Running loss: 0.86691\n",
      "Epoch: 0 | Iteration: 38593 | Classification loss: 0.60680 | Regression loss: 0.31127 | Running loss: 0.86675\n",
      "Epoch: 0 | Iteration: 38594 | Classification loss: 0.48274 | Regression loss: 0.69355 | Running loss: 0.86779\n",
      "Epoch: 0 | Iteration: 38595 | Classification loss: 0.42421 | Regression loss: 0.72581 | Running loss: 0.86890\n",
      "Epoch: 0 | Iteration: 38596 | Classification loss: 0.45139 | Regression loss: 0.47396 | Running loss: 0.86928\n",
      "Epoch: 0 | Iteration: 38597 | Classification loss: 0.48862 | Regression loss: 0.46597 | Running loss: 0.86969\n",
      "Epoch: 0 | Iteration: 38598 | Classification loss: 0.36629 | Regression loss: 0.58620 | Running loss: 0.86987\n",
      "Epoch: 0 | Iteration: 38599 | Classification loss: 0.36654 | Regression loss: 0.53244 | Running loss: 0.86969\n",
      "Epoch: 0 | Iteration: 38600 | Classification loss: 0.46968 | Regression loss: 0.54338 | Running loss: 0.87019\n",
      "Epoch: 0 | Iteration: 38601 | Classification loss: 0.29558 | Regression loss: 0.63759 | Running loss: 0.86991\n",
      "Epoch: 0 | Iteration: 38602 | Classification loss: 0.13670 | Regression loss: 0.36094 | Running loss: 0.86937\n",
      "Epoch: 0 | Iteration: 38603 | Classification loss: 0.24113 | Regression loss: 0.35640 | Running loss: 0.86818\n",
      "Epoch: 0 | Iteration: 38604 | Classification loss: 0.55203 | Regression loss: 0.67653 | Running loss: 0.86930\n",
      "Epoch: 0 | Iteration: 38605 | Classification loss: 0.29466 | Regression loss: 0.37077 | Running loss: 0.86965\n",
      "Epoch: 0 | Iteration: 38606 | Classification loss: 0.19463 | Regression loss: 0.30399 | Running loss: 0.86868\n",
      "Epoch: 0 | Iteration: 38607 | Classification loss: 0.42103 | Regression loss: 0.54033 | Running loss: 0.86837\n",
      "Epoch: 0 | Iteration: 38608 | Classification loss: 0.49085 | Regression loss: 0.62950 | Running loss: 0.86964\n",
      "Epoch: 0 | Iteration: 38609 | Classification loss: 0.35217 | Regression loss: 0.53214 | Running loss: 0.86954\n",
      "Epoch: 0 | Iteration: 38610 | Classification loss: 0.47706 | Regression loss: 0.51965 | Running loss: 0.87052\n",
      "Epoch: 0 | Iteration: 38611 | Classification loss: 0.37712 | Regression loss: 0.67177 | Running loss: 0.87104\n",
      "Epoch: 0 | Iteration: 38612 | Classification loss: 0.17644 | Regression loss: 0.38041 | Running loss: 0.87031\n",
      "Epoch: 0 | Iteration: 38613 | Classification loss: 0.51744 | Regression loss: 0.40682 | Running loss: 0.87018\n",
      "Epoch: 0 | Iteration: 38614 | Classification loss: 0.75914 | Regression loss: 0.08563 | Running loss: 0.87077\n",
      "Epoch: 0 | Iteration: 38615 | Classification loss: 0.25735 | Regression loss: 0.50991 | Running loss: 0.87121\n",
      "Epoch: 0 | Iteration: 38616 | Classification loss: 0.16415 | Regression loss: 0.35195 | Running loss: 0.87034\n",
      "Epoch: 0 | Iteration: 38617 | Classification loss: 0.45956 | Regression loss: 0.41085 | Running loss: 0.87075\n",
      "Epoch: 0 | Iteration: 38618 | Classification loss: 0.26636 | Regression loss: 0.57711 | Running loss: 0.87088\n",
      "Epoch: 0 | Iteration: 38619 | Classification loss: 0.34985 | Regression loss: 0.58040 | Running loss: 0.87051\n",
      "Epoch: 0 | Iteration: 38620 | Classification loss: 0.36477 | Regression loss: 0.75399 | Running loss: 0.87082\n",
      "Epoch: 0 | Iteration: 38621 | Classification loss: 0.35879 | Regression loss: 0.44914 | Running loss: 0.87061\n",
      "Epoch: 0 | Iteration: 38622 | Classification loss: 0.38590 | Regression loss: 0.57741 | Running loss: 0.87159\n",
      "Epoch: 0 | Iteration: 38623 | Classification loss: 0.05950 | Regression loss: 0.31882 | Running loss: 0.87118\n",
      "Epoch: 0 | Iteration: 38624 | Classification loss: 0.50995 | Regression loss: 0.37061 | Running loss: 0.87061\n",
      "Epoch: 0 | Iteration: 38625 | Classification loss: 0.29702 | Regression loss: 0.34299 | Running loss: 0.87121\n",
      "Epoch: 0 | Iteration: 38626 | Classification loss: 0.31265 | Regression loss: 0.39734 | Running loss: 0.87107\n",
      "Epoch: 0 | Iteration: 38627 | Classification loss: 0.45740 | Regression loss: 0.56913 | Running loss: 0.87232\n",
      "Epoch: 0 | Iteration: 38628 | Classification loss: 0.45215 | Regression loss: 0.57766 | Running loss: 0.87241\n",
      "Epoch: 0 | Iteration: 38629 | Classification loss: 0.87700 | Regression loss: 0.34588 | Running loss: 0.87347\n",
      "Epoch: 0 | Iteration: 38630 | Classification loss: 0.17331 | Regression loss: 0.39129 | Running loss: 0.87218\n",
      "Epoch: 0 | Iteration: 38631 | Classification loss: 0.51041 | Regression loss: 0.49186 | Running loss: 0.87197\n",
      "Epoch: 0 | Iteration: 38632 | Classification loss: 0.20970 | Regression loss: 0.24920 | Running loss: 0.87126\n",
      "Epoch: 0 | Iteration: 38633 | Classification loss: 0.45486 | Regression loss: 0.62854 | Running loss: 0.87194\n",
      "Epoch: 0 | Iteration: 38634 | Classification loss: 0.29539 | Regression loss: 0.46747 | Running loss: 0.87225\n",
      "Epoch: 0 | Iteration: 38635 | Classification loss: 0.29382 | Regression loss: 0.52166 | Running loss: 0.87210\n",
      "Epoch: 0 | Iteration: 38636 | Classification loss: 0.28439 | Regression loss: 0.50320 | Running loss: 0.87144\n",
      "Epoch: 0 | Iteration: 38637 | Classification loss: 0.33741 | Regression loss: 0.32154 | Running loss: 0.87144\n",
      "Epoch: 0 | Iteration: 38638 | Classification loss: 0.44349 | Regression loss: 0.55893 | Running loss: 0.87217\n",
      "Epoch: 0 | Iteration: 38639 | Classification loss: 0.48758 | Regression loss: 0.63827 | Running loss: 0.87262\n",
      "Epoch: 0 | Iteration: 38640 | Classification loss: 0.30505 | Regression loss: 0.37309 | Running loss: 0.87319\n",
      "Epoch: 0 | Iteration: 38641 | Classification loss: 0.43465 | Regression loss: 0.37546 | Running loss: 0.87269\n",
      "Epoch: 0 | Iteration: 38642 | Classification loss: 0.37403 | Regression loss: 0.48476 | Running loss: 0.87228\n",
      "Epoch: 0 | Iteration: 38643 | Classification loss: 0.17974 | Regression loss: 0.26544 | Running loss: 0.87128\n",
      "Epoch: 0 | Iteration: 38644 | Classification loss: 0.12788 | Regression loss: 0.00000 | Running loss: 0.87024\n",
      "Epoch: 0 | Iteration: 38645 | Classification loss: 0.21762 | Regression loss: 0.39272 | Running loss: 0.86956\n",
      "Epoch: 0 | Iteration: 38646 | Classification loss: 0.51352 | Regression loss: 0.56496 | Running loss: 0.86953\n",
      "Epoch: 0 | Iteration: 38647 | Classification loss: 0.29242 | Regression loss: 0.21125 | Running loss: 0.86955\n",
      "Epoch: 0 | Iteration: 38648 | Classification loss: 0.46675 | Regression loss: 0.53573 | Running loss: 0.87047\n",
      "Epoch: 0 | Iteration: 38649 | Classification loss: 0.24955 | Regression loss: 0.48583 | Running loss: 0.87034\n",
      "Epoch: 0 | Iteration: 38650 | Classification loss: 0.36444 | Regression loss: 0.59598 | Running loss: 0.87061\n",
      "Epoch: 0 | Iteration: 38651 | Classification loss: 0.35962 | Regression loss: 0.40895 | Running loss: 0.87024\n",
      "Epoch: 0 | Iteration: 38652 | Classification loss: 0.12451 | Regression loss: 0.26024 | Running loss: 0.86871\n",
      "Epoch: 0 | Iteration: 38653 | Classification loss: 0.22766 | Regression loss: 0.42108 | Running loss: 0.86809\n",
      "Epoch: 0 | Iteration: 38654 | Classification loss: 0.38862 | Regression loss: 0.35824 | Running loss: 0.86843\n",
      "Epoch: 0 | Iteration: 38655 | Classification loss: 0.43458 | Regression loss: 0.45632 | Running loss: 0.86782\n",
      "Epoch: 0 | Iteration: 38656 | Classification loss: 0.49729 | Regression loss: 0.32925 | Running loss: 0.86738\n",
      "Epoch: 0 | Iteration: 38657 | Classification loss: 0.24547 | Regression loss: 0.50297 | Running loss: 0.86671\n",
      "Epoch: 0 | Iteration: 38658 | Classification loss: 0.32234 | Regression loss: 0.36477 | Running loss: 0.86625\n",
      "Epoch: 0 | Iteration: 38659 | Classification loss: 0.25627 | Regression loss: 0.52604 | Running loss: 0.86585\n",
      "Epoch: 0 | Iteration: 38660 | Classification loss: 0.27630 | Regression loss: 0.29683 | Running loss: 0.86540\n",
      "Epoch: 0 | Iteration: 38661 | Classification loss: 0.49775 | Regression loss: 0.33852 | Running loss: 0.86570\n",
      "Epoch: 0 | Iteration: 38662 | Classification loss: 0.40574 | Regression loss: 0.51491 | Running loss: 0.86516\n",
      "Epoch: 0 | Iteration: 38663 | Classification loss: 0.35833 | Regression loss: 0.52781 | Running loss: 0.86555\n",
      "Epoch: 0 | Iteration: 38664 | Classification loss: 0.35052 | Regression loss: 0.52572 | Running loss: 0.86565\n",
      "Epoch: 0 | Iteration: 38665 | Classification loss: 0.76566 | Regression loss: 0.73159 | Running loss: 0.86694\n",
      "Epoch: 0 | Iteration: 38666 | Classification loss: 0.30123 | Regression loss: 0.54755 | Running loss: 0.86678\n",
      "Epoch: 0 | Iteration: 38667 | Classification loss: 0.40079 | Regression loss: 0.53300 | Running loss: 0.86725\n",
      "Epoch: 0 | Iteration: 38668 | Classification loss: 0.33007 | Regression loss: 0.43888 | Running loss: 0.86698\n",
      "Epoch: 0 | Iteration: 38669 | Classification loss: 0.34825 | Regression loss: 0.33953 | Running loss: 0.86643\n",
      "Epoch: 0 | Iteration: 38670 | Classification loss: 0.30168 | Regression loss: 0.44017 | Running loss: 0.86644\n",
      "Epoch: 0 | Iteration: 38671 | Classification loss: 0.34289 | Regression loss: 0.46021 | Running loss: 0.86642\n",
      "Epoch: 0 | Iteration: 38672 | Classification loss: 0.37699 | Regression loss: 0.51096 | Running loss: 0.86660\n",
      "Epoch: 0 | Iteration: 38673 | Classification loss: 0.22143 | Regression loss: 0.51783 | Running loss: 0.86652\n",
      "Epoch: 0 | Iteration: 38674 | Classification loss: 0.39112 | Regression loss: 0.43329 | Running loss: 0.86721\n",
      "Epoch: 0 | Iteration: 38675 | Classification loss: 0.47972 | Regression loss: 0.47343 | Running loss: 0.86776\n",
      "Epoch: 0 | Iteration: 38676 | Classification loss: 0.21531 | Regression loss: 0.34677 | Running loss: 0.86835\n",
      "Epoch: 0 | Iteration: 38677 | Classification loss: 0.45427 | Regression loss: 0.59900 | Running loss: 0.86930\n",
      "Epoch: 0 | Iteration: 38678 | Classification loss: 0.40759 | Regression loss: 0.52914 | Running loss: 0.86946\n",
      "Epoch: 0 | Iteration: 38679 | Classification loss: 0.27767 | Regression loss: 0.51236 | Running loss: 0.86909\n",
      "Epoch: 0 | Iteration: 38680 | Classification loss: 0.19806 | Regression loss: 0.31398 | Running loss: 0.86763\n",
      "Epoch: 0 | Iteration: 38681 | Classification loss: 0.38078 | Regression loss: 0.25881 | Running loss: 0.86768\n",
      "Epoch: 0 | Iteration: 38682 | Classification loss: 0.30566 | Regression loss: 0.43128 | Running loss: 0.86812\n",
      "Epoch: 0 | Iteration: 38683 | Classification loss: 0.20864 | Regression loss: 0.56180 | Running loss: 0.86866\n",
      "Epoch: 0 | Iteration: 38684 | Classification loss: 0.62733 | Regression loss: 0.71119 | Running loss: 0.86959\n",
      "Epoch: 0 | Iteration: 38685 | Classification loss: 0.48942 | Regression loss: 0.71796 | Running loss: 0.86974\n",
      "Epoch: 0 | Iteration: 38686 | Classification loss: 0.10931 | Regression loss: 0.35903 | Running loss: 0.86870\n",
      "Epoch: 0 | Iteration: 38687 | Classification loss: 0.21563 | Regression loss: 0.40584 | Running loss: 0.86885\n",
      "Epoch: 0 | Iteration: 38688 | Classification loss: 0.45364 | Regression loss: 0.68268 | Running loss: 0.86973\n",
      "Epoch: 0 | Iteration: 38689 | Classification loss: 0.22188 | Regression loss: 0.54859 | Running loss: 0.87039\n",
      "Epoch: 0 | Iteration: 38690 | Classification loss: 0.81632 | Regression loss: 0.84135 | Running loss: 0.87194\n",
      "Epoch: 0 | Iteration: 38691 | Classification loss: 0.47873 | Regression loss: 0.60481 | Running loss: 0.87295\n",
      "Epoch: 0 | Iteration: 38692 | Classification loss: 0.52030 | Regression loss: 0.45320 | Running loss: 0.87326\n",
      "Epoch: 0 | Iteration: 38693 | Classification loss: 0.45866 | Regression loss: 0.60627 | Running loss: 0.87409\n",
      "Epoch: 0 | Iteration: 38694 | Classification loss: 0.19985 | Regression loss: 0.42576 | Running loss: 0.87358\n",
      "Epoch: 0 | Iteration: 38695 | Classification loss: 0.26771 | Regression loss: 0.40663 | Running loss: 0.87304\n",
      "Epoch: 0 | Iteration: 38696 | Classification loss: 0.39491 | Regression loss: 0.63725 | Running loss: 0.87308\n",
      "Epoch: 0 | Iteration: 38697 | Classification loss: 0.43110 | Regression loss: 0.51219 | Running loss: 0.87284\n",
      "Epoch: 0 | Iteration: 38698 | Classification loss: 0.46391 | Regression loss: 0.48889 | Running loss: 0.87384\n",
      "Epoch: 0 | Iteration: 38699 | Classification loss: 0.49514 | Regression loss: 0.47339 | Running loss: 0.87486\n",
      "Epoch: 0 | Iteration: 38700 | Classification loss: 0.39363 | Regression loss: 0.52687 | Running loss: 0.87552\n",
      "Epoch: 0 | Iteration: 38701 | Classification loss: 0.62976 | Regression loss: 0.59794 | Running loss: 0.87639\n",
      "Epoch: 0 | Iteration: 38702 | Classification loss: 0.18588 | Regression loss: 0.35711 | Running loss: 0.87594\n",
      "Epoch: 0 | Iteration: 38703 | Classification loss: 0.27746 | Regression loss: 0.32131 | Running loss: 0.87606\n",
      "Epoch: 0 | Iteration: 38704 | Classification loss: 0.54073 | Regression loss: 0.61395 | Running loss: 0.87490\n",
      "Epoch: 0 | Iteration: 38705 | Classification loss: 0.42500 | Regression loss: 0.87165 | Running loss: 0.87577\n",
      "Epoch: 0 | Iteration: 38706 | Classification loss: 0.37736 | Regression loss: 0.56461 | Running loss: 0.87587\n",
      "Epoch: 0 | Iteration: 38707 | Classification loss: 0.24911 | Regression loss: 0.24617 | Running loss: 0.87519\n",
      "Epoch: 0 | Iteration: 38708 | Classification loss: 0.49816 | Regression loss: 0.62332 | Running loss: 0.87592\n",
      "Epoch: 0 | Iteration: 38709 | Classification loss: 0.28589 | Regression loss: 0.38735 | Running loss: 0.87529\n",
      "Epoch: 0 | Iteration: 38710 | Classification loss: 0.14563 | Regression loss: 0.27245 | Running loss: 0.87500\n",
      "Epoch: 0 | Iteration: 38711 | Classification loss: 0.31725 | Regression loss: 0.56314 | Running loss: 0.87549\n",
      "Epoch: 0 | Iteration: 38712 | Classification loss: 0.08532 | Regression loss: 0.27046 | Running loss: 0.87439\n",
      "Epoch: 0 | Iteration: 38713 | Classification loss: 0.46584 | Regression loss: 0.73669 | Running loss: 0.87462\n",
      "Epoch: 0 | Iteration: 38714 | Classification loss: 0.38812 | Regression loss: 0.50079 | Running loss: 0.87503\n",
      "Epoch: 0 | Iteration: 38715 | Classification loss: 0.48564 | Regression loss: 0.28120 | Running loss: 0.87523\n",
      "Epoch: 0 | Iteration: 38716 | Classification loss: 0.25899 | Regression loss: 0.39695 | Running loss: 0.87530\n",
      "Epoch: 0 | Iteration: 38717 | Classification loss: 0.23277 | Regression loss: 0.32789 | Running loss: 0.87491\n",
      "Epoch: 0 | Iteration: 38718 | Classification loss: 0.66391 | Regression loss: 0.58793 | Running loss: 0.87645\n",
      "Epoch: 0 | Iteration: 38719 | Classification loss: 0.49794 | Regression loss: 0.69688 | Running loss: 0.87700\n",
      "Epoch: 0 | Iteration: 38720 | Classification loss: 0.32133 | Regression loss: 0.26722 | Running loss: 0.87608\n",
      "Epoch: 0 | Iteration: 38721 | Classification loss: 0.54922 | Regression loss: 0.42564 | Running loss: 0.87602\n",
      "Epoch: 0 | Iteration: 38722 | Classification loss: 0.64040 | Regression loss: 0.70488 | Running loss: 0.87781\n",
      "Epoch: 0 | Iteration: 38723 | Classification loss: 0.36376 | Regression loss: 0.44148 | Running loss: 0.87726\n",
      "Epoch: 0 | Iteration: 38724 | Classification loss: 0.35941 | Regression loss: 0.46727 | Running loss: 0.87729\n",
      "Epoch: 0 | Iteration: 38725 | Classification loss: 0.43591 | Regression loss: 0.57772 | Running loss: 0.87750\n",
      "Epoch: 0 | Iteration: 38726 | Classification loss: 0.54992 | Regression loss: 0.62639 | Running loss: 0.87812\n",
      "Epoch: 0 | Iteration: 38727 | Classification loss: 0.29523 | Regression loss: 0.38576 | Running loss: 0.87629\n",
      "Epoch: 0 | Iteration: 38728 | Classification loss: 0.32249 | Regression loss: 0.38029 | Running loss: 0.87501\n",
      "Epoch: 0 | Iteration: 38729 | Classification loss: 0.31030 | Regression loss: 0.56152 | Running loss: 0.87569\n",
      "Epoch: 0 | Iteration: 38730 | Classification loss: 0.38766 | Regression loss: 0.68251 | Running loss: 0.87599\n",
      "Epoch: 0 | Iteration: 38731 | Classification loss: 0.34709 | Regression loss: 0.42840 | Running loss: 0.87657\n",
      "Epoch: 0 | Iteration: 38732 | Classification loss: 0.28364 | Regression loss: 0.44253 | Running loss: 0.87615\n",
      "Epoch: 0 | Iteration: 38733 | Classification loss: 0.45958 | Regression loss: 0.66574 | Running loss: 0.87685\n",
      "Epoch: 0 | Iteration: 38734 | Classification loss: 0.18299 | Regression loss: 0.37250 | Running loss: 0.87663\n",
      "Epoch: 0 | Iteration: 38735 | Classification loss: 0.41009 | Regression loss: 0.57603 | Running loss: 0.87712\n",
      "Epoch: 0 | Iteration: 38736 | Classification loss: 0.33836 | Regression loss: 0.40869 | Running loss: 0.87737\n",
      "Epoch: 0 | Iteration: 38737 | Classification loss: 0.39317 | Regression loss: 0.39217 | Running loss: 0.87789\n",
      "Epoch: 0 | Iteration: 38738 | Classification loss: 0.09737 | Regression loss: 0.31074 | Running loss: 0.87734\n",
      "Epoch: 0 | Iteration: 38739 | Classification loss: 0.38820 | Regression loss: 0.58098 | Running loss: 0.87801\n",
      "Epoch: 0 | Iteration: 38740 | Classification loss: 0.13712 | Regression loss: 0.28946 | Running loss: 0.87785\n",
      "Epoch: 0 | Iteration: 38741 | Classification loss: 0.52774 | Regression loss: 0.61858 | Running loss: 0.87907\n",
      "Epoch: 0 | Iteration: 38742 | Classification loss: 0.28389 | Regression loss: 0.53545 | Running loss: 0.87969\n",
      "Epoch: 0 | Iteration: 38743 | Classification loss: 0.39390 | Regression loss: 0.59534 | Running loss: 0.88013\n",
      "Epoch: 0 | Iteration: 38744 | Classification loss: 0.58308 | Regression loss: 0.31722 | Running loss: 0.87975\n",
      "Epoch: 0 | Iteration: 38745 | Classification loss: 0.34151 | Regression loss: 0.44983 | Running loss: 0.87992\n",
      "Epoch: 0 | Iteration: 38746 | Classification loss: 0.41219 | Regression loss: 0.24467 | Running loss: 0.87997\n",
      "Epoch: 0 | Iteration: 38747 | Classification loss: 0.61471 | Regression loss: 0.50057 | Running loss: 0.88060\n",
      "Epoch: 0 | Iteration: 38748 | Classification loss: 0.39396 | Regression loss: 0.36860 | Running loss: 0.87950\n",
      "Epoch: 0 | Iteration: 38749 | Classification loss: 0.67176 | Regression loss: 0.55830 | Running loss: 0.88041\n",
      "Epoch: 0 | Iteration: 38750 | Classification loss: 0.37911 | Regression loss: 0.53814 | Running loss: 0.87896\n",
      "Epoch: 0 | Iteration: 38751 | Classification loss: 0.18424 | Regression loss: 0.39437 | Running loss: 0.87799\n",
      "Epoch: 0 | Iteration: 38752 | Classification loss: 0.35377 | Regression loss: 0.46579 | Running loss: 0.87782\n",
      "Epoch: 0 | Iteration: 38753 | Classification loss: 0.35080 | Regression loss: 0.44262 | Running loss: 0.87725\n",
      "Epoch: 0 | Iteration: 38754 | Classification loss: 0.90557 | Regression loss: 0.52716 | Running loss: 0.87877\n",
      "Epoch: 0 | Iteration: 38755 | Classification loss: 0.43823 | Regression loss: 0.82300 | Running loss: 0.88001\n",
      "Epoch: 0 | Iteration: 38756 | Classification loss: 0.21233 | Regression loss: 0.35801 | Running loss: 0.87857\n",
      "Epoch: 0 | Iteration: 38757 | Classification loss: 0.50621 | Regression loss: 0.36035 | Running loss: 0.87891\n",
      "Epoch: 0 | Iteration: 38758 | Classification loss: 0.36064 | Regression loss: 0.40357 | Running loss: 0.87786\n",
      "Epoch: 0 | Iteration: 38759 | Classification loss: 0.41299 | Regression loss: 0.51519 | Running loss: 0.87783\n",
      "Epoch: 0 | Iteration: 38760 | Classification loss: 0.23907 | Regression loss: 0.50054 | Running loss: 0.87764\n",
      "Epoch: 0 | Iteration: 38761 | Classification loss: 0.28702 | Regression loss: 0.39398 | Running loss: 0.87804\n",
      "Epoch: 0 | Iteration: 38762 | Classification loss: 0.26797 | Regression loss: 0.29605 | Running loss: 0.87755\n",
      "Epoch: 0 | Iteration: 38763 | Classification loss: 0.22113 | Regression loss: 0.26396 | Running loss: 0.87655\n",
      "Epoch: 0 | Iteration: 38764 | Classification loss: 0.39446 | Regression loss: 0.63954 | Running loss: 0.87638\n",
      "Epoch: 0 | Iteration: 38765 | Classification loss: 0.36451 | Regression loss: 0.48908 | Running loss: 0.87661\n",
      "Epoch: 0 | Iteration: 38766 | Classification loss: 0.50387 | Regression loss: 0.71255 | Running loss: 0.87651\n",
      "Epoch: 0 | Iteration: 38767 | Classification loss: 0.21769 | Regression loss: 0.25785 | Running loss: 0.87560\n",
      "Epoch: 0 | Iteration: 38768 | Classification loss: 0.31379 | Regression loss: 0.34786 | Running loss: 0.87536\n",
      "Epoch: 0 | Iteration: 38769 | Classification loss: 0.30316 | Regression loss: 0.37081 | Running loss: 0.87519\n",
      "Epoch: 0 | Iteration: 38770 | Classification loss: 0.21690 | Regression loss: 0.37318 | Running loss: 0.87400\n",
      "Epoch: 0 | Iteration: 38771 | Classification loss: 0.43878 | Regression loss: 0.46209 | Running loss: 0.87368\n",
      "Epoch: 0 | Iteration: 38772 | Classification loss: 0.13271 | Regression loss: 0.31761 | Running loss: 0.87242\n",
      "Epoch: 0 | Iteration: 38773 | Classification loss: 0.33310 | Regression loss: 0.53305 | Running loss: 0.87279\n",
      "Epoch: 0 | Iteration: 38774 | Classification loss: 0.31568 | Regression loss: 0.60383 | Running loss: 0.87264\n",
      "Epoch: 0 | Iteration: 38775 | Classification loss: 0.72293 | Regression loss: 0.68165 | Running loss: 0.87369\n",
      "Epoch: 0 | Iteration: 38776 | Classification loss: 0.26473 | Regression loss: 0.43061 | Running loss: 0.87329\n",
      "Epoch: 0 | Iteration: 38777 | Classification loss: 0.38473 | Regression loss: 0.52082 | Running loss: 0.87304\n",
      "Epoch: 0 | Iteration: 38778 | Classification loss: 0.53212 | Regression loss: 0.25347 | Running loss: 0.87210\n",
      "Epoch: 0 | Iteration: 38779 | Classification loss: 0.21360 | Regression loss: 0.40540 | Running loss: 0.87198\n",
      "Epoch: 0 | Iteration: 38780 | Classification loss: 0.58159 | Regression loss: 0.50795 | Running loss: 0.87308\n",
      "Epoch: 0 | Iteration: 38781 | Classification loss: 0.44844 | Regression loss: 0.67327 | Running loss: 0.87310\n",
      "Epoch: 0 | Iteration: 38782 | Classification loss: 0.42030 | Regression loss: 0.48879 | Running loss: 0.87306\n",
      "Epoch: 0 | Iteration: 38783 | Classification loss: 0.38465 | Regression loss: 0.62148 | Running loss: 0.87383\n",
      "Epoch: 0 | Iteration: 38784 | Classification loss: 0.40597 | Regression loss: 0.38445 | Running loss: 0.87398\n",
      "Epoch: 0 | Iteration: 38785 | Classification loss: 0.35051 | Regression loss: 0.47235 | Running loss: 0.87438\n",
      "Epoch: 0 | Iteration: 38786 | Classification loss: 0.47560 | Regression loss: 0.63556 | Running loss: 0.87438\n",
      "Epoch: 0 | Iteration: 38787 | Classification loss: 0.50895 | Regression loss: 0.59580 | Running loss: 0.87446\n",
      "Epoch: 0 | Iteration: 38788 | Classification loss: 0.28180 | Regression loss: 0.40598 | Running loss: 0.87389\n",
      "Epoch: 0 | Iteration: 38789 | Classification loss: 0.39318 | Regression loss: 0.50982 | Running loss: 0.87412\n",
      "Epoch: 0 | Iteration: 38790 | Classification loss: 0.37162 | Regression loss: 0.57619 | Running loss: 0.87497\n",
      "Epoch: 0 | Iteration: 38791 | Classification loss: 0.21620 | Regression loss: 0.31823 | Running loss: 0.87474\n",
      "Epoch: 0 | Iteration: 38792 | Classification loss: 0.45035 | Regression loss: 0.62395 | Running loss: 0.87538\n",
      "Epoch: 0 | Iteration: 38793 | Classification loss: 0.29504 | Regression loss: 0.42313 | Running loss: 0.87495\n",
      "Epoch: 0 | Iteration: 38794 | Classification loss: 0.41416 | Regression loss: 0.40855 | Running loss: 0.87523\n",
      "Epoch: 0 | Iteration: 38795 | Classification loss: 0.36750 | Regression loss: 0.57774 | Running loss: 0.87507\n",
      "Epoch: 0 | Iteration: 38796 | Classification loss: 0.39521 | Regression loss: 0.52435 | Running loss: 0.87477\n",
      "Epoch: 0 | Iteration: 38797 | Classification loss: 0.32252 | Regression loss: 0.54965 | Running loss: 0.87460\n",
      "Epoch: 0 | Iteration: 38798 | Classification loss: 0.47782 | Regression loss: 0.66183 | Running loss: 0.87482\n",
      "Epoch: 0 | Iteration: 38799 | Classification loss: 0.15862 | Regression loss: 0.41580 | Running loss: 0.87431\n",
      "Epoch: 0 | Iteration: 38800 | Classification loss: 0.42641 | Regression loss: 0.50697 | Running loss: 0.87456\n",
      "Epoch: 0 | Iteration: 38801 | Classification loss: 0.56452 | Regression loss: 0.44257 | Running loss: 0.87498\n",
      "Epoch: 0 | Iteration: 38802 | Classification loss: 0.62273 | Regression loss: 0.63986 | Running loss: 0.87613\n",
      "Epoch: 0 | Iteration: 38803 | Classification loss: 0.42986 | Regression loss: 0.60809 | Running loss: 0.87702\n",
      "Epoch: 0 | Iteration: 38804 | Classification loss: 0.31841 | Regression loss: 0.41804 | Running loss: 0.87684\n",
      "Epoch: 0 | Iteration: 38805 | Classification loss: 0.26645 | Regression loss: 0.36721 | Running loss: 0.87601\n",
      "Epoch: 0 | Iteration: 38806 | Classification loss: 0.39487 | Regression loss: 0.37423 | Running loss: 0.87574\n",
      "Epoch: 0 | Iteration: 38807 | Classification loss: 0.36365 | Regression loss: 0.55865 | Running loss: 0.87511\n",
      "Epoch: 0 | Iteration: 38808 | Classification loss: 0.34226 | Regression loss: 0.57409 | Running loss: 0.87514\n",
      "Epoch: 0 | Iteration: 38809 | Classification loss: 0.16706 | Regression loss: 0.24135 | Running loss: 0.87418\n",
      "Epoch: 0 | Iteration: 38810 | Classification loss: 0.41089 | Regression loss: 0.46303 | Running loss: 0.87425\n",
      "Epoch: 0 | Iteration: 38811 | Classification loss: 0.27753 | Regression loss: 0.57135 | Running loss: 0.87368\n",
      "Epoch: 0 | Iteration: 38812 | Classification loss: 0.49214 | Regression loss: 0.55726 | Running loss: 0.87432\n",
      "Epoch: 0 | Iteration: 38813 | Classification loss: 0.45968 | Regression loss: 0.53955 | Running loss: 0.87412\n",
      "Epoch: 0 | Iteration: 38814 | Classification loss: 0.31833 | Regression loss: 0.39383 | Running loss: 0.87429\n",
      "Epoch: 0 | Iteration: 38815 | Classification loss: 0.56227 | Regression loss: 0.58362 | Running loss: 0.87487\n",
      "Epoch: 0 | Iteration: 38816 | Classification loss: 0.46916 | Regression loss: 0.56282 | Running loss: 0.87552\n",
      "Epoch: 0 | Iteration: 38817 | Classification loss: 0.48300 | Regression loss: 0.57639 | Running loss: 0.87595\n",
      "Epoch: 0 | Iteration: 38818 | Classification loss: 0.44823 | Regression loss: 0.52280 | Running loss: 0.87554\n",
      "Epoch: 0 | Iteration: 38819 | Classification loss: 0.47897 | Regression loss: 0.58307 | Running loss: 0.87575\n",
      "Epoch: 0 | Iteration: 38820 | Classification loss: 0.58768 | Regression loss: 0.77667 | Running loss: 0.87751\n",
      "Epoch: 0 | Iteration: 38821 | Classification loss: 0.29123 | Regression loss: 0.39868 | Running loss: 0.87743\n",
      "Epoch: 0 | Iteration: 38822 | Classification loss: 0.68551 | Regression loss: 0.69200 | Running loss: 0.87883\n",
      "Epoch: 0 | Iteration: 38823 | Classification loss: 0.34323 | Regression loss: 0.56845 | Running loss: 0.87919\n",
      "Epoch: 0 | Iteration: 38824 | Classification loss: 0.48080 | Regression loss: 0.37543 | Running loss: 0.87939\n",
      "Epoch: 0 | Iteration: 38825 | Classification loss: 0.69302 | Regression loss: 0.74122 | Running loss: 0.88075\n",
      "Epoch: 0 | Iteration: 38826 | Classification loss: 0.70178 | Regression loss: 0.44576 | Running loss: 0.88128\n",
      "Epoch: 0 | Iteration: 38827 | Classification loss: 0.45913 | Regression loss: 0.60460 | Running loss: 0.88216\n",
      "Epoch: 0 | Iteration: 38828 | Classification loss: 0.22020 | Regression loss: 0.24901 | Running loss: 0.88170\n",
      "Epoch: 0 | Iteration: 38829 | Classification loss: 0.25147 | Regression loss: 0.42085 | Running loss: 0.88117\n",
      "Epoch: 0 | Iteration: 38830 | Classification loss: 0.42972 | Regression loss: 0.61216 | Running loss: 0.88227\n",
      "Epoch: 0 | Iteration: 38831 | Classification loss: 0.41290 | Regression loss: 0.66685 | Running loss: 0.88261\n",
      "Epoch: 0 | Iteration: 38832 | Classification loss: 0.19995 | Regression loss: 0.24398 | Running loss: 0.88199\n",
      "Epoch: 0 | Iteration: 38833 | Classification loss: 0.35127 | Regression loss: 0.41741 | Running loss: 0.88205\n",
      "Epoch: 0 | Iteration: 38834 | Classification loss: 0.34783 | Regression loss: 0.43032 | Running loss: 0.88266\n",
      "Epoch: 0 | Iteration: 38835 | Classification loss: 0.16892 | Regression loss: 0.24322 | Running loss: 0.88229\n",
      "Epoch: 0 | Iteration: 38836 | Classification loss: 0.22871 | Regression loss: 0.37659 | Running loss: 0.88243\n",
      "Epoch: 0 | Iteration: 38837 | Classification loss: 0.35572 | Regression loss: 0.51729 | Running loss: 0.88254\n",
      "Epoch: 0 | Iteration: 38838 | Classification loss: 0.16478 | Regression loss: 0.26487 | Running loss: 0.88142\n",
      "Epoch: 0 | Iteration: 38839 | Classification loss: 0.22584 | Regression loss: 0.25686 | Running loss: 0.88033\n",
      "Epoch: 0 | Iteration: 38840 | Classification loss: 0.34684 | Regression loss: 0.39789 | Running loss: 0.88017\n",
      "Epoch: 0 | Iteration: 38841 | Classification loss: 0.30474 | Regression loss: 0.66842 | Running loss: 0.87975\n",
      "Epoch: 0 | Iteration: 38842 | Classification loss: 0.47656 | Regression loss: 0.67832 | Running loss: 0.88067\n",
      "Epoch: 0 | Iteration: 38843 | Classification loss: 0.24100 | Regression loss: 0.29436 | Running loss: 0.87816\n",
      "Epoch: 0 | Iteration: 38844 | Classification loss: 0.45273 | Regression loss: 0.37536 | Running loss: 0.87872\n",
      "Epoch: 0 | Iteration: 38845 | Classification loss: 0.31255 | Regression loss: 0.26303 | Running loss: 0.87740\n",
      "Epoch: 0 | Iteration: 38846 | Classification loss: 0.31599 | Regression loss: 0.54670 | Running loss: 0.87695\n",
      "Epoch: 0 | Iteration: 38847 | Classification loss: 0.31573 | Regression loss: 0.42004 | Running loss: 0.87610\n",
      "Epoch: 0 | Iteration: 38848 | Classification loss: 0.50920 | Regression loss: 0.57054 | Running loss: 0.87651\n",
      "Epoch: 0 | Iteration: 38849 | Classification loss: 0.40696 | Regression loss: 0.55973 | Running loss: 0.87675\n",
      "Epoch: 0 | Iteration: 38850 | Classification loss: 0.54381 | Regression loss: 0.50685 | Running loss: 0.87724\n",
      "Epoch: 0 | Iteration: 38851 | Classification loss: 0.36792 | Regression loss: 0.73850 | Running loss: 0.87805\n",
      "Epoch: 0 | Iteration: 38852 | Classification loss: 0.29509 | Regression loss: 0.34644 | Running loss: 0.87831\n",
      "Epoch: 0 | Iteration: 38853 | Classification loss: 0.28479 | Regression loss: 0.37126 | Running loss: 0.87793\n",
      "Epoch: 0 | Iteration: 38854 | Classification loss: 0.49884 | Regression loss: 0.68007 | Running loss: 0.87796\n",
      "Epoch: 0 | Iteration: 38855 | Classification loss: 0.17882 | Regression loss: 0.25572 | Running loss: 0.87690\n",
      "Epoch: 0 | Iteration: 38856 | Classification loss: 0.30786 | Regression loss: 0.48064 | Running loss: 0.87790\n",
      "Epoch: 0 | Iteration: 38857 | Classification loss: 0.35352 | Regression loss: 0.53660 | Running loss: 0.87825\n",
      "Epoch: 0 | Iteration: 38858 | Classification loss: 0.21801 | Regression loss: 0.36562 | Running loss: 0.87787\n",
      "Epoch: 0 | Iteration: 38859 | Classification loss: 0.31924 | Regression loss: 0.46864 | Running loss: 0.87811\n",
      "Epoch: 0 | Iteration: 38860 | Classification loss: 0.25185 | Regression loss: 0.69368 | Running loss: 0.87814\n",
      "Epoch: 0 | Iteration: 38861 | Classification loss: 0.50864 | Regression loss: 0.60031 | Running loss: 0.87815\n",
      "Epoch: 0 | Iteration: 38862 | Classification loss: 0.08732 | Regression loss: 0.25815 | Running loss: 0.87684\n",
      "Epoch: 0 | Iteration: 38863 | Classification loss: 0.43598 | Regression loss: 0.41435 | Running loss: 0.87719\n",
      "Epoch: 0 | Iteration: 38864 | Classification loss: 0.53948 | Regression loss: 0.67618 | Running loss: 0.87823\n",
      "Epoch: 0 | Iteration: 38865 | Classification loss: 0.30520 | Regression loss: 0.41981 | Running loss: 0.87756\n",
      "Epoch: 0 | Iteration: 38866 | Classification loss: 0.31852 | Regression loss: 0.66182 | Running loss: 0.87757\n",
      "Epoch: 0 | Iteration: 38867 | Classification loss: 0.54114 | Regression loss: 0.51420 | Running loss: 0.87752\n",
      "Epoch: 0 | Iteration: 38868 | Classification loss: 0.55300 | Regression loss: 0.77062 | Running loss: 0.87867\n",
      "Epoch: 0 | Iteration: 38869 | Classification loss: 0.28722 | Regression loss: 0.46859 | Running loss: 0.87846\n",
      "Epoch: 0 | Iteration: 38870 | Classification loss: 0.33435 | Regression loss: 0.62435 | Running loss: 0.87867\n",
      "Epoch: 0 | Iteration: 38871 | Classification loss: 0.56716 | Regression loss: 0.36717 | Running loss: 0.87889\n",
      "Epoch: 0 | Iteration: 38872 | Classification loss: 0.42986 | Regression loss: 0.67343 | Running loss: 0.87993\n",
      "Epoch: 0 | Iteration: 38873 | Classification loss: 0.31787 | Regression loss: 0.38087 | Running loss: 0.87973\n",
      "Epoch: 0 | Iteration: 38874 | Classification loss: 0.69529 | Regression loss: 0.49521 | Running loss: 0.88026\n",
      "Epoch: 0 | Iteration: 38875 | Classification loss: 0.21722 | Regression loss: 0.39779 | Running loss: 0.88042\n",
      "Epoch: 0 | Iteration: 38876 | Classification loss: 0.41730 | Regression loss: 0.60484 | Running loss: 0.88057\n",
      "Epoch: 0 | Iteration: 38877 | Classification loss: 0.46573 | Regression loss: 0.60746 | Running loss: 0.88076\n",
      "Epoch: 0 | Iteration: 38878 | Classification loss: 0.47366 | Regression loss: 0.49244 | Running loss: 0.88136\n",
      "Epoch: 0 | Iteration: 38879 | Classification loss: 0.43620 | Regression loss: 0.44307 | Running loss: 0.88131\n",
      "Epoch: 0 | Iteration: 38880 | Classification loss: 0.59485 | Regression loss: 0.72044 | Running loss: 0.88229\n",
      "Epoch: 0 | Iteration: 38881 | Classification loss: 0.35673 | Regression loss: 0.46454 | Running loss: 0.88142\n",
      "Epoch: 0 | Iteration: 38882 | Classification loss: 0.38396 | Regression loss: 0.60303 | Running loss: 0.88049\n",
      "Epoch: 0 | Iteration: 38883 | Classification loss: 0.50109 | Regression loss: 0.53191 | Running loss: 0.88149\n",
      "Epoch: 0 | Iteration: 38884 | Classification loss: 0.31869 | Regression loss: 0.45137 | Running loss: 0.88130\n",
      "Epoch: 0 | Iteration: 38885 | Classification loss: 0.50912 | Regression loss: 0.71469 | Running loss: 0.88184\n",
      "Epoch: 0 | Iteration: 38886 | Classification loss: 0.40725 | Regression loss: 0.54434 | Running loss: 0.88161\n",
      "Epoch: 0 | Iteration: 38887 | Classification loss: 0.38301 | Regression loss: 0.44361 | Running loss: 0.88120\n",
      "Epoch: 0 | Iteration: 38888 | Classification loss: 0.18454 | Regression loss: 0.29210 | Running loss: 0.88005\n",
      "Epoch: 0 | Iteration: 38889 | Classification loss: 0.36227 | Regression loss: 0.53974 | Running loss: 0.87974\n",
      "Epoch: 0 | Iteration: 38890 | Classification loss: 0.37358 | Regression loss: 0.49309 | Running loss: 0.87958\n",
      "Epoch: 0 | Iteration: 38891 | Classification loss: 0.26435 | Regression loss: 0.26106 | Running loss: 0.87861\n",
      "Epoch: 0 | Iteration: 38892 | Classification loss: 0.55107 | Regression loss: 0.86234 | Running loss: 0.87963\n",
      "Epoch: 0 | Iteration: 38893 | Classification loss: 0.41629 | Regression loss: 0.58574 | Running loss: 0.87927\n",
      "Epoch: 0 | Iteration: 38894 | Classification loss: 0.21997 | Regression loss: 0.54789 | Running loss: 0.87925\n",
      "Epoch: 0 | Iteration: 38895 | Classification loss: 0.33443 | Regression loss: 0.44667 | Running loss: 0.87886\n",
      "Epoch: 0 | Iteration: 38896 | Classification loss: 0.30826 | Regression loss: 0.56354 | Running loss: 0.87929\n",
      "Epoch: 0 | Iteration: 38897 | Classification loss: 0.47977 | Regression loss: 0.48866 | Running loss: 0.88022\n",
      "Epoch: 0 | Iteration: 38898 | Classification loss: 0.36403 | Regression loss: 0.59100 | Running loss: 0.88037\n",
      "Epoch: 0 | Iteration: 38899 | Classification loss: 0.16983 | Regression loss: 0.19858 | Running loss: 0.87919\n",
      "Epoch: 0 | Iteration: 38900 | Classification loss: 0.49360 | Regression loss: 0.67722 | Running loss: 0.87991\n",
      "Epoch: 0 | Iteration: 38901 | Classification loss: 0.43706 | Regression loss: 0.44100 | Running loss: 0.88001\n",
      "Epoch: 0 | Iteration: 38902 | Classification loss: 0.23518 | Regression loss: 0.42737 | Running loss: 0.87922\n",
      "Epoch: 0 | Iteration: 38903 | Classification loss: 0.33457 | Regression loss: 0.37416 | Running loss: 0.87910\n",
      "Epoch: 0 | Iteration: 38904 | Classification loss: 0.31790 | Regression loss: 0.60218 | Running loss: 0.88015\n",
      "Epoch: 0 | Iteration: 38905 | Classification loss: 0.41245 | Regression loss: 0.65019 | Running loss: 0.87972\n",
      "Epoch: 0 | Iteration: 38906 | Classification loss: 0.27601 | Regression loss: 0.45042 | Running loss: 0.87950\n",
      "Epoch: 0 | Iteration: 38907 | Classification loss: 0.61702 | Regression loss: 0.52232 | Running loss: 0.87938\n",
      "Epoch: 0 | Iteration: 38908 | Classification loss: 0.19522 | Regression loss: 0.44601 | Running loss: 0.87744\n",
      "Epoch: 0 | Iteration: 38909 | Classification loss: 0.17430 | Regression loss: 0.36323 | Running loss: 0.87672\n",
      "Epoch: 0 | Iteration: 38910 | Classification loss: 0.43606 | Regression loss: 0.72522 | Running loss: 0.87745\n",
      "Epoch: 0 | Iteration: 38911 | Classification loss: 0.43848 | Regression loss: 0.61854 | Running loss: 0.87737\n",
      "Epoch: 0 | Iteration: 38912 | Classification loss: 0.16644 | Regression loss: 0.45241 | Running loss: 0.87621\n",
      "Epoch: 0 | Iteration: 38913 | Classification loss: 0.14647 | Regression loss: 0.28226 | Running loss: 0.87491\n",
      "Epoch: 0 | Iteration: 38914 | Classification loss: 0.37872 | Regression loss: 0.62580 | Running loss: 0.87589\n",
      "Epoch: 0 | Iteration: 38915 | Classification loss: 0.42026 | Regression loss: 0.54727 | Running loss: 0.87669\n",
      "Epoch: 0 | Iteration: 38916 | Classification loss: 0.51398 | Regression loss: 0.50974 | Running loss: 0.87674\n",
      "Epoch: 0 | Iteration: 38917 | Classification loss: 0.36527 | Regression loss: 0.56880 | Running loss: 0.87703\n",
      "Epoch: 0 | Iteration: 38918 | Classification loss: 0.26854 | Regression loss: 0.38445 | Running loss: 0.87643\n",
      "Epoch: 0 | Iteration: 38919 | Classification loss: 0.40884 | Regression loss: 0.43159 | Running loss: 0.87564\n",
      "Epoch: 0 | Iteration: 38920 | Classification loss: 0.27580 | Regression loss: 0.38217 | Running loss: 0.87516\n",
      "Epoch: 0 | Iteration: 38921 | Classification loss: 0.66044 | Regression loss: 0.77481 | Running loss: 0.87556\n",
      "Epoch: 0 | Iteration: 38922 | Classification loss: 0.38517 | Regression loss: 0.57092 | Running loss: 0.87543\n",
      "Epoch: 0 | Iteration: 38923 | Classification loss: 0.45779 | Regression loss: 0.56976 | Running loss: 0.87626\n",
      "Epoch: 0 | Iteration: 38924 | Classification loss: 0.37991 | Regression loss: 0.41548 | Running loss: 0.87591\n",
      "Epoch: 0 | Iteration: 38925 | Classification loss: 0.82491 | Regression loss: 0.64344 | Running loss: 0.87520\n",
      "Epoch: 0 | Iteration: 38926 | Classification loss: 0.21426 | Regression loss: 0.50968 | Running loss: 0.87510\n",
      "Epoch: 0 | Iteration: 38927 | Classification loss: 0.24435 | Regression loss: 0.39068 | Running loss: 0.87477\n",
      "Epoch: 0 | Iteration: 38928 | Classification loss: 0.44624 | Regression loss: 0.48707 | Running loss: 0.87536\n",
      "Epoch: 0 | Iteration: 38929 | Classification loss: 0.25169 | Regression loss: 0.44858 | Running loss: 0.87546\n",
      "Epoch: 0 | Iteration: 38930 | Classification loss: 0.21397 | Regression loss: 0.43227 | Running loss: 0.87504\n",
      "Epoch: 0 | Iteration: 38931 | Classification loss: 0.34643 | Regression loss: 0.62624 | Running loss: 0.87584\n",
      "Epoch: 0 | Iteration: 38932 | Classification loss: 0.28763 | Regression loss: 0.55046 | Running loss: 0.87607\n",
      "Epoch: 0 | Iteration: 38933 | Classification loss: 0.32536 | Regression loss: 0.49496 | Running loss: 0.87613\n",
      "Epoch: 0 | Iteration: 38934 | Classification loss: 0.44311 | Regression loss: 0.58526 | Running loss: 0.87695\n",
      "Epoch: 0 | Iteration: 38935 | Classification loss: 0.51677 | Regression loss: 0.50322 | Running loss: 0.87747\n",
      "Epoch: 0 | Iteration: 38936 | Classification loss: 0.28283 | Regression loss: 0.44287 | Running loss: 0.87795\n",
      "Epoch: 0 | Iteration: 38937 | Classification loss: 0.74234 | Regression loss: 0.50658 | Running loss: 0.87879\n",
      "Epoch: 0 | Iteration: 38938 | Classification loss: 0.53824 | Regression loss: 0.57815 | Running loss: 0.88005\n",
      "Epoch: 0 | Iteration: 38939 | Classification loss: 0.33133 | Regression loss: 0.57714 | Running loss: 0.87971\n",
      "Epoch: 0 | Iteration: 38940 | Classification loss: 0.50274 | Regression loss: 0.60248 | Running loss: 0.87962\n",
      "Epoch: 0 | Iteration: 38941 | Classification loss: 0.42331 | Regression loss: 0.60919 | Running loss: 0.87883\n",
      "Epoch: 0 | Iteration: 38942 | Classification loss: 0.28547 | Regression loss: 0.51528 | Running loss: 0.87818\n",
      "Epoch: 0 | Iteration: 38943 | Classification loss: 0.61703 | Regression loss: 0.65795 | Running loss: 0.87897\n",
      "Epoch: 0 | Iteration: 38944 | Classification loss: 0.25083 | Regression loss: 0.42109 | Running loss: 0.87862\n",
      "Epoch: 0 | Iteration: 38945 | Classification loss: 0.33973 | Regression loss: 0.59287 | Running loss: 0.87844\n",
      "Epoch: 0 | Iteration: 38946 | Classification loss: 0.33316 | Regression loss: 0.66530 | Running loss: 0.87882\n",
      "Epoch: 0 | Iteration: 38947 | Classification loss: 0.39345 | Regression loss: 0.57822 | Running loss: 0.87888\n",
      "Epoch: 0 | Iteration: 38948 | Classification loss: 0.17419 | Regression loss: 0.47770 | Running loss: 0.87911\n",
      "Epoch: 0 | Iteration: 38949 | Classification loss: 0.33763 | Regression loss: 0.57348 | Running loss: 0.87961\n",
      "Epoch: 0 | Iteration: 38950 | Classification loss: 0.16159 | Regression loss: 0.16302 | Running loss: 0.87848\n",
      "Epoch: 0 | Iteration: 38951 | Classification loss: 0.31062 | Regression loss: 0.55314 | Running loss: 0.87890\n",
      "Epoch: 0 | Iteration: 38952 | Classification loss: 0.14235 | Regression loss: 0.24703 | Running loss: 0.87731\n",
      "Epoch: 0 | Iteration: 38953 | Classification loss: 0.25757 | Regression loss: 0.56317 | Running loss: 0.87631\n",
      "Epoch: 0 | Iteration: 38954 | Classification loss: 0.36896 | Regression loss: 0.42677 | Running loss: 0.87599\n",
      "Epoch: 0 | Iteration: 38955 | Classification loss: 0.39008 | Regression loss: 0.43187 | Running loss: 0.87642\n",
      "Epoch: 0 | Iteration: 38956 | Classification loss: 0.30888 | Regression loss: 0.36676 | Running loss: 0.87531\n",
      "Epoch: 0 | Iteration: 38957 | Classification loss: 0.38438 | Regression loss: 0.51930 | Running loss: 0.87472\n",
      "Epoch: 0 | Iteration: 38958 | Classification loss: 0.25328 | Regression loss: 0.51256 | Running loss: 0.87401\n",
      "Epoch: 0 | Iteration: 38959 | Classification loss: 0.28190 | Regression loss: 0.48932 | Running loss: 0.87393\n",
      "Epoch: 0 | Iteration: 38960 | Classification loss: 0.30428 | Regression loss: 0.37850 | Running loss: 0.87331\n",
      "Epoch: 0 | Iteration: 38961 | Classification loss: 0.33901 | Regression loss: 0.34303 | Running loss: 0.87275\n",
      "Epoch: 0 | Iteration: 38962 | Classification loss: 0.35618 | Regression loss: 0.67186 | Running loss: 0.87257\n",
      "Epoch: 0 | Iteration: 38963 | Classification loss: 0.51726 | Regression loss: 0.61453 | Running loss: 0.87312\n",
      "Epoch: 0 | Iteration: 38964 | Classification loss: 0.47126 | Regression loss: 0.53148 | Running loss: 0.87321\n",
      "Epoch: 0 | Iteration: 38965 | Classification loss: 0.26584 | Regression loss: 0.50629 | Running loss: 0.87229\n",
      "Epoch: 0 | Iteration: 38966 | Classification loss: 0.38508 | Regression loss: 0.45133 | Running loss: 0.87151\n",
      "Epoch: 0 | Iteration: 38967 | Classification loss: 0.24302 | Regression loss: 0.50914 | Running loss: 0.87138\n",
      "Epoch: 0 | Iteration: 38968 | Classification loss: 0.27166 | Regression loss: 0.68540 | Running loss: 0.87116\n",
      "Epoch: 0 | Iteration: 38969 | Classification loss: 0.64206 | Regression loss: 0.64110 | Running loss: 0.87221\n",
      "Epoch: 0 | Iteration: 38970 | Classification loss: 0.19127 | Regression loss: 0.53066 | Running loss: 0.87251\n",
      "Epoch: 0 | Iteration: 38971 | Classification loss: 0.40689 | Regression loss: 0.52174 | Running loss: 0.87226\n",
      "Epoch: 0 | Iteration: 38972 | Classification loss: 0.32976 | Regression loss: 0.52567 | Running loss: 0.87252\n",
      "Epoch: 0 | Iteration: 38973 | Classification loss: 0.28161 | Regression loss: 0.53832 | Running loss: 0.87249\n",
      "Epoch: 0 | Iteration: 38974 | Classification loss: 0.24567 | Regression loss: 0.39934 | Running loss: 0.87251\n",
      "Epoch: 0 | Iteration: 38975 | Classification loss: 0.33915 | Regression loss: 0.22270 | Running loss: 0.87110\n",
      "Epoch: 0 | Iteration: 38976 | Classification loss: 0.35884 | Regression loss: 0.51291 | Running loss: 0.87113\n",
      "Epoch: 0 | Iteration: 38977 | Classification loss: 0.33535 | Regression loss: 0.39132 | Running loss: 0.87029\n",
      "Epoch: 0 | Iteration: 38978 | Classification loss: 0.30449 | Regression loss: 0.29428 | Running loss: 0.86949\n",
      "Epoch: 0 | Iteration: 38979 | Classification loss: 0.39994 | Regression loss: 0.51094 | Running loss: 0.86986\n",
      "Epoch: 0 | Iteration: 38980 | Classification loss: 0.40117 | Regression loss: 0.46975 | Running loss: 0.86996\n",
      "Epoch: 0 | Iteration: 38981 | Classification loss: 0.35783 | Regression loss: 0.63886 | Running loss: 0.87044\n",
      "Epoch: 0 | Iteration: 38982 | Classification loss: 0.49027 | Regression loss: 0.60974 | Running loss: 0.87032\n",
      "Epoch: 0 | Iteration: 38983 | Classification loss: 0.54081 | Regression loss: 0.41694 | Running loss: 0.87008\n",
      "Epoch: 0 | Iteration: 38984 | Classification loss: 0.46918 | Regression loss: 0.42796 | Running loss: 0.87015\n",
      "Epoch: 0 | Iteration: 38985 | Classification loss: 1.22263 | Regression loss: 0.15796 | Running loss: 0.87065\n",
      "Epoch: 0 | Iteration: 38986 | Classification loss: 0.40904 | Regression loss: 0.29577 | Running loss: 0.87097\n",
      "Epoch: 0 | Iteration: 38987 | Classification loss: 0.56024 | Regression loss: 0.57952 | Running loss: 0.87118\n",
      "Epoch: 0 | Iteration: 38988 | Classification loss: 0.37307 | Regression loss: 0.59603 | Running loss: 0.87112\n",
      "Epoch: 0 | Iteration: 38989 | Classification loss: 0.13510 | Regression loss: 0.30015 | Running loss: 0.87036\n",
      "Epoch: 0 | Iteration: 38990 | Classification loss: 0.24295 | Regression loss: 0.49940 | Running loss: 0.87064\n",
      "Epoch: 0 | Iteration: 38991 | Classification loss: 0.47619 | Regression loss: 0.45575 | Running loss: 0.87079\n",
      "Epoch: 0 | Iteration: 38992 | Classification loss: 0.34584 | Regression loss: 0.45207 | Running loss: 0.87030\n",
      "Epoch: 0 | Iteration: 38993 | Classification loss: 0.29557 | Regression loss: 0.42211 | Running loss: 0.86957\n",
      "Epoch: 0 | Iteration: 38994 | Classification loss: 0.39575 | Regression loss: 0.48667 | Running loss: 0.86992\n",
      "Epoch: 0 | Iteration: 38995 | Classification loss: 0.19563 | Regression loss: 0.34283 | Running loss: 0.86932\n",
      "Epoch: 0 | Iteration: 38996 | Classification loss: 0.63812 | Regression loss: 0.71259 | Running loss: 0.87015\n",
      "Epoch: 0 | Iteration: 38997 | Classification loss: 0.60886 | Regression loss: 0.55104 | Running loss: 0.87098\n",
      "Epoch: 0 | Iteration: 38998 | Classification loss: 0.27479 | Regression loss: 0.42703 | Running loss: 0.87102\n",
      "Epoch: 0 | Iteration: 38999 | Classification loss: 0.30332 | Regression loss: 0.46287 | Running loss: 0.87075\n",
      "Epoch: 0 | Iteration: 39000 | Classification loss: 0.28003 | Regression loss: 0.49645 | Running loss: 0.87127\n",
      "Epoch: 0 | Iteration: 39001 | Classification loss: 0.36506 | Regression loss: 0.60703 | Running loss: 0.87183\n",
      "Epoch: 0 | Iteration: 39002 | Classification loss: 0.41067 | Regression loss: 0.42535 | Running loss: 0.87176\n",
      "Epoch: 0 | Iteration: 39003 | Classification loss: 0.34400 | Regression loss: 0.33897 | Running loss: 0.87166\n",
      "Epoch: 0 | Iteration: 39004 | Classification loss: 0.31245 | Regression loss: 0.46451 | Running loss: 0.87083\n",
      "Epoch: 0 | Iteration: 39005 | Classification loss: 0.26359 | Regression loss: 0.50612 | Running loss: 0.86971\n",
      "Epoch: 0 | Iteration: 39006 | Classification loss: 0.49608 | Regression loss: 0.53195 | Running loss: 0.86990\n",
      "Epoch: 0 | Iteration: 39007 | Classification loss: 0.36806 | Regression loss: 0.53791 | Running loss: 0.86962\n",
      "Epoch: 0 | Iteration: 39008 | Classification loss: 0.40181 | Regression loss: 0.51562 | Running loss: 0.87039\n",
      "Epoch: 0 | Iteration: 39009 | Classification loss: 0.21757 | Regression loss: 0.35182 | Running loss: 0.87005\n",
      "Epoch: 0 | Iteration: 39010 | Classification loss: 0.19689 | Regression loss: 0.23615 | Running loss: 0.86900\n",
      "Epoch: 0 | Iteration: 39011 | Classification loss: 0.34152 | Regression loss: 0.38865 | Running loss: 0.86857\n",
      "Epoch: 0 | Iteration: 39012 | Classification loss: 0.45833 | Regression loss: 0.65191 | Running loss: 0.86814\n",
      "Epoch: 0 | Iteration: 39013 | Classification loss: 0.30419 | Regression loss: 0.49092 | Running loss: 0.86862\n",
      "Epoch: 0 | Iteration: 39014 | Classification loss: 0.34047 | Regression loss: 0.53616 | Running loss: 0.86759\n",
      "Epoch: 0 | Iteration: 39015 | Classification loss: 0.34629 | Regression loss: 0.41139 | Running loss: 0.86826\n",
      "Epoch: 0 | Iteration: 39016 | Classification loss: 0.10772 | Regression loss: 0.28269 | Running loss: 0.86718\n",
      "Epoch: 0 | Iteration: 39017 | Classification loss: 0.24851 | Regression loss: 0.30151 | Running loss: 0.86623\n",
      "Epoch: 0 | Iteration: 39018 | Classification loss: 0.35768 | Regression loss: 0.66285 | Running loss: 0.86498\n",
      "Epoch: 0 | Iteration: 39019 | Classification loss: 0.38909 | Regression loss: 0.36102 | Running loss: 0.86528\n",
      "Epoch: 0 | Iteration: 39020 | Classification loss: 0.23964 | Regression loss: 0.42460 | Running loss: 0.86506\n",
      "Epoch: 0 | Iteration: 39021 | Classification loss: 0.46226 | Regression loss: 0.55850 | Running loss: 0.86538\n",
      "Epoch: 0 | Iteration: 39022 | Classification loss: 0.36427 | Regression loss: 0.56580 | Running loss: 0.86581\n",
      "Epoch: 0 | Iteration: 39023 | Classification loss: 9.20586 | Regression loss: 0.00000 | Running loss: 0.88267\n",
      "Epoch: 0 | Iteration: 39024 | Classification loss: 0.76468 | Regression loss: 0.39199 | Running loss: 0.88287\n",
      "Epoch: 0 | Iteration: 39025 | Classification loss: 0.40304 | Regression loss: 0.51835 | Running loss: 0.88352\n",
      "Epoch: 0 | Iteration: 39026 | Classification loss: 0.46420 | Regression loss: 0.52258 | Running loss: 0.88360\n",
      "Epoch: 0 | Iteration: 39027 | Classification loss: 0.41402 | Regression loss: 0.45886 | Running loss: 0.88374\n",
      "Epoch: 0 | Iteration: 39028 | Classification loss: 0.23797 | Regression loss: 0.39572 | Running loss: 0.88421\n",
      "Epoch: 0 | Iteration: 39029 | Classification loss: 0.33402 | Regression loss: 0.35082 | Running loss: 0.88342\n",
      "Epoch: 0 | Iteration: 39030 | Classification loss: 0.53700 | Regression loss: 0.62602 | Running loss: 0.88363\n",
      "Epoch: 0 | Iteration: 39031 | Classification loss: 0.45656 | Regression loss: 0.49505 | Running loss: 0.87753\n",
      "Epoch: 0 | Iteration: 39032 | Classification loss: 0.37394 | Regression loss: 0.48879 | Running loss: 0.87795\n",
      "Epoch: 0 | Iteration: 39033 | Classification loss: 0.26956 | Regression loss: 0.27633 | Running loss: 0.87730\n",
      "Epoch: 0 | Iteration: 39034 | Classification loss: 0.70133 | Regression loss: 0.54874 | Running loss: 0.87807\n",
      "Epoch: 0 | Iteration: 39035 | Classification loss: 0.26754 | Regression loss: 0.27146 | Running loss: 0.87731\n",
      "Epoch: 0 | Iteration: 39036 | Classification loss: 0.46598 | Regression loss: 0.40097 | Running loss: 0.87769\n",
      "Epoch: 0 | Iteration: 39037 | Classification loss: 0.38874 | Regression loss: 0.47925 | Running loss: 0.87762\n",
      "Epoch: 0 | Iteration: 39038 | Classification loss: 0.25473 | Regression loss: 0.37571 | Running loss: 0.87739\n",
      "Epoch: 0 | Iteration: 39039 | Classification loss: 0.40194 | Regression loss: 0.57811 | Running loss: 0.87729\n",
      "Epoch: 0 | Iteration: 39040 | Classification loss: 0.44023 | Regression loss: 0.61687 | Running loss: 0.87808\n",
      "Epoch: 0 | Iteration: 39041 | Classification loss: 0.48572 | Regression loss: 0.64694 | Running loss: 0.87868\n",
      "Epoch: 0 | Iteration: 39042 | Classification loss: 0.54451 | Regression loss: 0.36589 | Running loss: 0.87815\n",
      "Epoch: 0 | Iteration: 39043 | Classification loss: 0.25067 | Regression loss: 0.38918 | Running loss: 0.87850\n",
      "Epoch: 0 | Iteration: 39044 | Clas