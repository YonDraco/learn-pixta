{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab2b71bb-13ae-41b4-bf1d-fec27a9eb170",
   "metadata": {
    "tags": []
   },
   "source": [
    "### import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "862cad28-41d1-4790-8f76-0e1c5a885dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoahoang/env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics.functional import accuracy\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning import seed_everything, LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88da0bfd-1ce8-43a5-ac21-7ca2718b4ad2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "becde56e-860d-48db-ae26-ed8406356abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa5db598-0eb7-4fe0-98ce-b4eaaf119cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation use transformer\n",
    "dataset_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((300,300)),\n",
    "        transforms.RandomRotation(50,expand=True),  \n",
    "        transforms.Resize((300,300)),\n",
    "        transforms.RandomCrop((120,120)),\n",
    "        transforms.RandomVerticalFlip(0.4),\n",
    "        transforms.RandomHorizontalFlip(0.4),                     \n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.2, saturation=0, hue=0), \n",
    "        transforms.ToTensor(),\n",
    "        AddGaussianNoise(0.1, 0.08),\n",
    "        transforms.RandomErasing(),\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((300, 300)),\n",
    "        transforms.ToTensor()])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf0ee54b-517b-47fe-9afe-247264fa3662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetDataset(Dataset):\n",
    "    def __init__(self, file_txt, root_dir, transform=None):\n",
    "        with open(file_txt, 'r') as f:\n",
    "            self.img_infos = f.readlines()\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_infos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_info = self.img_infos[idx]\n",
    "        img_info = img_info.split(' ')\n",
    "        img_name = img_info[0]\n",
    "        \n",
    "        img_label = torch.zeros(37)\n",
    "        img_label[int(img_info[1]) - 1] = 1.\n",
    "        img_path = os.path.join(self.root_dir, img_name + '.jpg')\n",
    "        img = cv2.imread(img_path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, img_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f35e25d-c1f2-444e-ae34-c5aecd22c357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hoahoang\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbe1a72e-08b6-46ff-b82a-57b8fae53c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hoahoang/training/data/oxford-iiit-pet\n"
     ]
    }
   ],
   "source": [
    "cd /home/hoahoang/training/data/oxford-iiit-pet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75217983-2d73-441c-bfbe-dc39a11407e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = {\n",
    "    'train': PetDataset(file_txt='./annotations/trainval.txt', root_dir='./images', transform=dataset_transforms['train']),\n",
    "    'valid': PetDataset(file_txt='./annotations/test.txt', root_dir='./images', transform=dataset_transforms['valid']),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d37faf-25a8-46b6-9c35-389ead8744d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e86eaa2e-e501-4068-94b3-7a74914bf44d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OurModel(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=1e-3, batch_size=16):\n",
    "        super().__init__()\n",
    "        self.base_model = models.resnet50(pretrained=True)\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 37)\n",
    "        )\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam([   \n",
    "                {'params': list(model.parameters())[:-1], 'lr': 1e-4},\n",
    "                {'params': list(model.parameters())[-1], 'lr': 5e-2}\n",
    "                ])\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def configure_callbacks(self):\n",
    "        early_stopping = EarlyStopping(monitor='train_loss', mode='min', patience=5, verbose=True, min_delta=0.001)\n",
    "        checkpoint_callback = ModelCheckpoint(monitor='val_acc', mode='max', dirpath='./', save_top_k=1)\n",
    "        return [early_stopping, checkpoint_callback]\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset_path['train'], batch_size=self.batch_size, shuffle=True, num_workers=16)\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.CrossEntropyLoss(reduction='mean')(y_hat, y)\n",
    "        self.log('train_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def _shared_eval_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.CrossEntropyLoss(reduction='mean')(y_hat, y)\n",
    "        pred = torch.softmax(y_hat, dim=1)\n",
    "        y = y.int()\n",
    "        acc = accuracy(pred, y)\n",
    "        return loss, acc\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset_path['valid'], batch_size=self.batch_size, shuffle=False, num_workers=16)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self._shared_eval_step(batch, batch_idx)\n",
    "        metrics = {\"val_acc\": acc, \"val_loss\": loss}\n",
    "        self.log_dict(metrics, prog_bar=True, on_epoch=True)\n",
    "        return metrics\n",
    "    \n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     x, y = batch\n",
    "    #     loss = F.cross_entropy(self(x), y)\n",
    "    #     return {'val_loss': loss, 'log': {'val_loss': loss}}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        val_loss_mean = sum([o['val_loss'] for o in outputs]) / len(outputs)\n",
    "        # show val_acc in progress bar but only log val_loss\n",
    "        results = {'progress_bar': {'val_loss': val_loss_mean.item()}, 'log': {'val_loss': val_loss_mean.item()},\n",
    "                   'val_loss': val_loss_mean.item()}\n",
    "        return results\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.base_model.load_state_dict(state_dict)\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.base_model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfb29fd-4301-49ae-aa0b-ec00d89b1234",
   "metadata": {
    "tags": []
   },
   "source": [
    "### trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40db6c7a-d6fe-4598-a77b-48a3777e8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"runs\", name=\"resnet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90ea4299-11ef-4706-9e3c-7ecd917c04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# few functions of trainer: auto_lr_find, accumulate_grad_batches, limit_training_batches, num_sanity_val_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "574ecc40-0f55-46ae-bb4c-3992d9678eef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoahoang/env/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:152: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=[<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7ff6857e8710>])` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=[<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7ff6857e8710>])`.\n",
      "  f\"Setting `Trainer(checkpoint_callback={checkpoint_callback})` is deprecated in v1.5 and will \"\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: EarlyStopping, ModelCheckpoint\n",
      "Missing logger folder: runs/resnet50\n",
      "\n",
      "  | Name       | Type   | Params\n",
      "--------------------------------------\n",
      "0 | base_model | ResNet | 23.6 M\n",
      "--------------------------------------\n",
      "23.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.6 M    Total params\n",
      "94.335    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  30%|███████████████████████████                                                              | 140/460 [01:18<03:00,  1.77it/s, loss=3.12, v_num=0, train_loss_step=3.280]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  37%|████████████████████████████████▉                                                        | 170/460 [01:34<02:42,  1.79it/s, loss=2.99, v_num=0, train_loss_step=2.710]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████████████████████████████████████████████                                             | 230/460 [02:06<02:06,  1.82it/s, loss=2.8, v_num=0, train_loss_step=2.850]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                              | 0/230 [00:01<?, ?it/s]\u001b[A\n",
      "Epoch 0:  52%|██████████████████████████████████████████████▉                                           | 240/460 [02:18<02:06,  1.74it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  54%|████████████████████████████████████████████████▉                                         | 250/460 [02:27<02:04,  1.69it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  57%|██████████████████████████████████████████████████▊                                       | 260/460 [02:36<02:00,  1.66it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  59%|████████████████████████████████████████████████████▊                                     | 270/460 [02:45<01:56,  1.63it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  61%|██████████████████████████████████████████████████████▊                                   | 280/460 [02:54<01:52,  1.60it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  63%|████████████████████████████████████████████████████████▋                                 | 290/460 [03:03<01:47,  1.58it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████████████▋                               | 300/460 [03:12<01:42,  1.56it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  67%|████████████████████████████████████████████████████████████▋                             | 310/460 [03:21<01:37,  1.54it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  70%|██████████████████████████████████████████████████████████████▌                           | 320/460 [03:30<01:32,  1.52it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  72%|████████████████████████████████████████████████████████████████▌                         | 330/460 [03:39<01:26,  1.50it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  74%|██████████████████████████████████████████████████████████████████▌                       | 340/460 [03:49<01:21,  1.48it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  76%|████████████████████████████████████████████████████████████████████▍                     | 350/460 [03:58<01:14,  1.47it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  78%|██████████████████████████████████████████████████████████████████████▍                   | 360/460 [04:07<01:08,  1.45it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  80%|████████████████████████████████████████████████████████████████████████▍                 | 370/460 [04:16<01:02,  1.44it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  83%|██████████████████████████████████████████████████████████████████████████▎               | 380/460 [04:25<00:55,  1.43it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  85%|████████████████████████████████████████████████████████████████████████████▎             | 390/460 [04:34<00:49,  1.42it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  87%|██████████████████████████████████████████████████████████████████████████████▎           | 400/460 [04:43<00:42,  1.41it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  89%|████████████████████████████████████████████████████████████████████████████████▏         | 410/460 [04:53<00:35,  1.40it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  91%|██████████████████████████████████████████████████████████████████████████████████▏       | 420/460 [05:02<00:28,  1.39it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  93%|████████████████████████████████████████████████████████████████████████████████████▏     | 430/460 [05:11<00:21,  1.38it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  96%|██████████████████████████████████████████████████████████████████████████████████████    | 440/460 [05:20<00:14,  1.37it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████████████████████████████████████████████████████████  | 450/460 [05:30<00:07,  1.36it/s, loss=2.8, v_num=0, train_loss_step=2.850]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████████████████████████████| 460/460 [05:38<00:00,  1.36it/s, loss=2.8, v_num=0, train_loss_step=2.850, val_acc=0.973, val_loss=2.850]\u001b[A\n",
      "Epoch 0: 100%|███████████████████████████████████| 460/460 [05:38<00:00,  1.36it/s, loss=2.8, v_num=0, train_loss_step=2.850, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved. New best score: 3.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  20%|██████▊                            | 90/460 [06:27<26:34,  4.31s/it, loss=2.59, v_num=0, train_loss_step=2.940, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  35%|███████████▊                      | 160/460 [07:02<13:12,  2.64s/it, loss=2.67, v_num=0, train_loss_step=2.660, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|█████████████████                 | 230/460 [07:37<07:37,  1.99s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                              | 0/230 [00:01<?, ?it/s]\u001b[A\n",
      "Epoch 1:  52%|█████████████████▋                | 240/460 [07:49<07:10,  1.96s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  54%|██████████████████▍               | 250/460 [07:58<06:42,  1.92s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  57%|███████████████████▏              | 260/460 [08:08<06:15,  1.88s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  59%|███████████████████▉              | 270/460 [08:17<05:50,  1.84s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  61%|████████████████████▋             | 280/460 [08:27<05:26,  1.81s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  63%|█████████████████████▍            | 290/460 [08:36<05:02,  1.78s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  65%|██████████████████████▏           | 300/460 [08:45<04:40,  1.75s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  67%|██████████████████████▉           | 310/460 [08:55<04:18,  1.73s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  70%|███████████████████████▋          | 320/460 [09:04<03:58,  1.70s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  72%|████████████████████████▍         | 330/460 [09:13<03:38,  1.68s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  74%|█████████████████████████▏        | 340/460 [09:23<03:18,  1.66s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  76%|█████████████████████████▊        | 350/460 [09:32<02:59,  1.64s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  78%|██████████████████████████▌       | 360/460 [09:42<02:41,  1.62s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  80%|███████████████████████████▎      | 370/460 [09:51<02:23,  1.60s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  83%|████████████████████████████      | 380/460 [10:01<02:06,  1.58s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  85%|████████████████████████████▊     | 390/460 [10:10<01:49,  1.57s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  87%|█████████████████████████████▌    | 400/460 [10:19<01:32,  1.55s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  89%|██████████████████████████████▎   | 410/460 [10:29<01:16,  1.53s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  91%|███████████████████████████████   | 420/460 [10:39<01:00,  1.52s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  93%|███████████████████████████████▊  | 430/460 [10:48<00:45,  1.51s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  96%|████████████████████████████████▌ | 440/460 [10:57<00:29,  1.50s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1:  98%|█████████████████████████████████▎| 450/460 [11:07<00:14,  1.48s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.850, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1: 100%|██████████████████████████████████| 460/460 [11:16<00:00,  1.47s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.860, train_loss_epoch=3.240]\u001b[A\n",
      "Epoch 1: 100%|██████████████████████████████████| 460/460 [11:16<00:00,  1.47s/it, loss=2.68, v_num=0, train_loss_step=2.600, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 0.559 >= min_delta = 0.001. New best score: 2.682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  11%|███▌                             | 50/460 [11:44<1:36:14, 14.08s/it, loss=2.56, v_num=0, train_loss_step=2.290, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  26%|█████████▏                         | 120/460 [12:16<34:48,  6.14s/it, loss=2.5, v_num=0, train_loss_step=2.380, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|█████████████████                 | 230/460 [13:08<13:08,  3.43s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                              | 0/230 [00:01<?, ?it/s]\u001b[A\n",
      "Epoch 2:  52%|█████████████████▋                | 240/460 [13:20<12:13,  3.33s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  54%|██████████████████▍               | 250/460 [13:31<11:21,  3.25s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  57%|███████████████████▏              | 260/460 [13:43<10:33,  3.17s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  59%|███████████████████▉              | 270/460 [13:53<09:46,  3.09s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  61%|████████████████████▋             | 280/460 [14:03<09:02,  3.01s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  63%|█████████████████████▍            | 290/460 [14:12<08:19,  2.94s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  65%|██████████████████████▏           | 300/460 [14:22<07:39,  2.87s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  67%|██████████████████████▉           | 310/460 [14:31<07:01,  2.81s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  70%|███████████████████████▋          | 320/460 [14:40<06:25,  2.75s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  72%|████████████████████████▍         | 330/460 [14:50<05:50,  2.70s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  74%|█████████████████████████▏        | 340/460 [14:59<05:17,  2.65s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  76%|█████████████████████████▊        | 350/460 [15:08<04:45,  2.60s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  78%|██████████████████████████▌       | 360/460 [15:17<04:14,  2.55s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  80%|███████████████████████████▎      | 370/460 [15:27<03:45,  2.51s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  83%|████████████████████████████      | 380/460 [15:36<03:17,  2.46s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  85%|████████████████████████████▊     | 390/460 [15:45<02:49,  2.43s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  87%|█████████████████████████████▌    | 400/460 [15:55<02:23,  2.39s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  89%|██████████████████████████████▎   | 410/460 [16:04<01:57,  2.35s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  91%|███████████████████████████████   | 420/460 [16:13<01:32,  2.32s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  93%|███████████████████████████████▊  | 430/460 [16:22<01:08,  2.29s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  96%|████████████████████████████████▌ | 440/460 [16:32<00:45,  2.25s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2:  98%|█████████████████████████████████▎| 450/460 [16:41<00:22,  2.23s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.860, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2: 100%|██████████████████████████████████| 460/460 [16:50<00:00,  2.20s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.680]\u001b[A\n",
      "Epoch 2: 100%|██████████████████████████████████| 460/460 [16:50<00:00,  2.20s/it, loss=2.39, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 0.190 >= min_delta = 0.001. New best score: 2.492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:   2%|▋                              | 10/460 [16:59<12:44:33, 101.94s/it, loss=2.35, v_num=0, train_loss_step=1.980, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  30%|██████████▋                        | 140/460 [18:04<41:18,  7.75s/it, loss=2.3, v_num=0, train_loss_step=2.990, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|█████████████████                 | 230/460 [18:49<18:49,  4.91s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                              | 0/230 [00:01<?, ?it/s]\u001b[A\n",
      "Epoch 3:  52%|█████████████████▋                | 240/460 [19:01<17:26,  4.76s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  54%|██████████████████▍               | 250/460 [19:11<16:06,  4.60s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  57%|███████████████████▏              | 260/460 [19:20<14:52,  4.46s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  59%|███████████████████▉              | 270/460 [19:30<13:43,  4.33s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  61%|████████████████████▋             | 280/460 [19:39<12:38,  4.21s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  63%|█████████████████████▍            | 290/460 [19:48<11:36,  4.10s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  65%|██████████████████████▏           | 300/460 [19:58<10:39,  3.99s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  67%|██████████████████████▉           | 310/460 [20:07<09:44,  3.89s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  70%|███████████████████████▋          | 320/460 [20:16<08:52,  3.80s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  72%|████████████████████████▍         | 330/460 [20:26<08:02,  3.72s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  74%|█████████████████████████▏        | 340/460 [20:35<07:15,  3.63s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  76%|█████████████████████████▊        | 350/460 [20:44<06:31,  3.56s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  78%|██████████████████████████▌       | 360/460 [20:53<05:48,  3.48s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  80%|███████████████████████████▎      | 370/460 [21:03<05:07,  3.41s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  83%|████████████████████████████      | 380/460 [21:12<04:27,  3.35s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  85%|████████████████████████████▊     | 390/460 [21:21<03:50,  3.29s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  87%|█████████████████████████████▌    | 400/460 [21:31<03:13,  3.23s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  89%|██████████████████████████████▎   | 410/460 [21:40<02:38,  3.17s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  91%|███████████████████████████████   | 420/460 [21:49<02:04,  3.12s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  93%|███████████████████████████████▊  | 430/460 [21:59<01:32,  3.07s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  96%|████████████████████████████████▌ | 440/460 [22:08<01:00,  3.02s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3:  98%|█████████████████████████████████▎| 450/460 [22:17<00:29,  2.97s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.650, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3: 100%|██████████████████████████████████| 460/460 [22:26<00:00,  2.93s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.490]\u001b[A\n",
      "Epoch 3: 100%|██████████████████████████████████| 460/460 [22:26<00:00,  2.93s/it, loss=2.22, v_num=0, train_loss_step=1.680, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 0.164 >= min_delta = 0.001. New best score: 2.328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  20%|██████▋                           | 90/460 [23:15<1:35:36, 15.50s/it, loss=2.2, v_num=0, train_loss_step=2.660, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  28%|█████████▌                        | 130/460 [23:34<59:50, 10.88s/it, loss=2.21, v_num=0, train_loss_step=1.970, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|█████████████████                 | 230/460 [24:22<24:22,  6.36s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                              | 0/230 [00:01<?, ?it/s]\u001b[A\n",
      "Epoch 4:  52%|█████████████████▋                | 240/460 [24:34<22:31,  6.14s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  54%|██████████████████▍               | 250/460 [24:43<20:46,  5.93s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  57%|███████████████████▏              | 260/460 [24:52<19:08,  5.74s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  59%|███████████████████▉              | 270/460 [25:01<17:36,  5.56s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  61%|████████████████████▋             | 280/460 [25:10<16:10,  5.39s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  63%|█████████████████████▍            | 290/460 [25:18<14:50,  5.24s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  65%|██████████████████████▏           | 300/460 [25:27<13:34,  5.09s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  67%|██████████████████████▉           | 310/460 [25:36<12:23,  4.95s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  70%|███████████████████████▋          | 320/460 [25:44<11:15,  4.83s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  72%|████████████████████████▍         | 330/460 [25:53<10:11,  4.71s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  74%|█████████████████████████▏        | 340/460 [26:01<09:11,  4.59s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  76%|█████████████████████████▊        | 350/460 [26:10<08:13,  4.49s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  78%|██████████████████████████▌       | 360/460 [26:18<07:18,  4.39s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  80%|███████████████████████████▎      | 370/460 [26:27<06:26,  4.29s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  83%|████████████████████████████      | 380/460 [26:36<05:36,  4.20s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  85%|████████████████████████████▊     | 390/460 [26:45<04:48,  4.12s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  87%|█████████████████████████████▌    | 400/460 [26:54<04:02,  4.04s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  89%|██████████████████████████████▎   | 410/460 [27:02<03:17,  3.96s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  91%|███████████████████████████████   | 420/460 [27:11<02:35,  3.88s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  93%|███████████████████████████████▊  | 430/460 [27:20<01:54,  3.82s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  96%|████████████████████████████████▌ | 440/460 [27:29<01:14,  3.75s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4:  98%|█████████████████████████████████▎| 450/460 [27:38<00:36,  3.69s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.973, val_loss=2.700, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4: 100%|██████████████████████████████████| 460/460 [27:47<00:00,  3.62s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.330]\u001b[A\n",
      "Epoch 4: 100%|██████████████████████████████████| 460/460 [27:47<00:00,  3.62s/it, loss=2.23, v_num=0, train_loss_step=2.750, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 0.102 >= min_delta = 0.001. New best score: 2.226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:   4%|█▍                              | 20/460 [28:02<10:16:46, 84.10s/it, loss=2.12, v_num=0, train_loss_step=2.270, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  33%|██████████▊                      | 150/460 [29:03<1:00:03, 11.62s/it, loss=2.3, v_num=0, train_loss_step=2.550, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|█████████████████                 | 230/460 [29:41<29:41,  7.75s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                              | 0/230 [00:01<?, ?it/s]\u001b[A\n",
      "Epoch 5:  52%|█████████████████▋                | 240/460 [29:53<27:24,  7.47s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  54%|██████████████████▍               | 250/460 [30:03<25:14,  7.21s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  57%|███████████████████▏              | 260/460 [30:12<23:14,  6.97s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  59%|███████████████████▉              | 270/460 [30:21<21:22,  6.75s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  61%|████████████████████▋             | 280/460 [30:31<19:37,  6.54s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  63%|█████████████████████▍            | 290/460 [30:40<17:58,  6.35s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  65%|██████████████████████▏           | 300/460 [30:49<16:26,  6.17s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  67%|██████████████████████▉           | 310/460 [30:59<14:59,  6.00s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  70%|███████████████████████▋          | 320/460 [31:08<13:37,  5.84s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  72%|████████████████████████▍         | 330/460 [31:17<12:19,  5.69s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  74%|█████████████████████████▏        | 340/460 [31:26<11:05,  5.55s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  76%|█████████████████████████▊        | 350/460 [31:35<09:55,  5.42s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  78%|██████████████████████████▌       | 360/460 [31:44<08:49,  5.29s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  80%|███████████████████████████▎      | 370/460 [31:53<07:45,  5.17s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  83%|████████████████████████████      | 380/460 [32:03<06:44,  5.06s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  85%|████████████████████████████▊     | 390/460 [32:12<05:46,  4.95s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  87%|█████████████████████████████▌    | 400/460 [32:21<04:51,  4.85s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  89%|██████████████████████████████▎   | 410/460 [32:30<03:57,  4.76s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  91%|███████████████████████████████   | 420/460 [32:40<03:06,  4.67s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  93%|███████████████████████████████▊  | 430/460 [32:49<02:17,  4.58s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  96%|████████████████████████████████▌ | 440/460 [32:58<01:29,  4.50s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5:  98%|█████████████████████████████████▎| 450/460 [33:07<00:44,  4.42s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5: 100%|██████████████████████████████████| 460/460 [33:16<00:00,  4.34s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.230]\u001b[A\n",
      "Epoch 5: 100%|██████████████████████████████████| 460/460 [33:16<00:00,  4.34s/it, loss=2.17, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 0.045 >= min_delta = 0.001. New best score: 2.181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:   4%|█▎                             | 20/460 [33:30<12:17:00, 100.50s/it, loss=2.19, v_num=0, train_loss_step=2.320, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  26%|████████▎                       | 120/460 [34:17<1:37:08, 17.14s/it, loss=2.11, v_num=0, train_loss_step=2.740, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|█████████████████                 | 230/460 [35:08<35:08,  9.17s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                              | 0/230 [00:01<?, ?it/s]\u001b[A\n",
      "Epoch 6:  52%|█████████████████▋                | 240/460 [35:20<32:24,  8.84s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  54%|██████████████████▍               | 250/460 [35:29<29:49,  8.52s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  57%|███████████████████▏              | 260/460 [35:38<27:25,  8.23s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  59%|███████████████████▉              | 270/460 [35:47<25:11,  7.96s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  61%|████████████████████▋             | 280/460 [35:56<23:06,  7.70s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  63%|█████████████████████▍            | 290/460 [36:06<21:09,  7.47s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  65%|██████████████████████▏           | 300/460 [36:15<19:20,  7.25s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  67%|██████████████████████▉           | 310/460 [36:24<17:37,  7.05s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  70%|███████████████████████▋          | 320/460 [36:33<15:59,  6.86s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  72%|████████████████████████▍         | 330/460 [36:42<14:27,  6.67s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  74%|█████████████████████████▏        | 340/460 [36:51<13:00,  6.51s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  76%|█████████████████████████▊        | 350/460 [37:00<11:37,  6.35s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  78%|██████████████████████████▌       | 360/460 [37:09<10:19,  6.19s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  80%|███████████████████████████▎      | 370/460 [37:18<09:04,  6.05s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  83%|████████████████████████████      | 380/460 [37:27<07:53,  5.92s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  85%|████████████████████████████▊     | 390/460 [37:36<06:45,  5.79s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  87%|█████████████████████████████▌    | 400/460 [37:45<05:39,  5.66s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  89%|██████████████████████████████▎   | 410/460 [37:54<04:37,  5.55s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  91%|███████████████████████████████   | 420/460 [38:03<03:37,  5.44s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  93%|███████████████████████████████▊  | 430/460 [38:12<02:39,  5.33s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  96%|████████████████████████████████▌ | 440/460 [38:21<01:44,  5.23s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6:  98%|█████████████████████████████████▎| 450/460 [38:29<00:51,  5.13s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.440, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6: 100%|██████████████████████████████████| 460/460 [38:38<00:00,  5.04s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.180]\u001b[A\n",
      "Epoch 6: 100%|██████████████████████████████████| 460/460 [38:38<00:00,  5.04s/it, loss=2.03, v_num=0, train_loss_step=2.490, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 0.091 >= min_delta = 0.001. New best score: 2.090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  33%|██████████▍                     | 150/460 [39:52<1:22:23, 15.95s/it, loss=2.23, v_num=0, train_loss_step=2.160, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  37%|███████████▊                    | 170/460 [40:01<1:08:16, 14.13s/it, loss=1.95, v_num=0, train_loss_step=2.370, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  50%|█████████████████▌                 | 230/460 [40:29<40:29, 10.56s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                              | 0/230 [00:01<?, ?it/s]\u001b[A\n",
      "Epoch 7:  52%|██████████████████▎                | 240/460 [40:41<37:18, 10.17s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  54%|███████████████████                | 250/460 [40:51<34:18,  9.80s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  57%|███████████████████▊               | 260/460 [41:00<31:32,  9.46s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  59%|████████████████████▌              | 270/460 [41:09<28:57,  9.15s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  61%|█████████████████████▎             | 280/460 [41:19<26:33,  8.85s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  63%|██████████████████████             | 290/460 [41:28<24:18,  8.58s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  65%|██████████████████████▊            | 300/460 [41:38<22:12,  8.33s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  67%|███████████████████████▌           | 310/460 [41:47<20:13,  8.09s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  70%|████████████████████████▎          | 320/460 [41:56<18:21,  7.87s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  72%|█████████████████████████          | 330/460 [42:06<16:35,  7.66s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  74%|█████████████████████████▊         | 340/460 [42:15<14:54,  7.46s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  76%|██████████████████████████▋        | 350/460 [42:25<13:19,  7.27s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  78%|███████████████████████████▍       | 360/460 [42:34<11:49,  7.10s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  80%|████████████████████████████▏      | 370/460 [42:43<10:23,  6.93s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  83%|████████████████████████████▉      | 380/460 [42:53<09:01,  6.77s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  85%|█████████████████████████████▋     | 390/460 [43:02<07:43,  6.62s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  87%|██████████████████████████████▍    | 400/460 [43:12<06:28,  6.48s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  89%|███████████████████████████████▏   | 410/460 [43:21<05:17,  6.35s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  91%|███████████████████████████████▉   | 420/460 [43:31<04:08,  6.22s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  93%|████████████████████████████████▋  | 430/460 [43:40<03:02,  6.09s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  96%|█████████████████████████████████▍ | 440/460 [43:50<01:59,  5.98s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7:  98%|██████████████████████████████████▏| 450/460 [43:59<00:58,  5.87s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.974, val_loss=2.160, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████| 460/460 [44:08<00:00,  5.76s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.090]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████| 460/460 [44:08<00:00,  5.76s/it, loss=1.9, v_num=0, train_loss_step=1.740, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 0.037 >= min_delta = 0.001. New best score: 2.053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  26%|████████▎                       | 120/460 [45:08<2:07:53, 22.57s/it, loss=2.07, v_num=0, train_loss_step=2.400, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  37%|███████████▊                    | 170/460 [45:31<1:17:39, 16.07s/it, loss=2.07, v_num=0, train_loss_step=2.330, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  50%|█████████████████                 | 230/460 [45:59<45:59, 12.00s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                              | 0/230 [00:01<?, ?it/s]\u001b[A\n",
      "Epoch 8:  52%|█████████████████▋                | 240/460 [46:11<42:20, 11.55s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  54%|██████████████████▍               | 250/460 [46:20<38:55, 11.12s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  57%|███████████████████▏              | 260/460 [46:30<35:46, 10.73s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  59%|███████████████████▉              | 270/460 [46:39<32:50, 10.37s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  61%|████████████████████▋             | 280/460 [46:48<30:05, 10.03s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  63%|█████████████████████▍            | 290/460 [46:58<27:32,  9.72s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  65%|██████████████████████▏           | 300/460 [47:07<25:08,  9.43s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  67%|██████████████████████▉           | 310/460 [47:17<22:52,  9.15s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  70%|███████████████████████▋          | 320/460 [47:26<20:45,  8.89s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  72%|████████████████████████▍         | 330/460 [47:35<18:44,  8.65s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  74%|█████████████████████████▏        | 340/460 [47:45<16:51,  8.43s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  76%|█████████████████████████▊        | 350/460 [47:54<15:03,  8.21s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  78%|██████████████████████████▌       | 360/460 [48:03<13:21,  8.01s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  80%|███████████████████████████▎      | 370/460 [48:13<11:43,  7.82s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  83%|████████████████████████████      | 380/460 [48:22<10:11,  7.64s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  85%|████████████████████████████▊     | 390/460 [48:32<08:42,  7.47s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  87%|█████████████████████████████▌    | 400/460 [48:41<07:18,  7.30s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  89%|██████████████████████████████▎   | 410/460 [48:50<05:57,  7.15s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  91%|███████████████████████████████   | 420/460 [49:00<04:40,  7.00s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  93%|███████████████████████████████▊  | 430/460 [49:09<03:25,  6.86s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  96%|████████████████████████████████▌ | 440/460 [49:18<02:14,  6.72s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8:  98%|█████████████████████████████████▎| 450/460 [49:28<01:05,  6.60s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.973, val_loss=2.740, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8: 100%|██████████████████████████████████| 460/460 [49:36<00:00,  6.47s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.050]\u001b[A\n",
      "Epoch 8: 100%|██████████████████████████████████| 460/460 [49:36<00:00,  6.47s/it, loss=1.93, v_num=0, train_loss_step=2.000, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 0.037 >= min_delta = 0.001. New best score: 2.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  11%|███▌                             | 50/460 [50:05<6:50:48, 60.12s/it, loss=1.94, v_num=0, train_loss_step=2.950, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  33%|██████████▍                     | 150/460 [50:57<1:45:18, 20.38s/it, loss=2.07, v_num=0, train_loss_step=2.170, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  50%|█████████████████                 | 230/460 [51:35<51:35, 13.46s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                                                              | 0/230 [00:01<?, ?it/s]\u001b[A\n",
      "Epoch 9:  52%|█████████████████▋                | 240/460 [51:47<47:28, 12.95s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  54%|██████████████████▍               | 250/460 [51:55<43:37, 12.46s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  57%|███████████████████▏              | 260/460 [52:04<40:03, 12.02s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  59%|███████████████████▉              | 270/460 [52:13<36:45, 11.61s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  61%|████████████████████▋             | 280/460 [52:22<33:40, 11.22s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  63%|█████████████████████▍            | 290/460 [52:31<30:47, 10.87s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  65%|██████████████████████▏           | 300/460 [52:39<28:05, 10.53s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  67%|██████████████████████▉           | 310/460 [52:48<25:33, 10.22s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  70%|███████████████████████▋          | 320/460 [52:56<23:09,  9.93s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  72%|████████████████████████▍         | 330/460 [53:05<20:54,  9.65s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  74%|█████████████████████████▏        | 340/460 [53:13<18:47,  9.39s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  76%|█████████████████████████▊        | 350/460 [53:21<16:46,  9.15s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  78%|██████████████████████████▌       | 360/460 [53:30<14:51,  8.92s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  80%|███████████████████████████▎      | 370/460 [53:39<13:03,  8.70s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  83%|████████████████████████████      | 380/460 [53:47<11:19,  8.49s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  85%|████████████████████████████▊     | 390/460 [53:56<09:40,  8.30s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  87%|█████████████████████████████▌    | 400/460 [54:04<08:06,  8.11s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  89%|██████████████████████████████▎   | 410/460 [54:13<06:36,  7.93s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  91%|███████████████████████████████   | 420/460 [54:22<05:10,  7.77s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  93%|███████████████████████████████▊  | 430/460 [54:30<03:48,  7.61s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  96%|████████████████████████████████▌ | 440/460 [54:39<02:29,  7.45s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9:  98%|█████████████████████████████████▎| 450/460 [54:48<01:13,  7.31s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.974, val_loss=2.460, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9: 100%|██████████████████████████████████| 460/460 [54:57<00:00,  7.17s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.971, val_loss=3.130, train_loss_epoch=2.020]\u001b[A\n",
      "Epoch 9: 100%|██████████████████████████████████| 460/460 [54:57<00:00,  7.17s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.971, val_loss=3.130, train_loss_epoch=1.990]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved by 0.031 >= min_delta = 0.001. New best score: 1.986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████████████████████████████| 460/460 [54:57<00:00,  7.17s/it, loss=2.04, v_num=0, train_loss_step=2.060, val_acc=0.971, val_loss=3.130, train_loss_epoch=1.990]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35681/1017879334.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Saved model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'save' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    early_stop_callback = EarlyStopping(monitor='val_loss', min_delta=0.00, patience=5, verbose=True)\n",
    "    checkpoint_callback = ModelCheckpoint(monitor='val_acc', mode='max', dirpath='./', save_top_k=1)\n",
    "    model = OurModel()\n",
    "    trainer = Trainer(max_epochs=10, min_epochs=1, auto_lr_find=False, auto_scale_batch_size=False,logger=logger,\n",
    "                      progress_bar_refresh_rate=10, callbacks=[early_stop_callback], checkpoint_callback=[checkpoint_callback],)\n",
    "    trainer.tune(model)\n",
    "    trainer.fit(model)\n",
    "    save(model.state_dict(), 'Saved model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b3353f9-e05d-4ce3-acde-72f486b8e97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoahoang/env/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1448: UserWarning: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `validate(ckpt_path='best')` to use and best model checkpoint and avoid this warning or `ckpt_path=trainer.checkpoint_callback.last_model_path` to use the last model.\n",
      "  f\"`.{fn}(ckpt_path=None)` was called without a model.\"\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: EarlyStopping, ModelCheckpoint\n",
      "Restoring states from the checkpoint path at /home/hoahoang/training/data/oxford-iiit-pet/epoch=6-step=1610-v1.ckpt\n",
      "Loaded model weights from checkpoint at /home/hoahoang/training/data/oxford-iiit-pet/epoch=6-step=1610-v1.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 230/230 [03:27<00:00,  1.11it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         val_acc            0.9744840264320374\n",
      "        val_loss             2.155937433242798\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_acc': 0.9744840264320374, 'val_loss': 2.155937433242798}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a8af90-57f7-4b1c-92d0-237a67a90a72",
   "metadata": {},
   "source": [
    "### visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad2130d7-2e5f-47bd-b7a6-6fbbdc7f53b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "TensorBoard 2.8.0 at http://labserver:6009/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir=runs --load_fast=false --bind_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
