{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from torch) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (0.7.2)\n",
      "Requirement already satisfied: packaging in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: torch>=1.3.1 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from torchmetrics) (1.11.0)\n",
      "Requirement already satisfied: pyDeprecate==0.3.* in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from torchmetrics) (0.3.1)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from torchmetrics) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from torch>=1.3.1->torchmetrics) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from packaging->torchmetrics) (3.0.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision==0.9.0\n",
      "  Using cached torchvision-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
      "Requirement already satisfied: torchaudio==0.8.0 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (0.8.0)\n",
      "Collecting pytorch-lightning==1.2.2\n",
      "  Using cached pytorch_lightning-1.2.2-py3-none-any.whl (816 kB)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from torchvision==0.9.0) (9.0.1)\n",
      "Collecting torch==1.8.0\n",
      "  Using cached torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
      "Requirement already satisfied: numpy in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from torchvision==0.9.0) (1.21.5)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from pytorch-lightning==1.2.2) (2.8.0)\n",
      "Requirement already satisfied: future>=0.17.1 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from pytorch-lightning==1.2.2) (0.18.2)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from pytorch-lightning==1.2.2) (4.63.0)\n",
      "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from pytorch-lightning==1.2.2) (6.0)\n",
      "Requirement already satisfied: fsspec[http]>=0.8.1 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from pytorch-lightning==1.2.2) (2022.2.0)\n",
      "Requirement already satisfied: typing-extensions in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from torch==1.8.0->torchvision==0.9.0) (4.1.1)\n",
      "Requirement already satisfied: requests in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (2.27.1)\n",
      "Requirement already satisfied: aiohttp in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (3.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (3.3.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (1.0.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (1.44.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (0.37.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (59.5.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (2.0.3)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (3.19.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.2) (2.6.0)\n",
      "Requirement already satisfied: six in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (4.11.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (2.0.12)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (6.0.2)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.2) (0.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/tungnguyendinh/interns/env/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.2) (3.2.0)\n",
      "Installing collected packages: torch, torchvision, pytorch-lightning\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0\n",
      "    Uninstalling torch-1.11.0:\n",
      "      Successfully uninstalled torch-1.11.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.12.0\n",
      "    Uninstalling torchvision-0.12.0:\n",
      "      Successfully uninstalled torchvision-0.12.0\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.5.10\n",
      "    Uninstalling pytorch-lightning-1.5.10:\n",
      "      Successfully uninstalled pytorch-lightning-1.5.10\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 2.5.3 requires spacy<4, which is not installed.\n",
      "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.8.0 which is incompatible.\n",
      "lightning-flash 0.7.1 requires pytorch-lightning>=1.3.6, but you have pytorch-lightning 1.2.2 which is incompatible.\n",
      "lightning-bolts 0.5.0 requires pytorch-lightning>=1.4.0, but you have pytorch-lightning 1.2.2 which is incompatible.\n",
      "kornia 0.6.3 requires torch>=1.8.1, but you have torch 1.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pytorch-lightning-1.2.2 torch-1.8.0 torchvision-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision==0.9.0 torchaudio==0.8.0 pytorch-lightning==1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "id": "8PWJx26vtqYe",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'functional_datapipe' from 'torch.utils.data' (/home/tungnguyendinh/interns/env/lib/python3.7/site-packages/torch/utils/data/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35043/502979400.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightningModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/interns/env/lib/python3.7/site-packages/pytorch_lightning/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# We are not importing the rest of the lightning during the build process, as it may not be compiled yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightningDataModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLightningModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/interns/env/lib/python3.7/site-packages/pytorch_lightning/metrics/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# See the License for the specific language governing permissions and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m from pytorch_lightning.metrics.classification import (  # noqa: F401\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mAccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mAUC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/interns/env/lib/python3.7/site-packages/pytorch_lightning/metrics/classification/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# See the License for the specific language governing permissions and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAccuracy\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAUC\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauroc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAUROC\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/interns/env/lib/python3.7/site-packages/pytorch_lightning/metrics/classification/accuracy.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_accuracy_compute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_accuracy_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/interns/env/lib/python3.7/site-packages/pytorch_lightning/metrics/functional/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# See the License for the specific language governing permissions and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauc\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauroc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauroc\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/interns/env/lib/python3.7/site-packages/pytorch_lightning/metrics/functional/accuracy.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_input_format_classification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/interns/env/lib/python3.7/site-packages/pytorch_lightning/metrics/classification/helpers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mselect_topk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_onehot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightningEnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/interns/env/lib/python3.7/site-packages/pytorch_lightning/metrics/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrank_zero_warn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mMETRIC_EPS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/interns/env/lib/python3.7/site-packages/pytorch_lightning/utilities/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_func\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmove_data_to_device\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m from pytorch_lightning.utilities.distributed import (  # noqa: F401\n\u001b[1;32m     20\u001b[0m     \u001b[0mAllGatherGrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/interns/env/lib/python3.7/site-packages/pytorch_lightning/utilities/apply_func.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_TORCHTEXT_AVAILABLE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mBatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/interns/env/lib/python3.7/site-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/interns/env/lib/python3.7/site-packages/torchtext/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mag_news\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAG_NEWS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mamazonreviewfull\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAmazonReviewFull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mamazonreviewpolarity\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAmazonReviewPolarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/interns/env/lib/python3.7/site-packages/torchtext/datasets/ag_news.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_module_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m from torchtext.data.datasets_utils import (\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0m_wrap_split_argument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0m_create_dataset_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/interns/env/lib/python3.7/site-packages/torchtext/data/datasets_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mextract_archive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_datapipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterDataPipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStreamWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'functional_datapipe' from 'torch.utils.data' (/home/tungnguyendinh/interns/env/lib/python3.7/site-packages/torch/utils/data/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import glob\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n",
    "import torchmetrics\n",
    "import logging\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch.utils.data import random_split\n",
    "from typing import Dict, List, Optional, Sequence, Tuple, Type, Union\n",
    "from torch import Tensor\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from torchvision import transforms as T\n",
    "# from warnings import warn\n",
    "# from kornia import augmentation, geometry, image_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/tungnguyendinh/interns/users/hoa_hoangthi/data/pascal_2007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "TgZZnNohtvb9",
    "outputId": "022062c9-f093-499d-e14b-17955e7b753f"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('./train.csv')\n",
    "print(data_train)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n1d80nf0vHA8"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "mul_labels = list(itertools.chain(*[lbs.split(\" \") for lbs in data_train['labels']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "4hq2tak9vJV8",
    "outputId": "c82897da-7c37-4c5e-923e-4e2a709dc247"
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(y=sorted(mul_labels), orient='v')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "2b5W_os_tzjN",
    "outputId": "1995b802-7e8d-436b-e27a-128c3401305f"
   },
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('./test.csv')\n",
    "print(data_test)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wv5nPEfyzcfK",
    "outputId": "5af355b3-765a-4221-9627-035d08c5b65d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_unique = set(mul_labels)\n",
    "print(f\"unique labels: {labels_unique}\")\n",
    "data_train['labels_sorted'] = [\" \".join(sorted(lbs.split(\" \"))) for lbs in data_train['labels']]\n",
    "\n",
    "labels_combine = {}\n",
    "for comb in data_train['labels_sorted']:\n",
    "    labels_combine[comb] = labels_combine.get(comb, 0) + 1\n",
    "\n",
    "show_counts = '\\n'.join(sorted(f'\\t{k}: {v}' for k, v in labels_combine.items()))\n",
    "print(f\"unique combinations: \\n\" + show_counts)\n",
    "print(f\"total: {sum(labels_combine.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7rb4KkAzn4A"
   },
   "outputs": [],
   "source": [
    "labels = ['dog', 'tvmonitor', 'person', 'bird', 'chair', 'car', 'sofa', 'sheep', 'bottle', 'bicycle', 'motorbike', 'bus', 'boat', 'pottedplant', 'horse', 'cat', 'aeroplane', 'cow', 'train', 'diningtable']\n",
    "mul_labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "_8GqJ_MGzsKh",
    "outputId": "30d3137c-a440-4b02-b5d1-74a528c7a52a"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('./train.csv')\n",
    "label_train = []\n",
    "import cv2\n",
    "for i in range(len(data_train)):\n",
    "  vitri = 0\n",
    "  lb = np.zeros(20)\n",
    "  for j in mul_labels:\n",
    "    labels = data_train['labels'][i].split(' ')\n",
    "    for k in labels:\n",
    "      if k == j:\n",
    "        lb[vitri]=1\n",
    "    vitri+=1\n",
    "  label_train.append(lb)\n",
    "\n",
    "data_train['label_train'] = label_train\n",
    "print(data_train['label_train'][2])\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5vuOtBBzxvB"
   },
   "outputs": [],
   "source": [
    "DATASET_IMAGE_MEAN = (0.48690377, 0.62658835, 0.4078062)\n",
    "DATASET_IMAGE_STD = (0.18142496, 0.15883319, 0.19026241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2D68U6cozxsC"
   },
   "outputs": [],
   "source": [
    "class Pascal2007Dataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df_data: Union[str, pd.DataFrame] = 'train.csv',\n",
    "        path_img_dir: str = './train',\n",
    "        transforms=None,\n",
    "        mode: str = 'train',\n",
    "        split: float = 0.8,\n",
    "        uq_labels: Tuple[str] = None,\n",
    "        random_state=42,\n",
    "    ):\n",
    "        self.path_img_dir = path_img_dir\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "\n",
    "        # set or load the config table\n",
    "        if isinstance(df_data, pd.DataFrame):\n",
    "            self.data = df_data\n",
    "        elif isinstance(df_data, str):\n",
    "            assert os.path.isfile(df_data), f\"missing file: {df_data}\"\n",
    "            self.data = pd.read_csv(df_data)\n",
    "        else:\n",
    "            raise ValueError(f'unrecognised input for DataFrame/CSV: {df_data}')\n",
    "\n",
    "        # take over existing table or load from file\n",
    "        if uq_labels:\n",
    "            self.labels_unique = tuple(uq_labels)\n",
    "        else:\n",
    "            labels_all = list(itertools.chain(*[lbs.split(\" \") for lbs in self.raw_labels]))\n",
    "            self.labels_unique = tuple(sorted(set(labels_all)))\n",
    "        self.labels_lut = {lb: i for i, lb in enumerate(self.labels_unique)}\n",
    "        self.num_classes = len(self.labels_unique)\n",
    "\n",
    "        # shuffle data\n",
    "        self.data = self.data.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "        # split dataset\n",
    "        assert 0.0 <= split <= 1.0, f\"split {split} is out of range\"\n",
    "        frac = int(split * len(self.data))\n",
    "        self.data = self.data[:frac] if mode == 'train' else self.data[frac:]\n",
    "        self.img_names = list(self.data['fname'])\n",
    "        self.labels = self._prepare_labels()\n",
    "        # compute importance order\n",
    "        self.label_importance_index = []\n",
    "\n",
    "    @property\n",
    "    def raw_labels(self):\n",
    "        return list(self.data['labels'])\n",
    "\n",
    "    def _prepare_labels(self) -> list:\n",
    "        return [torch.tensor(self.to_binary_encoding(lb)) if lb else None for lb in self.raw_labels]\n",
    "\n",
    "    @property\n",
    "    def label_histogram(self) -> Tensor:\n",
    "        lb_stack = torch.tensor(list(map(tuple, self.labels)))\n",
    "        return torch.sum(lb_stack, dim=0)\n",
    "\n",
    "    def to_binary_encoding(self, labels: str) -> tuple:\n",
    "        # processed with encoding\n",
    "        one_hot = [0] * len(self.labels_unique)\n",
    "        for lb in labels.split(\" \"):\n",
    "            one_hot[self.labels_lut[lb]] = 1\n",
    "        return tuple(one_hot)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        img_name = self.img_names[idx]\n",
    "        img_path = os.path.join(self.path_img_dir, img_name)\n",
    "        assert os.path.isfile(img_path)\n",
    "        label = self.labels[idx]\n",
    "        img = plt.imread(img_path)\n",
    "\n",
    "        # augmentation\n",
    "        if self.transforms:\n",
    "            img = self.transforms(Image.fromarray(img))\n",
    "        # in case of predictions, return image name as label\n",
    "        label = label if label is not None else img_name\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_sample_pseudo_label(self, idx: int):\n",
    "        if not self.label_importance_index:\n",
    "            idx_nb = list(enumerate(self.label_histogram))\n",
    "            idx_nb = sorted(idx_nb, key=lambda x: x[1])\n",
    "            self.label_importance_index = [i[0] for i in idx_nb]\n",
    "        binary = self.labels[idx]\n",
    "        # take the less occurred label, not the tuple combination as combination does not matter too much\n",
    "        for i in self.label_importance_index:\n",
    "            if binary[i]:\n",
    "                return i\n",
    "        # this is a failer...\n",
    "        return tuple(binary.numpy())\n",
    "\n",
    "    def get_sample_pseudo_labels(self, *_):\n",
    "        return [self.get_sample_pseudo_label(i) for i in range(len(self))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BmNe7xFlzxk5"
   },
   "outputs": [],
   "source": [
    "class Pascal2007SimpleDataset(Pascal2007Dataset):\n",
    "    \n",
    "    def _translate_labels(self, lb):\n",
    "        if lb is None:\n",
    "            return None\n",
    "        lb = self.labels_lut['complex'] if torch.sum(lb) > 1 else torch.argmax(lb)\n",
    "        return int(lb)\n",
    "\n",
    "    def _prepare_labels(self) -> list:\n",
    "        labels = super()._prepare_labels()\n",
    "        return list(map(self._translate_labels, labels))\n",
    "\n",
    "    @property\n",
    "    def label_histogram(self) -> Tensor:\n",
    "        if not isinstance(self.labels, Tensor):\n",
    "            self.labels = torch.tensor(self.labels)\n",
    "        return torch.bincount(self.labels)\n",
    "\n",
    "    def get_sample_pseudo_label(self, idx: int):\n",
    "        return self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eyr6i3NOzxcC"
   },
   "outputs": [],
   "source": [
    "class Pascal2007DM(LightningDataModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        path_csv: str = 'train.csv',\n",
    "        base_path: str = '.',\n",
    "        batch_size: int = 32,\n",
    "        num_workers: int = None,\n",
    "        simple: bool = False,\n",
    "        train_transforms=None,\n",
    "        valid_transforms=None,\n",
    "        split: float = 0.8,\n",
    "        balancing: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # path configurations\n",
    "        assert os.path.isdir(base_path), f\"missing folder: {base_path}\"\n",
    "        self.train_dir = os.path.join(base_path, 'train')\n",
    "        self.test_dir = os.path.join(base_path, 'test')\n",
    "\n",
    "        if not os.path.isfile(path_csv):\n",
    "            path_csv = os.path.join(base_path, path_csv)\n",
    "        assert os.path.isfile(path_csv), f\"missing table: {path_csv}\"\n",
    "        self.path_csv = path_csv\n",
    "\n",
    "        # other configs\n",
    "        self.batch_size = batch_size\n",
    "        self.split = split\n",
    "        self.num_workers = num_workers if num_workers is not None else os.cpu_count()\n",
    "        self.labels_unique: Sequence = ...\n",
    "        self.lut_label: Dict = ...\n",
    "        self.label_histogram: Tensor = ...\n",
    "        self.balancing = balancing\n",
    "\n",
    "        # need to be filled in setup()\n",
    "        self.train_dataset = None\n",
    "        self.valid_dataset = None\n",
    "        self.test_table = []\n",
    "        self.test_dataset = None\n",
    "        self.train_transforms = train_transforms \n",
    "        self.valid_transforms = valid_transforms \n",
    "        self.dataset_cls: Type = Pascal2007SimpleDataset if simple else Pascal2007Dataset\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def num_classes(self) -> int:\n",
    "        assert self.train_dataset and self.valid_dataset\n",
    "        return max(self.train_dataset.num_classes, self.valid_dataset.num_classes)\n",
    "\n",
    "    @staticmethod\n",
    "    def binary_mapping(\n",
    "        encoding: Tensor,\n",
    "        lut_label: Dict[int, str],\n",
    "        thr: float = 0.5,\n",
    "        label_required: bool = True,\n",
    "    ) -> Union[str, List[str]]:\n",
    "        \"\"\"Convert Model outputs to string labels\n",
    "        Args:\n",
    "            encoding: one-hot encoding\n",
    "            lut_label: look-up-table with labels\n",
    "            thr: threshold for label binarization\n",
    "            label_required: if it is required to return any label and no label is above `thr`, use argmax\n",
    "        \"\"\"\n",
    "        assert lut_label\n",
    "        # on case it is not one hot encoding but single label\n",
    "        if encoding.nelement() == 1:\n",
    "            return lut_label[encoding[0]]\n",
    "        labels = [lut_label[i] for i, s in enumerate(encoding) if s >= thr]\n",
    "        # in case no reached threshold then take max\n",
    "        if not labels and label_required:\n",
    "            idx = torch.argmax(encoding).item()\n",
    "            labels = [lut_label[idx]]\n",
    "        return sorted(labels)\n",
    "\n",
    "    def binary_encoding_to_labels(\n",
    "        self,\n",
    "        encoding: Tensor,\n",
    "        thr: float = 0.5,\n",
    "        label_required: bool = True,\n",
    "    ) -> Union[str, List[str]]:\n",
    "        \"\"\"Convert Model outputs to string labels\n",
    "        Args:\n",
    "            encoding: one-hot encoding\n",
    "            thr: threshold for label binarization\n",
    "            label_required: if it is required to return any label and no label is above `thr`, use argmax\n",
    "        \"\"\"\n",
    "        return self.binary_mapping(encoding, self.lut_label, thr=thr, label_required=label_required)\n",
    "\n",
    "    def setup(self, *_, **__) -> None:\n",
    "        \"\"\"Prepare datasets\"\"\"\n",
    "        assert os.path.isdir(self.train_dir), f\"missing folder: {self.train_dir}\"\n",
    "        ds = self.dataset_cls(self.path_csv, self.train_dir, mode = 'train',split=1.0)\n",
    "        self.labels_unique = ds.labels_unique\n",
    "        self.label_histogram = ds.label_histogram\n",
    "        self.lut_label = dict(enumerate(self.labels_unique))\n",
    "\n",
    "        ds_defaults = dict(\n",
    "            df_data=self.path_csv,\n",
    "            path_img_dir=self.train_dir,\n",
    "            split=self.split,\n",
    "            uq_labels=self.labels_unique,\n",
    "        )\n",
    "        self.train_dataset = self.dataset_cls(**ds_defaults, mode='train', transforms=self.train_transforms)\n",
    "        logging.info(f\"training dataset: {len(self.train_dataset)}\")\n",
    "        self.valid_dataset = self.dataset_cls(**ds_defaults, mode='valid', transforms=self.valid_transforms)\n",
    "        logging.info(f\"validation dataset: {len(self.valid_dataset)}\")\n",
    "\n",
    "        if not os.path.isdir(self.test_dir):\n",
    "            return\n",
    "        ls_images = glob.glob(os.path.join(self.test_dir, '*.*'))\n",
    "        ls_images = [os.path.basename(p) for p in ls_images if os.path.splitext(p)[-1] in IMAGE_EXTENSIONS]\n",
    "        self.test_table = [dict(image=n, labels='') for n in ls_images]\n",
    "        self.test_dataset = self.dataset_cls(\n",
    "            df_data=pd.DataFrame(self.test_table),\n",
    "            path_img_dir=self.test_dir,\n",
    "            split=0,\n",
    "            uq_labels=self.labels_unique,\n",
    "            mode='test',\n",
    "            transforms=self.valid_transforms\n",
    "        )\n",
    "        logging.info(f\"test dataset: {len(self.test_dataset)}\")\n",
    "\n",
    "    def _dataloader_extra_args(self, dataset: Pascal2007Dataset) -> dict:\n",
    "        dl_kwargs = dict(shuffle=True)\n",
    "        # if you ask and you have it\n",
    "        if self.balancing and ImbalancedDatasetSampler:\n",
    "            dl_kwargs = dict(\n",
    "                shuffle=False,\n",
    "                sampler=ImbalancedDatasetSampler(\n",
    "                    dataset=dataset,\n",
    "                    callback_get_label=self.dataset_cls.get_sample_pseudo_labels,\n",
    "                )\n",
    "            )\n",
    "        elif self.balancing:\n",
    "            warn('You have asked for `ImbalancedDatasetSampler` but you do not have it installed.')\n",
    "        return dl_kwargs\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        dl_kwargs = self._dataloader_extra_args(self.train_dataset)\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            **dl_kwargs,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.valid_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> Optional[DataLoader]:\n",
    "        if self.test_dataset:\n",
    "            return DataLoader(\n",
    "                self.test_dataset,\n",
    "                batch_size=self.batch_size,\n",
    "                num_workers=0,\n",
    "                shuffle=False,\n",
    "            )\n",
    "        logging.warning('no testing images found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9A2rNuq0BwA"
   },
   "outputs": [],
   "source": [
    "dataset = Pascal2007Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "kDRH3sfl0Bs5",
    "outputId": "f9a2eff3-a0b2-4900-e876-106741562219"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 9), facecolor='white')\n",
    "for i in range(9):\n",
    "    img, lb = dataset[i]\n",
    "    ax = fig.add_subplot(3, 3, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwGiN9FC0BpS"
   },
   "outputs": [],
   "source": [
    "class LitResnet(nn.Module):\n",
    "\n",
    "    def __init__(self, arch: str, pretrained: bool = True, num_classes: int = 6):\n",
    "        super().__init__()\n",
    "        self.arch = arch\n",
    "        self.num_classes = num_classes\n",
    "        self.model = torchvision.models.__dict__[arch](pretrained=pretrained)\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class LitPlantPathology(LightningModule):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: Union[nn.Module, str] = \"ResNet50\",\n",
    "        lr: float = 1e-4,\n",
    "        augmentations: Optional[nn.Module] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if isinstance(model, str):\n",
    "            model = LitResnet(arch=model)\n",
    "        self.model = model\n",
    "        self.arch = model.arch\n",
    "        self.num_classes = model.num_classes\n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.train_precision = torchmetrics.Precision(**self._metrics_extra_args)\n",
    "        self.train_f1_score = torchmetrics.F1(**self._metrics_extra_args)\n",
    "        self.val_accuracy = torchmetrics.Accuracy()\n",
    "        self.val_precision = torchmetrics.Precision(**self._metrics_extra_args)\n",
    "        self.val_f1_score = torchmetrics.F1(**self._metrics_extra_args)\n",
    "        self.learning_rate = lr\n",
    "        self.aug = augmentations\n",
    "\n",
    "    @property\n",
    "    def _metrics_extra_args(self):\n",
    "        return dict()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return F.softmax(self.model(x))\n",
    "\n",
    "    def compute_loss(self, y_hat: Tensor, y: Tensor):\n",
    "        return F.cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        if self.aug:\n",
    "            x = self.aug(x)  # => batched augmentations\n",
    "        y_hat = self(x)\n",
    "        loss = self.compute_loss(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=False)\n",
    "        self.log(\"train_acc\", self.train_accuracy(y_hat, y), prog_bar=False)\n",
    "        self.log(\"train_prec\", self.train_precision(y_hat, y), prog_bar=False)\n",
    "        self.log(\"train_f1\", self.train_f1_score(y_hat, y), prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.compute_loss(y_hat, y)\n",
    "        self.log(\"valid_loss\", loss, prog_bar=False)\n",
    "        self.log(\"valid_acc\", self.val_accuracy(y_hat, y), prog_bar=True)\n",
    "        self.log(\"valid_prec\", self.val_precision(y_hat, y), prog_bar=True)\n",
    "        self.log(\"valid_f1\", self.val_f1_score(y_hat, y), prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, self.trainer.max_epochs, 0)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "\n",
    "class MultiPascal2007(LitPlantPathology):\n",
    "\n",
    "    @property\n",
    "    def _metrics_extra_args(self):\n",
    "        return dict(num_classes=self.num_classes, average='weighted')\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return torch.sigmoid(self.model(x))\n",
    "\n",
    "    def compute_loss(self, y_hat: Tensor, y: Tensor):\n",
    "        return F.binary_cross_entropy_with_logits(y_hat, y.to(y_hat.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5JHEA8u1lew"
   },
   "outputs": [],
   "source": [
    "IMAGE_EXTENSIONS = ('.png', '.jpg', '.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3UxhPPZ1lcB",
    "outputId": "cd8015a5-f61f-4d57-ba41-3381bd99718f"
   },
   "outputs": [],
   "source": [
    "TORCHVISION_TRAIN_TRANSFORM = T.Compose([\n",
    "    T.Resize(size=300, interpolation=Image.BILINEAR),\n",
    "    T.RandomRotation(degrees=30),\n",
    "    T.RandomPerspective(distortion_scale=0.4),\n",
    "    T.RandomResizedCrop(size=224),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(DATASET_IMAGE_MEAN, DATASET_IMAGE_STD),  # custom\n",
    "])\n",
    "#: default validation augmentation\n",
    "TORCHVISION_VALID_TRANSFORM = T.Compose([\n",
    "    T.Resize(size=300, interpolation=Image.BILINEAR),\n",
    "    T.CenterCrop(size=224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(DATASET_IMAGE_MEAN, DATASET_IMAGE_STD),  # custom\n",
    "])\n",
    "\n",
    "\n",
    "class Resize(nn.Module):\n",
    "\n",
    "    def __init__(self, size: int):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return geometry.resize(x[None], self.size)[0]\n",
    "\n",
    "\n",
    "class LitPreprocess(nn.Module):\n",
    "    \"\"\"Applies the processing to the image in the worker before collate.\"\"\"\n",
    "\n",
    "    def __init__(self, img_size: int):\n",
    "        super().__init__()\n",
    "        self.preprocess = nn.Sequential(\n",
    "            Resize((img_size, img_size)),  # use this better to see whole image\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = image_to_tensor(np.array(x)).float() / 255.\n",
    "        assert len(x.shape) == 3, x.shape\n",
    "        out = self.preprocess(x)\n",
    "        return out[0]\n",
    "\n",
    "\n",
    "class LitAugmenter(nn.Module):\n",
    "    \"\"\"Applies random augmentation to a batch of images.\"\"\"\n",
    "\n",
    "    def __init__(self, viz: bool = False):\n",
    "        super().__init__()\n",
    "        self.viz = viz\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        assert len(x.shape) == 4, x.shape\n",
    "        out = x\n",
    "        out = self.augmentations(out)\n",
    "        if self.viz:\n",
    "            out = self.denorm(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "KORNIA_TRAIN_TRANSFORM = LitPreprocess(512)\n",
    "KORNIA_VALID_TRANSFORM = LitPreprocess(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QAa9TB7_1lZR"
   },
   "outputs": [],
   "source": [
    "class PlantPathologyDM(LightningDataModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        path_csv: str = 'train.csv',\n",
    "        base_path: str = '.',\n",
    "        batch_size: int = 32,\n",
    "        num_workers: int = None,\n",
    "        simple: bool = False,\n",
    "        train_transforms=None,\n",
    "        valid_transforms=None,\n",
    "        split: float = 0.8,\n",
    "        balancing: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # path configurations\n",
    "        assert os.path.isdir(base_path), f\"missing folder: {base_path}\"\n",
    "        self.train_dir = os.path.join(base_path, 'train')\n",
    "        self.test_dir = os.path.join(base_path, 'test')\n",
    "\n",
    "        if not os.path.isfile(path_csv):\n",
    "            path_csv = os.path.join(base_path, path_csv)\n",
    "        assert os.path.isfile(path_csv), f\"missing table: {path_csv}\"\n",
    "        self.path_csv = path_csv\n",
    "\n",
    "        # other configs\n",
    "        self.batch_size = batch_size\n",
    "        self.split = split\n",
    "        self.num_workers = num_workers if num_workers is not None else os.cpu_count()\n",
    "        self.labels_unique: Sequence = ...\n",
    "        self.lut_label: Dict = ...\n",
    "        self.label_histogram: Tensor = ...\n",
    "        self.balancing = balancing\n",
    "\n",
    "        # need to be filled in setup()\n",
    "        self.train_dataset = None\n",
    "        self.valid_dataset = None\n",
    "        self.test_table = []\n",
    "        self.test_dataset = None\n",
    "        self.train_transforms = train_transforms or KORNIA_TRAIN_TRANSFORM\n",
    "        self.valid_transforms = valid_transforms or KORNIA_VALID_TRANSFORM\n",
    "        self.dataset_cls: Type = Pascal2007SimpleDataset if simple else Pascal2007Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjOF6-nH1e4Y",
    "outputId": "30894ef7-12ba-4e2c-9017-cfacf7d085e4"
   },
   "outputs": [],
   "source": [
    "dm = Pascal2007DM(\n",
    "    simple = False,\n",
    "    batch_size=98,\n",
    "    train_transforms=TORCHVISION_TRAIN_TRANSFORM,\n",
    "    valid_transforms=TORCHVISION_VALID_TRANSFORM,\n",
    "    split=0.9,\n",
    "    balancing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O028vWFB1zWC",
    "outputId": "cfdd5aee-e8df-4009-f05b-c4adc0fb9423",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdfXgneT0Bme"
   },
   "outputs": [],
   "source": [
    "net = LitResnet(arch='resnext101_32x8d', num_classes=dm.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WByVrwTA2aqA",
    "outputId": "e1748615-2afc-4f6a-b008-cbce6904fd17",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MultiPascal2007(model = net, lr = 6e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1RER7ZXf2alg"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from torchsampler import ImbalancedDatasetSampler\n",
    "except ImportError:\n",
    "    ImbalancedDatasetSampler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580,
     "referenced_widgets": [
      "06e72bc1767047d1bcd9be4cbe2ca8bf",
      "0aa4860b5b8541b9ab22fc8fb8b84080",
      "6b6c84a6753048ca99c1a25771f4db17",
      "e79d1a748ed6467587977d9887db2faf",
      "d160bf3606e34a328f775ef730776b55",
      "ef5f79b39327462cace53d8e6faa968e",
      "85d40e4a88924f7f9a10cd83ddc9906d",
      "6c39638548e64ed8a7ed45b9b5f83652",
      "9e512a789d94462f9e9f224db2b2a44b",
      "7cfee8da26c94e599ecdab77018ff3e7",
      "7375e754526d437b9b70df4c900cbd7c"
     ]
    },
    "id": "QqTiA1sY0BjR",
    "outputId": "b978a641-eb1c-447b-f91e-2a2adc53f92b"
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "print(pl.__version__)\n",
    "\n",
    "logger = pl.loggers.CSVLogger(save_dir='logs/', name=model.arch)\n",
    "swa = pl.callbacks.StochasticWeightAveraging(swa_epoch_start=0.6)\n",
    "ckpt = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='valid_f1',\n",
    "    save_top_k=1,\n",
    "    save_last=True,\n",
    "    # save_weights_only=True,\n",
    "    filename='checkpoint/{epoch:02d}-{valid_acc:.4f}-{valid_f1:.4f}',\n",
    "    # verbose=False,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    # fast_dev_run=True,\n",
    "    gpus=2,\n",
    "    callbacks=[ckpt, swa, MyPrintingCallback()],\n",
    "    logger=logger,\n",
    "    max_epochs=1,\n",
    "    precision=16,\n",
    "    # overfit_batches=5,\n",
    "    auto_lr_find=True,\n",
    "    accumulate_grad_batches=4,\n",
    "    val_check_interval=0.5,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    weights_summary='top',\n",
    ")\n",
    "\n",
    "trainer.fit(model=model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLbf-xsS0BgQ"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfGUKHyw0Bc5"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "class MyPrintingCallback(Callback):\n",
    "    def on_inint_start(self, trainer):\n",
    "        print(\"Bat dau khoi tao trainer\")\n",
    "    \n",
    "    def on_init_end(self, trainer):\n",
    "        print(\"trainer bat dau\")\n",
    "        \n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        print(\"lam gi do den khi traning ket thuc\")\n",
    "        \n",
    "trainner = pl.Trainer(callbacks=[MyPrintingCallback()])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Mycallback(pl.Callback):\n",
    "#     def on_pretrain_routime_stat()\n",
    "#     def on_pretrain_routime_end()\n",
    "#     def on_train_start()\n",
    "#     def on_train_epoch_start()\n",
    "#     def on_tran_batch_start()\n",
    "#     def optimizer_step()\n",
    "#     def on_before_zero_grad()\n",
    "#     def on_train_batch_end()\n",
    "#     def on_validation_epoch_start()\n",
    "#     def on_validatin_batch_start()\n",
    "#     def on_validation_epoch_end()\n",
    "#     def on_train_end()\n",
    "#     def teardown()'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "final_multi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06e72bc1767047d1bcd9be4cbe2ca8bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0aa4860b5b8541b9ab22fc8fb8b84080",
       "IPY_MODEL_6b6c84a6753048ca99c1a25771f4db17",
       "IPY_MODEL_e79d1a748ed6467587977d9887db2faf"
      ],
      "layout": "IPY_MODEL_d160bf3606e34a328f775ef730776b55"
     }
    },
    "0aa4860b5b8541b9ab22fc8fb8b84080": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef5f79b39327462cace53d8e6faa968e",
      "placeholder": "​",
      "style": "IPY_MODEL_85d40e4a88924f7f9a10cd83ddc9906d",
      "value": "Validation sanity check:   0%"
     }
    },
    "6b6c84a6753048ca99c1a25771f4db17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c39638548e64ed8a7ed45b9b5f83652",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e512a789d94462f9e9f224db2b2a44b",
      "value": 0
     }
    },
    "6c39638548e64ed8a7ed45b9b5f83652": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7375e754526d437b9b70df4c900cbd7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7cfee8da26c94e599ecdab77018ff3e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85d40e4a88924f7f9a10cd83ddc9906d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e512a789d94462f9e9f224db2b2a44b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d160bf3606e34a328f775ef730776b55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "e79d1a748ed6467587977d9887db2faf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cfee8da26c94e599ecdab77018ff3e7",
      "placeholder": "​",
      "style": "IPY_MODEL_7375e754526d437b9b70df4c900cbd7c",
      "value": " 0/2 [00:00&lt;?, ?it/s]"
     }
    },
    "ef5f79b39327462cace53d8e6faa968e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
